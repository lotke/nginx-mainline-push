diff -Naur nginx-1.11.3/nginx-push-stream-module/AUTHORS nginx-1.11.3-push/nginx-push-stream-module/AUTHORS
--- nginx-1.11.3/nginx-push-stream-module/AUTHORS	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/AUTHORS	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,2 @@
+Wandenberg Peixoto <wandenberg@gmail.com>
+Rog√©rio Carvalho Schneider <stockrt@gmail.com>
diff -Naur nginx-1.11.3/nginx-push-stream-module/CHANGELOG.textile nginx-1.11.3-push/nginx-push-stream-module/CHANGELOG.textile
--- nginx-1.11.3/nginx-push-stream-module/CHANGELOG.textile	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/CHANGELOG.textile	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,237 @@
+h1(#changelog). Changelog
+
+h2. Version 0.5.1
+
+* Fix websocket handler to avoid read data from connections either closed or with error
+
+h2. Version 0.5.0
+
+* Improvements on pushstream.js
+* Add push_stream_header_template_file directive
+* Fix the support for large messages
+* [performance] Reduce the number of lookups for channels
+* [performance] Use distributed lock instead of only one lock for all operations
+* [performance] Changed the parser of message template to apply it at once
+* Fix buffer usage to avoid them to be overwritten
+
+h2. Version 0.4.1
+
+* Fix to not send a trailing comma on jsonp object
+* Fix pushstream.js log messages when firebug is opened after the page was loaded on Firefox
+* Changed pushstream.js license to MIT
+* Fix DoS on message formatter when text contains huge number of template patterns (Thanks _Buglloc_)
+* Fix send messages through WebSocket connection when the server is using kqueue
+* Ensure all queue members are initialized to not produce errors on calling remove function, without insert them on a queue
+* Fix to be possible compile with clang
+* Fix stuck connections when sending only header responses
+* Fix socket leak on reload process for sockets used in inter process communication and connections
+
+h2. Version 0.4.0
+
+* Added support to use variables as value on push_stream_allowed_origins directive
+* Removed global variables to allow have more than one http block on the same Nginx instance
+* Added initial support to send binary data
+* Added support to get old messages using time and tag to all wrappers on pushstream.js
+* Added push_stream_timeout_with_body directive to indicate whether send a full message on timed out long polling connections, or not
+* Removed default value from push_stream_padding_by_user_agent directive, it was "[A|a]ndroid 2,4097,4097:[S|s]afari,1025,0"
+* Change the publish message action through a WebSocket connection to add the message to all subscribed channels
+* Added support to get channels statistics, delete channels and publish message to some channels specifying their ids on push_stream_channels_path
+* Avoid reapply formatter to header, message or footer template when inside an if on event source mode
+* Added support for OPTIONS method on publisher location
+* Unified longPollingTimeout and timeout configurations on javascript client
+* Renamed some javascript client configurations
+** jsonDataKey -> jsonTextKey
+** longPollingUseJSONP -> useJSONP
+** longPollingTagArgument -> tagArgument
+** longPollingTimeArgument -> timeArgument
+** longPollingByHeaders -> messagesControlByArgument (value must be changed appropriately)
+** reconnecttimeout -> reconnectOnTimeoutInterval
+** checkChannelAvailabilityInterval -> reconnectOnChannelUnavailableInterval
+** secondsAgo -> messagesPublishedAfter
+* Removed some javascript client configurations
+** longPollingInterval
+* Fix lazy reload
+* Normalize use of backtrack, last_event_id and if_modified_since/if_none_match values to get old messages on all subscriber modes
+* Added push_stream_last_event_id directive to make possible pass the Last-Event-Id value without set header
+* Changed push_stream_store_messages directive to make possible set it inside an if block
+* Renamed broadcast feature to wildcard, more adequate with the way it works
+** push_stream_broadcast_channel_prefix -> push_stream_wildcard_channel_prefix
+** push_stream_broadcast_channel_max_qtd -> push_stream_wildcard_channel_max_qtd
+** push_stream_max_number_of_broadcast_channels -> push_stream_max_number_of_wildcard_channels
+* Removed push_stream_content_type directive, use default_type Nginx directive to set the value, except on JSONP and Event Source modes
+* Removed push_stream_keepalive directive, let Nginx decide when to use keepalive and how many requests accept using keepalive_* directives
+* Removed push_stream_shared_memory_cleanup_objects_ttl directive
+* Changed push_stream_websocket directive to be a subtype of push_stream_subscriber directive
+* Changed push_stream_eventsource_support directive to be a subtype of push_stream_subscriber directive
+* Fix to support gzip usage
+* Added the feature to send a custom 'channel delete message' on the body of the DELETE request
+* Removed push_stream_channel_id variable, use the push_stream_channels_path instead of it
+* Changed push_stream_channels_path variable to directive, and make possible set it inside an if block
+* Back to use Nginx chunked filter
+
+h2. Version 0.3.5
+
+* Use JSONP when port numbers don't match.
+* Set expires headers to avoid cache
+* Add push_stream_channel_info_on_publish, push_stream_channel_inactivity_time and push_stream_allowed_origins directives
+* Not sending the access control headers by default, send only when the allowed_origins directive is set, for security reasons
+* Send a ping frame as feedback when publishing a message through WebSocket connection
+* Adding the number of stored messages and the number of channels and messages in the trash to summarized channels statistics
+* Remove default header template for EventSource subscribers
+* Force content type as application/javascript on jsonp requests
+* Simplifying some internal structures
+* Fix memory leak when use the feature of do a DELETE in a channel
+* Fix memory leak which happens after a worker dies or the server receive the SIGHUP (reload) signal (Thanks _Rob Mueller_ , _Bron Gondwana_ , _Andrew Wansink_ and their team)
+* Fix status change notification when the server is stopped on long polling and jsonp modes (Thanks _nickiv_ for bug report on IE)
+* Fix domain set for xss on pushstream.js when domain has more than three parts (Thanks _Sebastien_)
+* Adding function to ensure dates with two digits days on long polling requests (Thanks _Dunaeth_ for bug report on IE)
+* Avoiding unescape of not string messages on pushstream.js (Thanks _karolciba_)
+
+h2. Version 0.3.4
+
+* Improvement on javascript cleanup objects
+* Fixing initial temp pool size
+* Fixing memory leak when recovering channel from trash, the workers_with_subscribers queue was wrongly reinitialized without free the memory on it
+* Changed default value of push_stream_message_ttl to 30 minutes to avoid memory leak of a message which is never discarded
+* Changed javascript configurations to be more flexible
+* Changed JSONP to receive old messages as array
+* Changed channels ids parser for a smarter version, using regular expression
+
+h2. Version 0.3.3
+
+* Adding JSONP support to pushstream.js and dynamically callback parameter
+* Adding event type feature to Event Source support
+* Adding tag and time available at message template, and make possible pass these values without set headers
+* Adding a reference count to the message to avoid discard it before be processed for all workers
+* Adding padding messages based on user agent to bypass some problems on android/safari browsers on long-polling
+* Improvement on memory usage to reuse chains and buffers
+* Improvement on javascript message parser regexp
+* Improvement on sending alert messages to workers only when necessary
+* Improvement on reset ping timer when a message is sent
+* Improvement on disconnect any subscriber which receives a non OK response when writing to its socket
+* Improvement on documentation organization
+* Improvement on preventing XSS when using pushstream.js
+* Fixing memory leak when saving channels on a rbtree with ids which collides, problem inherited from Nginx and reported by Lanshun Zhou
+* Fixing memory leak in javascript
+* Fixing read messages in high throughput using keepalive on
+* Fixing EventSourceWrapper class on pushstream.js to use native reconnection feature from EventSource
+
+h2. Version 0.3.2
+
+* Adding WebSocket support
+* Adding a default header template for EventSource to call _onopen_ callback quickly
+* Adding examples of use for PushStream javascript class
+* Refactor on PushStream javascript class adding support for new protocols
+* Changing etag for messages published in different channels to receive sequential values if they were published on same second
+* Improvement on delete channel removing unnecessary loop
+* Fixing bug on delete channel with long polling subscribers
+
+h2. Version 0.3.1
+
+* Adding _push_stream_longpolling_connection_ttl_ directive to be possible use different values for timeout of stream and long polling subscribers on the same location
+* Adding _push_stream_max_subscribers_per_channel_ directive to limit the number of subscribers per channel
+* Enabling some directives to be used on location context, now this works as expected
+** push_stream_ping_message_interval
+** push_stream_subscriber_connection_ttl
+* Replace ping and disconnect routines by individual timers in each request, it make disconnect timeout more accurate
+* Finalizing failed connections on sending messages or ping to subscribers, it prevent leak of writing connections using HTTPS
+* Fixing delivery message when etag from newer message is lower than an old message
+* Fixing cleanup messages when only use max_messages_stored_per_channel directive
+* Fixing bug on ping and disconnect timers behavior when working with long polling subscribers
+* Fixing bug on init and exit worker to execute module code only on SINGLE or WORKER process, to be possible use the module and proxy cache on the same nginx
+
+h2. Version 0.3.0
+
+* Adding Event Source support
+* Adding Polling support
+* Adding Long Polling support
+* Moving some directives to be used on http context instead of location
+** push_stream_min_message_buffer_timeout
+** push_stream_max_message_buffer_length
+** push_stream_max_channel_id_length
+** push_stream_ping_message_interval
+** push_stream_subscriber_connection_timeout
+** push_stream_broadcast_channel_prefix
+** push_stream_max_number_of_channels
+** push_stream_max_number_of_broadcast_channels
+* Renaming some directives
+** push_stream_max_reserved_memory -> push_stream_shared_memory_size
+** push_stream_memory_cleanup_timeout -> push_stream_shared_memory_cleanup_objects_ttl
+** push_stream_min_message_buffer_timeout -> push_stream_message_ttl
+** push_stream_max_message_buffer_length -> push_stream_max_messages_stored_per_channel
+** push_stream_subscriber_connection_timeout -> push_stream_subscriber_connection_ttl
+
+h2. Version 0.2.7
+
+* Adding uptime information for server and workers on statistics
+* Avoiding counters to overlap on decrement
+
+h2. Version 0.2.6
+
+* Adding directive push_stream_footer_template to send a text to subscriber before close connection (channel delete or subscriber timeout)
+* Adding support to retrieve old messages using If-Modified-Since header
+* Fixing bug on some points which does not check if alloc memory was done successful
+* Fixing bug on PushStream.js to work on Internet Explorer 9
+
+h2. Version 0.2.5
+
+* Adding directives to change text for channel deleted and ping messages
+* Adding feature to get channels statistics by prefix (Suggested by Alexey Vdovin)
+* Adding publisher administrator feature to delete channels (Suggested by Alexey Vdovin)
+* Fixing bug which removed default message template
+* Fixing messages sent to subscribers to be a truly transfer encoding chunked connection
+* Removing support for versions 0.7.x
+* Removing hack to keep connection open (Thanks _Maxim Dounin_)
+
+h2. Version 0.2.4
+
+* Adding keepalive support
+* Fixing bug when reloading nginx configuration file (Thanks _Rob Mueller_ for bug report)
+
+h2. Version 0.2.3
+
+* Fixing bug to accept different message templates on different subscriber locations (Now you CAN remove push_stream_message_template directive from publisher location, it will not be used there)
+* Fixing bug on publisher which let too many open connections with fast publishers on some nginx versions
+* Fixing bug of segfault when the module is part of nginx but not in use (Thanks _Rob Mueller_ for bug report)
+* Fixing bug when store message is off, memory of messages was not free after sent to subscribers
+
+h2. Version 0.2.2
+
+* Fixing bug when apply message and channel name to template with values containing the same template pattern, could result in 100% of memory and CPU consumption, by recursion
+* Fixing bug when manipulating a channel which was removed from tree for another worker (the 100% CPU bug)
+* Fixing memory allocation for channel id
+* Fixing response for detailed channels statistics when have a big number of channels
+* Creating different timers to clear the memory, one for expired messages and another for empty channels
+* Disable Nginx chunked filter for module locations
+
+h2. Version 0.2.1
+
+* Fixing bug on return for publisher, was rejecting the message for some clients
+* Fixing bug on allocation memory of ngx_str_t variables to ensure that has a char \0 at the end of each of them
+* Adding instruction to discard body, to release the connection as soon as possible
+* Adding license information
+* Organizing test suite
+
+h2. Version 0.2.0
+
+* Fixing bugs on release shared memory
+* Fixing bug on receive POST with empty message
+* Adding a different location to get channels statistics *push_stream_channels_statistics*
+* Adding new directives push_stream_max_number_of_channels, push_stream_max_number_of_broadcast_channels and push_stream_memory_cleanup_timeout
+* Removed support to PUT and DELETE http methods on publisher location
+* Removed different types of return on publishing messages in case that was published on a empty channel or on one which has subscribers
+* Removed directive push_stream_subscriber_disconnect_interval, this interval is calculate based on push_stream_subscriber_connection_timeout
+* Removed directive push_stream_min_message_buffer_length
+* Change default values of some directives
+
+(head). | directive | old value | new value |
+|push_stream_min_message_buffer_timeout|7200 seconds|_unset_|
+|push_stream_max_message_buffer_length|10|_unset_|
+|push_stream_authorized_channels_only|on|off|
+|push_stream_store_messages|on|off|
+|push_stream_max_channel_id_length|1024 bytes|_unset_|
+|push_stream_broadcast_channel_max_qtd|1|_unset_|
+
+h2. Version 0.1.0
+
+Initial version of this module was based on "pushmodule":http://pushmodule.slact.net
diff -Naur nginx-1.11.3/nginx-push-stream-module/config nginx-1.11.3-push/nginx-push-stream-module/config
--- nginx-1.11.3/nginx-push-stream-module/config	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/config	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,20 @@
+ngx_addon_name=ngx_http_push_stream_module
+CORE_INCS="$CORE_INCS ${ngx_addon_dir}/src ${ngx_addon_dir}/include"
+
+if test -n "$ngx_module_link"; then
+    ngx_module_type=HTTP
+    ngx_module_name=${ngx_addon_name}
+    ngx_module_srcs="${ngx_addon_dir}/src/${ngx_addon_name}.c"
+
+    . auto/module
+else
+    HTTP_MODULES="$HTTP_MODULES ${ngx_addon_name}"
+    NGX_ADDON_SRCS="$NGX_ADDON_SRCS ${ngx_addon_dir}/src/${ngx_addon_name}.c"
+fi
+
+have=NGX_HTTP_HEADERS . auto/have
+. auto/feature
+
+#if not have sha1 or do not want to use WebSocket comment the lines bellow
+USE_SHA1=YES
+have=NGX_HAVE_SHA1 . auto/have
diff -Naur nginx-1.11.3/nginx-push-stream-module/COPYING nginx-1.11.3-push/nginx-push-stream-module/COPYING
--- nginx-1.11.3/nginx-push-stream-module/COPYING	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/COPYING	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,674 @@
+                    GNU GENERAL PUBLIC LICENSE
+                       Version 3, 29 June 2007
+
+ Copyright (C) 2007 Free Software Foundation, Inc. <http://fsf.org/>
+ Everyone is permitted to copy and distribute verbatim copies
+ of this license document, but changing it is not allowed.
+
+                            Preamble
+
+  The GNU General Public License is a free, copyleft license for
+software and other kinds of works.
+
+  The licenses for most software and other practical works are designed
+to take away your freedom to share and change the works.  By contrast,
+the GNU General Public License is intended to guarantee your freedom to
+share and change all versions of a program--to make sure it remains free
+software for all its users.  We, the Free Software Foundation, use the
+GNU General Public License for most of our software; it applies also to
+any other work released this way by its authors.  You can apply it to
+your programs, too.
+
+  When we speak of free software, we are referring to freedom, not
+price.  Our General Public Licenses are designed to make sure that you
+have the freedom to distribute copies of free software (and charge for
+them if you wish), that you receive source code or can get it if you
+want it, that you can change the software or use pieces of it in new
+free programs, and that you know you can do these things.
+
+  To protect your rights, we need to prevent others from denying you
+these rights or asking you to surrender the rights.  Therefore, you have
+certain responsibilities if you distribute copies of the software, or if
+you modify it: responsibilities to respect the freedom of others.
+
+  For example, if you distribute copies of such a program, whether
+gratis or for a fee, you must pass on to the recipients the same
+freedoms that you received.  You must make sure that they, too, receive
+or can get the source code.  And you must show them these terms so they
+know their rights.
+
+  Developers that use the GNU GPL protect your rights with two steps:
+(1) assert copyright on the software, and (2) offer you this License
+giving you legal permission to copy, distribute and/or modify it.
+
+  For the developers' and authors' protection, the GPL clearly explains
+that there is no warranty for this free software.  For both users' and
+authors' sake, the GPL requires that modified versions be marked as
+changed, so that their problems will not be attributed erroneously to
+authors of previous versions.
+
+  Some devices are designed to deny users access to install or run
+modified versions of the software inside them, although the manufacturer
+can do so.  This is fundamentally incompatible with the aim of
+protecting users' freedom to change the software.  The systematic
+pattern of such abuse occurs in the area of products for individuals to
+use, which is precisely where it is most unacceptable.  Therefore, we
+have designed this version of the GPL to prohibit the practice for those
+products.  If such problems arise substantially in other domains, we
+stand ready to extend this provision to those domains in future versions
+of the GPL, as needed to protect the freedom of users.
+
+  Finally, every program is threatened constantly by software patents.
+States should not allow patents to restrict development and use of
+software on general-purpose computers, but in those that do, we wish to
+avoid the special danger that patents applied to a free program could
+make it effectively proprietary.  To prevent this, the GPL assures that
+patents cannot be used to render the program non-free.
+
+  The precise terms and conditions for copying, distribution and
+modification follow.
+
+                       TERMS AND CONDITIONS
+
+  0. Definitions.
+
+  "This License" refers to version 3 of the GNU General Public License.
+
+  "Copyright" also means copyright-like laws that apply to other kinds of
+works, such as semiconductor masks.
+
+  "The Program" refers to any copyrightable work licensed under this
+License.  Each licensee is addressed as "you".  "Licensees" and
+"recipients" may be individuals or organizations.
+
+  To "modify" a work means to copy from or adapt all or part of the work
+in a fashion requiring copyright permission, other than the making of an
+exact copy.  The resulting work is called a "modified version" of the
+earlier work or a work "based on" the earlier work.
+
+  A "covered work" means either the unmodified Program or a work based
+on the Program.
+
+  To "propagate" a work means to do anything with it that, without
+permission, would make you directly or secondarily liable for
+infringement under applicable copyright law, except executing it on a
+computer or modifying a private copy.  Propagation includes copying,
+distribution (with or without modification), making available to the
+public, and in some countries other activities as well.
+
+  To "convey" a work means any kind of propagation that enables other
+parties to make or receive copies.  Mere interaction with a user through
+a computer network, with no transfer of a copy, is not conveying.
+
+  An interactive user interface displays "Appropriate Legal Notices"
+to the extent that it includes a convenient and prominently visible
+feature that (1) displays an appropriate copyright notice, and (2)
+tells the user that there is no warranty for the work (except to the
+extent that warranties are provided), that licensees may convey the
+work under this License, and how to view a copy of this License.  If
+the interface presents a list of user commands or options, such as a
+menu, a prominent item in the list meets this criterion.
+
+  1. Source Code.
+
+  The "source code" for a work means the preferred form of the work
+for making modifications to it.  "Object code" means any non-source
+form of a work.
+
+  A "Standard Interface" means an interface that either is an official
+standard defined by a recognized standards body, or, in the case of
+interfaces specified for a particular programming language, one that
+is widely used among developers working in that language.
+
+  The "System Libraries" of an executable work include anything, other
+than the work as a whole, that (a) is included in the normal form of
+packaging a Major Component, but which is not part of that Major
+Component, and (b) serves only to enable use of the work with that
+Major Component, or to implement a Standard Interface for which an
+implementation is available to the public in source code form.  A
+"Major Component", in this context, means a major essential component
+(kernel, window system, and so on) of the specific operating system
+(if any) on which the executable work runs, or a compiler used to
+produce the work, or an object code interpreter used to run it.
+
+  The "Corresponding Source" for a work in object code form means all
+the source code needed to generate, install, and (for an executable
+work) run the object code and to modify the work, including scripts to
+control those activities.  However, it does not include the work's
+System Libraries, or general-purpose tools or generally available free
+programs which are used unmodified in performing those activities but
+which are not part of the work.  For example, Corresponding Source
+includes interface definition files associated with source files for
+the work, and the source code for shared libraries and dynamically
+linked subprograms that the work is specifically designed to require,
+such as by intimate data communication or control flow between those
+subprograms and other parts of the work.
+
+  The Corresponding Source need not include anything that users
+can regenerate automatically from other parts of the Corresponding
+Source.
+
+  The Corresponding Source for a work in source code form is that
+same work.
+
+  2. Basic Permissions.
+
+  All rights granted under this License are granted for the term of
+copyright on the Program, and are irrevocable provided the stated
+conditions are met.  This License explicitly affirms your unlimited
+permission to run the unmodified Program.  The output from running a
+covered work is covered by this License only if the output, given its
+content, constitutes a covered work.  This License acknowledges your
+rights of fair use or other equivalent, as provided by copyright law.
+
+  You may make, run and propagate covered works that you do not
+convey, without conditions so long as your license otherwise remains
+in force.  You may convey covered works to others for the sole purpose
+of having them make modifications exclusively for you, or provide you
+with facilities for running those works, provided that you comply with
+the terms of this License in conveying all material for which you do
+not control copyright.  Those thus making or running the covered works
+for you must do so exclusively on your behalf, under your direction
+and control, on terms that prohibit them from making any copies of
+your copyrighted material outside their relationship with you.
+
+  Conveying under any other circumstances is permitted solely under
+the conditions stated below.  Sublicensing is not allowed; section 10
+makes it unnecessary.
+
+  3. Protecting Users' Legal Rights From Anti-Circumvention Law.
+
+  No covered work shall be deemed part of an effective technological
+measure under any applicable law fulfilling obligations under article
+11 of the WIPO copyright treaty adopted on 20 December 1996, or
+similar laws prohibiting or restricting circumvention of such
+measures.
+
+  When you convey a covered work, you waive any legal power to forbid
+circumvention of technological measures to the extent such circumvention
+is effected by exercising rights under this License with respect to
+the covered work, and you disclaim any intention to limit operation or
+modification of the work as a means of enforcing, against the work's
+users, your or third parties' legal rights to forbid circumvention of
+technological measures.
+
+  4. Conveying Verbatim Copies.
+
+  You may convey verbatim copies of the Program's source code as you
+receive it, in any medium, provided that you conspicuously and
+appropriately publish on each copy an appropriate copyright notice;
+keep intact all notices stating that this License and any
+non-permissive terms added in accord with section 7 apply to the code;
+keep intact all notices of the absence of any warranty; and give all
+recipients a copy of this License along with the Program.
+
+  You may charge any price or no price for each copy that you convey,
+and you may offer support or warranty protection for a fee.
+
+  5. Conveying Modified Source Versions.
+
+  You may convey a work based on the Program, or the modifications to
+produce it from the Program, in the form of source code under the
+terms of section 4, provided that you also meet all of these conditions:
+
+    a) The work must carry prominent notices stating that you modified
+    it, and giving a relevant date.
+
+    b) The work must carry prominent notices stating that it is
+    released under this License and any conditions added under section
+    7.  This requirement modifies the requirement in section 4 to
+    "keep intact all notices".
+
+    c) You must license the entire work, as a whole, under this
+    License to anyone who comes into possession of a copy.  This
+    License will therefore apply, along with any applicable section 7
+    additional terms, to the whole of the work, and all its parts,
+    regardless of how they are packaged.  This License gives no
+    permission to license the work in any other way, but it does not
+    invalidate such permission if you have separately received it.
+
+    d) If the work has interactive user interfaces, each must display
+    Appropriate Legal Notices; however, if the Program has interactive
+    interfaces that do not display Appropriate Legal Notices, your
+    work need not make them do so.
+
+  A compilation of a covered work with other separate and independent
+works, which are not by their nature extensions of the covered work,
+and which are not combined with it such as to form a larger program,
+in or on a volume of a storage or distribution medium, is called an
+"aggregate" if the compilation and its resulting copyright are not
+used to limit the access or legal rights of the compilation's users
+beyond what the individual works permit.  Inclusion of a covered work
+in an aggregate does not cause this License to apply to the other
+parts of the aggregate.
+
+  6. Conveying Non-Source Forms.
+
+  You may convey a covered work in object code form under the terms
+of sections 4 and 5, provided that you also convey the
+machine-readable Corresponding Source under the terms of this License,
+in one of these ways:
+
+    a) Convey the object code in, or embodied in, a physical product
+    (including a physical distribution medium), accompanied by the
+    Corresponding Source fixed on a durable physical medium
+    customarily used for software interchange.
+
+    b) Convey the object code in, or embodied in, a physical product
+    (including a physical distribution medium), accompanied by a
+    written offer, valid for at least three years and valid for as
+    long as you offer spare parts or customer support for that product
+    model, to give anyone who possesses the object code either (1) a
+    copy of the Corresponding Source for all the software in the
+    product that is covered by this License, on a durable physical
+    medium customarily used for software interchange, for a price no
+    more than your reasonable cost of physically performing this
+    conveying of source, or (2) access to copy the
+    Corresponding Source from a network server at no charge.
+
+    c) Convey individual copies of the object code with a copy of the
+    written offer to provide the Corresponding Source.  This
+    alternative is allowed only occasionally and noncommercially, and
+    only if you received the object code with such an offer, in accord
+    with subsection 6b.
+
+    d) Convey the object code by offering access from a designated
+    place (gratis or for a charge), and offer equivalent access to the
+    Corresponding Source in the same way through the same place at no
+    further charge.  You need not require recipients to copy the
+    Corresponding Source along with the object code.  If the place to
+    copy the object code is a network server, the Corresponding Source
+    may be on a different server (operated by you or a third party)
+    that supports equivalent copying facilities, provided you maintain
+    clear directions next to the object code saying where to find the
+    Corresponding Source.  Regardless of what server hosts the
+    Corresponding Source, you remain obligated to ensure that it is
+    available for as long as needed to satisfy these requirements.
+
+    e) Convey the object code using peer-to-peer transmission, provided
+    you inform other peers where the object code and Corresponding
+    Source of the work are being offered to the general public at no
+    charge under subsection 6d.
+
+  A separable portion of the object code, whose source code is excluded
+from the Corresponding Source as a System Library, need not be
+included in conveying the object code work.
+
+  A "User Product" is either (1) a "consumer product", which means any
+tangible personal property which is normally used for personal, family,
+or household purposes, or (2) anything designed or sold for incorporation
+into a dwelling.  In determining whether a product is a consumer product,
+doubtful cases shall be resolved in favor of coverage.  For a particular
+product received by a particular user, "normally used" refers to a
+typical or common use of that class of product, regardless of the status
+of the particular user or of the way in which the particular user
+actually uses, or expects or is expected to use, the product.  A product
+is a consumer product regardless of whether the product has substantial
+commercial, industrial or non-consumer uses, unless such uses represent
+the only significant mode of use of the product.
+
+  "Installation Information" for a User Product means any methods,
+procedures, authorization keys, or other information required to install
+and execute modified versions of a covered work in that User Product from
+a modified version of its Corresponding Source.  The information must
+suffice to ensure that the continued functioning of the modified object
+code is in no case prevented or interfered with solely because
+modification has been made.
+
+  If you convey an object code work under this section in, or with, or
+specifically for use in, a User Product, and the conveying occurs as
+part of a transaction in which the right of possession and use of the
+User Product is transferred to the recipient in perpetuity or for a
+fixed term (regardless of how the transaction is characterized), the
+Corresponding Source conveyed under this section must be accompanied
+by the Installation Information.  But this requirement does not apply
+if neither you nor any third party retains the ability to install
+modified object code on the User Product (for example, the work has
+been installed in ROM).
+
+  The requirement to provide Installation Information does not include a
+requirement to continue to provide support service, warranty, or updates
+for a work that has been modified or installed by the recipient, or for
+the User Product in which it has been modified or installed.  Access to a
+network may be denied when the modification itself materially and
+adversely affects the operation of the network or violates the rules and
+protocols for communication across the network.
+
+  Corresponding Source conveyed, and Installation Information provided,
+in accord with this section must be in a format that is publicly
+documented (and with an implementation available to the public in
+source code form), and must require no special password or key for
+unpacking, reading or copying.
+
+  7. Additional Terms.
+
+  "Additional permissions" are terms that supplement the terms of this
+License by making exceptions from one or more of its conditions.
+Additional permissions that are applicable to the entire Program shall
+be treated as though they were included in this License, to the extent
+that they are valid under applicable law.  If additional permissions
+apply only to part of the Program, that part may be used separately
+under those permissions, but the entire Program remains governed by
+this License without regard to the additional permissions.
+
+  When you convey a copy of a covered work, you may at your option
+remove any additional permissions from that copy, or from any part of
+it.  (Additional permissions may be written to require their own
+removal in certain cases when you modify the work.)  You may place
+additional permissions on material, added by you to a covered work,
+for which you have or can give appropriate copyright permission.
+
+  Notwithstanding any other provision of this License, for material you
+add to a covered work, you may (if authorized by the copyright holders of
+that material) supplement the terms of this License with terms:
+
+    a) Disclaiming warranty or limiting liability differently from the
+    terms of sections 15 and 16 of this License; or
+
+    b) Requiring preservation of specified reasonable legal notices or
+    author attributions in that material or in the Appropriate Legal
+    Notices displayed by works containing it; or
+
+    c) Prohibiting misrepresentation of the origin of that material, or
+    requiring that modified versions of such material be marked in
+    reasonable ways as different from the original version; or
+
+    d) Limiting the use for publicity purposes of names of licensors or
+    authors of the material; or
+
+    e) Declining to grant rights under trademark law for use of some
+    trade names, trademarks, or service marks; or
+
+    f) Requiring indemnification of licensors and authors of that
+    material by anyone who conveys the material (or modified versions of
+    it) with contractual assumptions of liability to the recipient, for
+    any liability that these contractual assumptions directly impose on
+    those licensors and authors.
+
+  All other non-permissive additional terms are considered "further
+restrictions" within the meaning of section 10.  If the Program as you
+received it, or any part of it, contains a notice stating that it is
+governed by this License along with a term that is a further
+restriction, you may remove that term.  If a license document contains
+a further restriction but permits relicensing or conveying under this
+License, you may add to a covered work material governed by the terms
+of that license document, provided that the further restriction does
+not survive such relicensing or conveying.
+
+  If you add terms to a covered work in accord with this section, you
+must place, in the relevant source files, a statement of the
+additional terms that apply to those files, or a notice indicating
+where to find the applicable terms.
+
+  Additional terms, permissive or non-permissive, may be stated in the
+form of a separately written license, or stated as exceptions;
+the above requirements apply either way.
+
+  8. Termination.
+
+  You may not propagate or modify a covered work except as expressly
+provided under this License.  Any attempt otherwise to propagate or
+modify it is void, and will automatically terminate your rights under
+this License (including any patent licenses granted under the third
+paragraph of section 11).
+
+  However, if you cease all violation of this License, then your
+license from a particular copyright holder is reinstated (a)
+provisionally, unless and until the copyright holder explicitly and
+finally terminates your license, and (b) permanently, if the copyright
+holder fails to notify you of the violation by some reasonable means
+prior to 60 days after the cessation.
+
+  Moreover, your license from a particular copyright holder is
+reinstated permanently if the copyright holder notifies you of the
+violation by some reasonable means, this is the first time you have
+received notice of violation of this License (for any work) from that
+copyright holder, and you cure the violation prior to 30 days after
+your receipt of the notice.
+
+  Termination of your rights under this section does not terminate the
+licenses of parties who have received copies or rights from you under
+this License.  If your rights have been terminated and not permanently
+reinstated, you do not qualify to receive new licenses for the same
+material under section 10.
+
+  9. Acceptance Not Required for Having Copies.
+
+  You are not required to accept this License in order to receive or
+run a copy of the Program.  Ancillary propagation of a covered work
+occurring solely as a consequence of using peer-to-peer transmission
+to receive a copy likewise does not require acceptance.  However,
+nothing other than this License grants you permission to propagate or
+modify any covered work.  These actions infringe copyright if you do
+not accept this License.  Therefore, by modifying or propagating a
+covered work, you indicate your acceptance of this License to do so.
+
+  10. Automatic Licensing of Downstream Recipients.
+
+  Each time you convey a covered work, the recipient automatically
+receives a license from the original licensors, to run, modify and
+propagate that work, subject to this License.  You are not responsible
+for enforcing compliance by third parties with this License.
+
+  An "entity transaction" is a transaction transferring control of an
+organization, or substantially all assets of one, or subdividing an
+organization, or merging organizations.  If propagation of a covered
+work results from an entity transaction, each party to that
+transaction who receives a copy of the work also receives whatever
+licenses to the work the party's predecessor in interest had or could
+give under the previous paragraph, plus a right to possession of the
+Corresponding Source of the work from the predecessor in interest, if
+the predecessor has it or can get it with reasonable efforts.
+
+  You may not impose any further restrictions on the exercise of the
+rights granted or affirmed under this License.  For example, you may
+not impose a license fee, royalty, or other charge for exercise of
+rights granted under this License, and you may not initiate litigation
+(including a cross-claim or counterclaim in a lawsuit) alleging that
+any patent claim is infringed by making, using, selling, offering for
+sale, or importing the Program or any portion of it.
+
+  11. Patents.
+
+  A "contributor" is a copyright holder who authorizes use under this
+License of the Program or a work on which the Program is based.  The
+work thus licensed is called the contributor's "contributor version".
+
+  A contributor's "essential patent claims" are all patent claims
+owned or controlled by the contributor, whether already acquired or
+hereafter acquired, that would be infringed by some manner, permitted
+by this License, of making, using, or selling its contributor version,
+but do not include claims that would be infringed only as a
+consequence of further modification of the contributor version.  For
+purposes of this definition, "control" includes the right to grant
+patent sublicenses in a manner consistent with the requirements of
+this License.
+
+  Each contributor grants you a non-exclusive, worldwide, royalty-free
+patent license under the contributor's essential patent claims, to
+make, use, sell, offer for sale, import and otherwise run, modify and
+propagate the contents of its contributor version.
+
+  In the following three paragraphs, a "patent license" is any express
+agreement or commitment, however denominated, not to enforce a patent
+(such as an express permission to practice a patent or covenant not to
+sue for patent infringement).  To "grant" such a patent license to a
+party means to make such an agreement or commitment not to enforce a
+patent against the party.
+
+  If you convey a covered work, knowingly relying on a patent license,
+and the Corresponding Source of the work is not available for anyone
+to copy, free of charge and under the terms of this License, through a
+publicly available network server or other readily accessible means,
+then you must either (1) cause the Corresponding Source to be so
+available, or (2) arrange to deprive yourself of the benefit of the
+patent license for this particular work, or (3) arrange, in a manner
+consistent with the requirements of this License, to extend the patent
+license to downstream recipients.  "Knowingly relying" means you have
+actual knowledge that, but for the patent license, your conveying the
+covered work in a country, or your recipient's use of the covered work
+in a country, would infringe one or more identifiable patents in that
+country that you have reason to believe are valid.
+
+  If, pursuant to or in connection with a single transaction or
+arrangement, you convey, or propagate by procuring conveyance of, a
+covered work, and grant a patent license to some of the parties
+receiving the covered work authorizing them to use, propagate, modify
+or convey a specific copy of the covered work, then the patent license
+you grant is automatically extended to all recipients of the covered
+work and works based on it.
+
+  A patent license is "discriminatory" if it does not include within
+the scope of its coverage, prohibits the exercise of, or is
+conditioned on the non-exercise of one or more of the rights that are
+specifically granted under this License.  You may not convey a covered
+work if you are a party to an arrangement with a third party that is
+in the business of distributing software, under which you make payment
+to the third party based on the extent of your activity of conveying
+the work, and under which the third party grants, to any of the
+parties who would receive the covered work from you, a discriminatory
+patent license (a) in connection with copies of the covered work
+conveyed by you (or copies made from those copies), or (b) primarily
+for and in connection with specific products or compilations that
+contain the covered work, unless you entered into that arrangement,
+or that patent license was granted, prior to 28 March 2007.
+
+  Nothing in this License shall be construed as excluding or limiting
+any implied license or other defenses to infringement that may
+otherwise be available to you under applicable patent law.
+
+  12. No Surrender of Others' Freedom.
+
+  If conditions are imposed on you (whether by court order, agreement or
+otherwise) that contradict the conditions of this License, they do not
+excuse you from the conditions of this License.  If you cannot convey a
+covered work so as to satisfy simultaneously your obligations under this
+License and any other pertinent obligations, then as a consequence you may
+not convey it at all.  For example, if you agree to terms that obligate you
+to collect a royalty for further conveying from those to whom you convey
+the Program, the only way you could satisfy both those terms and this
+License would be to refrain entirely from conveying the Program.
+
+  13. Use with the GNU Affero General Public License.
+
+  Notwithstanding any other provision of this License, you have
+permission to link or combine any covered work with a work licensed
+under version 3 of the GNU Affero General Public License into a single
+combined work, and to convey the resulting work.  The terms of this
+License will continue to apply to the part which is the covered work,
+but the special requirements of the GNU Affero General Public License,
+section 13, concerning interaction through a network will apply to the
+combination as such.
+
+  14. Revised Versions of this License.
+
+  The Free Software Foundation may publish revised and/or new versions of
+the GNU General Public License from time to time.  Such new versions will
+be similar in spirit to the present version, but may differ in detail to
+address new problems or concerns.
+
+  Each version is given a distinguishing version number.  If the
+Program specifies that a certain numbered version of the GNU General
+Public License "or any later version" applies to it, you have the
+option of following the terms and conditions either of that numbered
+version or of any later version published by the Free Software
+Foundation.  If the Program does not specify a version number of the
+GNU General Public License, you may choose any version ever published
+by the Free Software Foundation.
+
+  If the Program specifies that a proxy can decide which future
+versions of the GNU General Public License can be used, that proxy's
+public statement of acceptance of a version permanently authorizes you
+to choose that version for the Program.
+
+  Later license versions may give you additional or different
+permissions.  However, no additional obligations are imposed on any
+author or copyright holder as a result of your choosing to follow a
+later version.
+
+  15. Disclaimer of Warranty.
+
+  THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BY
+APPLICABLE LAW.  EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHT
+HOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM "AS IS" WITHOUT WARRANTY
+OF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO,
+THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
+PURPOSE.  THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAM
+IS WITH YOU.  SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF
+ALL NECESSARY SERVICING, REPAIR OR CORRECTION.
+
+  16. Limitation of Liability.
+
+  IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING
+WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR CONVEYS
+THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANY
+GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THE
+USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OF
+DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRD
+PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS),
+EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OF
+SUCH DAMAGES.
+
+  17. Interpretation of Sections 15 and 16.
+
+  If the disclaimer of warranty and limitation of liability provided
+above cannot be given local legal effect according to their terms,
+reviewing courts shall apply local law that most closely approximates
+an absolute waiver of all civil liability in connection with the
+Program, unless a warranty or assumption of liability accompanies a
+copy of the Program in return for a fee.
+
+                     END OF TERMS AND CONDITIONS
+
+            How to Apply These Terms to Your New Programs
+
+  If you develop a new program, and you want it to be of the greatest
+possible use to the public, the best way to achieve this is to make it
+free software which everyone can redistribute and change under these terms.
+
+  To do so, attach the following notices to the program.  It is safest
+to attach them to the start of each source file to most effectively
+state the exclusion of warranty; and each file should have at least
+the "copyright" line and a pointer to where the full notice is found.
+
+    <one line to give the program's name and a brief idea of what it does.>
+    Copyright (C) <year>  <name of author>
+
+    This program is free software: you can redistribute it and/or modify
+    it under the terms of the GNU General Public License as published by
+    the Free Software Foundation, either version 3 of the License, or
+    (at your option) any later version.
+
+    This program is distributed in the hope that it will be useful,
+    but WITHOUT ANY WARRANTY; without even the implied warranty of
+    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+    GNU General Public License for more details.
+
+    You should have received a copy of the GNU General Public License
+    along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+Also add information on how to contact you by electronic and paper mail.
+
+  If the program does terminal interaction, make it output a short
+notice like this when it starts in an interactive mode:
+
+    <program>  Copyright (C) <year>  <name of author>
+    This program comes with ABSOLUTELY NO WARRANTY; for details type `show w'.
+    This is free software, and you are welcome to redistribute it
+    under certain conditions; type `show c' for details.
+
+The hypothetical commands `show w' and `show c' should show the appropriate
+parts of the General Public License.  Of course, your program's commands
+might be different; for a GUI interface, you would use an "about box".
+
+  You should also get your employer (if you work as a programmer) or school,
+if any, to sign a "copyright disclaimer" for the program, if necessary.
+For more information on this, and how to apply and follow the GNU GPL, see
+<http://www.gnu.org/licenses/>.
+
+  The GNU General Public License does not permit incorporating your program
+into proprietary programs.  If your program is a subroutine library, you
+may consider it more useful to permit linking proprietary applications with
+the library.  If this is what you want to do, use the GNU Lesser General
+Public License instead of this License.  But first, please read
+<http://www.gnu.org/philosophy/why-not-lgpl.html>.
diff -Naur nginx-1.11.3/nginx-push-stream-module/docs/directives/channels_statistics.textile nginx-1.11.3-push/nginx-push-stream-module/docs/directives/channels_statistics.textile
--- nginx-1.11.3/nginx-push-stream-module/docs/directives/channels_statistics.textile	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/docs/directives/channels_statistics.textile	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,32 @@
+h1(#channels_statistic). Channel Statistics Configuration
+
+h2(#push_stream_channels_statistics). push_stream_channels_statistics <a name="push_stream_channels_statistics" href="#">&nbsp;</a>
+
+*syntax:* _push_stream_channels_statistics_
+
+*context:* _location_
+
+*release version:* _0.2.0_
+
+Defines a location as a source of statistics. You can use this location to get statistics about a specific, group or all channels, in a resumed or summarized way.
+To get statistics about:
+- all channels in a summarized way, you have to make a GET in this location without specify a name in the push_stream_channels_path directive.
+- all channels in a detailed way, you have to specify "ALL" in the push_stream_channels_path.
+- prefixed channels in a detailed way, you have to specify "_prefix_ *" in the push_stream_channels_path.
+- a channel, you have to specify the name in the push_stream_channels_path.
+- some channels, you have to specify their names in the push_stream_channels_path.
+
+You can get statistics in the formats plain, xml, yaml and json. The default is json, to change this behavior you can use *Accept* header parameter passing values like "text/plain", "application/xml", "application/yaml" and "application/json" respectively.
+
+<pre>
+  location /channels-stats {
+      push_stream_channels_statistics;
+      push_stream_channels_path               $arg_id;
+  }
+
+  # /channels-stats -> get statistics about all channels in a summarized way
+  # /channels-stats?id=ALL -> get statistics about all channels in a detailed way
+  # /channels-stats?id=channel_* -> get statistics about all channels which starts with 'channel_'
+  # /channels-stats?id=channel_id -> get statistics about a channel
+  # /channels-stats?id=channel_id_1/channel_id_5 -> get statistics about some channels
+</pre>
diff -Naur nginx-1.11.3/nginx-push-stream-module/docs/directives/main.textile nginx-1.11.3-push/nginx-push-stream-module/docs/directives/main.textile
--- nginx-1.11.3/nginx-push-stream-module/docs/directives/main.textile	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/docs/directives/main.textile	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,158 @@
+h1(#main_configuration). Main Configuration
+
+h2(#push_stream_shared_memory_size). push_stream_shared_memory_size <a name="push_stream_shared_memory_size" href="#">&nbsp;</a>
+
+*syntax:* _push_stream_shared_memory_size size [name]_
+
+*default:* _none_
+
+*context:* _http_
+
+The size of the memory chunk this module will use to store published messages, channels and other shared structures.
+When this memory is full any new request for publish a message or subscribe a channel will receive an 500 Internal Server Error response.
+If you have more than one http block on same Nginx instance and do not want they share the same memory, you can set different names to each one with the optional argument _name_.
+
+
+h2(#push_stream_channel_deleted_message_text). push_stream_channel_deleted_message_text <a name="push_stream_channel_deleted_message_text" href="#">&nbsp;</a>
+
+*syntax:* _push_stream_channel_deleted_message_text string_
+
+*default:* _Channel deleted_
+
+*context:* _http_
+
+*release version:* _0.2.5_
+
+The string used on channel deleted message sent to subscribers when the channel is deleted by a publisher.
+
+
+h2(#push_stream_ping_message_text). push_stream_ping_message_text <a name="push_stream_ping_message_text" href="#">&nbsp;</a>
+
+*syntax:* _push_stream_ping_message_text string_
+
+*default:* _none_
+
+*context:* _http_
+
+*release version:* _0.2.5_
+
+The string used on ping message sent to subscribers.
+
+
+h2(#push_stream_channel_inactivity_time). push_stream_channel_inactivity_time <a name="push_stream_channel_inactivity_time" href="#">&nbsp;</a>
+
+*syntax:* _push_stream_channel_inactivity_time time_
+
+*default:* _30s_
+
+*context:* _http_
+
+*release version:* _0.3.5_
+
+The length of time after what a channel will be considered inactive, counted after the last message was published on it or the last subscriber entered on it.
+After this time the channel will no longer be available and will be moved to the trash queue.
+When the "push_stream_authorized_channels_only":push_stream_authorized_channels_only is set to on, the inactivity time is only used to know when the channel should be moved to trash.
+
+
+h2(#push_stream_message_ttl). push_stream_message_ttl <a name="push_stream_message_ttl" href="#">&nbsp;</a>
+
+*syntax:* _push_stream_message_ttl time_
+
+*default:* _30m_
+
+*context:* _http_
+
+The length of time a message may be queued before it is considered expired.
+
+
+h2(#push_stream_max_subscribers_per_channel). push_stream_max_subscribers_per_channel <a name="push_stream_max_subscribers_per_channel" href="#">&nbsp;</a>
+
+*syntax:* _push_stream_max_subscribers_per_channel number_
+
+*default:* _none_
+
+*context:* _http_
+
+*release version:* _0.3.1_
+
+The maximum number of subscribers accepted per channel. If you do not want to limit number of subscribers access to channels, just not set this directive.
+
+
+h2(#push_stream_max_messages_stored_per_channel). push_stream_max_messages_stored_per_channel <a name="push_stream_max_messages_stored_per_channel" href="#">&nbsp;</a>
+
+*syntax:* _push_stream_max_messages_stored_per_channel number_
+
+*default:* _none_
+
+*context:* _http_
+
+The maximum number of messages to store per channel. A channel's message buffer will retain at most this many most recent messages. If you do not want messages to be discarded by length, just not set this directive.
+
+
+h2(#push_stream_max_channel_id_length). push_stream_max_channel_id_length <a name="push_stream_max_channel_id_length" href="#">&nbsp;</a>
+
+*syntax:* _push_stream_max_channel_id_length number_
+
+*default:* _none_
+
+*context:* _http_
+
+Maximum permissible channel id length (number of characters). Longer ids will receive an 400 Bad Request response. If you do not want to limit channel id length, just not set this directive.
+
+
+h2(#push_stream_max_number_of_channels). push_stream_max_number_of_channels <a name="push_stream_max_number_of_channels" href="#">&nbsp;</a>
+
+*syntax:* _push_stream_max_number_of_channels number_
+
+*default:* _none_
+
+*context:* _http_
+
+The maximum number of concurrent channels on the server. If you do not want to limit the number of channels, just not set this directive.
+
+
+h2(#push_stream_max_number_of_wildcard_channels). push_stream_max_number_of_wildcard_channels <a name="push_stream_max_number_of_wildcard_channels" href="#">&nbsp;</a>
+
+*syntax:* _push_stream_max_number_of_wildcard_channels number_
+
+*default:* _none_
+
+*context:* _http_
+
+The maximum number of concurrent wildcard channels on the server. If you do not want to limit the number of wildcard channels, just not set this directive.
+
+
+h2(#push_stream_wildcard_channel_prefix). push_stream_wildcard_channel_prefix <a name="push_stream_wildcard_channel_prefix" href="#">&nbsp;</a>
+
+*syntax:* _push_stream_wildcard_channel_prefix string_
+
+*default:* _none_
+
+*context:* _http_
+
+The string prefix used to identify a wildcard channel, example: when you set this directive as "bd_", "bd_ch1" will be a wildcard channel.
+A wildcard channel is technically equals to a normal one. It is intended to be used when the "push_stream_authorized_channels_only":push_stream_authorized_channels_only is set to on.
+
+
+h2(#push_stream_events_channel_id). push_stream_events_channel_id <a name="push_stream_events_channel_id" href="#">&nbsp;</a>
+
+*syntax:* _push_stream_events_channel_id string_
+
+*default:* _none_
+
+*context:* _http_
+
+*release version:* _0.6.0_
+
+The string identify an events channel where some control messages will be published.
+Examples:
+{"type": "channel_created", "channel": "CHANNEL_ID"}
+{"type": "channel_destroyed", "channel": "CHANNEL_ID"}
+{"type": "client_subscribed", "channel": "CHANNEL_ID"}
+{"type": "client_unsubscribed", "channel": "CHANNEL_ID"}
+
+By default this channel is not available to subscription. To allow subscriptions to it is necessary set "push_stream_allow_connections_to_events_channel":push_stream_allow_connections_to_events_channel to on.
+
+
+[push_stream_authorized_channels_only]subscribers.textile#push_stream_authorized_channels_only
+[push_stream_allow_connections_to_events_channel]subscribers.textile#push_stream_allow_connections_to_events_channel
diff -Naur nginx-1.11.3/nginx-push-stream-module/docs/directives/publishers.textile nginx-1.11.3-push/nginx-push-stream-module/docs/directives/publishers.textile
--- nginx-1.11.3/nginx-push-stream-module/docs/directives/publishers.textile	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/docs/directives/publishers.textile	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,75 @@
+h1(#publishers_configuration). Publishers Configuration
+
+h2(#push_stream_publisher). push_stream_publisher <a name="push_stream_publisher" href="#">&nbsp;</a>
+
+*syntax:* _push_stream_publisher [normal | admin]_
+
+*default:* _normal_
+
+*context:* _location_
+
+Defines a location as a message publisher. Requests to a publisher location are treated as messages to be sent to subscribers.
+This location supports the following http methods:
+GET, make possible to get statistics about the channel
+POST/PUT, publish a message to the channel
+DELETE, remove any existent stored messages, disconnect any subscriber, and delete the channel. Available only if _admin_ value is used in this directive.
+
+<pre>
+  # normal publisher location
+  location /pub {
+      push_stream_publisher;
+      push_stream_channels_path               $arg_id;
+  }
+
+  # GET    /pub?id=channel_id -> get statistics about a channel
+  # POST   /pub?id=channel_id -> publish a message to the channel
+
+  # admin publisher location
+  location /pub_admin {
+      push_stream_publisher                   admin;
+      push_stream_channels_path               $arg_id;
+  }
+
+  # GET    /pub_admin?id=channel_id -> get statistics about a channel
+  # POST   /pub_admin?id=channel_id -> publish a message to the channel
+  # DELETE /pub_admin?id=channel_id -> delete the channel
+</pre>
+
+
+h2(#push_stream_channels_path). push_stream_channels_path <a name="push_stream_channels_path" href="#">&nbsp;</a>
+
+*values:* _channel id_
+
+*location:* _push_stream_publisher, push_stream_channels_statistics_
+
+A string to uniquely identify a communication channel. Must be present on location of the push_stream_publisher and push_stream_channels_statistics.
+
+<pre>
+push_stream_channels_path $arg_id;
+#channel id is now the url query string parameter "id"
+#(/pub?id=channel_id_string or /channels-stats?id=channel_id_string)
+</pre>
+
+
+h2(#push_stream_store_messages). push_stream_store_messages <a name="push_stream_store_messages" href="#">&nbsp;</a>
+
+*syntax:* _push_stream_store_messages on | off_
+
+*default:* _off_
+
+*context:* _location (push_stream_publisher)_
+
+Whether or not message queuing is enabled.
+
+
+h2(#push_stream_channel_info_on_publish). push_stream_channel_info_on_publish <a name="push_stream_channel_info_on_publish" href="#">&nbsp;</a>
+
+*syntax:* _push_stream_channel_info_on_publish on | off_
+
+*default:* _on_
+
+*context:* _location (push_stream_publisher)_
+
+*release version:* _0.3.5_
+
+Enable send back channel information after publish a message.
diff -Naur nginx-1.11.3/nginx-push-stream-module/docs/directives/subscribers.textile nginx-1.11.3-push/nginx-push-stream-module/docs/directives/subscribers.textile
--- nginx-1.11.3/nginx-push-stream-module/docs/directives/subscribers.textile	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/docs/directives/subscribers.textile	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,318 @@
+h1(#subscribers_configuration). Subscribers Configuration
+
+h2(#push_stream_subscriber). push_stream_subscriber <a name="push_stream_subscriber" href="#">&nbsp;</a>
+
+*syntax:* _push_stream_subscriber [streaming | polling | long-polling | eventsource | websocket]_
+
+*default:* _streaming_
+
+*context:* _location_
+
+Defines a location as a subscriber. This location represents a subscriber's interface to a channel's message queue.
+This location only supports GET http method to receive published messages.
+The polling and long-polling modes could be set by the request header *X-Nginx-PushStream-Mode* overriding push_stream_subscriber directive value, except for websocket.
+The eventsource mode enable "Event Source":eventsource_ref support for subscribers, using the headers Event-ID and Event-Type on publish is possible to set values to _id:_ and _event:_ attributes on message sent to subscribers.
+The websocket mode enable subscriber to use WebSocket protocol.
+
+
+<pre>
+  # streaming subscriber location
+  location /sub/(.*) {
+      push_stream_subscriber;
+      # positional channel path
+      push_stream_channels_path                   $1;
+  }
+
+  curl -s --no-buffer localhost/sub/ch1 -H 'X-Nginx-PushStream-Mode:polling'      #polling request on a streaming location
+  curl -s --no-buffer localhost/sub/ch1 -H 'X-Nginx-PushStream-Mode:long-polling' #long-polling request on a streaming location
+
+  # polling subscriber location
+  location /sub/(.*) {
+      push_stream_subscriber                      polling;
+      # positional channel path
+      push_stream_channels_path                   $1;
+  }
+
+  curl -s --no-buffer localhost/sub/ch1                                           #polling request
+  curl -s --no-buffer localhost/sub/ch1 -H 'X-Nginx-PushStream-Mode:long-polling' #long-polling request on a polling location
+
+  # long polling subscriber location
+  location /sub/(.*) {
+      push_stream_subscriber                      long-polling;
+      # positional channel path
+      push_stream_channels_path                   $1;
+  }
+
+  curl -s --no-buffer localhost/sub/ch1                                           #long-polling request
+  curl -s --no-buffer localhost/sub/ch1 -H 'X-Nginx-PushStream-Mode:polling'      #polling request on a logn-polling location
+
+  # eventsource subscriber location
+  location /sub/(.*) {
+      push_stream_subscriber                      eventsource;
+      # positional channel path
+      push_stream_channels_path                   $1;
+  }
+
+  curl -s --no-buffer localhost/sub/ch1                                           #eventsource request
+
+  # eventsource subscriber location
+  location /sub/(.*) {
+      push_stream_subscriber                      websocket;
+      # positional channel path
+      push_stream_channels_path                   $1;
+  }
+</pre>
+
+
+h2(#push_stream_channels_path). push_stream_channels_path <a name="push_stream_channels_path" href="#">&nbsp;</a>
+
+*values:* _set of channels id and backtrack desired messages_
+
+*location:* _push_stream_subscriber_
+
+A string representing a set of channels id and backtrack desired messages separated by slash, example _/channel1.b3/channel2.b5/channel3.b2_.
+The backtrack means the amount of old messages from each of the channels that will be delivered to the subscriber. On the example will be 3 messages from channel1, 5 from channel2 and 2 from channel3.
+Backtrack isn't needed, you can only sign channels without get old messages, or you can mix things.
+More accepted examples: _/channel1_ , _/channel1/channel2_ , _/channel1.b5/channel2_ , _/channel1/channel2.b6_ , ...
+
+"*How is it used on a publisher location?*":push_stream_channels_path
+
+<pre>
+location /sub/(.*) {
+  push_stream_channels_path $1;
+}
+#channels path is now part of url
+#(/sub/channel_id_string or /sub/channel_id_string.b2/other_channel)
+</pre>
+
+
+h2(#push_stream_authorized_channels_only). push_stream_authorized_channels_only <a name="push_stream_authorized_channels_only" href="#">&nbsp;</a>
+
+*syntax:* _push_stream_authorized_channels_only on | off_
+
+*default:* _off_
+
+*context:* _location (push_stream_subscriber)_
+
+When set to on, subscribers can connect only to a channel with at least one stored message.
+All subscriber requests to nonexistent channels or channels without stored messages will get a 403 Forbidden response.
+This restriction is not applied to wildcard channels, but to connect to a wildcard channel is necessary to connect to at least one normal channel on the same request.
+
+
+h2(#push_stream_header_template_file). push_stream_header_template_file <a name="push_stream_header_template_file" href="#">&nbsp;</a>
+
+*syntax:* _push_stream_header_template_file string_
+
+*default:* _none_
+
+*context:* _location (push_stream_subscriber)_
+
+The path of a file with the text that will be sent to subscribers when they arrive, except when long polling connections timed out.
+The file is read only once on server startup.
+Must not be used on the same level (http/server/location block) of push_stream_header_template directive.
+
+
+h2(#push_stream_header_template). push_stream_header_template <a name="push_stream_header_template" href="#">&nbsp;</a>
+
+*syntax:* _push_stream_header_template string_
+
+*default:* _none_
+
+*context:* _location (push_stream_subscriber)_
+
+The text that will be sent to subscribers when they arrive, except when long polling connections timed out.
+Must not be used on the same level (http/server/location block) of push_stream_header_template_file directive.
+
+
+h2(#push_stream_message_template). push_stream_message_template <a name="push_stream_message_template" href="#">&nbsp;</a>
+
+*syntax:* _push_stream_message_template string_
+
+*default:* _==~text~==_
+
+*context:* _location (push_stream_subscriber)_
+
+The text template that will be used to format the message before be sent to subscribers. The template can contain any number of the reserved words: ==~id~, ~text~, ~size~, ~channel~, ~time~, ~tag~, ~event-id~ and ~event-type~, example: "&lt;script&gt;p(~id~,'~channel~','~text~', ~tag~, '~time~');&lt;/script&gt;"==
+
+
+h2(#push_stream_footer_template). push_stream_footer_template <a name="push_stream_footer_template" href="#">&nbsp;</a>
+
+*syntax:* _push_stream_footer_template string_
+
+*default:* _none_
+
+*context:* _location (push_stream_subscriber)_
+
+*release version:* _0.2.6_
+
+The text that will be sent to subscribers before connection is closed (channel deleted or subscriber timeout), except when long polling connections timed out.
+
+
+h2(#push_stream_wildcard_channel_max_qtd). push_stream_wildcard_channel_max_qtd <a name="push_stream_wildcard_channel_max_qtd" href="#">&nbsp;</a>
+
+*syntax:* _push_stream_wildcard_channel_max_qtd number_
+
+*default:* _none_
+
+*context:* _location (push_stream_subscriber)_
+
+The maximum number of wildcard channels that a subscriber may sign on the request.
+This directive works in conjunction with "push_stream_authorized_channels_only":push_stream_authorized_channels_only to preserve the server from a kind of attack where a subscriber sign one normal channel and many nonexistent wildcard channels.
+
+
+h2(#push_stream_ping_message_interval). push_stream_ping_message_interval <a name="push_stream_ping_message_interval" href="#">&nbsp;</a>
+
+*syntax:* _push_stream_ping_message_interval time_
+
+*default:* _none_
+
+*context:* _location (push_stream_subscriber)_
+
+The time interval in which a keepalive message is sent to subscribers. If you do not want to send ping messages, just not set this directive.
+
+
+h2(#push_stream_subscriber_connection_ttl). push_stream_subscriber_connection_ttl <a name="push_stream_subscriber_connection_ttl" href="#">&nbsp;</a>
+
+*syntax:* _push_stream_subscriber_connection_ttl time_
+
+*default:* _none_
+
+*context:* _location (push_stream_subscriber)_
+
+The length of time a subscriber will stay connected before it is considered expired and disconnected. If you do not want subscribers to be automatically disconnected, just not set this directive.
+
+
+h2(#push_stream_longpolling_connection_ttl). push_stream_longpolling_connection_ttl <a name="push_stream_longpolling_connection_ttl" href="#">&nbsp;</a>
+
+*syntax:* _push_stream_longpolling_connection_ttl time_
+
+*default:* _value in push_stream_subscriber_connection_ttl_
+
+*context:* _location (push_stream_subscriber)_
+
+*release version:* _0.3.1_
+
+The length of time a long polling subscriber will stay connected waiting for a message before it is disconnected. If you do not want subscribers to be automatically disconnected, just not set this directive and push_stream_longpolling_connection_ttl directive.
+
+
+h2(#push_stream_timeout_with_body). push_stream_timeout_with_body <a name="push_stream_timeout_with_body" href="#">&nbsp;</a>
+
+*syntax:* _push_stream_timeout_with_body on | off_
+
+*default:* _off_
+
+*context:* _location (push_stream_subscriber)_
+
+*release version:* _0.4.0_
+
+When set to on will send a http 200 message indicating that a timeout happens on long polling connections instead of send only a http 304 header.
+
+
+h2(#push_stream_websocket_allow_publish). push_stream_websocket_allow_publish <a name="push_stream_websocket_allow_publish" href="#">&nbsp;</a>
+
+*syntax:* _push_stream_websocket_allow_publish on | off_
+
+*default:* _off_
+
+*context:* _location_
+
+*release version:* _0.3.2_
+
+Enable a WebSocket subscriber send messages to the channel(s) it is connected through the same connection it is receiving the messages, using _send_ method from WebSocket interface.
+
+
+h2(#push_stream_allow_connections_to_events_channel). push_stream_allow_connections_to_events_channel <a name="push_stream_allow_connections_to_events_channel" href="#">&nbsp;</a>
+
+*syntax:* _push_stream_allow_connections_to_events_channel on | off_
+
+*default:* _off_
+
+*context:* _location_
+
+*release version:* _0.6.0_
+
+Enable subscriptions to events channel.
+
+
+h2(#push_stream_last_received_message_time). push_stream_last_received_message_time <a name="push_stream_last_received_message_time" href="#">&nbsp;</a>
+
+*syntax:* _push_stream_last_received_message_time string_
+
+*default:* _none_
+
+*context:* _location_
+
+*release version:* _0.3.3_
+
+Set the time when last message was received. With that the server knows which messages has to be sent to subscriber. Is a replacement for If-Modified-Since header. Example, $arg_time indicate that the value will be taken from time argument.
+
+
+h2(#push_stream_last_received_message_tag). push_stream_last_received_message_tag <a name="push_stream_last_received_message_tag" href="#">&nbsp;</a>
+
+*syntax:* _push_stream_last_received_message_tag string_
+
+*default:* _none_
+
+*context:* _location_
+
+*release version:* _0.3.3_
+
+Set the tag of the last received message. With that the server knows which messages has to be sent to subscriber. Is a replacement for If-None-Match header. Example, $arg_tag indicate that the value will be taken from tag argument.
+
+
+h2(#push_stream_last_event_id). push_stream_last_event_id <a name="push_stream_last_event_id" href="#">&nbsp;</a>
+
+*syntax:* _push_stream_last_event_id string_
+
+*default:* _none_
+
+*context:* _location_
+
+*release version:* _0.4.0_
+
+Set the last event id of a message. With that the server knows which messages has to be sent to subscriber. Is a replacement for Last-Event-Id header. Example, $arg_last_event indicate that the value will be taken from last_event argument.
+
+
+h2(#push_stream_user_agent). push_stream_user_agent <a name="push_stream_user_agent" href="#">&nbsp;</a>
+
+*syntax:* _push_stream_user_agent string_
+
+*default:* _http user-agent header_
+
+*context:* _location_
+
+*release version:* _0.3.3_
+
+Set from where the user agent will be get to be used on validation for the need of padding. Is a replacement for User-Agent header. Example, $arg_ua indicate that the value will be take from ua argument.
+
+
+h2(#push_stream_padding_by_user_agent). push_stream_padding_by_user_agent <a name="push_stream_padding_by_user_agent" href="#">&nbsp;</a>
+
+*syntax:* _push_stream_padding_by_user_agent string_
+
+*default:* _none_
+
+*context:* _location_
+
+*release version:* _0.3.3_
+
+Set the minimum header size and minimum message size to each user agent who match the given expression. The value may be compound for many groups on the format _user-agent-regexp,header_min_size,message_min_size_ separate by a colon (_:_) .
+
+
+h2(#push_stream_allowed_origins). push_stream_allowed_origins <a name="push_stream_allowed_origins" href="#">&nbsp;</a>
+
+*syntax:* _push_stream_allowed_origins string_
+
+*default:* _none_
+
+*context:* _location (push_stream_publisher, push_stream_channels_subscriber)_
+
+*release version:* _0.3.4_
+
+Set the value used on the Access-Control-Allow-Origin header to allow cross domain requests by javascript.
+You can use a variable as value to this directive.
+When this directive is set, the module will set Access-Control-Allow-Methods and Access-Control-Allow-Headers headers with proper values.
+
+[eventsource_ref]http://dev.w3.org/html5/eventsource/
+[push_stream_authorized_channels_only]subscribers.textile#push_stream_authorized_channels_only
+[push_stream_channels_path]publishers.textile#push_stream_channels_path
diff -Naur nginx-1.11.3/nginx-push-stream-module/docs/examples/curl.textile nginx-1.11.3-push/nginx-push-stream-module/docs/examples/curl.textile
--- nginx-1.11.3/nginx-push-stream-module/docs/examples/curl.textile	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/docs/examples/curl.textile	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,190 @@
+h1(#curl). Curl examples <a name="curl" href="#">&nbsp;</a>
+
+Some commands to explain how the module protocol is implemented, and help to do your own client ;)
+
+Configure your server like suggested bellow. You should complete this configuration with other directives according to the target application.
+
+*Server:*
+
+<pre>
+    location /channels-stats {
+        # activate channels statistics mode for this location
+        push_stream_channels_statistics;
+
+        # query string based channel id
+        push_stream_channels_path               $arg_id;
+    }
+
+    location /pub {
+        # activate publisher (admin) mode for this location
+        push_stream_publisher admin;
+
+        # query string based channel id
+        push_stream_channels_path               $arg_id;
+    }
+
+    location ~ /sub/(.*) {
+        # activate long-polling mode for this location
+        push_stream_subscriber      long-polling;
+
+        # positional channel path
+        push_stream_channels_path         $1;
+
+        # message template
+        push_stream_message_template                "{\"id\":~id~,\"channel\":\"~channel~\",\"text\":\"~text~\"}";
+
+        # connection timeout
+        push_stream_longpolling_connection_ttl        30s;
+    }
+</pre>
+
+
+h2(#common_operations). Common operations
+
+<pre>
+# Subscribe to a channel
+curl -s -v --no-buffer 'http://localhost/sub/my_channel_1'
+curl -s -v --no-buffer 'http://localhost/sub/your_channel_1'
+curl -s -v --no-buffer 'http://localhost/sub/your_channel_2'
+
+# Publish messages
+curl -s -v -X POST 'http://localhost/pub?id=my_channel_1' -d 'Hello World!'
+curl -s -v -X POST 'http://localhost/pub?id=your_channel_1' -d 'Hi everybody!'
+curl -s -v -X POST 'http://localhost/pub?id=your_channel_2' -d 'Goodbye!'
+
+# Channels Stats for publisher (json format)
+curl -s -v 'http://localhost/pub?id=my_channel_1'
+
+# All Channels Stats summarized (json format)
+curl -s -v 'http://localhost/channels-stats'
+
+# All Channels Stats detailed (json format)
+curl -s -v 'http://localhost/channels-stats?id=ALL'
+
+# Prefixed Channels Stats detailed (json format)
+curl -s -v 'http://localhost/channels-stats?id=your_channel_*'
+
+# Channels Stats (json format)
+curl -s -v 'http://localhost/channels-stats?id=my_channel_1'
+
+# Delete Channels
+curl -s -v -X DELETE 'http://localhost/pub?id=my_channel_1'
+</pre>
+
+
+h2(#getting_old_messages). Getting old messages
+
+To get old messages you can use a backtrack, an event id or a time in the past to specify a start point.
+All control methods use some HTTP headers by default, except for backtrack.
+But they can use other methods also, like URL parameters.
+
+To deliver old messages it's necessary to properly configure the directives "push_stream_store_messages", "push_stream_max_messages_stored_per_channel" and "push_stream_message_ttl".
+
+
+*Using backtrack:*
+
+<pre>
+# To get the last 4 messages from channelA, the last 2 messages from channelC and no old messages from channelB
+curl -s -v --no-buffer 'http://localhost/sub/channelA.b4/channelB/channelC.b2'
+</pre>
+
+
+*Using time in the past:*
+
+When a message is published it receives a time and a tag value.
+The tag is used to untie messages published on the same second.
+These values are available to the message template using the ==~time~== and ==~tag~== patterns, and also on headers "Last-Modified" and "Etag" when on long-polling mode.
+
+<pre>
+# publish a message on t1
+curl -s -v -X POST 'http://localhost/pub?id=channelA' -d '1'
+# publish another message on t2
+curl -s -v -X POST 'http://localhost/pub?id=channelA' -d '2'
+# publish another message on t2
+curl -s -v -X POST 'http://localhost/pub?id=channelA' -d '3'
+# publish another message on t3
+curl -s -v -X POST 'http://localhost/pub?id=channelA' -d '4'
+
+# Get the messages published after the t2 time, tag 1
+curl -s -v --no-buffer 'http://localhost/sub/channelA' -H 'If-Modified-Since: t2' -H 'If-None-Match: 1'
+
+# t2, must be on the format "%a, %d %b %Y %T %Z", for instance "Thu, 1 Jan 1970 00:00:00 GMT"
+# this subscriber will receive the messages "3" and "4"
+</pre>
+
+*Using time in the past (not using headers):*
+
+Adding the directives "push_stream_last_received_message_time", "push_stream_last_received_message_tag" to subscriber location,
+is possible to set the values for getting old messages using other methods, like URL parameters or a piece of the path.
+
+modified server:
+
+<pre>
+    location ~ /sub/(.*) {
+        push_stream_subscriber      long-polling;
+        push_stream_channels_path         $1;
+
+        push_stream_last_received_message_time $arg_time;
+        push_stream_last_received_message_tag  $arg_tag;
+
+        push_stream_message_template           "{\"id\":~id~,\"channel\":\"~channel~\",\"text\":\"~text~\", \"time\":\"~time~\", \"tag\":\"~tag~\"}";
+
+        push_stream_longpolling_connection_ttl        30s;
+    }
+</pre>
+
+using the same published messages on the above example:
+
+<pre>
+# Get the messages published after the t2 time, tag 2
+curl -s -v --no-buffer 'http://localhost/sub/channelA?tag=2&time=t2'
+
+# t2, must be on the format "%a, %d %b %Y %T %Z", for instance "Thu, 1 Jan 1970 00:00:00 GMT"
+# this subscriber will receive only the message "4"
+</pre>
+
+
+*Using EventId:*
+
+When a message is published with an Event-Id header this value can be used as a start point to get old messages.
+It's available to the message template using the ==~event-id~== pattern.
+
+<pre>
+
+curl -s -v -X POST 'http://localhost/pub?id=channelA' -d '1'
+curl -s -v -X POST 'http://localhost/pub?id=channelA' -d '2' -H 'Event-Id: some_special_event'
+curl -s -v -X POST 'http://localhost/pub?id=channelA' -d '3'
+curl -s -v -X POST 'http://localhost/pub?id=channelA' -d '4'
+
+# Get the messages published after that event, in this example messages '3' and '4'
+curl -s -v --no-buffer 'http://localhost/sub/channelA' -H 'Last-Event-Id: some_special_event'
+</pre>
+
+*Using EventId (not using headers):*
+
+Adding the directive "push_stream_last_event_id" to subscriber location,
+is possible to set the value for getting old messages using other methods, like URL parameters or a piece of the path.
+
+modified server:
+
+<pre>
+    location ~ /sub/(.*) {
+        push_stream_subscriber      long-polling;
+        push_stream_channels_path         $1;
+
+        push_stream_last_event_id $arg_last_id;
+
+        push_stream_message_template           "{\"id\":~id~,\"channel\":\"~channel~\",\"text\":\"~text~\", \"event\":\"~event-id~\"}";
+
+        push_stream_longpolling_connection_ttl        30s;
+    }
+</pre>
+
+using the same published messages on the above example:
+
+<pre>
+# Get the messages published after the event 'some_special_event'
+curl -s -v --no-buffer 'http://localhost/sub/channelA?last_id=some_special_event'
+
+# this subscriber will receive the messages '3' and '4'
+</pre>
diff -Naur nginx-1.11.3/nginx-push-stream-module/docs/examples/event_source.textile nginx-1.11.3-push/nginx-push-stream-module/docs/examples/event_source.textile
--- nginx-1.11.3/nginx-push-stream-module/docs/examples/event_source.textile	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/docs/examples/event_source.textile	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,214 @@
+h1(#event_source). Event Source <a name="event_source" href="#">&nbsp;</a>
+
+Using EventSource to receive the messages.
+*This example uses the PushStream class present in _misc/js/pushstream.js_ file, copy it to your server htdocs.*
+
+Configure your server like suggested bellow. You should complete this configuration with other directives according to the target application.
+Create a html page with the content on **Client** part, access it from browser and try with the command *curl http://localhost/pub?id=ch1 -d =="Some Text"==* .
+
+*Server:*
+
+<pre>
+    location /pub {
+        # activate publisher (admin) mode for this location
+        push_stream_publisher admin;
+
+        # query string based channel id
+        push_stream_channels_path               $arg_id;
+    }
+
+    location ~ /ev/(.*) {
+        # activate event source mode for this location
+        push_stream_subscriber eventsource;
+
+        # positional channel path
+        push_stream_channels_path                   $1;
+        # message template
+        push_stream_message_template                "{\"id\":~id~,\"channel\":\"~channel~\",\"text\":\"~text~\"}";
+
+        # ping frequency
+        push_stream_ping_message_interval           10s;
+    }
+</pre>
+
+*Client:*
+
+<pre>
+<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
+    "http://www.w3.org/TR/html4/strict.dtd">
+<html>
+<head>
+    <meta http-equiv="Content-type" content="text/html; charset=utf-8" />
+    <title>Event Source Example</title>
+</head>
+<body>
+    <p>Messages:</p>
+    <div id="messages" style="width:800px;height:300px;overflow:scroll;"></div>
+
+    <script src="/js/pushstream.js" type="text/javascript" language="javascript" charset="utf-8"></script>
+    <script type="text/javascript" language="javascript" charset="utf-8">
+    // <![CDATA[
+    function messageReceived(text, id, channel) {
+      document.getElementById('messages').innerHTML += id + ': ' + text + '<br>';
+    };
+
+    var pushstream = new PushStream({
+      host: window.location.hostname,
+      port: window.location.port,
+      modes: "eventsource"
+    });
+    pushstream.onmessage = messageReceived;
+    pushstream.addChannel('ch1');
+    pushstream.connect();
+    // ]]>
+    </script>
+</body>
+</html>
+</pre>
+
+h2(#using_channels_by_argument). Using Channels by argument
+
+By default pushstream.js send the desired channels to the server as part of the url.
+If needed you can change this behavior changing the javascript usage, like the example bellow, to not set the location as a regular expression.
+
+*Server:*
+
+<pre>
+    location /pub {
+        # activate publisher (admin) mode for this location
+        push_stream_publisher admin;
+
+        # query string based channel id
+        push_stream_channels_path               $arg_id;
+    }
+
+    location /ev {
+        # activate event source mode for this location
+        push_stream_subscriber eventsource;
+
+        # positional channel path
+        push_stream_channels_path                   $arg_channels;
+        # message template
+        push_stream_message_template                "{\"id\":~id~,\"channel\":\"~channel~\",\"text\":\"~text~\"}";
+
+        # ping frequency
+        push_stream_ping_message_interval           10s;
+    }
+</pre>
+
+*Client:*
+
+<pre>
+<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
+    "http://www.w3.org/TR/html4/strict.dtd">
+<html>
+<head>
+    <meta http-equiv="Content-type" content="text/html; charset=utf-8" />
+    <title>Event Source Example</title>
+</head>
+<body>
+    <p>Messages:</p>
+    <div id="messages" style="width:800px;height:300px;overflow:scroll;"></div>
+
+    <script src="/js/pushstream.js" type="text/javascript" language="javascript" charset="utf-8"></script>
+    <script type="text/javascript" language="javascript" charset="utf-8">
+    // <![CDATA[
+    function messageReceived(text, id, channel) {
+      document.getElementById('messages').innerHTML += id + ': ' + text + '<br>';
+    };
+
+    var pushstream = new PushStream({
+      host: window.location.hostname,
+      port: window.location.port,
+      modes: "eventsource",
+      channelsByArgument: true,
+      channelsArgument: 'channels' //this is the default value, you have to change it to be the same value used on push_stream_channels_path directive
+    });
+    pushstream.onmessage = messageReceived;
+    pushstream.addChannel('ch1');
+    pushstream.connect();
+    // ]]>
+    </script>
+</body>
+</html>
+</pre>
+
+h2(#getting_old_messages). Getting old messages
+
+To get old messages you can set a backtrack, an event id or a time in the past.
+To proper work on reconnections you should set ==~tag~ and ~time~== on the message template, and configure the server to receive the values.
+
+*Server:*
+
+<pre>
+    location /pub {
+        # activate publisher (admin) mode for this location
+        push_stream_publisher admin;
+
+        # query string based channel id
+        push_stream_channels_path               $arg_id;
+
+        # store messages in memory
+        push_stream_store_messages              on;
+    }
+
+    location ~ /ev/(.*) {
+        # activate event source mode for this location
+        push_stream_subscriber eventsource;
+
+        # positional channel path
+        push_stream_channels_path                   $1;
+
+        push_stream_last_received_message_time      "$arg_time";
+        push_stream_last_received_message_tag       "$arg_tag";
+
+        # message template
+        push_stream_message_template                "{\"id\":~id~,\"channel\":\"~channel~\",\"text\":\"~text~\",\"tag\":\"~tag~\",\"time\":\"~time~\"}";
+
+        # ping frequency
+        push_stream_ping_message_interval           10s;
+
+    }
+</pre>
+
+*Client:*
+
+<pre>
+<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
+    "http://www.w3.org/TR/html4/strict.dtd">
+<html>
+<head>
+    <meta http-equiv="Content-type" content="text/html; charset=utf-8" />
+    <title>Event Source Example</title>
+</head>
+<body>
+    <p>Messages:</p>
+    <div id="messages" style="width:800px;height:300px;overflow:scroll;"></div>
+
+    <script src="/js/pushstream.js" type="text/javascript" language="javascript" charset="utf-8"></script>
+    <script type="text/javascript" language="javascript" charset="utf-8">
+    // <![CDATA[
+    function messageReceived(text, id, channel) {
+      document.getElementById('messages').innerHTML += id + ': ' + text + '<br>';
+    };
+
+    var pushstream = new PushStream({
+      host: window.location.hostname,
+      port: window.location.port,
+      modes: "eventsource",
+      messagesPublishedAfter: 5,
+      messagesControlByArgument: true
+    });
+    pushstream.onmessage = messageReceived;
+    pushstream.addChannel('ch1');
+    pushstream.connect();
+    // ]]>
+    </script>
+</body>
+</html>
+</pre>
+
+*Observations:*
+
+* _push_stream_message_template_ should be exactly like as the example to be used with PushStream class
+* WebSocket, EventSource and Forever iFrame may be combined setting _/ws_, _/sub_ and _/ev_ locations on same server and setting *modes: "websocket|eventsource|stream"* on client. With that if the browser supports Websocket or Event Source, it will use it, if not it will use iFrame, following the order on _modes_ attribute.
diff -Naur nginx-1.11.3/nginx-push-stream-module/docs/examples/forever_iframe.textile nginx-1.11.3-push/nginx-push-stream-module/docs/examples/forever_iframe.textile
--- nginx-1.11.3/nginx-push-stream-module/docs/examples/forever_iframe.textile	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/docs/examples/forever_iframe.textile	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,230 @@
+h1(#forever_iframe). Forever Iframe <a name="forever_iframe" href="#">&nbsp;</a>
+
+Using an invisible iFrame on the page to receive the messages and pass them to main page.
+*This example uses the PushStream class present in _misc/js/pushstream.js_ file, copy it to your server htdocs.*
+
+Configure your server like suggested bellow. You should complete this configuration with other directives according to the target application.
+Create a html page with the content on **Client** part, access it from browser and try with the command *curl http://localhost/pub?id=ch1 -d =="Some Text"==* .
+
+*Server:*
+
+<pre>
+    location /pub {
+        # activate publisher (admin) mode for this location
+        push_stream_publisher admin;
+
+        # query string based channel id
+        push_stream_channels_path               $arg_id;
+    }
+
+    location ~ /sub/(.*) {
+        # activate subscriber (streaming) mode for this location
+        push_stream_subscriber;
+
+        # positional channel path
+        push_stream_channels_path                   $1;
+
+        # header to be sent when receiving new subscriber connection
+        push_stream_header_template                 "<html><head><meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\r\n<meta http-equiv=\"Cache-Control\" content=\"no-store\">\r\n<meta http-equiv=\"Cache-Control\" content=\"no-cache\">\r\n<meta http-equiv=\"Pragma\" content=\"no-cache\">\r\n<meta http-equiv=\"Expires\" content=\"Thu, 1 Jan 1970 00:00:00 GMT\">\r\n<script type=\"text/javascript\">\r\nwindow.onError = null;\r\ntry{ document.domain = (window.location.hostname.match(/^(\d{1,3}\.){3}\d{1,3}$/)) ? window.location.hostname : window.location.hostname.split('.').slice(-1 * Math.max(window.location.hostname.split('.').length - 1, (window.location.hostname.match(/(\w{4,}\.\w{2}|\.\w{3,})$/) ? 2 : 3))).join('.');}catch(e){}\r\nparent.PushStream.register(this);\r\n</script>\r\n</head>\r\n<body>";
+        # message template
+        push_stream_message_template                "<script>p(~id~,'~channel~','~text~');</script>";
+        # footer to be sent when finishing subscriber connection
+        push_stream_footer_template                 "</body></html>";
+        # content-type
+        default_type                                "text/html; charset=utf-8";
+        # ping frequency
+        push_stream_ping_message_interval           10s;
+    }
+</pre>
+
+*Client:*
+
+<pre>
+<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
+    "http://www.w3.org/TR/html4/strict.dtd">
+<html>
+<head>
+    <meta http-equiv="Content-type" content="text/html; charset=utf-8" />
+    <title>Forever iFrame Example</title>
+</head>
+<body>
+    <p>Messages:</p>
+    <div id="messages" style="width:800px;height:300px;overflow:scroll;"></div>
+
+    <script src="/js/pushstream.js" type="text/javascript" language="javascript" charset="utf-8"></script>
+    <script type="text/javascript" language="javascript" charset="utf-8">
+    // <![CDATA[
+    function messageReceived(text, id, channel) {
+      document.getElementById('messages').innerHTML += id + ': ' + text + '<br>';
+    };
+
+    var pushstream = new PushStream({
+      host: window.location.hostname,
+      port: window.location.port,
+      modes: "stream"
+    });
+    pushstream.onmessage = messageReceived;
+    pushstream.addChannel('ch1');
+    pushstream.connect();
+    // ]]>
+    </script>
+</body>
+</html>
+</pre>
+
+h2(#using_channels_by_argument). Using Channels by argument
+
+By default pushstream.js send the desired channels to the server as part of the url.
+If needed you can change this behavior changing the javascript usage, like the example bellow, to not set the location as a regular expression.
+
+*Server:*
+
+<pre>
+    location /pub {
+        # activate publisher (admin) mode for this location
+        push_stream_publisher admin;
+
+        # query string based channel id
+        push_stream_channels_path               $arg_id;
+    }
+
+    location /sub {
+        # activate subscriber (streaming) mode for this location
+        push_stream_subscriber;
+
+        # positional channel path
+        push_stream_channels_path                   $arg_channels;
+
+        # header to be sent when receiving new subscriber connection
+        push_stream_header_template                 "<html><head><meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\r\n<meta http-equiv=\"Cache-Control\" content=\"no-store\">\r\n<meta http-equiv=\"Cache-Control\" content=\"no-cache\">\r\n<meta http-equiv=\"Pragma\" content=\"no-cache\">\r\n<meta http-equiv=\"Expires\" content=\"Thu, 1 Jan 1970 00:00:00 GMT\">\r\n<script type=\"text/javascript\">\r\nwindow.onError = null;\r\ntry{ document.domain = (window.location.hostname.match(/^(\d{1,3}\.){3}\d{1,3}$/)) ? window.location.hostname : window.location.hostname.split('.').slice(-1 * Math.max(window.location.hostname.split('.').length - 1, (window.location.hostname.match(/(\w{4,}\.\w{2}|\.\w{3,})$/) ? 2 : 3))).join('.');}catch(e){}\r\nparent.PushStream.register(this);\r\n</script>\r\n</head>\r\n<body>";
+        # message template
+        push_stream_message_template                "<script>p(~id~,'~channel~','~text~');</script>";
+        # footer to be sent when finishing subscriber connection
+        push_stream_footer_template                 "</body></html>";
+        # content-type
+        default_type                                "text/html; charset=utf-8";
+        # ping frequency
+        push_stream_ping_message_interval           10s;
+    }
+</pre>
+
+*Client:*
+
+<pre>
+<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
+    "http://www.w3.org/TR/html4/strict.dtd">
+<html>
+<head>
+    <meta http-equiv="Content-type" content="text/html; charset=utf-8" />
+    <title>Forever iFrame Example</title>
+</head>
+<body>
+    <p>Messages:</p>
+    <div id="messages" style="width:800px;height:300px;overflow:scroll;"></div>
+
+    <script src="/js/pushstream.js" type="text/javascript" language="javascript" charset="utf-8"></script>
+    <script type="text/javascript" language="javascript" charset="utf-8">
+    // <![CDATA[
+    function messageReceived(text, id, channel) {
+      document.getElementById('messages').innerHTML += id + ': ' + text + '<br>';
+    };
+
+    var pushstream = new PushStream({
+      host: window.location.hostname,
+      port: window.location.port,
+      modes: "stream",
+      channelsByArgument: true,
+      channelsArgument: 'channels' //this is the default value, you have to change it to be the same value used on push_stream_channels_path directive
+    });
+    pushstream.onmessage = messageReceived;
+    pushstream.addChannel('ch1');
+    pushstream.connect();
+    // ]]>
+    </script>
+</body>
+</html>
+</pre>
+
+h2(#getting_old_messages). Getting old messages
+
+To get old messages you can set a backtrack, an event id or a time in the past.
+To proper work on reconnections you should set ==~tag~ and ~time~== on the message template, and configure the server to receive the values.
+
+*Server:*
+
+<pre>
+    location /pub {
+        # activate publisher (admin) mode for this location
+        push_stream_publisher admin;
+
+        # query string based channel id
+        push_stream_channels_path               $arg_id;
+
+        # store messages in memory
+        push_stream_store_messages              on;
+    }
+
+    location ~ /sub/(.*) {
+        # activate subscriber (streaming) mode for this location
+        push_stream_subscriber;
+
+        # positional channel path
+        push_stream_channels_path                   $1;
+
+        push_stream_last_received_message_time      "$arg_time";
+        push_stream_last_received_message_tag       "$arg_tag";
+
+        # header to be sent when receiving new subscriber connection
+        push_stream_header_template                 "<html><head><meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\r\n<meta http-equiv=\"Cache-Control\" content=\"no-store\">\r\n<meta http-equiv=\"Cache-Control\" content=\"no-cache\">\r\n<meta http-equiv=\"Pragma\" content=\"no-cache\">\r\n<meta http-equiv=\"Expires\" content=\"Thu, 1 Jan 1970 00:00:00 GMT\">\r\n<script type=\"text/javascript\">\r\nwindow.onError = null;\r\ntry{ document.domain = (window.location.hostname.match(/^(\d{1,3}\.){3}\d{1,3}$/)) ? window.location.hostname : window.location.hostname.split('.').slice(-1 * Math.max(window.location.hostname.split('.').length - 1, (window.location.hostname.match(/(\w{4,}\.\w{2}|\.\w{3,})$/) ? 2 : 3))).join('.');}catch(e){}\r\nparent.PushStream.register(this);\r\n</script>\r\n</head>\r\n<body>";
+        # message template
+        push_stream_message_template                "<script>p(~id~,'~channel~','~text~','~event-id~', '~time~', '~tag~');</script>";
+        # footer to be sent when finishing subscriber connection
+        push_stream_footer_template                 "</body></html>";
+        # content-type
+        default_type                                "text/html; charset=utf-8";
+        # ping frequency
+        push_stream_ping_message_interval           10s;
+    }
+</pre>
+
+*Client:*
+
+<pre>
+<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
+    "http://www.w3.org/TR/html4/strict.dtd">
+<html>
+<head>
+    <meta http-equiv="Content-type" content="text/html; charset=utf-8" />
+    <title>Event Source Example</title>
+</head>
+<body>
+    <p>Messages:</p>
+    <div id="messages" style="width:800px;height:300px;overflow:scroll;"></div>
+
+    <script src="/js/pushstream.js" type="text/javascript" language="javascript" charset="utf-8"></script>
+    <script type="text/javascript" language="javascript" charset="utf-8">
+    // <![CDATA[
+    function messageReceived(text, id, channel) {
+      document.getElementById('messages').innerHTML += id + ': ' + text + '<br>';
+    };
+
+    var pushstream = new PushStream({
+      host: window.location.hostname,
+      port: window.location.port,
+      modes: "stream",
+      messagesPublishedAfter: 5,
+      messagesControlByArgument: true
+    });
+    pushstream.onmessage = messageReceived;
+    pushstream.addChannel('ch1');
+    pushstream.connect();
+    // ]]>
+    </script>
+</body>
+</html>
+</pre>
+
+*Observations:*
+
+* _push_stream_message_template_ should be exactly like as the example to be used with PushStream class
+* WebSocket, EventSource and Forever iFrame may be combined setting _/ws_, _/sub_ and _/ev_ locations on same server and setting *modes: "websocket|eventsource|stream"* on client. With that if the browser supports Websocket or Event Source, it will use it, if not it will use iFrame, following the order on _modes_ attribute.
diff -Naur nginx-1.11.3/nginx-push-stream-module/docs/examples/long_polling.textile nginx-1.11.3-push/nginx-push-stream-module/docs/examples/long_polling.textile
--- nginx-1.11.3/nginx-push-stream-module/docs/examples/long_polling.textile	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/docs/examples/long_polling.textile	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,366 @@
+h1(#long_polling). Long Polling <a name="long_polling" href="#">&nbsp;</a>
+
+Using PushStream to receive the messages through long polling technique.
+*This example uses the PushStream class present in _misc/js/pushstream.js_ file, copy it to your server htdocs.*
+
+Configure your server like suggested bellow. You should complete this configuration with other directives according to the target application.
+Create a html page with the content on **Client** part, access it from browser and try with the command *curl http://localhost/pub?id=ch1 -d =="Some Text"==* .
+
+*Server:*
+
+<pre>
+    location /pub {
+        # activate publisher (admin) mode for this location
+        push_stream_publisher admin;
+
+        # query string based channel id
+        push_stream_channels_path               $arg_id;
+    }
+
+    location ~ /lp/(.*) {
+        # activate long-polling mode for this location
+        push_stream_subscriber      long-polling;
+
+        # positional channel path
+        push_stream_channels_path         $1;
+
+        # message template
+        push_stream_message_template                "{\"id\":~id~,\"channel\":\"~channel~\",\"text\":\"~text~\"}";
+
+        # connection timeout
+        push_stream_longpolling_connection_ttl        30s;
+    }
+</pre>
+
+*Client:*
+
+<pre>
+<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
+    "http://www.w3.org/TR/html4/strict.dtd">
+<html>
+<head>
+    <meta http-equiv="Content-type" content="text/html; charset=utf-8" />
+    <title>Long Polling Example</title>
+</head>
+<body>
+    <p>Messages:</p>
+    <div id="messages" style="width:800px;height:300px;overflow:scroll;"></div>
+
+    <script src="/js/pushstream.js" type="text/javascript" language="javascript" charset="utf-8"></script>
+    <script type="text/javascript" language="javascript" charset="utf-8">
+    // <![CDATA[
+    function messageReceived(text, id, channel) {
+      document.getElementById('messages').innerHTML += id + ': ' + text + '<br>';
+    };
+
+    var pushstream = new PushStream({
+      host: window.location.hostname,
+      port: window.location.port,
+      modes: "longpolling"
+    });
+    pushstream.onmessage = messageReceived;
+    pushstream.addChannel('ch1');
+    pushstream.connect();
+    // ]]>
+    </script>
+</body>
+</html>
+</pre>
+
+h2(#using_channels_by_argument). Using Channels by argument
+
+By default pushstream.js send the desired channels to the server as part of the url.
+If needed you can change this behavior changing the javascript usage, like the example bellow, to not set the location as a regular expression.
+
+*Server:*
+
+<pre>
+    location /pub {
+        # activate publisher (admin) mode for this location
+        push_stream_publisher admin;
+
+        # query string based channel id
+        push_stream_channels_path               $arg_id;
+    }
+
+    location /lp {
+        # activate long-polling mode for this location
+        push_stream_subscriber      long-polling;
+
+        # positional channel path
+        push_stream_channels_path         $arg_channels;
+
+        # message template
+        push_stream_message_template                "{\"id\":~id~,\"channel\":\"~channel~\",\"text\":\"~text~\"}";
+
+        # connection timeout
+        push_stream_longpolling_connection_ttl        30s;
+    }
+</pre>
+
+*Client:*
+
+<pre>
+<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
+    "http://www.w3.org/TR/html4/strict.dtd">
+<html>
+<head>
+    <meta http-equiv="Content-type" content="text/html; charset=utf-8" />
+    <title>Long Polling Example</title>
+</head>
+<body>
+    <p>Messages:</p>
+    <div id="messages" style="width:800px;height:300px;overflow:scroll;"></div>
+
+    <script src="/js/pushstream.js" type="text/javascript" language="javascript" charset="utf-8"></script>
+    <script type="text/javascript" language="javascript" charset="utf-8">
+    // <![CDATA[
+    function messageReceived(text, id, channel) {
+      document.getElementById('messages').innerHTML += id + ': ' + text + '<br>';
+    };
+
+    var pushstream = new PushStream({
+      host: window.location.hostname,
+      port: window.location.port,
+      modes: "longpolling",
+      channelsByArgument: true,
+      channelsArgument: 'channels' //this is the default value, you have to change it to be the same value used on push_stream_channels_path directive
+    });
+    pushstream.onmessage = messageReceived;
+    pushstream.addChannel('ch1');
+    pushstream.connect();
+    // ]]>
+    </script>
+</body>
+</html>
+</pre>
+
+h2(#not_using_headers). Not using headers control
+
+Long Polling, by default, uses some HTTP headers to control which was the last message received, server uses Etag and Last-Modified-Time to inform the client, and the client uses If-Modified-Since and If-None-Match to inform the server.
+If needed you can change this behavior using some additional directives and changing the javascript usage, like the example bellow.
+
+*Server:*
+
+<pre>
+    location /pub {
+        # activate publisher (admin) mode for this location
+        push_stream_publisher admin;
+
+        # query string based channel id
+        push_stream_channels_path               $arg_id;
+    }
+
+    location ~ /lp/(.*) {
+        # activate long-polling mode for this location
+        push_stream_subscriber      long-polling;
+
+        # positional channel path
+        push_stream_channels_path         $1;
+
+        # message template
+        push_stream_message_template                "{\"id\":~id~,\"channel\":\"~channel~\",\"text\":\"~text~\",\"tag\":~tag~,\"time\":\"~time~\"}";
+
+        push_stream_last_received_message_tag       $arg_tag;
+        push_stream_last_received_message_time      $arg_time;
+
+        # connection timeout
+        push_stream_longpolling_connection_ttl        30s;
+    }
+</pre>
+
+*Client:*
+
+<pre>
+<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
+    "http://www.w3.org/TR/html4/strict.dtd">
+<html>
+<head>
+    <meta http-equiv="Content-type" content="text/html; charset=utf-8" />
+    <title>Long Polling Example</title>
+</head>
+<body>
+    <p>Messages:</p>
+    <div id="messages" style="width:800px;height:300px;overflow:scroll;"></div>
+
+    <script src="/js/pushstream.js" type="text/javascript" language="javascript" charset="utf-8"></script>
+    <script type="text/javascript" language="javascript" charset="utf-8">
+    // <![CDATA[
+    function messageReceived(text, id, channel) {
+      document.getElementById('messages').innerHTML += id + ': ' + text + '<br>';
+    };
+
+    var pushstream = new PushStream({
+      host: window.location.hostname,
+      port: window.location.port,
+      modes: "longpolling",
+      messagesControlByArgument: true,
+      tagArgument: 'tag',    //this is the default value, you have to change it to be the same value used on push_stream_last_received_message_tag directive
+      timeArgument: 'time'   //this is the default value, you have to change it to be the same value used on push_stream_last_received_message_time directive
+    });
+    pushstream.onmessage = messageReceived;
+    pushstream.addChannel('ch1');
+    pushstream.connect();
+    // ]]>
+    </script>
+</body>
+</html>
+</pre>
+
+h1(#jsonp). JSONP <a name="jsonp" href="#">&nbsp;</a>
+
+*JSONP is a special case of long polling, used when the server where the content is produced has a different domain from the server where is the page which consumes the content.*
+
+Using PushStream to receive the messages through JSONP technique.
+*This example uses the PushStream class present in _misc/js/pushstream.js_ file, copy it to your server htdocs.*
+
+Configure your server like suggested bellow. You should complete this configuration with other directives according to the target application.
+Create a html page with the content on **Client** part, access it from browser and try with the command *curl http://localhost/pub?id=ch1 -d "Some Text"*.
+
+_The configuration in the example is the same used on long polling, just forcing the use of JSONP, this is automatic when the domains are different_
+
+*Server:*
+
+<pre>
+    location /pub {
+        # activate publisher (admin) mode for this location
+        push_stream_publisher admin;
+
+        # query string based channel id
+        push_stream_channels_path               $arg_id;
+    }
+
+    location ~ /lp/(.*) {
+        # activate long-polling mode for this location
+        push_stream_subscriber      long-polling;
+
+        # positional channel path
+        push_stream_channels_path         $1;
+
+        # message template
+        push_stream_message_template                "{\"id\":~id~,\"channel\":\"~channel~\",\"text\":\"~text~\",\"tag\":~tag~,\"time\":\"~time~\"}";
+
+        push_stream_last_received_message_tag       $arg_tag;
+        push_stream_last_received_message_time      $arg_time;
+
+        # connection timeout
+        push_stream_longpolling_connection_ttl        30s;
+    }
+</pre>
+
+*Client:*
+
+<pre>
+<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
+    "http://www.w3.org/TR/html4/strict.dtd">
+<html>
+<head>
+    <meta http-equiv="Content-type" content="text/html; charset=utf-8" />
+    <title>Long Polling Example</title>
+</head>
+<body>
+    <p>Messages:</p>
+    <div id="messages" style="width:800px;height:300px;overflow:scroll;"></div>
+
+    <script src="/js/pushstream.js" type="text/javascript" language="javascript" charset="utf-8"></script>
+    <script type="text/javascript" language="javascript" charset="utf-8">
+    // <![CDATA[
+    function messageReceived(text, id, channel) {
+      document.getElementById('messages').innerHTML += id + ': ' + text + '<br>';
+    };
+
+    var pushstream = new PushStream({
+      host: window.location.hostname,
+      port: window.location.port,
+      modes: "longpolling",
+      tagArgument: 'tag',    //this is the default value, you have to change it to be the same value used on push_stream_last_received_message_tag directive
+      timeArgument: 'time',  //this is the default value, you have to change it to be the same value used on push_stream_last_received_message_time directive
+      useJSONP: true,        //this is used only to force jsonp usage on example, it is automatic true when the domains are different
+      timeout: 30000         //this is the default value, you have to change it to be the same value used on push_stream_longpolling_connection_ttl directive in miliseconds
+    });
+    pushstream.onmessage = messageReceived;
+    pushstream.addChannel('ch1');
+    pushstream.connect();
+    // ]]>
+    </script>
+</body>
+</html>
+</pre>
+
+h2(#getting_old_messages). Getting old messages
+
+To get old messages you can set a backtrack, an event id or a time in the past.
+To proper work on reconnections you should set ==~tag~ and ~time~== on the message template, and configure the server to receive the values.
+
+*Server:*
+
+<pre>
+    location /pub {
+        # activate publisher (admin) mode for this location
+        push_stream_publisher admin;
+
+        # query string based channel id
+        push_stream_channels_path               $arg_id;
+
+        # store messages in memory
+        push_stream_store_messages              on;
+    }
+
+    location ~ /lp/(.*) {
+        # activate long-polling mode for this location
+        push_stream_subscriber      long-polling;
+
+        # positional channel path
+        push_stream_channels_path                   $1;
+
+        push_stream_last_received_message_time      "$arg_time";
+        push_stream_last_received_message_tag       "$arg_tag";
+
+        # message template
+        push_stream_message_template                "{\"id\":~id~,\"channel\":\"~channel~\",\"text\":\"~text~\",\"tag\":\"~tag~\",\"time\":\"~time~\"}";
+
+        # connection timeout
+        push_stream_longpolling_connection_ttl        30s;
+    }
+</pre>
+
+*Client:*
+
+<pre>
+<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
+    "http://www.w3.org/TR/html4/strict.dtd">
+<html>
+<head>
+    <meta http-equiv="Content-type" content="text/html; charset=utf-8" />
+    <title>Event Source Example</title>
+</head>
+<body>
+    <p>Messages:</p>
+    <div id="messages" style="width:800px;height:300px;overflow:scroll;"></div>
+
+    <script src="/js/pushstream.js" type="text/javascript" language="javascript" charset="utf-8"></script>
+    <script type="text/javascript" language="javascript" charset="utf-8">
+    // <![CDATA[
+    function messageReceived(text, id, channel) {
+      document.getElementById('messages').innerHTML += id + ': ' + text + '<br>';
+    };
+
+    var pushstream = new PushStream({
+      host: window.location.hostname,
+      port: window.location.port,
+      modes: "longpolling",
+      messagesPublishedAfter: 5,
+      messagesControlByArgument: true
+    });
+    pushstream.onmessage = messageReceived;
+    pushstream.addChannel('ch1');
+    pushstream.connect();
+    // ]]>
+    </script>
+</body>
+</html>
+</pre>
+
+*Observations:*
+
+* _push_stream_message_template_ should be exactly like as the example to be used with PushStream class
diff -Naur nginx-1.11.3/nginx-push-stream-module/docs/examples/m_jpeg.textile nginx-1.11.3-push/nginx-push-stream-module/docs/examples/m_jpeg.textile
--- nginx-1.11.3/nginx-push-stream-module/docs/examples/m_jpeg.textile	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/docs/examples/m_jpeg.textile	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,52 @@
+h1(#m_jpeg). M-JPEG example <a name="m_jpeg" href="#">&nbsp;</a>
+
+Using the module to stream images over HTTP "(wiki)":wiki.
+
+Configure your server like suggested bellow. You should complete this configuration with other directives according to the target application.
+
+*Server:*
+
+<pre>
+    location /pub {
+        client_max_body_size                    1m;
+        client_body_buffer_size                 1m;
+
+        # activate publisher (admin) mode for this location
+        push_stream_publisher admin;
+
+        # query string based channel id
+        push_stream_channels_path               $arg_id;
+    }
+
+    location ~ /sub/(.*) {
+        default_type "multipart/x-mixed-replace; boundary=endofsection";
+
+        push_stream_subscriber;
+
+        # positional channel path
+        push_stream_channels_path         $1;
+
+        # message template
+        push_stream_message_template "--endofsection\nX-Timestamp: ~time~\nContent-Type: image/jpg\nContent-Length: ~size~\n\n~text~";
+    }
+
+    location / {
+        default_type "text/html";
+        return 200 "<html><head><title>M-JPEG example</title></head><body><img src='/sub/ch1' /></body></html>";
+    }
+</pre>
+
+
+Open any browser and point it to your server, like "http://localhost/"
+Post jpeg images.
+
+<pre>
+
+curl -s -v -X POST 'http://localhost:9080/pub?id=ch1' --data-binary @image1.jpg
+curl -s -v -X POST 'http://localhost:9080/pub?id=ch1' --data-binary @image2.jpg
+curl -s -v -X POST 'http://localhost:9080/pub?id=ch1' --data-binary @image3.jpg
+...
+
+</pre>
+
+[wiki]https://en.wikipedia.org/wiki/Motion_JPEG#M-JPEG_over_HTTP
\ No newline at end of file
diff -Naur nginx-1.11.3/nginx-push-stream-module/docs/examples/websocket.textile nginx-1.11.3-push/nginx-push-stream-module/docs/examples/websocket.textile
--- nginx-1.11.3/nginx-push-stream-module/docs/examples/websocket.textile	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/docs/examples/websocket.textile	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,218 @@
+h1(#websocket). WebSocket <a name="websocket" href="#">&nbsp;</a>
+
+Using WebSocket to receive the messages.
+*This example uses the PushStream class present in _misc/js/pushstream.js_ file, copy it to your server htdocs.*
+
+Configure your server like suggested bellow. You should complete this configuration with other directives according to the target application.
+Create a html page with the content on **Client** part, access it from browser and try with the command *curl http://localhost/pub?id=ch1 -d =="Some Text"==* .
+
+*Server:*
+
+<pre>
+    location /pub {
+        # activate publisher (admin) mode for this location
+        push_stream_publisher admin;
+
+        # query string based channel id
+        push_stream_channels_path               $arg_id;
+    }
+
+    location ~ /ws/(.*) {
+        # activate websocket mode for this location
+        push_stream_subscriber websocket;
+
+        # positional channel path
+        push_stream_channels_path                   $1;
+        # message template
+        push_stream_message_template                "{\"id\":~id~,\"channel\":\"~channel~\",\"text\":\"~text~\"}";
+
+        push_stream_websocket_allow_publish         on;
+
+        # ping frequency
+        push_stream_ping_message_interval           10s;
+    }
+</pre>
+
+*Client:*
+
+<pre>
+<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
+    "http://www.w3.org/TR/html4/strict.dtd">
+<html>
+<head>
+    <meta http-equiv="Content-type" content="text/html; charset=utf-8" />
+    <title>WebSocket Example</title>
+</head>
+<body>
+    <p>Messages:</p>
+    <div id="messages" style="width:800px;height:300px;overflow:scroll;"></div>
+
+    <script src="/js/pushstream.js" type="text/javascript" language="javascript" charset="utf-8"></script>
+    <script type="text/javascript" language="javascript" charset="utf-8">
+    // <![CDATA[
+    function messageReceived(text, id, channel) {
+      document.getElementById('messages').innerHTML += id + ': ' + text + '<br>';
+    };
+
+    var pushstream = new PushStream({
+      host: window.location.hostname,
+      port: window.location.port,
+      modes: "websocket"
+    });
+    pushstream.onmessage = messageReceived;
+    pushstream.addChannel('ch1');
+    pushstream.connect();
+    // ]]>
+    </script>
+</body>
+</html>
+</pre>
+
+h2(#using_channels_by_argument). Using Channels by argument
+
+By default pushstream.js send the desired channels to the server as part of the url.
+If needed you can change this behavior changing the javascript usage, like the example bellow, to not set the location as a regular expression.
+
+*Server:*
+
+<pre>
+    location /pub {
+        # activate publisher (admin) mode for this location
+        push_stream_publisher admin;
+
+        # query string based channel id
+        push_stream_channels_path               $arg_id;
+    }
+
+    location /ws {
+        # activate websocket mode for this location
+        push_stream_subscriber websocket;
+
+        # positional channel path
+        push_stream_channels_path                   $arg_channels;
+        # message template
+        push_stream_message_template                "{\"id\":~id~,\"channel\":\"~channel~\",\"text\":\"~text~\"}";
+
+        push_stream_websocket_allow_publish         on;
+
+        # ping frequency
+        push_stream_ping_message_interval           10s;
+    }
+</pre>
+
+*Client:*
+
+<pre>
+<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
+    "http://www.w3.org/TR/html4/strict.dtd">
+<html>
+<head>
+    <meta http-equiv="Content-type" content="text/html; charset=utf-8" />
+    <title>WebSocket Example</title>
+</head>
+<body>
+    <p>Messages:</p>
+    <div id="messages" style="width:800px;height:300px;overflow:scroll;"></div>
+
+    <script src="/js/pushstream.js" type="text/javascript" language="javascript" charset="utf-8"></script>
+    <script type="text/javascript" language="javascript" charset="utf-8">
+    // <![CDATA[
+    function messageReceived(text, id, channel) {
+      document.getElementById('messages').innerHTML += id + ': ' + text + '<br>';
+    };
+
+    var pushstream = new PushStream({
+      host: window.location.hostname,
+      port: window.location.port,
+      modes: "websocket",
+      channelsByArgument: true,
+      channelsArgument: 'channels' //this is the default value, you have to change it to be the same value used on push_stream_channels_path directive
+    });
+    pushstream.onmessage = messageReceived;
+    pushstream.addChannel('ch1');
+    pushstream.connect();
+    // ]]>
+    </script>
+</body>
+</html>
+</pre>
+
+h2(#getting_old_messages). Getting old messages
+
+To get old messages you can set a backtrack, an event id or a time in the past.
+To proper work on reconnections you should set ==~tag~ and ~time~== on the message template, and configure the server to receive the values.
+
+*Server:*
+
+<pre>
+    location /pub {
+        # activate publisher (admin) mode for this location
+        push_stream_publisher admin;
+
+        # query string based channel id
+        push_stream_channels_path               $arg_id;
+
+        # store messages in memory
+        push_stream_store_messages              on;
+    }
+
+    location ~ /ws/(.*) {
+        # activate websocket mode for this location
+        push_stream_subscriber websocket;
+
+        # positional channel path
+        push_stream_channels_path                   $1;
+
+        push_stream_last_received_message_time      "$arg_time";
+        push_stream_last_received_message_tag       "$arg_tag";
+
+        # message template
+        push_stream_message_template                "{\"id\":~id~,\"channel\":\"~channel~\",\"text\":\"~text~\",\"tag\":\"~tag~\",\"time\":\"~time~\"}";
+
+        # ping frequency
+        push_stream_ping_message_interval           10s;
+
+    }
+</pre>
+
+*Client:*
+
+<pre>
+<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
+    "http://www.w3.org/TR/html4/strict.dtd">
+<html>
+<head>
+    <meta http-equiv="Content-type" content="text/html; charset=utf-8" />
+    <title>Event Source Example</title>
+</head>
+<body>
+    <p>Messages:</p>
+    <div id="messages" style="width:800px;height:300px;overflow:scroll;"></div>
+
+    <script src="/js/pushstream.js" type="text/javascript" language="javascript" charset="utf-8"></script>
+    <script type="text/javascript" language="javascript" charset="utf-8">
+    // <![CDATA[
+    function messageReceived(text, id, channel) {
+      document.getElementById('messages').innerHTML += id + ': ' + text + '<br>';
+    };
+
+    var pushstream = new PushStream({
+      host: window.location.hostname,
+      port: window.location.port,
+      modes: "websocket",
+      messagesPublishedAfter: 5,
+      messagesControlByArgument: true
+    });
+    pushstream.onmessage = messageReceived;
+    pushstream.addChannel('ch1');
+    pushstream.connect();
+    // ]]>
+    </script>
+</body>
+</html>
+</pre>
+
+*Observations:*
+
+* _push_stream_message_template_ should be exactly like as the example to be used with PushStream class
+* WebSocket, EventSource and Forever iFrame may be combined setting _/ws_, _/sub_ and _/ev_ locations on same server and setting *modes: "websocket|eventsource|stream"* on client. With that if the browser supports Websocket or Event Source, it will use it, if not it will use iFrame, following the order on _modes_ attribute.
diff -Naur nginx-1.11.3/nginx-push-stream-module/docs/javascript_client.textile nginx-1.11.3-push/nginx-push-stream-module/docs/javascript_client.textile
--- nginx-1.11.3/nginx-push-stream-module/docs/javascript_client.textile	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/docs/javascript_client.textile	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,87 @@
+h1(#javascript_client). Javascript Client <a name="javascript_client" href="#">&nbsp;</a>
+
+The _PushStream_ javascript class is an abstraction for which kind of connection is in use.
+It supports 4 kinds of connection: Stream, EventSource, WebSocket and LongPolling.
+The main idea is to provide a single interface to be used on your code, be easy to change from one kind to another, or to use some of the kinds together, one as a fallback to the others.
+It does not depend of any framework, like jQuery or MooTools, and can be used with any of them.
+
+h2(#basic_usage). Basic Usage <a name="basic_usage" href="#">&nbsp;</a>
+
+<pre>
+<script>
+  var pushstream = new PushStream();
+  pushstream.onmessage = function(data) {
+    alert(data);
+  };
+  pushstream.addChannel('example');
+  pushstream.connect();
+</script>
+</pre>
+
+h2(#configuration). Configuration <a name="configuration" href="#">&nbsp;</a>
+
+The _PushStream_ class accept some configurations on its constructor to replace the default values.
+Example:
+
+<pre>
+<script>
+  var pushstream = new PushStream({
+    timeout: 20000,
+    modes: 'eventsource|stream'
+  });
+  // ... extra code ...
+</script>
+</pre>
+
+(head). | configuration | default | type | description |
+| useSSL | false | boolean | if should use or not SSL on the connection |
+| host | current host name | string | the host name to connect and get messages |
+| port | 80/443 (if using SSL) | number | the port number to connect and get messages |
+| timeout | 30000 | number | the amount of time to consider that a connection has some problem (in milliseconds) |
+| pingtimeout | 30000 | number | the amount of time to consider that a connection does not receive a ping message (in milliseconds) |
+| reconnectOnTimeoutInterval | 3000 | number | the amount of time to do a new connection after a timeout happens (in milliseconds) |
+| reconnectOnChannelUnavailableInterval | 60000 | number | the amount of time to do a new connection after receives a 403, indicating that a channel is unavailable (in milliseconds) |
+| autoReconnect | true | boolean | enable / disable the internal routine to reconnect the client after a failure |
+| messagesPublishedAfter | - | number/date | get messages published at less than this time, on the first connection |
+| lastEventId | - | string | get messages published after the message with this event id |
+| messagesControlByArgument | true | boolean | when to use time and tag values by headers instead of arguments on long polling connections |
+| tagArgument | 'tag' | string | argument name to send tag value, specially used on JSONP mode  |
+| timeArgument | 'time' | string | argument name to send time value, specially used on JSONP mode |
+| eventIdArgument | 'eventid' | string | argument name to send eventid value, specially used on JSONP mode |
+| useJSONP | false | boolean | when to use JSONP mode on long polling connections, mandatorily true when current domain or port is different from the target server (cross domain restrictions)  |
+| urlPrefixPublisher | '/pub' | string | the location prefix used to post messages |
+| urlPrefixStream | '/sub' | string | the location prefix used to do Stream mode connections |
+| urlPrefixEventsource | '/ev' | string | the location prefix used to do EventSource mode connections |
+| urlPrefixLongpolling | '/lp' | string | the location prefix used to do LongPolling mode connections |
+| urlPrefixWebsocket | '/ws' | string | the location prefix used to do WebSocket mode connections |
+| jsonIdKey | 'id' | string | the key name to extract message id from received message |
+| jsonChannelKey | 'channel' | string | the key name to extract channel id from received message |
+| jsonTextKey | 'text' | string | the key name to extract message text from received message |
+| jsonTagKey | 'tag' | string | the key name to extract message tag from received message |
+| jsonTimeKey | 'time' | string | the key name to extract message time from received message |
+| jsonEventIdKey | 'eventid' | string | the key name to extract message event id from received message |
+| modes | 'eventsource&#124;websocket&#124;stream&#124;longpolling' | string | methods supported by the server which can be used by the browser, separated by '&#124;', on the order of preference |
+| channelsByArgument | false | boolean | when to send target channels names by argument on subscriber connections |
+| channelsArgument | 'channels' | string | the argument name to send target channels names on subscriber connections |
+
+h2(#callbacks). Callbacks and Functions <a name="callbacks" href="#">&nbsp;</a>
+
+The _PushStream_ class has some callbacks and functions that can be overwritten.
+Example:
+
+<pre>
+<script>
+  var pushstream = new PushStream();
+  pushstream.onstatuschange = function(status) {
+    alert("The new status is: " + status);
+  };
+  // ... extra code ...
+</script>
+</pre>
+
+(head). | callback/function | description |
+| extraParams | implement this function returning an object with extra parameters to send on subscriber connections, where the key is the parameter name and the value will be the parameter value, like {"foo":"bar", "xyz":"1"} -> "foo=bar&xyz=1" |
+| onerror | implement this function to be notified when an error happens, the argument received is an object with a key named 'type' indicating if was a 'load' or a 'timeout' error |
+| onstatuschange | implement this function to receive the new connection status as argument, which can be PushStream.CLOSED, PushStream.CONNECTING or PushStream.OPEN |
+| onchanneldeleted | implement this function to be notified when a channel was deleted on the server. The channel id will be the given argument|
+| onmessage | implement this function to receive the messages from server, the arguments are, in order: text, id, channel, eventid, isLastMessageFromBatch, time. The isLastMessageFromBatch argument indicate when is, or not, the last message received on a batch when using long polling connections |
diff -Naur nginx-1.11.3/nginx-push-stream-module/docs/server_tests.textile nginx-1.11.3-push/nginx-push-stream-module/docs/server_tests.textile
--- nginx-1.11.3/nginx-push-stream-module/docs/server_tests.textile	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/docs/server_tests.textile	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,29 @@
+h1(#tests). Tests <a name="tests" href="#">&nbsp;</a>
+
+The tests for this module are written in Ruby, and are acceptance tests.
+To run them is needed to have an environment with:
+
+* ruby >= 1.9.3
+* bundler >= 1.1.4
+
+and install required gems doing:
+
+<pre>
+cd misc/
+bundle install --without docs
+</pre>
+
+Then issue @rake spec@.
+This command run the tests using nginx *executable* located at _/usr/local/nginx/sbin/nginx_ with _1_ *worker* responding at *host* _127.0.0.1_ and *port* _9990_.
+To change this behavior use the commands bellow
+
+<pre>
+NGINX_EXEC="../build/nginx-1.2.0/objs/nginx" rake spec   # to change default path for nginx executable
+NGINX_HOST="my_machine" rake spec                        # to change default hostname
+NGINX_PORT=9889 rake spec                                # to change default port
+NGINX_WORKERS=2 rake spec                                # to change dafault number of workers used
+
+and can combine any of these parameters, like:
+
+NGINX_PORT=9889 NGINX_EXEC="../build/nginx-1.2.0/objs/nginx" rake spec
+</pre>
diff -Naur nginx-1.11.3/nginx-push-stream-module/include/ngx_http_push_stream_module.h nginx-1.11.3-push/nginx-push-stream-module/include/ngx_http_push_stream_module.h
--- nginx-1.11.3/nginx-push-stream-module/include/ngx_http_push_stream_module.h	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/include/ngx_http_push_stream_module.h	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,466 @@
+/*
+ * Copyright (C) 2010-2015 Wandenberg Peixoto <wandenberg@gmail.com>, Rog√©rio Carvalho Schneider <stockrt@gmail.com>
+ *
+ * This file is part of Nginx Push Stream Module.
+ *
+ * Nginx Push Stream Module is free software: you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation, either version 3 of the License, or
+ * (at your option) any later version.
+ *
+ * Nginx Push Stream Module is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with Nginx Push Stream Module.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ *
+ * ngx_http_push_stream_module.h
+ *
+ * Created: Oct 26, 2010
+ * Authors: Wandenberg Peixoto <wandenberg@gmail.com>, Rog√©rio Carvalho Schneider <stockrt@gmail.com>
+ */
+
+#ifndef NGX_HTTP_PUSH_STREAM_MODULE_H_
+#define NGX_HTTP_PUSH_STREAM_MODULE_H_
+
+#include <ngx_config.h>
+#include <ngx_core.h>
+#include <ngx_http.h>
+#include <nginx.h>
+
+typedef struct {
+    ngx_queue_t                     queue;
+    ngx_regex_t                    *agent;
+    ngx_uint_t                      header_min_len;
+    ngx_uint_t                      message_min_len;
+} ngx_http_push_stream_padding_t;
+
+typedef enum {
+    PUSH_STREAM_TEMPLATE_PART_TYPE_ID = 0,
+    PUSH_STREAM_TEMPLATE_PART_TYPE_TAG,
+    PUSH_STREAM_TEMPLATE_PART_TYPE_TIME,
+    PUSH_STREAM_TEMPLATE_PART_TYPE_EVENT_ID,
+    PUSH_STREAM_TEMPLATE_PART_TYPE_EVENT_TYPE,
+    PUSH_STREAM_TEMPLATE_PART_TYPE_CHANNEL,
+    PUSH_STREAM_TEMPLATE_PART_TYPE_TEXT,
+    PUSH_STREAM_TEMPLATE_PART_TYPE_SIZE,
+    PUSH_STREAM_TEMPLATE_PART_TYPE_LITERAL
+} ngx_http_push_stream_template_part_type;
+
+typedef struct {
+    ngx_queue_t                                queue;
+    ngx_http_push_stream_template_part_type    kind;
+    ngx_str_t                                  text;
+} ngx_http_push_stream_template_parts_t;
+
+// template queue
+typedef struct {
+    ngx_queue_t                     queue;
+    ngx_str_t                      *template;
+    ngx_uint_t                      index;
+    ngx_flag_t                      eventsource;
+    ngx_flag_t                      websocket;
+    ngx_queue_t                     parts;
+    ngx_uint_t                      qtd_message_id;
+    ngx_uint_t                      qtd_event_id;
+    ngx_uint_t                      qtd_event_type;
+    ngx_uint_t                      qtd_channel;
+    ngx_uint_t                      qtd_text;
+    ngx_uint_t                      qtd_size;
+    ngx_uint_t                      qtd_tag;
+    ngx_uint_t                      qtd_time;
+    size_t                          literal_len;
+} ngx_http_push_stream_template_t;
+
+typedef struct ngx_http_push_stream_msg_s ngx_http_push_stream_msg_t;
+typedef struct ngx_http_push_stream_shm_data_s ngx_http_push_stream_shm_data_t;
+typedef struct ngx_http_push_stream_global_shm_data_s ngx_http_push_stream_global_shm_data_t;
+typedef struct ngx_http_push_stream_channel_s ngx_http_push_stream_channel_t;
+
+typedef struct {
+    ngx_flag_t                      enabled;
+    ngx_str_t                       channel_deleted_message_text;
+    time_t                          channel_inactivity_time;
+    ngx_str_t                       ping_message_text;
+    ngx_uint_t                      qtd_templates;
+    ngx_str_t                       wildcard_channel_prefix;
+    ngx_uint_t                      max_number_of_channels;
+    ngx_uint_t                      max_number_of_wildcard_channels;
+    time_t                          message_ttl;
+    ngx_uint_t                      max_subscribers_per_channel;
+    ngx_uint_t                      max_messages_stored_per_channel;
+    ngx_uint_t                      max_channel_id_length;
+    ngx_queue_t                     msg_templates;
+    ngx_flag_t                      timeout_with_body;
+    ngx_str_t                       events_channel_id;
+    ngx_http_push_stream_channel_t *events_channel;
+    ngx_regex_t                    *backtrack_parser_regex;
+    ngx_http_push_stream_msg_t     *ping_msg;
+    ngx_http_push_stream_msg_t     *longpooling_timeout_msg;
+    ngx_shm_zone_t                 *shm_zone;
+    ngx_slab_pool_t                *shpool;
+    ngx_http_push_stream_shm_data_t*shm_data;
+} ngx_http_push_stream_main_conf_t;
+
+typedef struct {
+    ngx_http_complex_value_t       *channels_path;
+    ngx_uint_t                      authorized_channels_only;
+    ngx_flag_t                      store_messages;
+    ngx_str_t                       header_template;
+    ngx_str_t                       message_template;
+    ngx_int_t                       message_template_index;
+    ngx_str_t                       footer_template;
+    ngx_uint_t                      wildcard_channel_max_qtd;
+    ngx_uint_t                      location_type;
+    ngx_msec_t                      ping_message_interval;
+    ngx_msec_t                      subscriber_connection_ttl;
+    ngx_msec_t                      longpolling_connection_ttl;
+    ngx_flag_t                      websocket_allow_publish;
+    ngx_flag_t                      channel_info_on_publish;
+    ngx_flag_t                      allow_connections_to_events_channel;
+    ngx_http_complex_value_t       *last_received_message_time;
+    ngx_http_complex_value_t       *last_received_message_tag;
+    ngx_http_complex_value_t       *last_event_id;
+    ngx_http_complex_value_t       *user_agent;
+    ngx_str_t                       padding_by_user_agent;
+    ngx_queue_t                    *paddings;
+    ngx_http_complex_value_t       *allowed_origins;
+} ngx_http_push_stream_loc_conf_t;
+
+// shared memory segment name
+static ngx_str_t    ngx_http_push_stream_shm_name = ngx_string("push_stream_module");
+static ngx_str_t    ngx_http_push_stream_global_shm_name = ngx_string("push_stream_module_global");
+
+// message queue
+struct ngx_http_push_stream_msg_s {
+    ngx_queue_t                     queue;
+    time_t                          expires;
+    time_t                          time;
+    ngx_flag_t                      deleted;
+    ngx_int_t                       id;
+    ngx_str_t                       raw;
+    ngx_int_t                       tag;
+    ngx_str_t                      *event_id;
+    ngx_str_t                      *event_type;
+    ngx_str_t                      *event_id_message;
+    ngx_str_t                      *event_type_message;
+    ngx_str_t                      *formatted_messages;
+    ngx_int_t                       workers_ref_count;
+    ngx_uint_t                      qtd_templates;
+};
+
+typedef struct ngx_http_push_stream_subscriber_s ngx_http_push_stream_subscriber_t;
+
+typedef struct {
+    ngx_queue_t                         queue;
+    pid_t                               pid;
+    ngx_int_t                           slot;
+    ngx_queue_t                         subscriptions;
+    ngx_uint_t                          subscribers;
+} ngx_http_push_stream_pid_queue_t;
+
+struct ngx_http_push_stream_channel_s {
+    ngx_rbtree_node_t                   node;
+    ngx_queue_t                         queue;
+    ngx_str_t                           id;
+    ngx_uint_t                          last_message_id;
+    time_t                              last_message_time;
+    ngx_int_t                           last_message_tag;
+    ngx_uint_t                          stored_messages;
+    ngx_uint_t                          subscribers;
+    ngx_queue_t                         workers_with_subscribers;
+    ngx_queue_t                         message_queue;
+    time_t                              expires;
+    ngx_flag_t                          deleted;
+    ngx_flag_t                          wildcard;
+    char                                for_events;
+    ngx_http_push_stream_msg_t         *channel_deleted_message;
+    ngx_shmtx_t                        *mutex;
+};
+
+typedef struct {
+    ngx_queue_t                         queue;
+    ngx_str_t                           id;
+    ngx_uint_t                          published_messages;
+    ngx_uint_t                          stored_messages;
+    ngx_uint_t                          subscribers;
+} ngx_http_push_stream_channel_info_t;
+
+
+typedef struct {
+    ngx_queue_t                         queue;
+    ngx_queue_t                         channel_worker_queue;
+    ngx_http_push_stream_subscriber_t  *subscriber;
+    ngx_http_push_stream_channel_t     *channel;
+    ngx_http_push_stream_pid_queue_t   *channel_worker_sentinel;
+} ngx_http_push_stream_subscription_t;
+
+struct ngx_http_push_stream_subscriber_s {
+    ngx_http_request_t                         *request;
+    ngx_queue_t                                 subscriptions;
+    ngx_pid_t                                   worker_subscribed_pid;
+    ngx_flag_t                                  longpolling;
+    ngx_queue_t                                 worker_queue;
+};
+
+typedef struct {
+    ngx_queue_t                     queue;
+    ngx_str_t                      *id;
+    ngx_uint_t                      backtrack_messages;
+    ngx_http_push_stream_channel_t *channel;
+} ngx_http_push_stream_requested_channel_t;
+
+typedef struct {
+    unsigned char fin:1;
+    unsigned char rsv1:1;
+    unsigned char rsv2:1;
+    unsigned char rsv3:1;
+    unsigned char opcode:4;
+    unsigned char mask:1;
+    unsigned char mask_key[4];
+    uint64_t payload_len;
+    u_char  header[8];
+    u_char *payload;
+    ngx_uint_t step;
+    ngx_buf_t  buf;
+    ngx_str_t consolidated;
+    unsigned char fragmented:1;
+    unsigned char last_fragment:1;
+} ngx_http_push_stream_frame_t;
+
+typedef struct {
+    ngx_event_t                        *disconnect_timer;
+    ngx_event_t                        *ping_timer;
+    ngx_http_push_stream_subscriber_t  *subscriber;
+    ngx_flag_t                          longpolling;
+    ngx_flag_t                          message_sent;
+    ngx_pool_t                         *temp_pool;
+    ngx_chain_t                        *free;
+    ngx_chain_t                        *busy;
+    ngx_http_push_stream_padding_t     *padding;
+    ngx_str_t                          *callback;
+    ngx_http_push_stream_requested_channel_t *requested_channels;
+    ngx_http_push_stream_frame_t       *frame;
+} ngx_http_push_stream_module_ctx_t;
+
+// messages to worker processes
+typedef struct {
+    ngx_queue_t                         queue;
+    ngx_http_push_stream_msg_t         *msg; // ->shared memory
+    ngx_pid_t                           pid;
+    ngx_http_push_stream_channel_t     *channel; // ->shared memory
+    ngx_queue_t                        *subscriptions_sentinel; // ->a worker's local pool
+    ngx_http_push_stream_main_conf_t   *mcf;
+} ngx_http_push_stream_worker_msg_t;
+
+typedef struct {
+    ngx_queue_t                         messages_queue;
+    ngx_queue_t                         subscribers_queue;
+    ngx_uint_t                          subscribers; // # of subscribers in the worker
+    time_t                              startup;
+    pid_t                               pid;
+} ngx_http_push_stream_worker_data_t;
+
+// shared memory
+struct ngx_http_push_stream_global_shm_data_s {
+    pid_t                                   pid[NGX_MAX_PROCESSES];
+    ngx_queue_t                             shm_datas_queue;
+};
+
+struct ngx_http_push_stream_shm_data_s {
+    ngx_rbtree_t                            tree;
+    ngx_uint_t                              channels;           // # of channels being used
+    ngx_uint_t                              wildcard_channels;  // # of wildcard channels being used
+    ngx_uint_t                              published_messages; // # of published messagens in all channels
+    ngx_uint_t                              stored_messages;    // # of messages being stored
+    ngx_uint_t                              subscribers;        // # of subscribers in all channels
+    ngx_queue_t                             messages_trash;
+    ngx_shmtx_t                             messages_trash_mutex;
+    ngx_shmtx_sh_t                          messages_trash_lock;
+    ngx_queue_t                             channels_queue;
+    ngx_shmtx_t                             channels_queue_mutex;
+    ngx_shmtx_sh_t                          channels_queue_lock;
+    ngx_queue_t                             channels_trash;
+    ngx_shmtx_t                             channels_trash_mutex;
+    ngx_shmtx_sh_t                          channels_trash_lock;
+    ngx_queue_t                             channels_to_delete;
+    ngx_shmtx_t                             channels_to_delete_mutex;
+    ngx_shmtx_sh_t                          channels_to_delete_lock;
+    ngx_uint_t                              channels_in_trash;  // # of channels in trash queue
+    ngx_uint_t                              messages_in_trash;  // # of messages in trash queue
+    ngx_http_push_stream_worker_data_t      ipc[NGX_MAX_PROCESSES]; // interprocess stuff
+    time_t                                  startup;
+    time_t                                  last_message_time;
+    ngx_int_t                               last_message_tag;
+    ngx_queue_t                             shm_data_queue;
+    ngx_http_push_stream_main_conf_t       *mcf;
+    ngx_shm_zone_t                         *shm_zone;
+    ngx_slab_pool_t                        *shpool;
+    ngx_uint_t                              slots_for_census;
+    ngx_uint_t                              mutex_round_robin;
+    ngx_shmtx_t                             channels_mutex[10];
+    ngx_shmtx_sh_t                          channels_lock[10];
+    ngx_shmtx_t                             cleanup_mutex;
+    ngx_shmtx_sh_t                          cleanup_lock;
+    ngx_shmtx_t                             events_channel_mutex;
+    ngx_shmtx_sh_t                          events_channel_lock;
+};
+
+ngx_shm_zone_t     *ngx_http_push_stream_global_shm_zone = NULL;
+
+ngx_str_t         **ngx_http_push_stream_module_paddings_chunks = NULL;
+ngx_str_t         **ngx_http_push_stream_module_paddings_chunks_for_eventsource = NULL;
+
+// channel
+static ngx_int_t        ngx_http_push_stream_send_response_all_channels_info_summarized(ngx_http_request_t *r);
+static ngx_int_t        ngx_http_push_stream_send_response_all_channels_info_detailed(ngx_http_request_t *r, ngx_str_t *prefix);
+static ngx_int_t        ngx_http_push_stream_send_response_channels_info_detailed(ngx_http_request_t *r, ngx_http_push_stream_requested_channel_t *requested_channels);
+
+static ngx_int_t        ngx_http_push_stream_find_or_add_template(ngx_conf_t *cf, ngx_str_t template, ngx_flag_t eventsource, ngx_flag_t websocket);
+
+static const ngx_str_t  NGX_HTTP_PUSH_STREAM_ALL_CHANNELS_INFO_ID = ngx_string("ALL");
+
+static const ngx_str_t NGX_HTTP_PUSH_STREAM_NO_CHANNEL_ID_MESSAGE  = ngx_string("No channel id provided.");
+static const ngx_str_t NGX_HTTP_PUSH_STREAM_CHANNEL_ID_NOT_AUTHORIZED_MESSAGE = ngx_string("Channel id not authorized for this method.");
+static const ngx_str_t NGX_HTTP_PUSH_STREAM_EMPTY_POST_REQUEST_MESSAGE = ngx_string("Empty post requests are not allowed.");
+static const ngx_str_t NGX_HTTP_PUSH_STREAM_TOO_LARGE_CHANNEL_ID_MESSAGE = ngx_string("Channel id is too large.");
+static const ngx_str_t NGX_HTTP_PUSH_STREAM_TOO_MUCH_WILDCARD_CHANNELS = ngx_string("Subscribed too much wildcard channels.");
+static const ngx_str_t NGX_HTTP_PUSH_STREAM_TOO_SUBSCRIBERS_PER_CHANNEL = ngx_string("Subscribers limit per channel has been exceeded.");
+static const ngx_str_t NGX_HTTP_PUSH_STREAM_CANNOT_CREATE_CHANNELS = ngx_string("Subscriber could not create channels.");
+static const ngx_str_t NGX_HTTP_PUSH_STREAM_NUMBER_OF_CHANNELS_EXCEEDED_MESSAGE = ngx_string("Number of channels were exceeded.");
+static const ngx_str_t NGX_HTTP_PUSH_STREAM_INTERNAL_ONLY_EVENTS_CHANNEL_MESSAGE = ngx_string("Only internal routines can change events channel.");
+static const ngx_str_t NGX_HTTP_PUSH_STREAM_SUBSCRIPTION_EVENTS_CHANNEL_FORBIDDEN_MESSAGE = ngx_string("Subscription to events channel is not allowed.");
+static const ngx_str_t NGX_HTTP_PUSH_STREAM_NO_MANDATORY_HEADERS_MESSAGE = ngx_string("Don't have at least one of the mandatory headers: Connection, Upgrade, Sec-WebSocket-Key and Sec-WebSocket-Version");
+static const ngx_str_t NGX_HTTP_PUSH_STREAM_WRONG_WEBSOCKET_VERSION_MESSAGE = ngx_string("Version not supported. Supported versions: 8, 13");
+static const ngx_str_t NGX_HTTP_PUSH_STREAM_CHANNEL_DELETED = ngx_string("Channel deleted.");
+
+#define NGX_HTTP_PUSH_STREAM_UNSET_CHANNEL_ID               (void *) -1
+#define NGX_HTTP_PUSH_STREAM_TOO_LARGE_CHANNEL_ID           (void *) -2
+#define NGX_HTTP_PUSH_STREAM_NUMBER_OF_CHANNELS_EXCEEDED    (void *) -3
+
+static ngx_str_t        NGX_HTTP_PUSH_STREAM_EMPTY = ngx_string("");
+static const ngx_str_t  NGX_HTTP_PUSH_STREAM_BACKTRACK_PATTERN = ngx_string("((\\.b([0-9]+))?(/|$))");
+static const ngx_str_t  NGX_HTTP_PUSH_STREAM_CALLBACK = ngx_string("callback");
+
+static const ngx_str_t  NGX_HTTP_PUSH_STREAM_DATE_FORMAT_ISO_8601 = ngx_string("%4d-%02d-%02dT%02d:%02d:%02d");
+
+// headers
+static const ngx_str_t  NGX_HTTP_PUSH_STREAM_HEADER_EVENT_ID = ngx_string("Event-Id");
+static const ngx_str_t  NGX_HTTP_PUSH_STREAM_HEADER_EVENT_TYPE = ngx_string("Event-Type");
+static const ngx_str_t  NGX_HTTP_PUSH_STREAM_HEADER_LAST_EVENT_ID = ngx_string("Last-Event-Id");
+static const ngx_str_t  NGX_HTTP_PUSH_STREAM_HEADER_ALLOW = ngx_string("Allow");
+static const ngx_str_t  NGX_HTTP_PUSH_STREAM_HEADER_EXPLAIN = ngx_string("X-Nginx-PushStream-Explain");
+static const ngx_str_t  NGX_HTTP_PUSH_STREAM_HEADER_MODE = ngx_string("X-Nginx-PushStream-Mode");
+static const ngx_str_t  NGX_HTTP_PUSH_STREAM_HEADER_TAG = ngx_string("X-Nginx-PushStream-Tag");
+static const ngx_str_t  NGX_HTTP_PUSH_STREAM_HEADER_COMMIT = ngx_string("X-Nginx-PushStream-Commit");
+static const ngx_str_t  NGX_HTTP_PUSH_STREAM_HEADER_ETAG = ngx_string("Etag");
+static const ngx_str_t  NGX_HTTP_PUSH_STREAM_HEADER_IF_NONE_MATCH = ngx_string("If-None-Match");
+static const ngx_str_t  NGX_HTTP_PUSH_STREAM_HEADER_UPGRADE = ngx_string("Upgrade");
+static const ngx_str_t  NGX_HTTP_PUSH_STREAM_HEADER_CONNECTION = ngx_string("Connection");
+static const ngx_str_t  NGX_HTTP_PUSH_STREAM_HEADER_SEC_WEBSOCKET_KEY = ngx_string("Sec-WebSocket-Key");
+static const ngx_str_t  NGX_HTTP_PUSH_STREAM_HEADER_SEC_WEBSOCKET_VERSION = ngx_string("Sec-WebSocket-Version");
+static const ngx_str_t  NGX_HTTP_PUSH_STREAM_HEADER_SEC_WEBSOCKET_ACCEPT = ngx_string("Sec-WebSocket-Accept");
+static const ngx_str_t  NGX_HTTP_PUSH_STREAM_HEADER_ACCESS_CONTROL_ALLOW_ORIGIN = ngx_string("Access-Control-Allow-Origin");
+static const ngx_str_t  NGX_HTTP_PUSH_STREAM_HEADER_ACCESS_CONTROL_ALLOW_METHODS = ngx_string("Access-Control-Allow-Methods");
+static const ngx_str_t  NGX_HTTP_PUSH_STREAM_HEADER_ACCESS_CONTROL_ALLOW_HEADERS = ngx_string("Access-Control-Allow-Headers");
+
+static const ngx_str_t  NGX_HTTP_PUSH_STREAM_WEBSOCKET_UPGRADE = ngx_string("WebSocket");
+static const ngx_str_t  NGX_HTTP_PUSH_STREAM_WEBSOCKET_CONNECTION = ngx_string("Upgrade");
+static const ngx_str_t  NGX_HTTP_PUSH_STREAM_WEBSOCKET_SIGN_KEY = ngx_string("258EAFA5-E914-47DA-95CA-C5AB0DC85B11");
+static const ngx_str_t  NGX_HTTP_PUSH_STREAM_WEBSOCKET_SUPPORTED_VERSIONS = ngx_string("8, 13");
+
+static const ngx_str_t  NGX_HTTP_PUSH_STREAM_101_STATUS_LINE = ngx_string("101 Switching Protocols");
+
+
+static const ngx_str_t  NGX_HTTP_PUSH_STREAM_MODE_NORMAL   = ngx_string("normal");
+static const ngx_str_t  NGX_HTTP_PUSH_STREAM_MODE_ADMIN    = ngx_string("admin");
+
+static const ngx_str_t  NGX_HTTP_PUSH_STREAM_MODE_STREAMING   = ngx_string("streaming");
+static const ngx_str_t  NGX_HTTP_PUSH_STREAM_MODE_POLLING     = ngx_string("polling");
+static const ngx_str_t  NGX_HTTP_PUSH_STREAM_MODE_LONGPOLLING = ngx_string("long-polling");
+static const ngx_str_t  NGX_HTTP_PUSH_STREAM_MODE_EVENTSOURCE = ngx_string("eventsource");
+static const ngx_str_t  NGX_HTTP_PUSH_STREAM_MODE_WEBSOCKET   = ngx_string("websocket");
+
+#define NGX_HTTP_PUSH_STREAM_SUBSCRIBER_MODE_STREAMING   0
+#define NGX_HTTP_PUSH_STREAM_SUBSCRIBER_MODE_POLLING     1
+#define NGX_HTTP_PUSH_STREAM_SUBSCRIBER_MODE_LONGPOLLING 2
+#define NGX_HTTP_PUSH_STREAM_SUBSCRIBER_MODE_EVENTSOURCE 3
+#define NGX_HTTP_PUSH_STREAM_SUBSCRIBER_MODE_WEBSOCKET   4
+
+#define NGX_HTTP_PUSH_STREAM_PUBLISHER_MODE_NORMAL       5
+#define NGX_HTTP_PUSH_STREAM_PUBLISHER_MODE_ADMIN        6
+#define NGX_HTTP_PUSH_STREAM_STATISTICS_MODE             7
+
+
+#define NGX_HTTP_PUSH_STREAM_WEBSOCKET_VERSION_8         8
+#define NGX_HTTP_PUSH_STREAM_WEBSOCKET_VERSION_13        13
+
+#define NGX_HTTP_PUSH_STREAM_WEBSOCKET_SHA1_SIGNED_HASH_LENGTH 20
+#define NGX_HTTP_PUSH_STREAM_WEBSOCKET_FRAME_HEADER_MAX_LENGTH 144
+
+#define NGX_HTTP_PUSH_STREAM_WEBSOCKET_LAST_FRAME   0x8
+
+#define NGX_HTTP_PUSH_STREAM_WEBSOCKET_TEXT_OPCODE  0x1
+#define NGX_HTTP_PUSH_STREAM_WEBSOCKET_CLOSE_OPCODE 0x8
+#define NGX_HTTP_PUSH_STREAM_WEBSOCKET_PING_OPCODE  0x9
+#define NGX_HTTP_PUSH_STREAM_WEBSOCKET_PONG_OPCODE  0xA
+
+static const u_char NGX_HTTP_PUSH_STREAM_WEBSOCKET_TEXT_LAST_FRAME_BYTE    =  NGX_HTTP_PUSH_STREAM_WEBSOCKET_TEXT_OPCODE  | (NGX_HTTP_PUSH_STREAM_WEBSOCKET_LAST_FRAME << 4);
+static const u_char NGX_HTTP_PUSH_STREAM_WEBSOCKET_CLOSE_LAST_FRAME_BYTE[] = {NGX_HTTP_PUSH_STREAM_WEBSOCKET_CLOSE_OPCODE | (NGX_HTTP_PUSH_STREAM_WEBSOCKET_LAST_FRAME << 4), 0x00};
+static const u_char NGX_HTTP_PUSH_STREAM_WEBSOCKET_PING_LAST_FRAME_BYTE[]  = {NGX_HTTP_PUSH_STREAM_WEBSOCKET_PING_OPCODE  | (NGX_HTTP_PUSH_STREAM_WEBSOCKET_LAST_FRAME << 4), 0x00};
+static const u_char NGX_HTTP_PUSH_STREAM_WEBSOCKET_PONG_LAST_FRAME_BYTE[]  = {NGX_HTTP_PUSH_STREAM_WEBSOCKET_PONG_OPCODE  | (NGX_HTTP_PUSH_STREAM_WEBSOCKET_LAST_FRAME << 4), 0x00};
+static const u_char NGX_HTTP_PUSH_STREAM_WEBSOCKET_PAYLOAD_LEN_16_BYTE   = 126;
+static const u_char NGX_HTTP_PUSH_STREAM_WEBSOCKET_PAYLOAD_LEN_64_BYTE   = 127;
+
+static const ngx_str_t NGX_HTTP_PUSH_STREAM_WEBSOCKET_CLOSE_REASON = ngx_string("\x03\xF0{\"http_status\": %d, \"explain\":\"%V\"}");
+
+
+// other stuff
+static const ngx_str_t  NGX_HTTP_PUSH_STREAM_ALLOW_GET_POST_PUT_DELETE_METHODS = ngx_string("GET, POST, PUT, DELETE");
+static const ngx_str_t  NGX_HTTP_PUSH_STREAM_ALLOW_GET_POST_PUT_METHODS = ngx_string("GET, POST, PUT");
+static const ngx_str_t  NGX_HTTP_PUSH_STREAM_ALLOW_GET = ngx_string("GET");
+
+static const ngx_str_t  NGX_HTTP_PUSH_STREAM_ALLOWED_HEADERS = ngx_string("If-Modified-Since,If-None-Match,Etag,Event-Id,Event-Type,Last-Event-Id");
+
+#define NGX_HTTP_PUSH_STREAM_CHECK_AND_FINALIZE_REQUEST_ON_ERROR(val, fail, r, errormessage) \
+    if (val == fail) {                                                       \
+        ngx_log_error(NGX_LOG_ERR, r->connection->log, 0, errormessage);     \
+        ngx_http_finalize_request(r, NGX_HTTP_INTERNAL_SERVER_ERROR);        \
+        return;                                                              \
+    }
+
+#define NGX_HTTP_PUSH_STREAM_CHECK_AND_FINALIZE_REQUEST_ON_ERROR_LOCKED(val, fail, r, errormessage) \
+    if (val == fail) {                                                       \
+        ngx_shmtx_unlock(&(shpool)->mutex);                                  \
+        ngx_log_error(NGX_LOG_ERR, r->connection->log, 0, errormessage);     \
+        ngx_http_finalize_request(r, NGX_HTTP_INTERNAL_SERVER_ERROR);        \
+        return;                                                              \
+    }
+
+#define NGX_HTTP_PUSH_STREAM_DECREMENT_COUNTER(counter) \
+    (counter = (counter > 1) ? counter - 1 : 0)
+
+#define NGX_HTTP_PUSH_STREAM_DECREMENT_COUNTER_BY(counter, qtd) \
+    (counter = (counter > qtd) ? counter - qtd : 0)
+
+#define NGX_HTTP_PUSH_STREAM_TIME_FMT_LEN   30 //sizeof("Mon, 28 Sep 1970 06:00:00 GMT")
+
+
+/**
+ * borrowed from Nginx core files
+ */
+typedef enum {
+    NGX_HTTP_PUSH_STREAM_EXPIRES_OFF,
+    NGX_HTTP_PUSH_STREAM_EXPIRES_EPOCH,
+    NGX_HTTP_PUSH_STREAM_EXPIRES_MAX,
+    NGX_HTTP_PUSH_STREAM_EXPIRES_ACCESS,
+    NGX_HTTP_PUSH_STREAM_EXPIRES_MODIFIED,
+    NGX_HTTP_PUSH_STREAM_EXPIRES_DAILY,
+    NGX_HTTP_PUSH_STREAM_EXPIRES_UNSET
+} ngx_http_push_stream_expires_t;
+
+
+#endif /* NGX_HTTP_PUSH_STREAM_MODULE_H_ */
diff -Naur nginx-1.11.3/nginx-push-stream-module/include/ngx_http_push_stream_module_ipc.h nginx-1.11.3-push/nginx-push-stream-module/include/ngx_http_push_stream_module_ipc.h
--- nginx-1.11.3/nginx-push-stream-module/include/ngx_http_push_stream_module_ipc.h	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/include/ngx_http_push_stream_module_ipc.h	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,77 @@
+/*
+ * This file is distributed under the MIT License.
+ *
+ * Copyright (c) 2009 Leo Ponomarev
+ *
+ * Permission is hereby granted, free of charge, to any person
+ * obtaining a copy of this software and associated documentation
+ * files (the "Software"), to deal in the Software without
+ * restriction, including without limitation the rights to use,
+ * copy, modify, merge, publish, distribute, sublicense, and/or sell
+ * copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following
+ * conditions:
+ *
+ * The above copyright notice and this permission notice shall be
+ * included in all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES
+ * OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
+ * HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,
+ * WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
+ * OTHER DEALINGS IN THE SOFTWARE.
+ *
+ *
+ * ngx_http_push_stream_module_ipc.h
+ *
+ * Modified: Oct 26, 2010
+ * Modifications by: Wandenberg Peixoto <wandenberg@gmail.com>, Rog√©rio Carvalho Schneider <stockrt@gmail.com>
+ */
+
+#ifndef NGX_HTTP_PUSH_STREAM_MODULE_IPC_H_
+#define NGX_HTTP_PUSH_STREAM_MODULE_IPC_H_
+
+#include <ngx_http_push_stream_module.h>
+#include <ngx_http_push_stream_module_subscriber.h>
+
+#include <ngx_channel.h>
+
+// constants
+static ngx_channel_t NGX_CMD_HTTP_PUSH_STREAM_CHECK_MESSAGES = {49, 0, 0, -1};
+static ngx_channel_t NGX_CMD_HTTP_PUSH_STREAM_CENSUS_SUBSCRIBERS = {50, 0, 0, -1};
+static ngx_channel_t NGX_CMD_HTTP_PUSH_STREAM_DELETE_CHANNEL = {51, 0, 0, -1};
+static ngx_channel_t NGX_CMD_HTTP_PUSH_STREAM_CLEANUP_SHUTTING_DOWN = {52, 0, 0, -1};
+
+// worker processes of the world, unite.
+ngx_socket_t    ngx_http_push_stream_socketpairs[NGX_MAX_PROCESSES][2];
+
+static ngx_int_t    ngx_http_push_stream_register_worker_message_handler(ngx_cycle_t *cycle);
+
+static void    ngx_http_push_stream_broadcast(ngx_http_push_stream_channel_t *channel, ngx_http_push_stream_msg_t *msg, ngx_log_t *log, ngx_http_push_stream_main_conf_t *mcf);
+
+static ngx_int_t        ngx_http_push_stream_alert_worker(ngx_pid_t pid, ngx_int_t slot, ngx_log_t *log, ngx_channel_t command);
+#define ngx_http_push_stream_alert_worker_check_messages(pid, slot, log) ngx_http_push_stream_alert_worker(pid, slot, log, NGX_CMD_HTTP_PUSH_STREAM_CHECK_MESSAGES)
+#define ngx_http_push_stream_alert_worker_census_subscribers(pid, slot, log) ngx_http_push_stream_alert_worker(pid, slot, log, NGX_CMD_HTTP_PUSH_STREAM_CENSUS_SUBSCRIBERS)
+#define ngx_http_push_stream_alert_worker_delete_channel(pid, slot, log) ngx_http_push_stream_alert_worker(pid, slot, log, NGX_CMD_HTTP_PUSH_STREAM_DELETE_CHANNEL)
+#define ngx_http_push_stream_alert_worker_shutting_down_cleanup(pid, slot, log) ngx_http_push_stream_alert_worker(pid, slot, log, NGX_CMD_HTTP_PUSH_STREAM_CLEANUP_SHUTTING_DOWN)
+
+static ngx_int_t        ngx_http_push_stream_send_worker_message(ngx_http_push_stream_channel_t *channel, ngx_queue_t *subscriptions_sentinel, ngx_pid_t pid, ngx_int_t worker_slot, ngx_http_push_stream_msg_t *msg, ngx_flag_t *queue_was_empty, ngx_log_t *log, ngx_http_push_stream_main_conf_t *mcf);
+
+static ngx_int_t        ngx_http_push_stream_init_ipc(ngx_cycle_t *cycle, ngx_int_t workers);
+static void             ngx_http_push_stream_ipc_exit_worker(ngx_cycle_t *cycle);
+static ngx_int_t        ngx_http_push_stream_ipc_init_worker(void);
+static void             ngx_http_push_stream_clean_worker_data(ngx_http_push_stream_shm_data_t *data);
+static void             ngx_http_push_stream_channel_handler(ngx_event_t *ev);
+static void             ngx_http_push_stream_alert_shutting_down_workers(void);
+
+
+static ngx_inline void  ngx_http_push_stream_process_worker_message(void);
+static ngx_inline void  ngx_http_push_stream_census_worker_subscribers(void);
+static ngx_inline void  ngx_http_push_stream_cleanup_shutting_down_worker(void);
+
+static ngx_int_t    ngx_http_push_stream_respond_to_subscribers(ngx_http_push_stream_channel_t *channel, ngx_queue_t *subscriptions, ngx_http_push_stream_msg_t *msg);
+
+#endif /* NGX_HTTP_PUSH_STREAM_MODULE_IPC_H_ */
diff -Naur nginx-1.11.3/nginx-push-stream-module/include/ngx_http_push_stream_module_publisher.h nginx-1.11.3-push/nginx-push-stream-module/include/ngx_http_push_stream_module_publisher.h
--- nginx-1.11.3/nginx-push-stream-module/include/ngx_http_push_stream_module_publisher.h	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/include/ngx_http_push_stream_module_publisher.h	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,36 @@
+/*
+ * Copyright (C) 2010-2015 Wandenberg Peixoto <wandenberg@gmail.com>, Rog√©rio Carvalho Schneider <stockrt@gmail.com>
+ *
+ * This file is part of Nginx Push Stream Module.
+ *
+ * Nginx Push Stream Module is free software: you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation, either version 3 of the License, or
+ * (at your option) any later version.
+ *
+ * Nginx Push Stream Module is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with Nginx Push Stream Module.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ *
+ * ngx_http_push_stream_module_publisher.h
+ *
+ * Created: Oct 26, 2010
+ * Authors: Wandenberg Peixoto <wandenberg@gmail.com>, Rog√©rio Carvalho Schneider <stockrt@gmail.com>
+ */
+
+#ifndef NGX_HTTP_PUSH_STREAM_MODULE_PUBLISHER_H_
+#define NGX_HTTP_PUSH_STREAM_MODULE_PUBLISHER_H_
+
+#include <ngx_http_push_stream_module.h>
+
+static ngx_int_t    ngx_http_push_stream_channels_statistics_handler(ngx_http_request_t *r);
+static ngx_int_t    ngx_http_push_stream_publisher_handler(ngx_http_request_t *r);
+static void         ngx_http_push_stream_publisher_body_handler(ngx_http_request_t *r);
+static void         ngx_http_push_stream_publisher_delete_handler(ngx_http_request_t *r);
+
+#endif /* NGX_HTTP_PUSH_STREAM_MODULE_PUBLISHER_H_ */
diff -Naur nginx-1.11.3/nginx-push-stream-module/include/ngx_http_push_stream_module_setup.h nginx-1.11.3-push/nginx-push-stream-module/include/ngx_http_push_stream_module_setup.h
--- nginx-1.11.3/nginx-push-stream-module/include/ngx_http_push_stream_module_setup.h	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/include/ngx_http_push_stream_module_setup.h	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,83 @@
+/*
+ * Copyright (C) 2010-2015 Wandenberg Peixoto <wandenberg@gmail.com>, Rog√©rio Carvalho Schneider <stockrt@gmail.com>
+ *
+ * This file is part of Nginx Push Stream Module.
+ *
+ * Nginx Push Stream Module is free software: you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation, either version 3 of the License, or
+ * (at your option) any later version.
+ *
+ * Nginx Push Stream Module is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with Nginx Push Stream Module.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ *
+ * ngx_http_push_stream_module_setup.h
+ *
+ * Created: Oct 26, 2010
+ * Authors: Wandenberg Peixoto <wandenberg@gmail.com>, Rog√©rio Carvalho Schneider <stockrt@gmail.com>
+ */
+
+#ifndef NGX_HTTP_PUSH_STREAM_MODULE_SETUP_H_
+#define NGX_HTTP_PUSH_STREAM_MODULE_SETUP_H_
+
+#include <ngx_http_push_stream_module.h>
+#include <ngx_http_push_stream_rbtree_util.h>
+#include <ngx_http_push_stream_module_utils.h>
+#include <ngx_http_push_stream_module_ipc.h>
+#include <ngx_http_push_stream_module_publisher.h>
+#include <ngx_http_push_stream_module_subscriber.h>
+#include <ngx_http_push_stream_module_websocket.h>
+
+#define NGX_HTTP_PUSH_STREAM_MESSAGE_BUFFER_CLEANUP_INTERVAL                5000     // 5 seconds
+static time_t NGX_HTTP_PUSH_STREAM_DEFAULT_SHM_MEMORY_CLEANUP_OBJECTS_TTL = 10;      // 10 seconds
+static time_t NGX_HTTP_PUSH_STREAM_DEFAULT_SHM_MEMORY_CLEANUP_INTERVAL    = 4000;    // 4 seconds
+static time_t NGX_HTTP_PUSH_STREAM_DEFAULT_MESSAGE_TTL                    = 1800;    // 30 minutes
+static time_t NGX_HTTP_PUSH_STREAM_DEFAULT_CHANNEL_INACTIVITY_TIME        = 30;      // 30 seconds
+
+#define NGX_HTTP_PUSH_STREAM_DEFAULT_HEADER_TEMPLATE  ""
+#define NGX_HTTP_PUSH_STREAM_DEFAULT_MESSAGE_TEMPLATE "~text~"
+#define NGX_HTTP_PUSH_STREAM_DEFAULT_FOOTER_TEMPLATE  ""
+
+#define NGX_HTTP_PUSH_STREAM_DEFAULT_ALLOWED_ORIGINS  ""
+
+#define NGX_HTTP_PUSH_STREAM_DEFAULT_PADDING_BY_USER_AGENT  ""
+
+#define NGX_HTTP_PUSH_STREAM_DEFAULT_WILDCARD_CHANNEL_PREFIX ""
+
+#define NGX_HTTP_PUSH_STREAM_DEFAULT_EVENTS_CHANNEL_ID ""
+
+static char *       ngx_http_push_stream_channels_statistics(ngx_conf_t *cf, ngx_command_t *cmd, void *conf);
+
+// publisher
+static char *       ngx_http_push_stream_publisher(ngx_conf_t *cf, ngx_command_t *cmd, void *conf);
+
+// subscriber
+static char *       ngx_http_push_stream_subscriber(ngx_conf_t *cf, ngx_command_t *cmd, void *conf);
+
+// setup
+static char *       ngx_http_push_stream_setup_handler(ngx_conf_t *cf, void *conf, ngx_int_t (*handler) (ngx_http_request_t *));
+static ngx_int_t    ngx_http_push_stream_init_module(ngx_cycle_t *cycle);
+static ngx_int_t    ngx_http_push_stream_init_worker(ngx_cycle_t *cycle);
+static void         ngx_http_push_stream_exit_worker(ngx_cycle_t *cycle);
+static void         ngx_http_push_stream_exit_master(ngx_cycle_t *cycle);
+static ngx_int_t    ngx_http_push_stream_preconfig(ngx_conf_t *cf);
+static ngx_int_t    ngx_http_push_stream_postconfig(ngx_conf_t *cf);
+static void *       ngx_http_push_stream_create_main_conf(ngx_conf_t *cf);
+static char *       ngx_http_push_stream_init_main_conf(ngx_conf_t *cf, void *parent);
+static void *       ngx_http_push_stream_create_loc_conf(ngx_conf_t *cf);
+static char *       ngx_http_push_stream_merge_loc_conf(ngx_conf_t *cf, void *parent, void *child);
+
+// shared memory
+char *              ngx_http_push_stream_set_shm_size_slot(ngx_conf_t *cf, ngx_command_t *cmd, void *conf);
+ngx_int_t           ngx_http_push_stream_init_shm_zone(ngx_shm_zone_t *shm_zone, void *data);
+ngx_int_t           ngx_http_push_stream_init_global_shm_zone(ngx_shm_zone_t *shm_zone, void *data);
+
+char *              ngx_http_push_stream_set_header_template_from_file(ngx_conf_t *cf, ngx_command_t *cmd, void *conf);
+
+#endif /* NGX_HTTP_PUSH_STREAM_MODULE_SETUP_H_ */
diff -Naur nginx-1.11.3/nginx-push-stream-module/include/ngx_http_push_stream_module_subscriber.h nginx-1.11.3-push/nginx-push-stream-module/include/ngx_http_push_stream_module_subscriber.h
--- nginx-1.11.3/nginx-push-stream-module/include/ngx_http_push_stream_module_subscriber.h	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/include/ngx_http_push_stream_module_subscriber.h	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,32 @@
+/*
+ * Copyright (C) 2010-2015 Wandenberg Peixoto <wandenberg@gmail.com>, Rog√©rio Carvalho Schneider <stockrt@gmail.com>
+ *
+ * This file is part of Nginx Push Stream Module.
+ *
+ * Nginx Push Stream Module is free software: you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation, either version 3 of the License, or
+ * (at your option) any later version.
+ *
+ * Nginx Push Stream Module is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with Nginx Push Stream Module.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ *
+ * ngx_http_push_stream_module_subscriber.h
+ *
+ * Created: Oct 26, 2010
+ * Authors: Wandenberg Peixoto <wandenberg@gmail.com>, Rog√©rio Carvalho Schneider <stockrt@gmail.com>
+ */
+
+#ifndef NGX_HTTP_PUSH_STREAM_MODULE_SUBSCRIBER_H_
+#define NGX_HTTP_PUSH_STREAM_MODULE_SUBSCRIBER_H_
+
+static ngx_int_t    ngx_http_push_stream_subscriber_handler(ngx_http_request_t *r);
+static ngx_int_t    ngx_http_push_stream_validate_channels(ngx_http_request_t *r, ngx_http_push_stream_requested_channel_t *channels_ids, ngx_int_t *status_code, ngx_str_t **explain_error_message);
+
+#endif /* NGX_HTTP_PUSH_STREAM_MODULE_SUBSCRIBER_H_ */
diff -Naur nginx-1.11.3/nginx-push-stream-module/include/ngx_http_push_stream_module_utils.h nginx-1.11.3-push/nginx-push-stream-module/include/ngx_http_push_stream_module_utils.h
--- nginx-1.11.3/nginx-push-stream-module/include/ngx_http_push_stream_module_utils.h	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/include/ngx_http_push_stream_module_utils.h	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,314 @@
+/*
+ * Copyright (C) 2010-2015 Wandenberg Peixoto <wandenberg@gmail.com>, Rog√©rio Carvalho Schneider <stockrt@gmail.com>
+ *
+ * This file is part of Nginx Push Stream Module.
+ *
+ * Nginx Push Stream Module is free software: you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation, either version 3 of the License, or
+ * (at your option) any later version.
+ *
+ * Nginx Push Stream Module is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with Nginx Push Stream Module.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ *
+ * ngx_http_push_stream_module_utils.h
+ *
+ * Created: Oct 26, 2010
+ * Authors: Wandenberg Peixoto <wandenberg@gmail.com>, Rog√©rio Carvalho Schneider <stockrt@gmail.com>
+ */
+
+#ifndef NGX_HTTP_PUSH_STREAM_MODULE_UTILS_H_
+#define NGX_HTTP_PUSH_STREAM_MODULE_UTILS_H_
+
+#include <ngx_http_push_stream_module.h>
+#include <ngx_http_push_stream_module_ipc.h>
+
+typedef struct {
+    ngx_queue_t           queue;
+    ngx_str_t            *line;
+} ngx_http_push_stream_line_t;
+
+typedef struct {
+    char                 *subtype;
+    size_t                len;
+    ngx_str_t            *content_type;
+    ngx_str_t            *format_item;
+    ngx_str_t            *format_group_head;
+    ngx_str_t            *format_group_item;
+    ngx_str_t            *format_group_last_item;
+    ngx_str_t            *format_group_tail;
+    ngx_str_t            *format_summarized;
+    ngx_str_t            *format_summarized_worker_item;
+    ngx_str_t            *format_summarized_worker_last_item;
+} ngx_http_push_stream_content_subtype_t;
+
+
+#define  NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_PLAIN_PATTERN "channel: %s" CRLF"published_messages: %ui" CRLF"stored_messages: %ui" CRLF"active_subscribers: %ui"
+#define  NGX_HTTP_PUSH_STREAM_WORKER_INFO_PLAIN_PATTERN "  pid: %d" CRLF"  subscribers: %ui" CRLF"  uptime: %ui"
+static ngx_str_t  NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_PLAIN = ngx_string(NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_PLAIN_PATTERN CRLF);
+static ngx_str_t  NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_GROUP_HEAD_PLAIN = ngx_string("hostname: %s, time: %s, channels: %ui, wildcard_channels: %ui, uptime: %ui, infos: " CRLF);
+static ngx_str_t  NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_GROUP_TAIL_PLAIN = ngx_string(CRLF);
+static ngx_str_t  NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_GROUP_ITEM_PLAIN = ngx_string(NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_PLAIN_PATTERN "," CRLF);
+static ngx_str_t  NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_GROUP_LAST_ITEM_PLAIN = ngx_string(NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_PLAIN_PATTERN);
+static ngx_str_t  NGX_HTTP_PUSH_STREAM_CHANNELS_INFO_SUMMARIZED_PLAIN = ngx_string("hostname: %s" CRLF "time: %s" CRLF "channels: %ui" CRLF "wildcard_channels: %ui" CRLF "published_messages: %ui" CRLF "stored_messages: %ui" CRLF "messages_in_trash: %ui" CRLF "channels_in_trash: %ui" CRLF "subscribers: %ui" CRLF "uptime: %ui" CRLF "by_worker:"CRLF"%s" CRLF);
+static ngx_str_t  NGX_HTTP_PUSH_STREAM_CHANNELS_INFO_SUMMARIZED_WORKER_ITEM_PLAIN = ngx_string(NGX_HTTP_PUSH_STREAM_WORKER_INFO_PLAIN_PATTERN "," CRLF);
+static ngx_str_t  NGX_HTTP_PUSH_STREAM_CHANNELS_INFO_SUMMARIZED_WORKER_LAST_ITEM_PLAIN = ngx_string(NGX_HTTP_PUSH_STREAM_WORKER_INFO_PLAIN_PATTERN);
+static ngx_str_t  NGX_HTTP_PUSH_STREAM_CONTENT_TYPE_PLAIN = ngx_string("text/plain");
+
+
+#define  NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_JSON_PATTERN "{\"channel\": \"%s\", \"published_messages\": %ui, \"stored_messages\": %ui, \"subscribers\": %ui}"
+#define  NGX_HTTP_PUSH_STREAM_WORKER_INFO_JSON_PATTERN "{\"pid\": \"%d\", \"subscribers\": %ui, \"uptime\": %ui}"
+static ngx_str_t  NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_JSON = ngx_string(NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_JSON_PATTERN CRLF);
+static ngx_str_t  NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_GROUP_HEAD_JSON = ngx_string("{\"hostname\": \"%s\", \"time\": \"%s\", \"channels\": %ui, \"wildcard_channels\": %ui, \"uptime\": %ui, \"infos\": [" CRLF);
+static ngx_str_t  NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_GROUP_TAIL_JSON = ngx_string("]}" CRLF);
+static ngx_str_t  NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_GROUP_ITEM_JSON = ngx_string(NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_JSON_PATTERN "," CRLF);
+static ngx_str_t  NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_GROUP_LAST_ITEM_JSON = ngx_string(NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_JSON_PATTERN CRLF);
+static ngx_str_t  NGX_HTTP_PUSH_STREAM_CHANNELS_INFO_SUMMARIZED_JSON = ngx_string("{\"hostname\": \"%s\", \"time\": \"%s\", \"channels\": %ui, \"wildcard_channels\": %ui, \"published_messages\": %ui, \"stored_messages\": %ui, \"messages_in_trash\": %ui, \"channels_in_trash\": %ui, \"subscribers\": %ui, \"uptime\": %ui, \"by_worker\": [" CRLF "%s" CRLF"]}" CRLF);
+static ngx_str_t  NGX_HTTP_PUSH_STREAM_CHANNELS_INFO_SUMMARIZED_WORKER_ITEM_JSON = ngx_string(NGX_HTTP_PUSH_STREAM_WORKER_INFO_JSON_PATTERN "," CRLF);
+static ngx_str_t  NGX_HTTP_PUSH_STREAM_CHANNELS_INFO_SUMMARIZED_WORKER_LAST_ITEM_JSON = ngx_string(NGX_HTTP_PUSH_STREAM_WORKER_INFO_JSON_PATTERN);
+static ngx_str_t  NGX_HTTP_PUSH_STREAM_CONTENT_TYPE_JSON = ngx_string("application/json");
+static ngx_str_t  NGX_HTTP_PUSH_STREAM_CONTENT_TYPE_X_JSON = ngx_string("text/x-json");
+
+#define  NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_YAML_PATTERN "  channel: %s" CRLF"  published_messages: %ui" CRLF"  stored_messages: %ui" CRLF"  subscribers: %ui"
+#define  NGX_HTTP_PUSH_STREAM_WORKER_INFO_YAML_PATTERN "    pid: %d" CRLF"    subscribers: %ui" CRLF"    uptime: %ui"
+static ngx_str_t  NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_YAML = ngx_string(NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_YAML_PATTERN CRLF);
+static ngx_str_t  NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_GROUP_HEAD_YAML = ngx_string("hostname: %s" CRLF"time: %s" CRLF"channels: %ui" CRLF"wildcard_channels: %ui" CRLF"uptime: %ui" CRLF"infos: "CRLF);
+static ngx_str_t  NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_GROUP_TAIL_YAML = ngx_string(CRLF);
+static ngx_str_t  NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_GROUP_ITEM_YAML = ngx_string(" -" CRLF NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_YAML_PATTERN CRLF);
+static ngx_str_t  NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_GROUP_LAST_ITEM_YAML = ngx_string(" -" CRLF NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_YAML_PATTERN);
+static ngx_str_t  NGX_HTTP_PUSH_STREAM_CHANNELS_INFO_SUMMARIZED_YAML = ngx_string("  hostname: %s" CRLF"  time: %s" CRLF"  channels: %ui" CRLF"  wildcard_channels: %ui" CRLF"  published_messages: %ui" CRLF"  stored_messages: %ui" CRLF"  messages_in_trash: %ui" CRLF"  channels_in_trash: %ui" CRLF"  subscribers: %ui" CRLF"  uptime: %ui" CRLF"  by_worker:"CRLF"%s" CRLF);
+static ngx_str_t  NGX_HTTP_PUSH_STREAM_CHANNELS_INFO_SUMMARIZED_WORKER_ITEM_YAML = ngx_string("   -" CRLF NGX_HTTP_PUSH_STREAM_WORKER_INFO_YAML_PATTERN CRLF);
+static ngx_str_t  NGX_HTTP_PUSH_STREAM_CHANNELS_INFO_SUMMARIZED_WORKER_LAST_ITEM_YAML = ngx_string("   -" CRLF NGX_HTTP_PUSH_STREAM_WORKER_INFO_YAML_PATTERN);
+static ngx_str_t  NGX_HTTP_PUSH_STREAM_CONTENT_TYPE_YAML = ngx_string("application/yaml");
+static ngx_str_t  NGX_HTTP_PUSH_STREAM_CONTENT_TYPE_X_YAML = ngx_string("text/x-yaml");
+
+
+#define  NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_XML_PATTERN \
+    "<channel>" CRLF \
+    "  <name>%s</name>" CRLF \
+    "  <published_messages>%ui</published_messages>" CRLF \
+    "  <stored_messages>%ui</stored_messages>" CRLF \
+    "  <subscribers>%ui</subscribers>" CRLF \
+    "</channel>" CRLF
+#define  NGX_HTTP_PUSH_STREAM_WORKER_INFO_XML_PATTERN \
+    "<worker>" CRLF \
+    "  <pid>%d</pid>" CRLF \
+    "  <subscribers>%ui</subscribers>" CRLF \
+    "  <uptime>%ui</uptime>" CRLF \
+    "</worker>" CRLF
+static ngx_str_t  NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_XML = ngx_string("<?xml version=\"1.0\" encoding=\"UTF-8\" ?>" CRLF NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_XML_PATTERN CRLF);
+static ngx_str_t  NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_GROUP_HEAD_XML = ngx_string("<?xml version=\"1.0\" encoding=\"UTF-8\" ?>" CRLF "<root>" CRLF"  <hostname>%s</hostname>" CRLF"  <time>%s</time>" CRLF"  <channels>%ui</channels>" CRLF"  <wildcard_channels>%ui</wildcard_channels>" CRLF"  <uptime>%ui</uptime>" CRLF"  <infos>" CRLF);
+static ngx_str_t  NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_GROUP_TAIL_XML = ngx_string("  </infos>" CRLF"</root>" CRLF);
+static ngx_str_t  NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_GROUP_ITEM_XML = ngx_string(NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_XML_PATTERN);
+static ngx_str_t  NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_GROUP_LAST_ITEM_XML = ngx_string(NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_XML_PATTERN);
+static ngx_str_t  NGX_HTTP_PUSH_STREAM_CHANNELS_INFO_SUMMARIZED_XML = ngx_string(
+        "<?xml version=\"1.0\" encoding=\"UTF-8\" ?>" CRLF \
+        "<infos>" CRLF \
+        "  <hostname>%s</hostname>" CRLF \
+        "  <time>%s</time>" CRLF \
+        "  <channels>%ui</channels>" CRLF \
+        "  <wildcard_channels>%ui</wildcard_channels>" CRLF \
+        "  <published_messages>%ui</published_messages>" CRLF \
+        "  <stored_messages>%ui</stored_messages>" CRLF \
+        "  <messages_in_trash>%ui</messages_in_trash>" CRLF \
+        "  <channels_in_trash>%ui</channels_in_trash>" CRLF \
+        "  <subscribers>%ui</subscribers>" CRLF \
+        "  <uptime>%ui</uptime>" CRLF \
+        "  <by_worker>%s</by_worker>" CRLF \
+        "</infos>" CRLF);
+static ngx_str_t  NGX_HTTP_PUSH_STREAM_CHANNELS_INFO_SUMMARIZED_WORKER_ITEM_XML = ngx_string(NGX_HTTP_PUSH_STREAM_WORKER_INFO_XML_PATTERN);
+static ngx_str_t  NGX_HTTP_PUSH_STREAM_CHANNELS_INFO_SUMMARIZED_WORKER_LAST_ITEM_XML = ngx_string(NGX_HTTP_PUSH_STREAM_WORKER_INFO_XML_PATTERN);
+static ngx_str_t  NGX_HTTP_PUSH_STREAM_CONTENT_TYPE_XML = ngx_string("application/xml");
+
+static ngx_http_push_stream_content_subtype_t subtypes[] = {
+    { "plain" , 5,
+            &NGX_HTTP_PUSH_STREAM_CONTENT_TYPE_PLAIN,
+            &NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_PLAIN,
+            &NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_GROUP_HEAD_PLAIN,
+            &NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_GROUP_ITEM_PLAIN,
+            &NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_GROUP_LAST_ITEM_PLAIN,
+            &NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_GROUP_TAIL_PLAIN,
+            &NGX_HTTP_PUSH_STREAM_CHANNELS_INFO_SUMMARIZED_PLAIN,
+            &NGX_HTTP_PUSH_STREAM_CHANNELS_INFO_SUMMARIZED_WORKER_ITEM_PLAIN,
+            &NGX_HTTP_PUSH_STREAM_CHANNELS_INFO_SUMMARIZED_WORKER_LAST_ITEM_PLAIN},
+    { "json"  , 4,
+            &NGX_HTTP_PUSH_STREAM_CONTENT_TYPE_JSON,
+            &NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_JSON,
+            &NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_GROUP_HEAD_JSON,
+            &NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_GROUP_ITEM_JSON,
+            &NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_GROUP_LAST_ITEM_JSON,
+            &NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_GROUP_TAIL_JSON,
+            &NGX_HTTP_PUSH_STREAM_CHANNELS_INFO_SUMMARIZED_JSON,
+            &NGX_HTTP_PUSH_STREAM_CHANNELS_INFO_SUMMARIZED_WORKER_ITEM_JSON,
+            &NGX_HTTP_PUSH_STREAM_CHANNELS_INFO_SUMMARIZED_WORKER_LAST_ITEM_JSON },
+    { "yaml"  , 4,
+            &NGX_HTTP_PUSH_STREAM_CONTENT_TYPE_YAML,
+            &NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_YAML,
+            &NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_GROUP_HEAD_YAML,
+            &NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_GROUP_ITEM_YAML,
+            &NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_GROUP_LAST_ITEM_YAML,
+            &NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_GROUP_TAIL_YAML,
+            &NGX_HTTP_PUSH_STREAM_CHANNELS_INFO_SUMMARIZED_YAML,
+            &NGX_HTTP_PUSH_STREAM_CHANNELS_INFO_SUMMARIZED_WORKER_ITEM_YAML,
+            &NGX_HTTP_PUSH_STREAM_CHANNELS_INFO_SUMMARIZED_WORKER_LAST_ITEM_YAML },
+    { "xml"   , 3,
+            &NGX_HTTP_PUSH_STREAM_CONTENT_TYPE_XML,
+            &NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_XML,
+            &NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_GROUP_HEAD_XML,
+            &NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_GROUP_ITEM_XML,
+            &NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_GROUP_LAST_ITEM_XML,
+            &NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_GROUP_TAIL_XML,
+            &NGX_HTTP_PUSH_STREAM_CHANNELS_INFO_SUMMARIZED_XML,
+            &NGX_HTTP_PUSH_STREAM_CHANNELS_INFO_SUMMARIZED_WORKER_ITEM_XML,
+            &NGX_HTTP_PUSH_STREAM_CHANNELS_INFO_SUMMARIZED_WORKER_LAST_ITEM_XML },
+    { "x-json", 6,
+            &NGX_HTTP_PUSH_STREAM_CONTENT_TYPE_X_JSON,
+            &NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_JSON,
+            &NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_GROUP_HEAD_JSON,
+            &NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_GROUP_ITEM_JSON,
+            &NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_GROUP_LAST_ITEM_JSON,
+            &NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_GROUP_TAIL_JSON,
+            &NGX_HTTP_PUSH_STREAM_CHANNELS_INFO_SUMMARIZED_JSON,
+            &NGX_HTTP_PUSH_STREAM_CHANNELS_INFO_SUMMARIZED_WORKER_ITEM_JSON,
+            &NGX_HTTP_PUSH_STREAM_CHANNELS_INFO_SUMMARIZED_WORKER_LAST_ITEM_JSON },
+    { "x-yaml", 6,
+            &NGX_HTTP_PUSH_STREAM_CONTENT_TYPE_X_YAML,
+            &NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_YAML,
+            &NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_GROUP_HEAD_YAML,
+            &NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_GROUP_ITEM_YAML,
+            &NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_GROUP_LAST_ITEM_YAML,
+            &NGX_HTTP_PUSH_STREAM_CHANNEL_INFO_GROUP_TAIL_YAML,
+            &NGX_HTTP_PUSH_STREAM_CHANNELS_INFO_SUMMARIZED_YAML,
+            &NGX_HTTP_PUSH_STREAM_CHANNELS_INFO_SUMMARIZED_WORKER_ITEM_YAML,
+            &NGX_HTTP_PUSH_STREAM_CHANNELS_INFO_SUMMARIZED_WORKER_LAST_ITEM_YAML }
+};
+
+static const ngx_int_t  NGX_HTTP_PUSH_STREAM_PING_MESSAGE_ID = -1;
+#define NGX_HTTP_PUSH_STREAM_PING_MESSAGE_TEXT " "
+
+static const ngx_int_t  NGX_HTTP_PUSH_STREAM_CHANNEL_DELETED_MESSAGE_ID = -2;
+#define NGX_HTTP_PUSH_STREAM_CHANNEL_DELETED_MESSAGE_TEXT "Channel deleted"
+
+static const ngx_int_t  NGX_HTTP_PUSH_STREAM_LONGPOOLING_TIMEOUT_MESSAGE_ID = -3;
+#define NGX_HTTP_PUSH_STREAM_LONGPOOLING_TIMEOUT_MESSAGE_TEXT "Timed out"
+
+static const ngx_str_t  NGX_HTTP_PUSH_STREAM_TOKEN_MESSAGE_ID = ngx_string("~id~");
+static const ngx_str_t  NGX_HTTP_PUSH_STREAM_TOKEN_MESSAGE_EVENT_ID = ngx_string("~event-id~");
+static const ngx_str_t  NGX_HTTP_PUSH_STREAM_TOKEN_MESSAGE_EVENT_TYPE = ngx_string("~event-type~");
+static const ngx_str_t  NGX_HTTP_PUSH_STREAM_TOKEN_MESSAGE_CHANNEL = ngx_string("~channel~");
+static const ngx_str_t  NGX_HTTP_PUSH_STREAM_TOKEN_MESSAGE_TEXT = ngx_string("~text~");
+static const ngx_str_t  NGX_HTTP_PUSH_STREAM_TOKEN_MESSAGE_SIZE = ngx_string("~size~");
+static const ngx_str_t  NGX_HTTP_PUSH_STREAM_TOKEN_MESSAGE_TAG = ngx_string("~tag~");
+static const ngx_str_t  NGX_HTTP_PUSH_STREAM_TOKEN_MESSAGE_TIME = ngx_string("~time~");
+
+static const ngx_str_t  NGX_HTTP_PUSH_STREAM_EVENTSOURCE_COMMENT_PREFIX = ngx_string(": ");
+static const ngx_str_t  NGX_HTTP_PUSH_STREAM_EVENTSOURCE_DEFAULT_HEADER_TEMPLATE = ngx_string(": \n");
+static const ngx_str_t  NGX_HTTP_PUSH_STREAM_EVENTSOURCE_COMMENT_TEMPLATE = ngx_string(": ~text~\n");
+static const ngx_str_t  NGX_HTTP_PUSH_STREAM_EVENTSOURCE_MESSAGE_PREFIX = ngx_string("data: ");
+static const ngx_str_t  NGX_HTTP_PUSH_STREAM_EVENTSOURCE_ID_TEMPLATE = ngx_string("id: ~event-id~\n");
+static const ngx_str_t  NGX_HTTP_PUSH_STREAM_EVENTSOURCE_EVENT_TEMPLATE = ngx_string("event: ~event-type~\n");
+static const ngx_str_t  NGX_HTTP_PUSH_STREAM_EVENTSOURCE_CONTENT_TYPE = ngx_string("text/event-stream; charset=utf-8");
+static const ngx_str_t  NGX_HTTP_PUSH_STREAM_EVENTSOURCE_PING_MESSAGE_CHUNK = ngx_string(": -1\n");
+
+static const ngx_str_t  NGX_HTTP_PUSH_STREAM_CALLBACK_INIT_CHUNK = ngx_string("([");
+static const ngx_str_t  NGX_HTTP_PUSH_STREAM_CALLBACK_MID_CHUNK = ngx_string(",");
+static const ngx_str_t  NGX_HTTP_PUSH_STREAM_CALLBACK_END_CHUNK = ngx_string("]);");
+static const ngx_str_t  NGX_HTTP_PUSH_STREAM_CALLBACK_CONTENT_TYPE = ngx_string("application/javascript");
+
+static const ngx_str_t  NGX_HTTP_PUSH_STREAM_PADDING_BY_USER_AGENT_PATTERN = ngx_string("([^:]+),(\\d+),(\\d+)");
+
+#define NGX_HTTP_PUSH_STREAM_EVENT_TEMPLATE "{\"type\": \"%V\", \"channel\": \"%V\"}%Z"
+static ngx_str_t  NGX_HTTP_PUSH_STREAM_EVENT_TYPE_CHANNEL_CREATED = ngx_string("channel_created");
+static ngx_str_t  NGX_HTTP_PUSH_STREAM_EVENT_TYPE_CHANNEL_DESTROYED = ngx_string("channel_destroyed");
+static ngx_str_t  NGX_HTTP_PUSH_STREAM_EVENT_TYPE_CLIENT_SUBSCRIBED = ngx_string("client_subscribed");
+static ngx_str_t  NGX_HTTP_PUSH_STREAM_EVENT_TYPE_CLIENT_UNSUBSCRIBED = ngx_string("client_unsubscribed");
+
+
+ngx_event_t         ngx_http_push_stream_memory_cleanup_event;
+ngx_event_t         ngx_http_push_stream_buffer_cleanup_event;
+
+// general request handling
+ngx_http_push_stream_msg_t *ngx_http_push_stream_convert_char_to_msg_on_shared(ngx_http_push_stream_main_conf_t *mcf, u_char *data, size_t len, ngx_http_push_stream_channel_t *channel, ngx_int_t id, ngx_str_t *event_id, ngx_str_t *event_type, ngx_pool_t *temp_pool);
+static ngx_int_t            ngx_http_push_stream_send_only_added_headers(ngx_http_request_t *r);
+static void                 ngx_http_push_stream_add_polling_headers(ngx_http_request_t *r, time_t last_modified_time, ngx_int_t tag, ngx_pool_t *temp_pool);
+static void                 ngx_http_push_stream_get_last_received_message_values(ngx_http_request_t *r, time_t *if_modified_since, ngx_int_t *tag, ngx_str_t **last_event_id);
+static ngx_table_elt_t *    ngx_http_push_stream_add_response_header(ngx_http_request_t *r, const ngx_str_t *header_name, const ngx_str_t *header_value);
+static ngx_str_t *          ngx_http_push_stream_get_header(ngx_http_request_t *r, const ngx_str_t *header_name);
+static ngx_int_t            ngx_http_push_stream_send_only_header_response(ngx_http_request_t *r, ngx_int_t status, const ngx_str_t *explain_error_message);
+static ngx_int_t            ngx_http_push_stream_send_only_header_response_and_finalize(ngx_http_request_t *r, ngx_int_t status, const ngx_str_t *explain_error_message);
+static ngx_str_t *          ngx_http_push_stream_str_replace(const ngx_str_t *org, const ngx_str_t *find, const ngx_str_t *replace, off_t offset, ngx_pool_t *temp_pool);
+static ngx_str_t *          ngx_http_push_stream_get_formatted_websocket_frame(const u_char *opcode, off_t opcode_len, const u_char *text, off_t text_len, ngx_pool_t *temp_pool);
+static ngx_str_t *          ngx_http_push_stream_get_formatted_message(ngx_http_request_t *r, ngx_http_push_stream_channel_t *channel, ngx_http_push_stream_msg_t *msg);
+static ngx_str_t *          ngx_http_push_stream_format_message(ngx_http_push_stream_channel_t *channel, ngx_http_push_stream_msg_t *message, ngx_str_t *text, ngx_http_push_stream_template_t *template, ngx_pool_t *temp_pool);
+static ngx_str_t *          ngx_http_push_stream_apply_template_to_each_line(ngx_str_t *text, const ngx_str_t *message_template, ngx_pool_t *temp_pool);
+static ngx_int_t            ngx_http_push_stream_send_response_content_header(ngx_http_request_t *r, ngx_http_push_stream_loc_conf_t *pslcf);
+static ngx_int_t            ngx_http_push_stream_send_response(ngx_http_request_t *r, ngx_str_t *text, const ngx_str_t *content_type, ngx_int_t status_code);
+static ngx_int_t            ngx_http_push_stream_send_response_message(ngx_http_request_t *r, ngx_http_push_stream_channel_t *channel, ngx_http_push_stream_msg_t *msg, ngx_flag_t send_callback, ngx_flag_t send_separator);
+static ngx_int_t            ngx_http_push_stream_send_response_text(ngx_http_request_t *r, const u_char *text, uint len, ngx_flag_t last_buffer);
+static void                 ngx_http_push_stream_send_response_finalize(ngx_http_request_t *r);
+static void                 ngx_http_push_stream_send_response_finalize_for_longpolling_by_timeout(ngx_http_request_t *r);
+static ngx_int_t            ngx_http_push_stream_send_websocket_close_frame(ngx_http_request_t *r, ngx_uint_t http_status, const ngx_str_t *reason);
+static ngx_int_t            ngx_http_push_stream_memory_cleanup(void);
+
+ngx_chain_t *               ngx_http_push_stream_get_buf(ngx_http_request_t *r);
+static void                 ngx_http_push_stream_unescape_uri(ngx_str_t *value);
+static void                 ngx_http_push_stream_complex_value(ngx_http_request_t *r, ngx_http_complex_value_t *val, ngx_str_t *value);
+
+
+ngx_int_t                   ngx_http_push_stream_add_msg_to_channel(ngx_http_push_stream_main_conf_t *mcf, ngx_log_t *log, ngx_http_push_stream_channel_t *channel, u_char *text, size_t len, ngx_str_t *event_id, ngx_str_t *event_type, ngx_flag_t store_messages, ngx_pool_t *temp_pool);
+ngx_int_t                   ngx_http_push_stream_send_event(ngx_http_push_stream_main_conf_t *mcf, ngx_log_t *log, ngx_http_push_stream_channel_t *channel, ngx_str_t *event_id, ngx_pool_t *temp_pool);
+
+static void                 ngx_http_push_stream_ping_timer_wake_handler(ngx_event_t *ev);
+static void                 ngx_http_push_stream_disconnect_timer_wake_handler(ngx_event_t *ev);
+static void                 ngx_http_push_stream_memory_cleanup_timer_wake_handler(ngx_event_t *ev);
+static void                 ngx_http_push_stream_buffer_timer_wake_handler(ngx_event_t *ev);
+
+static void                 ngx_http_push_stream_timer_set(ngx_msec_t timer_interval, ngx_event_t *event, ngx_event_handler_pt event_handler, ngx_flag_t start_timer);
+static void                 ngx_http_push_stream_timer_reset(ngx_msec_t timer_interval, ngx_event_t *timer_event);
+
+#define ngx_http_push_stream_memory_cleanup_timer_set(void) ngx_http_push_stream_timer_set(NGX_HTTP_PUSH_STREAM_DEFAULT_SHM_MEMORY_CLEANUP_INTERVAL, &ngx_http_push_stream_memory_cleanup_event, ngx_http_push_stream_memory_cleanup_timer_wake_handler, 1);
+#define ngx_http_push_stream_buffer_cleanup_timer_set(void) ngx_http_push_stream_timer_set(NGX_HTTP_PUSH_STREAM_MESSAGE_BUFFER_CLEANUP_INTERVAL, &ngx_http_push_stream_buffer_cleanup_event, ngx_http_push_stream_buffer_timer_wake_handler, 1);
+
+static void                 ngx_http_push_stream_worker_subscriber_cleanup(ngx_http_push_stream_subscriber_t *worker_subscriber);
+static ngx_str_t *          ngx_http_push_stream_create_str(ngx_pool_t *pool, uint len);
+
+static void                 ngx_http_push_stream_throw_the_message_away(ngx_http_push_stream_msg_t *msg, ngx_http_push_stream_shm_data_t *data);
+static ngx_flag_t           ngx_http_push_stream_delete_channel(ngx_http_push_stream_main_conf_t *mcf, ngx_http_push_stream_channel_t *channel, u_char *text, size_t len, ngx_pool_t *temp_pool);
+static void                 ngx_http_push_stream_collect_expired_messages_data(ngx_http_push_stream_shm_data_t *data, ngx_flag_t force);
+static void                 ngx_http_push_stream_collect_expired_messages_and_empty_channels(ngx_flag_t force);
+static void                 ngx_http_push_stream_free_message_memory(ngx_slab_pool_t *shpool, ngx_http_push_stream_msg_t *msg);
+static void                 ngx_http_push_stream_free_worker_message_memory(ngx_slab_pool_t *shpool, ngx_http_push_stream_worker_msg_t *worker_msg);
+static ngx_int_t            ngx_http_push_stream_free_memory_of_expired_messages_and_channels(ngx_flag_t force);
+ngx_uint_t                  ngx_http_push_stream_ensure_qtd_of_messages(ngx_http_push_stream_shm_data_t *data, ngx_http_push_stream_channel_t *channel, ngx_uint_t max_messages, ngx_flag_t expired);
+static ngx_inline void      ngx_http_push_stream_delete_worker_channel(void);
+
+static ngx_http_push_stream_content_subtype_t *     ngx_http_push_stream_match_channel_info_format_and_content_type(ngx_http_request_t *r, ngx_uint_t default_subtype);
+
+static ngx_queue_t *                                ngx_http_push_stream_split_by_crlf(ngx_str_t *msg, ngx_pool_t *temp_pool);
+static ngx_str_t *                                  ngx_http_push_stream_join_with_crlf(ngx_queue_t *lines, ngx_pool_t *temp_pool);
+
+static ngx_http_push_stream_module_ctx_t *          ngx_http_push_stream_add_request_context(ngx_http_request_t *r);
+
+static ngx_queue_t *        ngx_http_push_stream_parse_paddings(ngx_conf_t *cf, ngx_str_t *paddings_by_user_agent);
+
+static ngx_str_t *          ngx_http_push_stream_get_formatted_current_time(ngx_pool_t *pool);
+static ngx_str_t *          ngx_http_push_stream_get_formatted_hostname(ngx_pool_t *pool);
+
+uint64_t                    ngx_http_push_stream_htonll(uint64_t value);
+uint64_t                    ngx_http_push_stream_ntohll(uint64_t value);
+
+static ngx_int_t            ngx_http_push_stream_set_expires(ngx_http_request_t *r, ngx_http_push_stream_expires_t expires, time_t expires_time);
+
+ngx_http_push_stream_requested_channel_t *ngx_http_push_stream_parse_channels_ids_from_path(ngx_http_request_t *r, ngx_pool_t *pool);
+
+ngx_int_t                   ngx_http_push_stream_create_shmtx(ngx_shmtx_t *mtx, ngx_shmtx_sh_t *addr, u_char *name);
+
+ngx_flag_t                  ngx_http_push_stream_is_utf8(u_char *p, size_t n);
+
+#endif /* NGX_HTTP_PUSH_STREAM_MODULE_UTILS_H_ */
diff -Naur nginx-1.11.3/nginx-push-stream-module/include/ngx_http_push_stream_module_version.h nginx-1.11.3-push/nginx-push-stream-module/include/ngx_http_push_stream_module_version.h
--- nginx-1.11.3/nginx-push-stream-module/include/ngx_http_push_stream_module_version.h	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/include/ngx_http_push_stream_module_version.h	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,32 @@
+/*
+ * Copyright (C) 2010-2015 Wandenberg Peixoto <wandenberg@gmail.com>, Rog√©rio Carvalho Schneider <stockrt@gmail.com>
+ *
+ * This file is part of Nginx Push Stream Module.
+ *
+ * Nginx Push Stream Module is free software: you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation, either version 3 of the License, or
+ * (at your option) any later version.
+ *
+ * Nginx Push Stream Module is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with Nginx Push Stream Module.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ *
+ * ngx_http_push_stream_module.h
+ *
+ * Created: Oct 26, 2010
+ * Authors: Wandenberg Peixoto <wandenberg@gmail.com>, Rog√©rio Carvalho Schneider <stockrt@gmail.com>
+ */
+
+#ifndef NGX_HTTP_PUSH_STREAM_MODULE_VERSION_H_
+#define NGX_HTTP_PUSH_STREAM_MODULE_VERSION_H_
+
+static const ngx_str_t  NGX_HTTP_PUSH_STREAM_TAG = ngx_string("0.5.0");
+static const ngx_str_t  NGX_HTTP_PUSH_STREAM_COMMIT = ngx_string("5566c365977fbe4211b5c3757427b82604891a10");
+
+#endif /* NGX_HTTP_PUSH_STREAM_MODULE_VERSION_H_ */
diff -Naur nginx-1.11.3/nginx-push-stream-module/include/ngx_http_push_stream_module_websocket.h nginx-1.11.3-push/nginx-push-stream-module/include/ngx_http_push_stream_module_websocket.h
--- nginx-1.11.3/nginx-push-stream-module/include/ngx_http_push_stream_module_websocket.h	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/include/ngx_http_push_stream_module_websocket.h	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,43 @@
+/*
+ * Copyright (C) 2010-2015 Wandenberg Peixoto <wandenberg@gmail.com>, Rog√©rio Carvalho Schneider <stockrt@gmail.com>
+ *
+ * This file is part of Nginx Push Stream Module.
+ *
+ * Nginx Push Stream Module is free software: you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation, either version 3 of the License, or
+ * (at your option) any later version.
+ *
+ * Nginx Push Stream Module is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with Nginx Push Stream Module.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ *
+ * ngx_http_push_stream_module_websocket.h
+ *
+ * Created: Oct 20, 2011
+ * Authors: Wandenberg Peixoto <wandenberg@gmail.com>, Rog√©rio Carvalho Schneider <stockrt@gmail.com>
+ */
+
+#ifndef NGX_HTTP_PUSH_STREAM_MODULE_WEBSOCKET_H_
+#define NGX_HTTP_PUSH_STREAM_MODULE_WEBSOCKET_H_
+
+#if (NGX_HAVE_SHA1)
+#include <ngx_sha1.h>
+#endif
+
+#include <ngx_http_push_stream_module_utils.h>
+#include <ngx_http_push_stream_module_subscriber.h>
+
+static ngx_int_t    ngx_http_push_stream_websocket_handler(ngx_http_request_t *r);
+
+#define NGX_HTTP_PUSH_STREAM_WEBSOCKET_READ_START_STEP           0
+#define NGX_HTTP_PUSH_STREAM_WEBSOCKET_READ_GET_REAL_SIZE_STEP   1
+#define NGX_HTTP_PUSH_STREAM_WEBSOCKET_READ_GET_MASK_KEY_STEP    2
+#define NGX_HTTP_PUSH_STREAM_WEBSOCKET_READ_GET_PAYLOAD_STEP     3
+
+#endif /* NGX_HTTP_PUSH_STREAM_MODULE_WEBSOCKET_H_ */
diff -Naur nginx-1.11.3/nginx-push-stream-module/include/ngx_http_push_stream_rbtree_util.h nginx-1.11.3-push/nginx-push-stream-module/include/ngx_http_push_stream_rbtree_util.h
--- nginx-1.11.3/nginx-push-stream-module/include/ngx_http_push_stream_rbtree_util.h	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/include/ngx_http_push_stream_rbtree_util.h	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,44 @@
+/*
+ * This file is distributed under the MIT License.
+ *
+ * Copyright (c) 2009 Leo Ponomarev
+ *
+ * Permission is hereby granted, free of charge, to any person
+ * obtaining a copy of this software and associated documentation
+ * files (the "Software"), to deal in the Software without
+ * restriction, including without limitation the rights to use,
+ * copy, modify, merge, publish, distribute, sublicense, and/or sell
+ * copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following
+ * conditions:
+ *
+ * The above copyright notice and this permission notice shall be
+ * included in all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES
+ * OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
+ * HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,
+ * WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
+ * OTHER DEALINGS IN THE SOFTWARE.
+ *
+ *
+ * ngx_http_push_stream_rbtree_util.h
+ *
+ * Modified: Oct 26, 2010
+ * Modifications by: Wandenberg Peixoto <wandenberg@gmail.com>, Rog√©rio Carvalho Schneider <stockrt@gmail.com>
+ */
+
+#ifndef NGX_HTTP_PUSH_STREAM_RBTREE_UTIL_H_
+#define NGX_HTTP_PUSH_STREAM_RBTREE_UTIL_H_
+
+static ngx_http_push_stream_channel_t *     ngx_http_push_stream_get_channel(ngx_str_t *id, ngx_log_t *log, ngx_http_push_stream_main_conf_t *mcf);
+static ngx_http_push_stream_channel_t *     ngx_http_push_stream_find_channel(ngx_str_t *id, ngx_log_t *log, ngx_http_push_stream_main_conf_t *mcf);
+
+static void         ngx_rbtree_generic_insert(ngx_rbtree_node_t *temp, ngx_rbtree_node_t *node, ngx_rbtree_node_t *sentinel, int (*compare) (const ngx_rbtree_node_t *left, const ngx_rbtree_node_t *right));
+static void         ngx_http_push_stream_rbtree_insert(ngx_rbtree_node_t *temp, ngx_rbtree_node_t *node, ngx_rbtree_node_t *sentinel);
+static int          ngx_http_push_stream_compare_rbtree_node(const ngx_rbtree_node_t *v_left, const ngx_rbtree_node_t *v_right);
+
+#endif /* NGX_HTTP_PUSH_STREAM_RBTREE_UTIL_H_ */
diff -Naur nginx-1.11.3/nginx-push-stream-module/LICENSE nginx-1.11.3-push/nginx-push-stream-module/LICENSE
--- nginx-1.11.3/nginx-push-stream-module/LICENSE	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/LICENSE	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,17 @@
+Copyright (C) 2010-2015 Wandenberg Peixoto <wandenberg@gmail.com>, Rog√©rio Carvalho Schneider <stockrt@gmail.com>
+
+This program is free software: you can redistribute it and/or modify
+it under the terms of the GNU General Public License as published by
+the Free Software Foundation, either version 3 of the License, or
+(at your option) any later version.
+
+This program is distributed in the hope that it will be useful,
+but WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+GNU General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with this program.  If not, see <http://www.gnu.org/licenses/>.
+
+All files in this program are under GPL unless otherwise noted in
+file's header. Some files may be sublicensed.
diff -Naur nginx-1.11.3/nginx-push-stream-module/misc/examples/chat.html nginx-1.11.3-push/nginx-push-stream-module/misc/examples/chat.html
--- nginx-1.11.3/nginx-push-stream-module/misc/examples/chat.html	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/misc/examples/chat.html	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,132 @@
+<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
+    "http://www.w3.org/TR/html4/strict.dtd">
+<html>
+<head>
+    <meta http-equiv="Content-type" content="text/html; charset=utf-8" />
+    <title>Chat - Push Stream Module Example</title>
+    <style type="text/css">
+      form p { min-height: 20px;}
+    </style>
+</head>
+<body>
+    <form action="/pub" method="POST">
+        <p>
+            <span style="display: block; float: left; width: 55px;">mode:</span>
+            <span id="mode"></span>
+        </p>
+        <p>
+            <span style="display: block; float: left; width: 55px;">satus:</span>
+            <span class="online" style="display:none; color:green">online</span>
+            <span class="offline" style="display:block; color:red">offline</span>
+        </p>
+        <p>
+            <label for="room">Room:</label>
+            <input type="text" name="room" value="example" id="room" />
+        </p>
+        <p>
+            <label for="nick">Nick:</label>
+            <input type="text" name="nick" value="" id="nick" />
+        </p>
+        <p>
+            <label for="chat">Chat:</label>
+            <textarea name="chat" rows="8" cols="40" id="chat" readonly="readonly"></textarea>
+        </p>
+        <p>
+            <label for="message">Text:</label>
+            <textarea name="message" rows="2" cols="40" id="message"></textarea>
+        </p>
+        <p><input type="submit" value="Send" id="sendButton"/></p>
+    </form>
+    <p><input type="button" value="Show Log" id="showLog"/><input type="button" value="Hide Log" id="hideLog" style="display:none"/></p>
+    <div id="log" style="width:800px;height:200px;display:none;"></div>
+
+    <script src="/js/jquery.min.js" type="text/javascript" language="javascript" charset="utf-8"></script>
+    <script src="/js/pushstream.js" type="text/javascript" language="javascript" charset="utf-8"></script>
+    <script type="text/javascript" language="javascript" charset="utf-8">
+    // <![CDATA[
+    PushStream.LOG_LEVEL = 'debug';
+    var pushstream = new PushStream({
+      host: window.location.hostname,
+      port: window.location.port,
+      modes: "websocket|eventsource|stream"
+    });
+    pushstream.onmessage = _manageEvent;
+    pushstream.onstatuschange = _statuschanged;
+
+    function onSendText() {
+      $("#message").val('');
+    };
+
+    function _manageEvent(eventMessage) {
+      var chat = $("#chat");
+      if (eventMessage != '') {
+        var values = $.parseJSON(eventMessage);
+        var line = values.nick + ': ' + values.text.replace(/\\r/g, '\r').replace(/\\n/g, '\n');
+        if (chat.val() == '') {
+          chat.val(line);
+        } else {
+          chat.val(chat.val() + '\n' + line);
+        }
+
+        var lines = chat.val().split('\n');
+        if (lines.length > 100) {
+          chat.val(lines.slice(-100).join('\n'));
+        }
+      }
+      chat.scrollTop(chat[0].scrollHeight - chat.height());
+    };
+
+    function _statuschanged(state) {
+      if (state == PushStream.OPEN) {
+        $(".offline").hide();
+        $(".online").show();
+        $("#mode").html(pushstream.wrapper.type);
+      } else {
+        $(".offline").show();
+        $(".online").hide();
+        $("#mode").html("");
+      }
+    };
+
+    function _connect(channel) {
+      pushstream.removeAllChannels();
+      try {
+        pushstream.addChannel(channel);
+        pushstream.connect();
+      } catch(e) {alert(e)};
+
+      $("#chat").val('');
+    }
+
+    $("#sendButton").click(function(){
+      if (($("#nick").val() != "") && ($("#message").val() != "") && ($("#room").val() != "")) {
+        pushstream.sendMessage('{"nick":"' + $("#nick").val() + '", "text":"' + $("#message").val().replace(/\r/g, '\\\\r').replace(/\n/g, '\\\\n') + '"}', onSendText);
+      } else {
+        alert("nick, room and text are required");
+      }
+
+      return false;
+    });
+
+    $("#room").change(function(){
+      _connect($("#room").val());
+    });
+
+    $("#showLog").click(function(){
+      $("#log").html('<textarea id="Log4jsLogOutput" rows="10" cols="100"></textarea>').show();
+      $("#showLog").hide();
+      $("#hideLog").show();
+    });
+
+    $("#hideLog").click(function(){
+      $("#Log4jsLogOutput").remove();
+      $("#log").html('').hide();
+      $("#hideLog").hide();
+      $("#showLog").show();
+    });
+
+    _connect($("#room").val());
+    // ]]>
+    </script>
+</body>
+</html>
diff -Naur nginx-1.11.3/nginx-push-stream-module/misc/examples/chat_longpolling.html nginx-1.11.3-push/nginx-push-stream-module/misc/examples/chat_longpolling.html
--- nginx-1.11.3/nginx-push-stream-module/misc/examples/chat_longpolling.html	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/misc/examples/chat_longpolling.html	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,132 @@
+<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN"
+    "http://www.w3.org/TR/html4/strict.dtd">
+<html>
+<head>
+    <meta http-equiv="Content-type" content="text/html; charset=utf-8" />
+    <title>Chat Long Polling - Push Stream Module Example</title>
+    <style type="text/css">
+      form p { min-height: 20px;}
+    </style>
+</head>
+<body>
+    <form action="/pub" method="POST">
+        <p>
+            <span style="display: block; float: left; width: 55px;">mode:</span>
+            <span id="mode"></span>
+        </p>
+        <p>
+            <span style="display: block; float: left; width: 55px;">satus:</span>
+            <span class="online" style="display:none; color:green">online</span>
+            <span class="offline" style="display:block; color:red">offline</span>
+        </p>
+        <p>
+            <label for="room">Room:</label>
+            <input type="text" name="room" value="example" id="room" />
+        </p>
+        <p>
+            <label for="nick">Nick:</label>
+            <input type="text" name="nick" value="" id="nick" />
+        </p>
+        <p>
+            <label for="chat">Chat:</label>
+            <textarea name="chat" rows="8" cols="40" id="chat" readonly="readonly"></textarea>
+        </p>
+        <p>
+            <label for="message">Text:</label>
+            <textarea name="message" rows="2" cols="40" id="message"></textarea>
+        </p>
+        <p><input type="submit" value="Send" id="sendButton"/></p>
+    </form>
+    <p><input type="button" value="Show Log" id="showLog"/><input type="button" value="Hide Log" id="hideLog" style="display:none"/></p>
+    <div id="log" style="width:800px;height:200px;display:none;"></div>
+
+    <script src="/js/jquery.min.js" type="text/javascript" language="javascript" charset="utf-8"></script>
+    <script src="/js/pushstream.js" type="text/javascript" language="javascript" charset="utf-8"></script>
+    <script type="text/javascript" language="javascript" charset="utf-8">
+    // <![CDATA[
+    PushStream.LOG_LEVEL = 'debug';
+    var pushstream = new PushStream({
+      host: window.location.hostname,
+      port: window.location.port,
+      modes: "longpolling"
+    });
+    pushstream.onmessage = _manageEvent;
+    pushstream.onstatuschange = _statuschanged;
+
+    function onSendText() {
+      $("#message").val('');
+    };
+
+    function _manageEvent(eventMessage) {
+      var chat = $("#chat");
+      if (eventMessage != '') {
+        var values = $.parseJSON(eventMessage);
+        var line = values.nick + ': ' + values.text.replace(/\\r/g, '\r').replace(/\\n/g, '\n');
+        if (chat.val() == '') {
+          chat.val(line);
+        } else {
+          chat.val(chat.val() + '\n' + line);
+        }
+
+        var lines = chat.val().split('\n');
+        if (lines.length > 100) {
+          chat.val(lines.slice(-100).join('\n'));
+        }
+      }
+      chat.scrollTop(chat[0].scrollHeight - chat.height());
+    };
+
+    function _statuschanged(state) {
+      if (state == PushStream.OPEN) {
+        $(".offline").hide();
+        $(".online").show();
+        $("#mode").html(pushstream.wrapper.type);
+      } else {
+        $(".offline").show();
+        $(".online").hide();
+        $("#mode").html("");
+      }
+    };
+
+    function _connect(channel) {
+      pushstream.removeAllChannels();
+      try {
+        pushstream.addChannel(channel);
+        pushstream.connect();
+      } catch(e) {alert(e)};
+
+      $("#chat").val('');
+    }
+
+    $("#sendButton").click(function(){
+      if (($("#nick").val() != "") && ($("#message").val() != "") && ($("#room").val() != "")) {
+        pushstream.sendMessage('{"nick":"' + $("#nick").val() + '", "text":"' + $("#message").val().replace(/\r/g, '\\\\r').replace(/\n/g, '\\\\n') + '"}', onSendText);
+      } else {
+        alert("nick, room and text are required");
+      }
+
+      return false;
+    });
+
+    $("#room").change(function(){
+      _connect($("#room").val());
+    });
+
+    $("#showLog").click(function(){
+      $("#log").html('<textarea id="Log4jsLogOutput" rows="10" cols="100"></textarea>').show();
+      $("#showLog").hide();
+      $("#hideLog").show();
+    });
+
+    $("#hideLog").click(function(){
+      $("#Log4jsLogOutput").remove();
+      $("#log").html('').hide();
+      $("#hideLog").hide();
+      $("#showLog").show();
+    });
+
+    _connect($("#room").val());
+    // ]]>
+    </script>
+</body>
+</html>
diff -Naur nginx-1.11.3/nginx-push-stream-module/misc/Gemfile nginx-1.11.3-push/nginx-push-stream-module/misc/Gemfile
--- nginx-1.11.3/nginx-push-stream-module/misc/Gemfile	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/misc/Gemfile	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,30 @@
+source "https://rubygems.org"
+
+ruby '2.1.2'
+
+gem 'rake'
+
+group :test do
+  gem 'rspec'
+  gem 'nginx_test_helper', '~> 0.4.0'
+  gem 'jshintrb'
+  gem 'therubyracer'
+  gem 'jasmine'
+  gem 'listen'
+  gem 'rb-inotify', require: RUBY_PLATFORM.include?('linux') && 'rb-inotify'
+  gem 'rb-fsevent', require: RUBY_PLATFORM.include?('darwin') && 'rb-fsevent'
+  gem 'json'
+  gem 'thin'
+  gem 'net-http-persistent', require: 'net/http/persistent'
+  gem 'websocket-eventmachine-client'
+  gem 'em-eventsource'
+
+  gem 'byebug'
+end
+
+group :docs do
+  gem 'github-markup', require: 'github/markup'
+  gem 'RedCloth'
+  gem 'nokogiri'
+  gem 'filewatcher'
+end
diff -Naur nginx-1.11.3/nginx-push-stream-module/misc/Gemfile.lock nginx-1.11.3-push/nginx-push-stream-module/misc/Gemfile.lock
--- nginx-1.11.3/nginx-push-stream-module/misc/Gemfile.lock	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/misc/Gemfile.lock	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,122 @@
+GEM
+  remote: https://rubygems.org/
+  specs:
+    Platform (0.4.0)
+    RedCloth (4.2.9)
+    addressable (2.3.8)
+    byebug (4.0.5)
+      columnize (= 0.9.0)
+    celluloid (0.16.0)
+      timers (~> 4.0.0)
+    columnize (0.9.0)
+    cookiejar (0.3.2)
+    daemons (1.2.2)
+    diff-lcs (1.2.5)
+    em-eventsource (0.2.0)
+      em-http-request (>= 1.0.0)
+      eventmachine (>= 1.0.0.beta3)
+    em-http-request (1.1.2)
+      addressable (>= 2.3.4)
+      cookiejar
+      em-socksify (>= 0.3)
+      eventmachine (>= 1.0.3)
+      http_parser.rb (>= 0.6.0)
+    em-socksify (0.3.0)
+      eventmachine (>= 1.0.0.beta.4)
+    eventmachine (1.0.7)
+    execjs (2.5.0)
+    ffi (1.9.8)
+    filewatcher (0.4.0)
+      trollop (~> 2.0)
+    github-markup (1.3.3)
+    hitimes (1.2.2)
+    http_parser.rb (0.6.0)
+    jasmine (2.2.0)
+      jasmine-core (~> 2.2)
+      phantomjs
+      rack (>= 1.2.1)
+      rake
+    jasmine-core (2.2.0)
+    jshintrb (0.3.0)
+      execjs
+      multi_json (>= 1.3)
+      rake
+    json (1.8.2)
+    libv8 (3.16.14.7)
+    listen (2.10.0)
+      celluloid (~> 0.16.0)
+      rb-fsevent (>= 0.9.3)
+      rb-inotify (>= 0.9)
+    mini_portile (0.6.2)
+    multi_json (1.11.0)
+    net-http-persistent (2.9.4)
+    nginx_test_helper (0.4.1)
+      popen4
+    nokogiri (1.6.6.2)
+      mini_portile (~> 0.6.0)
+    open4 (1.3.4)
+    phantomjs (1.9.8.0)
+    popen4 (0.1.2)
+      Platform (>= 0.4.0)
+      open4 (>= 0.4.0)
+    rack (1.6.0)
+    rake (10.4.2)
+    rb-fsevent (0.9.4)
+    rb-inotify (0.9.5)
+      ffi (>= 0.5.0)
+    ref (1.0.5)
+    rspec (3.2.0)
+      rspec-core (~> 3.2.0)
+      rspec-expectations (~> 3.2.0)
+      rspec-mocks (~> 3.2.0)
+    rspec-core (3.2.3)
+      rspec-support (~> 3.2.0)
+    rspec-expectations (3.2.1)
+      diff-lcs (>= 1.2.0, < 2.0)
+      rspec-support (~> 3.2.0)
+    rspec-mocks (3.2.1)
+      diff-lcs (>= 1.2.0, < 2.0)
+      rspec-support (~> 3.2.0)
+    rspec-support (3.2.2)
+    therubyracer (0.12.2)
+      libv8 (~> 3.16.14.0)
+      ref
+    thin (1.6.3)
+      daemons (~> 1.0, >= 1.0.9)
+      eventmachine (~> 1.0)
+      rack (~> 1.0)
+    timers (4.0.1)
+      hitimes
+    trollop (2.1.2)
+    websocket (1.2.1)
+    websocket-eventmachine-base (1.1.0)
+      eventmachine (~> 1.0)
+      websocket (~> 1.0)
+      websocket-native (~> 1.0)
+    websocket-eventmachine-client (1.1.0)
+      websocket-eventmachine-base (~> 1.0)
+    websocket-native (1.0.0)
+
+PLATFORMS
+  ruby
+
+DEPENDENCIES
+  RedCloth
+  byebug
+  em-eventsource
+  filewatcher
+  github-markup
+  jasmine
+  jshintrb
+  json
+  listen
+  net-http-persistent
+  nginx_test_helper (~> 0.4.0)
+  nokogiri
+  rake
+  rb-fsevent
+  rb-inotify
+  rspec
+  therubyracer
+  thin
+  websocket-eventmachine-client
diff -Naur nginx-1.11.3/nginx-push-stream-module/misc/github_template.html.erb nginx-1.11.3-push/nginx-push-stream-module/misc/github_template.html.erb
--- nginx-1.11.3/nginx-push-stream-module/misc/github_template.html.erb	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/misc/github_template.html.erb	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,39 @@
+<!DOCTYPE html>
+<html class=" js no-flexbox flexbox-legacy canvas canvastext no-webgl no-touch geolocation postmessage no-websqldatabase indexeddb hashchange history draganddrop websockets rgba hsla multiplebgs backgroundsize borderimage borderradius boxshadow textshadow opacity cssanimations csscolumns cssgradients no-cssreflections csstransforms csstransforms3d csstransitions fontface generatedcontent video audio localstorage sessionstorage webworkers applicationcache svg inlinesvg smil svgclippaths mozilla">
+  <head>
+    <meta http-equiv="content-type" content="text/html; charset=UTF-8">
+    <meta charset="utf-8">
+    <title><%= filename %> - Preview to GitHub</title>
+
+    <link href="file://<%= base_path %>/css/github.css" media="screen" rel="stylesheet" type="text/css" />
+    <link href="file://<%= base_path %>/css/github2.css" media="screen" rel="stylesheet" type="text/css" />
+    <style>
+    #preview-content .markdown-body, #preview-content .plain {
+        background-color: #FFFFFF;
+        border: 1px solid #CACACA;
+        padding: 30px;
+    }
+    </style>
+  </head>
+  <body class="logged_out page-blob linux vis-public env-production ">
+    <div class="site">
+      <div class="container">
+        <div id="slider">
+          <div class="frames">
+            <div class="frame frame-center">
+              <div id="files" class="bubble">
+                <div class="file">
+                  <div id="preview-content" class="blob instapaper_body">
+                    <article class="markdown-body">
+                      <%= content %>
+                    </article>
+                  </div>
+                </div>
+              </div>
+            </div>
+          </div>
+        </div>
+      </div>
+    </div>
+  </body>
+</html>
diff -Naur nginx-1.11.3/nginx-push-stream-module/misc/js/jquery.min.js nginx-1.11.3-push/nginx-push-stream-module/misc/js/jquery.min.js
--- nginx-1.11.3/nginx-push-stream-module/misc/js/jquery.min.js	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/misc/js/jquery.min.js	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,154 @@
+/*!
+ * jQuery JavaScript Library v1.4.2
+ * http://jquery.com/
+ *
+ * Copyright 2010, John Resig
+ * Dual licensed under the MIT or GPL Version 2 licenses.
+ * http://jquery.org/license
+ *
+ * Includes Sizzle.js
+ * http://sizzlejs.com/
+ * Copyright 2010, The Dojo Foundation
+ * Released under the MIT, BSD, and GPL Licenses.
+ *
+ * Date: Sat Feb 13 22:33:48 2010 -0500
+ */
+(function(A,w){function ma(){if(!c.isReady){try{s.documentElement.doScroll("left")}catch(a){setTimeout(ma,1);return}c.ready()}}function Qa(a,b){b.src?c.ajax({url:b.src,async:false,dataType:"script"}):c.globalEval(b.text||b.textContent||b.innerHTML||"");b.parentNode&&b.parentNode.removeChild(b)}function X(a,b,d,f,e,j){var i=a.length;if(typeof b==="object"){for(var o in b)X(a,o,b[o],f,e,d);return a}if(d!==w){f=!j&&f&&c.isFunction(d);for(o=0;o<i;o++)e(a[o],b,f?d.call(a[o],o,e(a[o],b)):d,j);return a}return i?
+e(a[0],b):w}function J(){return(new Date).getTime()}function Y(){return false}function Z(){return true}function na(a,b,d){d[0].type=a;return c.event.handle.apply(b,d)}function oa(a){var b,d=[],f=[],e=arguments,j,i,o,k,n,r;i=c.data(this,"events");if(!(a.liveFired===this||!i||!i.live||a.button&&a.type==="click")){a.liveFired=this;var u=i.live.slice(0);for(k=0;k<u.length;k++){i=u[k];i.origType.replace(O,"")===a.type?f.push(i.selector):u.splice(k--,1)}j=c(a.target).closest(f,a.currentTarget);n=0;for(r=
+j.length;n<r;n++)for(k=0;k<u.length;k++){i=u[k];if(j[n].selector===i.selector){o=j[n].elem;f=null;if(i.preType==="mouseenter"||i.preType==="mouseleave")f=c(a.relatedTarget).closest(i.selector)[0];if(!f||f!==o)d.push({elem:o,handleObj:i})}}n=0;for(r=d.length;n<r;n++){j=d[n];a.currentTarget=j.elem;a.data=j.handleObj.data;a.handleObj=j.handleObj;if(j.handleObj.origHandler.apply(j.elem,e)===false){b=false;break}}return b}}function pa(a,b){return"live."+(a&&a!=="*"?a+".":"")+b.replace(/\./g,"`").replace(/ /g,
+"&")}function qa(a){return!a||!a.parentNode||a.parentNode.nodeType===11}function ra(a,b){var d=0;b.each(function(){if(this.nodeName===(a[d]&&a[d].nodeName)){var f=c.data(a[d++]),e=c.data(this,f);if(f=f&&f.events){delete e.handle;e.events={};for(var j in f)for(var i in f[j])c.event.add(this,j,f[j][i],f[j][i].data)}}})}function sa(a,b,d){var f,e,j;b=b&&b[0]?b[0].ownerDocument||b[0]:s;if(a.length===1&&typeof a[0]==="string"&&a[0].length<512&&b===s&&!ta.test(a[0])&&(c.support.checkClone||!ua.test(a[0]))){e=
+true;if(j=c.fragments[a[0]])if(j!==1)f=j}if(!f){f=b.createDocumentFragment();c.clean(a,b,f,d)}if(e)c.fragments[a[0]]=j?f:1;return{fragment:f,cacheable:e}}function K(a,b){var d={};c.each(va.concat.apply([],va.slice(0,b)),function(){d[this]=a});return d}function wa(a){return"scrollTo"in a&&a.document?a:a.nodeType===9?a.defaultView||a.parentWindow:false}var c=function(a,b){return new c.fn.init(a,b)},Ra=A.jQuery,Sa=A.$,s=A.document,T,Ta=/^[^<]*(<[\w\W]+>)[^>]*$|^#([\w-]+)$/,Ua=/^.[^:#\[\.,]*$/,Va=/\S/,
+Wa=/^(\s|\u00A0)+|(\s|\u00A0)+$/g,Xa=/^<(\w+)\s*\/?>(?:<\/\1>)?$/,P=navigator.userAgent,xa=false,Q=[],L,$=Object.prototype.toString,aa=Object.prototype.hasOwnProperty,ba=Array.prototype.push,R=Array.prototype.slice,ya=Array.prototype.indexOf;c.fn=c.prototype={init:function(a,b){var d,f;if(!a)return this;if(a.nodeType){this.context=this[0]=a;this.length=1;return this}if(a==="body"&&!b){this.context=s;this[0]=s.body;this.selector="body";this.length=1;return this}if(typeof a==="string")if((d=Ta.exec(a))&&
+(d[1]||!b))if(d[1]){f=b?b.ownerDocument||b:s;if(a=Xa.exec(a))if(c.isPlainObject(b)){a=[s.createElement(a[1])];c.fn.attr.call(a,b,true)}else a=[f.createElement(a[1])];else{a=sa([d[1]],[f]);a=(a.cacheable?a.fragment.cloneNode(true):a.fragment).childNodes}return c.merge(this,a)}else{if(b=s.getElementById(d[2])){if(b.id!==d[2])return T.find(a);this.length=1;this[0]=b}this.context=s;this.selector=a;return this}else if(!b&&/^\w+$/.test(a)){this.selector=a;this.context=s;a=s.getElementsByTagName(a);return c.merge(this,
+a)}else return!b||b.jquery?(b||T).find(a):c(b).find(a);else if(c.isFunction(a))return T.ready(a);if(a.selector!==w){this.selector=a.selector;this.context=a.context}return c.makeArray(a,this)},selector:"",jquery:"1.4.2",length:0,size:function(){return this.length},toArray:function(){return R.call(this,0)},get:function(a){return a==null?this.toArray():a<0?this.slice(a)[0]:this[a]},pushStack:function(a,b,d){var f=c();c.isArray(a)?ba.apply(f,a):c.merge(f,a);f.prevObject=this;f.context=this.context;if(b===
+"find")f.selector=this.selector+(this.selector?" ":"")+d;else if(b)f.selector=this.selector+"."+b+"("+d+")";return f},each:function(a,b){return c.each(this,a,b)},ready:function(a){c.bindReady();if(c.isReady)a.call(s,c);else Q&&Q.push(a);return this},eq:function(a){return a===-1?this.slice(a):this.slice(a,+a+1)},first:function(){return this.eq(0)},last:function(){return this.eq(-1)},slice:function(){return this.pushStack(R.apply(this,arguments),"slice",R.call(arguments).join(","))},map:function(a){return this.pushStack(c.map(this,
+function(b,d){return a.call(b,d,b)}))},end:function(){return this.prevObject||c(null)},push:ba,sort:[].sort,splice:[].splice};c.fn.init.prototype=c.fn;c.extend=c.fn.extend=function(){var a=arguments[0]||{},b=1,d=arguments.length,f=false,e,j,i,o;if(typeof a==="boolean"){f=a;a=arguments[1]||{};b=2}if(typeof a!=="object"&&!c.isFunction(a))a={};if(d===b){a=this;--b}for(;b<d;b++)if((e=arguments[b])!=null)for(j in e){i=a[j];o=e[j];if(a!==o)if(f&&o&&(c.isPlainObject(o)||c.isArray(o))){i=i&&(c.isPlainObject(i)||
+c.isArray(i))?i:c.isArray(o)?[]:{};a[j]=c.extend(f,i,o)}else if(o!==w)a[j]=o}return a};c.extend({noConflict:function(a){A.$=Sa;if(a)A.jQuery=Ra;return c},isReady:false,ready:function(){if(!c.isReady){if(!s.body)return setTimeout(c.ready,13);c.isReady=true;if(Q){for(var a,b=0;a=Q[b++];)a.call(s,c);Q=null}c.fn.triggerHandler&&c(s).triggerHandler("ready")}},bindReady:function(){if(!xa){xa=true;if(s.readyState==="complete")return c.ready();if(s.addEventListener){s.addEventListener("DOMContentLoaded",
+L,false);A.addEventListener("load",c.ready,false)}else if(s.attachEvent){s.attachEvent("onreadystatechange",L);A.attachEvent("onload",c.ready);var a=false;try{a=A.frameElement==null}catch(b){}s.documentElement.doScroll&&a&&ma()}}},isFunction:function(a){return $.call(a)==="[object Function]"},isArray:function(a){return $.call(a)==="[object Array]"},isPlainObject:function(a){if(!a||$.call(a)!=="[object Object]"||a.nodeType||a.setInterval)return false;if(a.constructor&&!aa.call(a,"constructor")&&!aa.call(a.constructor.prototype,
+"isPrototypeOf"))return false;var b;for(b in a);return b===w||aa.call(a,b)},isEmptyObject:function(a){for(var b in a)return false;return true},error:function(a){throw a;},parseJSON:function(a){if(typeof a!=="string"||!a)return null;a=c.trim(a);if(/^[\],:{}\s]*$/.test(a.replace(/\\(?:["\\\/bfnrt]|u[0-9a-fA-F]{4})/g,"@").replace(/"[^"\\\n\r]*"|true|false|null|-?\d+(?:\.\d*)?(?:[eE][+\-]?\d+)?/g,"]").replace(/(?:^|:|,)(?:\s*\[)+/g,"")))return A.JSON&&A.JSON.parse?A.JSON.parse(a):(new Function("return "+
+a))();else c.error("Invalid JSON: "+a)},noop:function(){},globalEval:function(a){if(a&&Va.test(a)){var b=s.getElementsByTagName("head")[0]||s.documentElement,d=s.createElement("script");d.type="text/javascript";if(c.support.scriptEval)d.appendChild(s.createTextNode(a));else d.text=a;b.insertBefore(d,b.firstChild);b.removeChild(d)}},nodeName:function(a,b){return a.nodeName&&a.nodeName.toUpperCase()===b.toUpperCase()},each:function(a,b,d){var f,e=0,j=a.length,i=j===w||c.isFunction(a);if(d)if(i)for(f in a){if(b.apply(a[f],
+d)===false)break}else for(;e<j;){if(b.apply(a[e++],d)===false)break}else if(i)for(f in a){if(b.call(a[f],f,a[f])===false)break}else for(d=a[0];e<j&&b.call(d,e,d)!==false;d=a[++e]);return a},trim:function(a){return(a||"").replace(Wa,"")},makeArray:function(a,b){b=b||[];if(a!=null)a.length==null||typeof a==="string"||c.isFunction(a)||typeof a!=="function"&&a.setInterval?ba.call(b,a):c.merge(b,a);return b},inArray:function(a,b){if(b.indexOf)return b.indexOf(a);for(var d=0,f=b.length;d<f;d++)if(b[d]===
+a)return d;return-1},merge:function(a,b){var d=a.length,f=0;if(typeof b.length==="number")for(var e=b.length;f<e;f++)a[d++]=b[f];else for(;b[f]!==w;)a[d++]=b[f++];a.length=d;return a},grep:function(a,b,d){for(var f=[],e=0,j=a.length;e<j;e++)!d!==!b(a[e],e)&&f.push(a[e]);return f},map:function(a,b,d){for(var f=[],e,j=0,i=a.length;j<i;j++){e=b(a[j],j,d);if(e!=null)f[f.length]=e}return f.concat.apply([],f)},guid:1,proxy:function(a,b,d){if(arguments.length===2)if(typeof b==="string"){d=a;a=d[b];b=w}else if(b&&
+!c.isFunction(b)){d=b;b=w}if(!b&&a)b=function(){return a.apply(d||this,arguments)};if(a)b.guid=a.guid=a.guid||b.guid||c.guid++;return b},uaMatch:function(a){a=a.toLowerCase();a=/(webkit)[ \/]([\w.]+)/.exec(a)||/(opera)(?:.*version)?[ \/]([\w.]+)/.exec(a)||/(msie) ([\w.]+)/.exec(a)||!/compatible/.test(a)&&/(mozilla)(?:.*? rv:([\w.]+))?/.exec(a)||[];return{browser:a[1]||"",version:a[2]||"0"}},browser:{}});P=c.uaMatch(P);if(P.browser){c.browser[P.browser]=true;c.browser.version=P.version}if(c.browser.webkit)c.browser.safari=
+true;if(ya)c.inArray=function(a,b){return ya.call(b,a)};T=c(s);if(s.addEventListener)L=function(){s.removeEventListener("DOMContentLoaded",L,false);c.ready()};else if(s.attachEvent)L=function(){if(s.readyState==="complete"){s.detachEvent("onreadystatechange",L);c.ready()}};(function(){c.support={};var a=s.documentElement,b=s.createElement("script"),d=s.createElement("div"),f="script"+J();d.style.display="none";d.innerHTML="   <link/><table></table><a href='/a' style='color:red;float:left;opacity:.55;'>a</a><input type='checkbox'/>";
+var e=d.getElementsByTagName("*"),j=d.getElementsByTagName("a")[0];if(!(!e||!e.length||!j)){c.support={leadingWhitespace:d.firstChild.nodeType===3,tbody:!d.getElementsByTagName("tbody").length,htmlSerialize:!!d.getElementsByTagName("link").length,style:/red/.test(j.getAttribute("style")),hrefNormalized:j.getAttribute("href")==="/a",opacity:/^0.55$/.test(j.style.opacity),cssFloat:!!j.style.cssFloat,checkOn:d.getElementsByTagName("input")[0].value==="on",optSelected:s.createElement("select").appendChild(s.createElement("option")).selected,
+parentNode:d.removeChild(d.appendChild(s.createElement("div"))).parentNode===null,deleteExpando:true,checkClone:false,scriptEval:false,noCloneEvent:true,boxModel:null};b.type="text/javascript";try{b.appendChild(s.createTextNode("window."+f+"=1;"))}catch(i){}a.insertBefore(b,a.firstChild);if(A[f]){c.support.scriptEval=true;delete A[f]}try{delete b.test}catch(o){c.support.deleteExpando=false}a.removeChild(b);if(d.attachEvent&&d.fireEvent){d.attachEvent("onclick",function k(){c.support.noCloneEvent=
+false;d.detachEvent("onclick",k)});d.cloneNode(true).fireEvent("onclick")}d=s.createElement("div");d.innerHTML="<input type='radio' name='radiotest' checked='checked'/>";a=s.createDocumentFragment();a.appendChild(d.firstChild);c.support.checkClone=a.cloneNode(true).cloneNode(true).lastChild.checked;c(function(){var k=s.createElement("div");k.style.width=k.style.paddingLeft="1px";s.body.appendChild(k);c.boxModel=c.support.boxModel=k.offsetWidth===2;s.body.removeChild(k).style.display="none"});a=function(k){var n=
+s.createElement("div");k="on"+k;var r=k in n;if(!r){n.setAttribute(k,"return;");r=typeof n[k]==="function"}return r};c.support.submitBubbles=a("submit");c.support.changeBubbles=a("change");a=b=d=e=j=null}})();c.props={"for":"htmlFor","class":"className",readonly:"readOnly",maxlength:"maxLength",cellspacing:"cellSpacing",rowspan:"rowSpan",colspan:"colSpan",tabindex:"tabIndex",usemap:"useMap",frameborder:"frameBorder"};var G="jQuery"+J(),Ya=0,za={};c.extend({cache:{},expando:G,noData:{embed:true,object:true,
+applet:true},data:function(a,b,d){if(!(a.nodeName&&c.noData[a.nodeName.toLowerCase()])){a=a==A?za:a;var f=a[G],e=c.cache;if(!f&&typeof b==="string"&&d===w)return null;f||(f=++Ya);if(typeof b==="object"){a[G]=f;e[f]=c.extend(true,{},b)}else if(!e[f]){a[G]=f;e[f]={}}a=e[f];if(d!==w)a[b]=d;return typeof b==="string"?a[b]:a}},removeData:function(a,b){if(!(a.nodeName&&c.noData[a.nodeName.toLowerCase()])){a=a==A?za:a;var d=a[G],f=c.cache,e=f[d];if(b){if(e){delete e[b];c.isEmptyObject(e)&&c.removeData(a)}}else{if(c.support.deleteExpando)delete a[c.expando];
+else a.removeAttribute&&a.removeAttribute(c.expando);delete f[d]}}}});c.fn.extend({data:function(a,b){if(typeof a==="undefined"&&this.length)return c.data(this[0]);else if(typeof a==="object")return this.each(function(){c.data(this,a)});var d=a.split(".");d[1]=d[1]?"."+d[1]:"";if(b===w){var f=this.triggerHandler("getData"+d[1]+"!",[d[0]]);if(f===w&&this.length)f=c.data(this[0],a);return f===w&&d[1]?this.data(d[0]):f}else return this.trigger("setData"+d[1]+"!",[d[0],b]).each(function(){c.data(this,
+a,b)})},removeData:function(a){return this.each(function(){c.removeData(this,a)})}});c.extend({queue:function(a,b,d){if(a){b=(b||"fx")+"queue";var f=c.data(a,b);if(!d)return f||[];if(!f||c.isArray(d))f=c.data(a,b,c.makeArray(d));else f.push(d);return f}},dequeue:function(a,b){b=b||"fx";var d=c.queue(a,b),f=d.shift();if(f==="inprogress")f=d.shift();if(f){b==="fx"&&d.unshift("inprogress");f.call(a,function(){c.dequeue(a,b)})}}});c.fn.extend({queue:function(a,b){if(typeof a!=="string"){b=a;a="fx"}if(b===
+w)return c.queue(this[0],a);return this.each(function(){var d=c.queue(this,a,b);a==="fx"&&d[0]!=="inprogress"&&c.dequeue(this,a)})},dequeue:function(a){return this.each(function(){c.dequeue(this,a)})},delay:function(a,b){a=c.fx?c.fx.speeds[a]||a:a;b=b||"fx";return this.queue(b,function(){var d=this;setTimeout(function(){c.dequeue(d,b)},a)})},clearQueue:function(a){return this.queue(a||"fx",[])}});var Aa=/[\n\t]/g,ca=/\s+/,Za=/\r/g,$a=/href|src|style/,ab=/(button|input)/i,bb=/(button|input|object|select|textarea)/i,
+cb=/^(a|area)$/i,Ba=/radio|checkbox/;c.fn.extend({attr:function(a,b){return X(this,a,b,true,c.attr)},removeAttr:function(a){return this.each(function(){c.attr(this,a,"");this.nodeType===1&&this.removeAttribute(a)})},addClass:function(a){if(c.isFunction(a))return this.each(function(n){var r=c(this);r.addClass(a.call(this,n,r.attr("class")))});if(a&&typeof a==="string")for(var b=(a||"").split(ca),d=0,f=this.length;d<f;d++){var e=this[d];if(e.nodeType===1)if(e.className){for(var j=" "+e.className+" ",
+i=e.className,o=0,k=b.length;o<k;o++)if(j.indexOf(" "+b[o]+" ")<0)i+=" "+b[o];e.className=c.trim(i)}else e.className=a}return this},removeClass:function(a){if(c.isFunction(a))return this.each(function(k){var n=c(this);n.removeClass(a.call(this,k,n.attr("class")))});if(a&&typeof a==="string"||a===w)for(var b=(a||"").split(ca),d=0,f=this.length;d<f;d++){var e=this[d];if(e.nodeType===1&&e.className)if(a){for(var j=(" "+e.className+" ").replace(Aa," "),i=0,o=b.length;i<o;i++)j=j.replace(" "+b[i]+" ",
+" ");e.className=c.trim(j)}else e.className=""}return this},toggleClass:function(a,b){var d=typeof a,f=typeof b==="boolean";if(c.isFunction(a))return this.each(function(e){var j=c(this);j.toggleClass(a.call(this,e,j.attr("class"),b),b)});return this.each(function(){if(d==="string")for(var e,j=0,i=c(this),o=b,k=a.split(ca);e=k[j++];){o=f?o:!i.hasClass(e);i[o?"addClass":"removeClass"](e)}else if(d==="undefined"||d==="boolean"){this.className&&c.data(this,"__className__",this.className);this.className=
+this.className||a===false?"":c.data(this,"__className__")||""}})},hasClass:function(a){a=" "+a+" ";for(var b=0,d=this.length;b<d;b++)if((" "+this[b].className+" ").replace(Aa," ").indexOf(a)>-1)return true;return false},val:function(a){if(a===w){var b=this[0];if(b){if(c.nodeName(b,"option"))return(b.attributes.value||{}).specified?b.value:b.text;if(c.nodeName(b,"select")){var d=b.selectedIndex,f=[],e=b.options;b=b.type==="select-one";if(d<0)return null;var j=b?d:0;for(d=b?d+1:e.length;j<d;j++){var i=
+e[j];if(i.selected){a=c(i).val();if(b)return a;f.push(a)}}return f}if(Ba.test(b.type)&&!c.support.checkOn)return b.getAttribute("value")===null?"on":b.value;return(b.value||"").replace(Za,"")}return w}var o=c.isFunction(a);return this.each(function(k){var n=c(this),r=a;if(this.nodeType===1){if(o)r=a.call(this,k,n.val());if(typeof r==="number")r+="";if(c.isArray(r)&&Ba.test(this.type))this.checked=c.inArray(n.val(),r)>=0;else if(c.nodeName(this,"select")){var u=c.makeArray(r);c("option",this).each(function(){this.selected=
+c.inArray(c(this).val(),u)>=0});if(!u.length)this.selectedIndex=-1}else this.value=r}})}});c.extend({attrFn:{val:true,css:true,html:true,text:true,data:true,width:true,height:true,offset:true},attr:function(a,b,d,f){if(!a||a.nodeType===3||a.nodeType===8)return w;if(f&&b in c.attrFn)return c(a)[b](d);f=a.nodeType!==1||!c.isXMLDoc(a);var e=d!==w;b=f&&c.props[b]||b;if(a.nodeType===1){var j=$a.test(b);if(b in a&&f&&!j){if(e){b==="type"&&ab.test(a.nodeName)&&a.parentNode&&c.error("type property can't be changed");
+a[b]=d}if(c.nodeName(a,"form")&&a.getAttributeNode(b))return a.getAttributeNode(b).nodeValue;if(b==="tabIndex")return(b=a.getAttributeNode("tabIndex"))&&b.specified?b.value:bb.test(a.nodeName)||cb.test(a.nodeName)&&a.href?0:w;return a[b]}if(!c.support.style&&f&&b==="style"){if(e)a.style.cssText=""+d;return a.style.cssText}e&&a.setAttribute(b,""+d);a=!c.support.hrefNormalized&&f&&j?a.getAttribute(b,2):a.getAttribute(b);return a===null?w:a}return c.style(a,b,d)}});var O=/\.(.*)$/,db=function(a){return a.replace(/[^\w\s\.\|`]/g,
+function(b){return"\\"+b})};c.event={add:function(a,b,d,f){if(!(a.nodeType===3||a.nodeType===8)){if(a.setInterval&&a!==A&&!a.frameElement)a=A;var e,j;if(d.handler){e=d;d=e.handler}if(!d.guid)d.guid=c.guid++;if(j=c.data(a)){var i=j.events=j.events||{},o=j.handle;if(!o)j.handle=o=function(){return typeof c!=="undefined"&&!c.event.triggered?c.event.handle.apply(o.elem,arguments):w};o.elem=a;b=b.split(" ");for(var k,n=0,r;k=b[n++];){j=e?c.extend({},e):{handler:d,data:f};if(k.indexOf(".")>-1){r=k.split(".");
+k=r.shift();j.namespace=r.slice(0).sort().join(".")}else{r=[];j.namespace=""}j.type=k;j.guid=d.guid;var u=i[k],z=c.event.special[k]||{};if(!u){u=i[k]=[];if(!z.setup||z.setup.call(a,f,r,o)===false)if(a.addEventListener)a.addEventListener(k,o,false);else a.attachEvent&&a.attachEvent("on"+k,o)}if(z.add){z.add.call(a,j);if(!j.handler.guid)j.handler.guid=d.guid}u.push(j);c.event.global[k]=true}a=null}}},global:{},remove:function(a,b,d,f){if(!(a.nodeType===3||a.nodeType===8)){var e,j=0,i,o,k,n,r,u,z=c.data(a),
+C=z&&z.events;if(z&&C){if(b&&b.type){d=b.handler;b=b.type}if(!b||typeof b==="string"&&b.charAt(0)==="."){b=b||"";for(e in C)c.event.remove(a,e+b)}else{for(b=b.split(" ");e=b[j++];){n=e;i=e.indexOf(".")<0;o=[];if(!i){o=e.split(".");e=o.shift();k=new RegExp("(^|\\.)"+c.map(o.slice(0).sort(),db).join("\\.(?:.*\\.)?")+"(\\.|$)")}if(r=C[e])if(d){n=c.event.special[e]||{};for(B=f||0;B<r.length;B++){u=r[B];if(d.guid===u.guid){if(i||k.test(u.namespace)){f==null&&r.splice(B--,1);n.remove&&n.remove.call(a,u)}if(f!=
+null)break}}if(r.length===0||f!=null&&r.length===1){if(!n.teardown||n.teardown.call(a,o)===false)Ca(a,e,z.handle);delete C[e]}}else for(var B=0;B<r.length;B++){u=r[B];if(i||k.test(u.namespace)){c.event.remove(a,n,u.handler,B);r.splice(B--,1)}}}if(c.isEmptyObject(C)){if(b=z.handle)b.elem=null;delete z.events;delete z.handle;c.isEmptyObject(z)&&c.removeData(a)}}}}},trigger:function(a,b,d,f){var e=a.type||a;if(!f){a=typeof a==="object"?a[G]?a:c.extend(c.Event(e),a):c.Event(e);if(e.indexOf("!")>=0){a.type=
+e=e.slice(0,-1);a.exclusive=true}if(!d){a.stopPropagation();c.event.global[e]&&c.each(c.cache,function(){this.events&&this.events[e]&&c.event.trigger(a,b,this.handle.elem)})}if(!d||d.nodeType===3||d.nodeType===8)return w;a.result=w;a.target=d;b=c.makeArray(b);b.unshift(a)}a.currentTarget=d;(f=c.data(d,"handle"))&&f.apply(d,b);f=d.parentNode||d.ownerDocument;try{if(!(d&&d.nodeName&&c.noData[d.nodeName.toLowerCase()]))if(d["on"+e]&&d["on"+e].apply(d,b)===false)a.result=false}catch(j){}if(!a.isPropagationStopped()&&
+f)c.event.trigger(a,b,f,true);else if(!a.isDefaultPrevented()){f=a.target;var i,o=c.nodeName(f,"a")&&e==="click",k=c.event.special[e]||{};if((!k._default||k._default.call(d,a)===false)&&!o&&!(f&&f.nodeName&&c.noData[f.nodeName.toLowerCase()])){try{if(f[e]){if(i=f["on"+e])f["on"+e]=null;c.event.triggered=true;f[e]()}}catch(n){}if(i)f["on"+e]=i;c.event.triggered=false}}},handle:function(a){var b,d,f,e;a=arguments[0]=c.event.fix(a||A.event);a.currentTarget=this;b=a.type.indexOf(".")<0&&!a.exclusive;
+if(!b){d=a.type.split(".");a.type=d.shift();f=new RegExp("(^|\\.)"+d.slice(0).sort().join("\\.(?:.*\\.)?")+"(\\.|$)")}e=c.data(this,"events");d=e[a.type];if(e&&d){d=d.slice(0);e=0;for(var j=d.length;e<j;e++){var i=d[e];if(b||f.test(i.namespace)){a.handler=i.handler;a.data=i.data;a.handleObj=i;i=i.handler.apply(this,arguments);if(i!==w){a.result=i;if(i===false){a.preventDefault();a.stopPropagation()}}if(a.isImmediatePropagationStopped())break}}}return a.result},props:"altKey attrChange attrName bubbles button cancelable charCode clientX clientY ctrlKey currentTarget data detail eventPhase fromElement handler keyCode layerX layerY metaKey newValue offsetX offsetY originalTarget pageX pageY prevValue relatedNode relatedTarget screenX screenY shiftKey srcElement target toElement view wheelDelta which".split(" "),
+fix:function(a){if(a[G])return a;var b=a;a=c.Event(b);for(var d=this.props.length,f;d;){f=this.props[--d];a[f]=b[f]}if(!a.target)a.target=a.srcElement||s;if(a.target.nodeType===3)a.target=a.target.parentNode;if(!a.relatedTarget&&a.fromElement)a.relatedTarget=a.fromElement===a.target?a.toElement:a.fromElement;if(a.pageX==null&&a.clientX!=null){b=s.documentElement;d=s.body;a.pageX=a.clientX+(b&&b.scrollLeft||d&&d.scrollLeft||0)-(b&&b.clientLeft||d&&d.clientLeft||0);a.pageY=a.clientY+(b&&b.scrollTop||
+d&&d.scrollTop||0)-(b&&b.clientTop||d&&d.clientTop||0)}if(!a.which&&(a.charCode||a.charCode===0?a.charCode:a.keyCode))a.which=a.charCode||a.keyCode;if(!a.metaKey&&a.ctrlKey)a.metaKey=a.ctrlKey;if(!a.which&&a.button!==w)a.which=a.button&1?1:a.button&2?3:a.button&4?2:0;return a},guid:1E8,proxy:c.proxy,special:{ready:{setup:c.bindReady,teardown:c.noop},live:{add:function(a){c.event.add(this,a.origType,c.extend({},a,{handler:oa}))},remove:function(a){var b=true,d=a.origType.replace(O,"");c.each(c.data(this,
+"events").live||[],function(){if(d===this.origType.replace(O,""))return b=false});b&&c.event.remove(this,a.origType,oa)}},beforeunload:{setup:function(a,b,d){if(this.setInterval)this.onbeforeunload=d;return false},teardown:function(a,b){if(this.onbeforeunload===b)this.onbeforeunload=null}}}};var Ca=s.removeEventListener?function(a,b,d){a.removeEventListener(b,d,false)}:function(a,b,d){a.detachEvent("on"+b,d)};c.Event=function(a){if(!this.preventDefault)return new c.Event(a);if(a&&a.type){this.originalEvent=
+a;this.type=a.type}else this.type=a;this.timeStamp=J();this[G]=true};c.Event.prototype={preventDefault:function(){this.isDefaultPrevented=Z;var a=this.originalEvent;if(a){a.preventDefault&&a.preventDefault();a.returnValue=false}},stopPropagation:function(){this.isPropagationStopped=Z;var a=this.originalEvent;if(a){a.stopPropagation&&a.stopPropagation();a.cancelBubble=true}},stopImmediatePropagation:function(){this.isImmediatePropagationStopped=Z;this.stopPropagation()},isDefaultPrevented:Y,isPropagationStopped:Y,
+isImmediatePropagationStopped:Y};var Da=function(a){var b=a.relatedTarget;try{for(;b&&b!==this;)b=b.parentNode;if(b!==this){a.type=a.data;c.event.handle.apply(this,arguments)}}catch(d){}},Ea=function(a){a.type=a.data;c.event.handle.apply(this,arguments)};c.each({mouseenter:"mouseover",mouseleave:"mouseout"},function(a,b){c.event.special[a]={setup:function(d){c.event.add(this,b,d&&d.selector?Ea:Da,a)},teardown:function(d){c.event.remove(this,b,d&&d.selector?Ea:Da)}}});if(!c.support.submitBubbles)c.event.special.submit=
+{setup:function(){if(this.nodeName.toLowerCase()!=="form"){c.event.add(this,"click.specialSubmit",function(a){var b=a.target,d=b.type;if((d==="submit"||d==="image")&&c(b).closest("form").length)return na("submit",this,arguments)});c.event.add(this,"keypress.specialSubmit",function(a){var b=a.target,d=b.type;if((d==="text"||d==="password")&&c(b).closest("form").length&&a.keyCode===13)return na("submit",this,arguments)})}else return false},teardown:function(){c.event.remove(this,".specialSubmit")}};
+if(!c.support.changeBubbles){var da=/textarea|input|select/i,ea,Fa=function(a){var b=a.type,d=a.value;if(b==="radio"||b==="checkbox")d=a.checked;else if(b==="select-multiple")d=a.selectedIndex>-1?c.map(a.options,function(f){return f.selected}).join("-"):"";else if(a.nodeName.toLowerCase()==="select")d=a.selectedIndex;return d},fa=function(a,b){var d=a.target,f,e;if(!(!da.test(d.nodeName)||d.readOnly)){f=c.data(d,"_change_data");e=Fa(d);if(a.type!=="focusout"||d.type!=="radio")c.data(d,"_change_data",
+e);if(!(f===w||e===f))if(f!=null||e){a.type="change";return c.event.trigger(a,b,d)}}};c.event.special.change={filters:{focusout:fa,click:function(a){var b=a.target,d=b.type;if(d==="radio"||d==="checkbox"||b.nodeName.toLowerCase()==="select")return fa.call(this,a)},keydown:function(a){var b=a.target,d=b.type;if(a.keyCode===13&&b.nodeName.toLowerCase()!=="textarea"||a.keyCode===32&&(d==="checkbox"||d==="radio")||d==="select-multiple")return fa.call(this,a)},beforeactivate:function(a){a=a.target;c.data(a,
+"_change_data",Fa(a))}},setup:function(){if(this.type==="file")return false;for(var a in ea)c.event.add(this,a+".specialChange",ea[a]);return da.test(this.nodeName)},teardown:function(){c.event.remove(this,".specialChange");return da.test(this.nodeName)}};ea=c.event.special.change.filters}s.addEventListener&&c.each({focus:"focusin",blur:"focusout"},function(a,b){function d(f){f=c.event.fix(f);f.type=b;return c.event.handle.call(this,f)}c.event.special[b]={setup:function(){this.addEventListener(a,
+d,true)},teardown:function(){this.removeEventListener(a,d,true)}}});c.each(["bind","one"],function(a,b){c.fn[b]=function(d,f,e){if(typeof d==="object"){for(var j in d)this[b](j,f,d[j],e);return this}if(c.isFunction(f)){e=f;f=w}var i=b==="one"?c.proxy(e,function(k){c(this).unbind(k,i);return e.apply(this,arguments)}):e;if(d==="unload"&&b!=="one")this.one(d,f,e);else{j=0;for(var o=this.length;j<o;j++)c.event.add(this[j],d,i,f)}return this}});c.fn.extend({unbind:function(a,b){if(typeof a==="object"&&
+!a.preventDefault)for(var d in a)this.unbind(d,a[d]);else{d=0;for(var f=this.length;d<f;d++)c.event.remove(this[d],a,b)}return this},delegate:function(a,b,d,f){return this.live(b,d,f,a)},undelegate:function(a,b,d){return arguments.length===0?this.unbind("live"):this.die(b,null,d,a)},trigger:function(a,b){return this.each(function(){c.event.trigger(a,b,this)})},triggerHandler:function(a,b){if(this[0]){a=c.Event(a);a.preventDefault();a.stopPropagation();c.event.trigger(a,b,this[0]);return a.result}},
+toggle:function(a){for(var b=arguments,d=1;d<b.length;)c.proxy(a,b[d++]);return this.click(c.proxy(a,function(f){var e=(c.data(this,"lastToggle"+a.guid)||0)%d;c.data(this,"lastToggle"+a.guid,e+1);f.preventDefault();return b[e].apply(this,arguments)||false}))},hover:function(a,b){return this.mouseenter(a).mouseleave(b||a)}});var Ga={focus:"focusin",blur:"focusout",mouseenter:"mouseover",mouseleave:"mouseout"};c.each(["live","die"],function(a,b){c.fn[b]=function(d,f,e,j){var i,o=0,k,n,r=j||this.selector,
+u=j?this:c(this.context);if(c.isFunction(f)){e=f;f=w}for(d=(d||"").split(" ");(i=d[o++])!=null;){j=O.exec(i);k="";if(j){k=j[0];i=i.replace(O,"")}if(i==="hover")d.push("mouseenter"+k,"mouseleave"+k);else{n=i;if(i==="focus"||i==="blur"){d.push(Ga[i]+k);i+=k}else i=(Ga[i]||i)+k;b==="live"?u.each(function(){c.event.add(this,pa(i,r),{data:f,selector:r,handler:e,origType:i,origHandler:e,preType:n})}):u.unbind(pa(i,r),e)}}return this}});c.each("blur focus focusin focusout load resize scroll unload click dblclick mousedown mouseup mousemove mouseover mouseout mouseenter mouseleave change select submit keydown keypress keyup error".split(" "),
+function(a,b){c.fn[b]=function(d){return d?this.bind(b,d):this.trigger(b)};if(c.attrFn)c.attrFn[b]=true});A.attachEvent&&!A.addEventListener&&A.attachEvent("onunload",function(){for(var a in c.cache)if(c.cache[a].handle)try{c.event.remove(c.cache[a].handle.elem)}catch(b){}});(function(){function a(g){for(var h="",l,m=0;g[m];m++){l=g[m];if(l.nodeType===3||l.nodeType===4)h+=l.nodeValue;else if(l.nodeType!==8)h+=a(l.childNodes)}return h}function b(g,h,l,m,q,p){q=0;for(var v=m.length;q<v;q++){var t=m[q];
+if(t){t=t[g];for(var y=false;t;){if(t.sizcache===l){y=m[t.sizset];break}if(t.nodeType===1&&!p){t.sizcache=l;t.sizset=q}if(t.nodeName.toLowerCase()===h){y=t;break}t=t[g]}m[q]=y}}}function d(g,h,l,m,q,p){q=0;for(var v=m.length;q<v;q++){var t=m[q];if(t){t=t[g];for(var y=false;t;){if(t.sizcache===l){y=m[t.sizset];break}if(t.nodeType===1){if(!p){t.sizcache=l;t.sizset=q}if(typeof h!=="string"){if(t===h){y=true;break}}else if(k.filter(h,[t]).length>0){y=t;break}}t=t[g]}m[q]=y}}}var f=/((?:\((?:\([^()]+\)|[^()]+)+\)|\[(?:\[[^[\]]*\]|['"][^'"]*['"]|[^[\]'"]+)+\]|\\.|[^ >+~,(\[\\]+)+|[>+~])(\s*,\s*)?((?:.|\r|\n)*)/g,
+e=0,j=Object.prototype.toString,i=false,o=true;[0,0].sort(function(){o=false;return 0});var k=function(g,h,l,m){l=l||[];var q=h=h||s;if(h.nodeType!==1&&h.nodeType!==9)return[];if(!g||typeof g!=="string")return l;for(var p=[],v,t,y,S,H=true,M=x(h),I=g;(f.exec(""),v=f.exec(I))!==null;){I=v[3];p.push(v[1]);if(v[2]){S=v[3];break}}if(p.length>1&&r.exec(g))if(p.length===2&&n.relative[p[0]])t=ga(p[0]+p[1],h);else for(t=n.relative[p[0]]?[h]:k(p.shift(),h);p.length;){g=p.shift();if(n.relative[g])g+=p.shift();
+t=ga(g,t)}else{if(!m&&p.length>1&&h.nodeType===9&&!M&&n.match.ID.test(p[0])&&!n.match.ID.test(p[p.length-1])){v=k.find(p.shift(),h,M);h=v.expr?k.filter(v.expr,v.set)[0]:v.set[0]}if(h){v=m?{expr:p.pop(),set:z(m)}:k.find(p.pop(),p.length===1&&(p[0]==="~"||p[0]==="+")&&h.parentNode?h.parentNode:h,M);t=v.expr?k.filter(v.expr,v.set):v.set;if(p.length>0)y=z(t);else H=false;for(;p.length;){var D=p.pop();v=D;if(n.relative[D])v=p.pop();else D="";if(v==null)v=h;n.relative[D](y,v,M)}}else y=[]}y||(y=t);y||k.error(D||
+g);if(j.call(y)==="[object Array]")if(H)if(h&&h.nodeType===1)for(g=0;y[g]!=null;g++){if(y[g]&&(y[g]===true||y[g].nodeType===1&&E(h,y[g])))l.push(t[g])}else for(g=0;y[g]!=null;g++)y[g]&&y[g].nodeType===1&&l.push(t[g]);else l.push.apply(l,y);else z(y,l);if(S){k(S,q,l,m);k.uniqueSort(l)}return l};k.uniqueSort=function(g){if(B){i=o;g.sort(B);if(i)for(var h=1;h<g.length;h++)g[h]===g[h-1]&&g.splice(h--,1)}return g};k.matches=function(g,h){return k(g,null,null,h)};k.find=function(g,h,l){var m,q;if(!g)return[];
+for(var p=0,v=n.order.length;p<v;p++){var t=n.order[p];if(q=n.leftMatch[t].exec(g)){var y=q[1];q.splice(1,1);if(y.substr(y.length-1)!=="\\"){q[1]=(q[1]||"").replace(/\\/g,"");m=n.find[t](q,h,l);if(m!=null){g=g.replace(n.match[t],"");break}}}}m||(m=h.getElementsByTagName("*"));return{set:m,expr:g}};k.filter=function(g,h,l,m){for(var q=g,p=[],v=h,t,y,S=h&&h[0]&&x(h[0]);g&&h.length;){for(var H in n.filter)if((t=n.leftMatch[H].exec(g))!=null&&t[2]){var M=n.filter[H],I,D;D=t[1];y=false;t.splice(1,1);if(D.substr(D.length-
+1)!=="\\"){if(v===p)p=[];if(n.preFilter[H])if(t=n.preFilter[H](t,v,l,p,m,S)){if(t===true)continue}else y=I=true;if(t)for(var U=0;(D=v[U])!=null;U++)if(D){I=M(D,t,U,v);var Ha=m^!!I;if(l&&I!=null)if(Ha)y=true;else v[U]=false;else if(Ha){p.push(D);y=true}}if(I!==w){l||(v=p);g=g.replace(n.match[H],"");if(!y)return[];break}}}if(g===q)if(y==null)k.error(g);else break;q=g}return v};k.error=function(g){throw"Syntax error, unrecognized expression: "+g;};var n=k.selectors={order:["ID","NAME","TAG"],match:{ID:/#((?:[\w\u00c0-\uFFFF-]|\\.)+)/,
+CLASS:/\.((?:[\w\u00c0-\uFFFF-]|\\.)+)/,NAME:/\[name=['"]*((?:[\w\u00c0-\uFFFF-]|\\.)+)['"]*\]/,ATTR:/\[\s*((?:[\w\u00c0-\uFFFF-]|\\.)+)\s*(?:(\S?=)\s*(['"]*)(.*?)\3|)\s*\]/,TAG:/^((?:[\w\u00c0-\uFFFF\*-]|\\.)+)/,CHILD:/:(only|nth|last|first)-child(?:\((even|odd|[\dn+-]*)\))?/,POS:/:(nth|eq|gt|lt|first|last|even|odd)(?:\((\d*)\))?(?=[^-]|$)/,PSEUDO:/:((?:[\w\u00c0-\uFFFF-]|\\.)+)(?:\((['"]?)((?:\([^\)]+\)|[^\(\)]*)+)\2\))?/},leftMatch:{},attrMap:{"class":"className","for":"htmlFor"},attrHandle:{href:function(g){return g.getAttribute("href")}},
+relative:{"+":function(g,h){var l=typeof h==="string",m=l&&!/\W/.test(h);l=l&&!m;if(m)h=h.toLowerCase();m=0;for(var q=g.length,p;m<q;m++)if(p=g[m]){for(;(p=p.previousSibling)&&p.nodeType!==1;);g[m]=l||p&&p.nodeName.toLowerCase()===h?p||false:p===h}l&&k.filter(h,g,true)},">":function(g,h){var l=typeof h==="string";if(l&&!/\W/.test(h)){h=h.toLowerCase();for(var m=0,q=g.length;m<q;m++){var p=g[m];if(p){l=p.parentNode;g[m]=l.nodeName.toLowerCase()===h?l:false}}}else{m=0;for(q=g.length;m<q;m++)if(p=g[m])g[m]=
+l?p.parentNode:p.parentNode===h;l&&k.filter(h,g,true)}},"":function(g,h,l){var m=e++,q=d;if(typeof h==="string"&&!/\W/.test(h)){var p=h=h.toLowerCase();q=b}q("parentNode",h,m,g,p,l)},"~":function(g,h,l){var m=e++,q=d;if(typeof h==="string"&&!/\W/.test(h)){var p=h=h.toLowerCase();q=b}q("previousSibling",h,m,g,p,l)}},find:{ID:function(g,h,l){if(typeof h.getElementById!=="undefined"&&!l)return(g=h.getElementById(g[1]))?[g]:[]},NAME:function(g,h){if(typeof h.getElementsByName!=="undefined"){var l=[];
+h=h.getElementsByName(g[1]);for(var m=0,q=h.length;m<q;m++)h[m].getAttribute("name")===g[1]&&l.push(h[m]);return l.length===0?null:l}},TAG:function(g,h){return h.getElementsByTagName(g[1])}},preFilter:{CLASS:function(g,h,l,m,q,p){g=" "+g[1].replace(/\\/g,"")+" ";if(p)return g;p=0;for(var v;(v=h[p])!=null;p++)if(v)if(q^(v.className&&(" "+v.className+" ").replace(/[\t\n]/g," ").indexOf(g)>=0))l||m.push(v);else if(l)h[p]=false;return false},ID:function(g){return g[1].replace(/\\/g,"")},TAG:function(g){return g[1].toLowerCase()},
+CHILD:function(g){if(g[1]==="nth"){var h=/(-?)(\d*)n((?:\+|-)?\d*)/.exec(g[2]==="even"&&"2n"||g[2]==="odd"&&"2n+1"||!/\D/.test(g[2])&&"0n+"+g[2]||g[2]);g[2]=h[1]+(h[2]||1)-0;g[3]=h[3]-0}g[0]=e++;return g},ATTR:function(g,h,l,m,q,p){h=g[1].replace(/\\/g,"");if(!p&&n.attrMap[h])g[1]=n.attrMap[h];if(g[2]==="~=")g[4]=" "+g[4]+" ";return g},PSEUDO:function(g,h,l,m,q){if(g[1]==="not")if((f.exec(g[3])||"").length>1||/^\w/.test(g[3]))g[3]=k(g[3],null,null,h);else{g=k.filter(g[3],h,l,true^q);l||m.push.apply(m,
+g);return false}else if(n.match.POS.test(g[0])||n.match.CHILD.test(g[0]))return true;return g},POS:function(g){g.unshift(true);return g}},filters:{enabled:function(g){return g.disabled===false&&g.type!=="hidden"},disabled:function(g){return g.disabled===true},checked:function(g){return g.checked===true},selected:function(g){return g.selected===true},parent:function(g){return!!g.firstChild},empty:function(g){return!g.firstChild},has:function(g,h,l){return!!k(l[3],g).length},header:function(g){return/h\d/i.test(g.nodeName)},
+text:function(g){return"text"===g.type},radio:function(g){return"radio"===g.type},checkbox:function(g){return"checkbox"===g.type},file:function(g){return"file"===g.type},password:function(g){return"password"===g.type},submit:function(g){return"submit"===g.type},image:function(g){return"image"===g.type},reset:function(g){return"reset"===g.type},button:function(g){return"button"===g.type||g.nodeName.toLowerCase()==="button"},input:function(g){return/input|select|textarea|button/i.test(g.nodeName)}},
+setFilters:{first:function(g,h){return h===0},last:function(g,h,l,m){return h===m.length-1},even:function(g,h){return h%2===0},odd:function(g,h){return h%2===1},lt:function(g,h,l){return h<l[3]-0},gt:function(g,h,l){return h>l[3]-0},nth:function(g,h,l){return l[3]-0===h},eq:function(g,h,l){return l[3]-0===h}},filter:{PSEUDO:function(g,h,l,m){var q=h[1],p=n.filters[q];if(p)return p(g,l,h,m);else if(q==="contains")return(g.textContent||g.innerText||a([g])||"").indexOf(h[3])>=0;else if(q==="not"){h=
+h[3];l=0;for(m=h.length;l<m;l++)if(h[l]===g)return false;return true}else k.error("Syntax error, unrecognized expression: "+q)},CHILD:function(g,h){var l=h[1],m=g;switch(l){case "only":case "first":for(;m=m.previousSibling;)if(m.nodeType===1)return false;if(l==="first")return true;m=g;case "last":for(;m=m.nextSibling;)if(m.nodeType===1)return false;return true;case "nth":l=h[2];var q=h[3];if(l===1&&q===0)return true;h=h[0];var p=g.parentNode;if(p&&(p.sizcache!==h||!g.nodeIndex)){var v=0;for(m=p.firstChild;m;m=
+m.nextSibling)if(m.nodeType===1)m.nodeIndex=++v;p.sizcache=h}g=g.nodeIndex-q;return l===0?g===0:g%l===0&&g/l>=0}},ID:function(g,h){return g.nodeType===1&&g.getAttribute("id")===h},TAG:function(g,h){return h==="*"&&g.nodeType===1||g.nodeName.toLowerCase()===h},CLASS:function(g,h){return(" "+(g.className||g.getAttribute("class"))+" ").indexOf(h)>-1},ATTR:function(g,h){var l=h[1];g=n.attrHandle[l]?n.attrHandle[l](g):g[l]!=null?g[l]:g.getAttribute(l);l=g+"";var m=h[2];h=h[4];return g==null?m==="!=":m===
+"="?l===h:m==="*="?l.indexOf(h)>=0:m==="~="?(" "+l+" ").indexOf(h)>=0:!h?l&&g!==false:m==="!="?l!==h:m==="^="?l.indexOf(h)===0:m==="$="?l.substr(l.length-h.length)===h:m==="|="?l===h||l.substr(0,h.length+1)===h+"-":false},POS:function(g,h,l,m){var q=n.setFilters[h[2]];if(q)return q(g,l,h,m)}}},r=n.match.POS;for(var u in n.match){n.match[u]=new RegExp(n.match[u].source+/(?![^\[]*\])(?![^\(]*\))/.source);n.leftMatch[u]=new RegExp(/(^(?:.|\r|\n)*?)/.source+n.match[u].source.replace(/\\(\d+)/g,function(g,
+h){return"\\"+(h-0+1)}))}var z=function(g,h){g=Array.prototype.slice.call(g,0);if(h){h.push.apply(h,g);return h}return g};try{Array.prototype.slice.call(s.documentElement.childNodes,0)}catch(C){z=function(g,h){h=h||[];if(j.call(g)==="[object Array]")Array.prototype.push.apply(h,g);else if(typeof g.length==="number")for(var l=0,m=g.length;l<m;l++)h.push(g[l]);else for(l=0;g[l];l++)h.push(g[l]);return h}}var B;if(s.documentElement.compareDocumentPosition)B=function(g,h){if(!g.compareDocumentPosition||
+!h.compareDocumentPosition){if(g==h)i=true;return g.compareDocumentPosition?-1:1}g=g.compareDocumentPosition(h)&4?-1:g===h?0:1;if(g===0)i=true;return g};else if("sourceIndex"in s.documentElement)B=function(g,h){if(!g.sourceIndex||!h.sourceIndex){if(g==h)i=true;return g.sourceIndex?-1:1}g=g.sourceIndex-h.sourceIndex;if(g===0)i=true;return g};else if(s.createRange)B=function(g,h){if(!g.ownerDocument||!h.ownerDocument){if(g==h)i=true;return g.ownerDocument?-1:1}var l=g.ownerDocument.createRange(),m=
+h.ownerDocument.createRange();l.setStart(g,0);l.setEnd(g,0);m.setStart(h,0);m.setEnd(h,0);g=l.compareBoundaryPoints(Range.START_TO_END,m);if(g===0)i=true;return g};(function(){var g=s.createElement("div"),h="script"+(new Date).getTime();g.innerHTML="<a name='"+h+"'/>";var l=s.documentElement;l.insertBefore(g,l.firstChild);if(s.getElementById(h)){n.find.ID=function(m,q,p){if(typeof q.getElementById!=="undefined"&&!p)return(q=q.getElementById(m[1]))?q.id===m[1]||typeof q.getAttributeNode!=="undefined"&&
+q.getAttributeNode("id").nodeValue===m[1]?[q]:w:[]};n.filter.ID=function(m,q){var p=typeof m.getAttributeNode!=="undefined"&&m.getAttributeNode("id");return m.nodeType===1&&p&&p.nodeValue===q}}l.removeChild(g);l=g=null})();(function(){var g=s.createElement("div");g.appendChild(s.createComment(""));if(g.getElementsByTagName("*").length>0)n.find.TAG=function(h,l){l=l.getElementsByTagName(h[1]);if(h[1]==="*"){h=[];for(var m=0;l[m];m++)l[m].nodeType===1&&h.push(l[m]);l=h}return l};g.innerHTML="<a href='#'></a>";
+if(g.firstChild&&typeof g.firstChild.getAttribute!=="undefined"&&g.firstChild.getAttribute("href")!=="#")n.attrHandle.href=function(h){return h.getAttribute("href",2)};g=null})();s.querySelectorAll&&function(){var g=k,h=s.createElement("div");h.innerHTML="<p class='TEST'></p>";if(!(h.querySelectorAll&&h.querySelectorAll(".TEST").length===0)){k=function(m,q,p,v){q=q||s;if(!v&&q.nodeType===9&&!x(q))try{return z(q.querySelectorAll(m),p)}catch(t){}return g(m,q,p,v)};for(var l in g)k[l]=g[l];h=null}}();
+(function(){var g=s.createElement("div");g.innerHTML="<div class='test e'></div><div class='test'></div>";if(!(!g.getElementsByClassName||g.getElementsByClassName("e").length===0)){g.lastChild.className="e";if(g.getElementsByClassName("e").length!==1){n.order.splice(1,0,"CLASS");n.find.CLASS=function(h,l,m){if(typeof l.getElementsByClassName!=="undefined"&&!m)return l.getElementsByClassName(h[1])};g=null}}})();var E=s.compareDocumentPosition?function(g,h){return!!(g.compareDocumentPosition(h)&16)}:
+function(g,h){return g!==h&&(g.contains?g.contains(h):true)},x=function(g){return(g=(g?g.ownerDocument||g:0).documentElement)?g.nodeName!=="HTML":false},ga=function(g,h){var l=[],m="",q;for(h=h.nodeType?[h]:h;q=n.match.PSEUDO.exec(g);){m+=q[0];g=g.replace(n.match.PSEUDO,"")}g=n.relative[g]?g+"*":g;q=0;for(var p=h.length;q<p;q++)k(g,h[q],l);return k.filter(m,l)};c.find=k;c.expr=k.selectors;c.expr[":"]=c.expr.filters;c.unique=k.uniqueSort;c.text=a;c.isXMLDoc=x;c.contains=E})();var eb=/Until$/,fb=/^(?:parents|prevUntil|prevAll)/,
+gb=/,/;R=Array.prototype.slice;var Ia=function(a,b,d){if(c.isFunction(b))return c.grep(a,function(e,j){return!!b.call(e,j,e)===d});else if(b.nodeType)return c.grep(a,function(e){return e===b===d});else if(typeof b==="string"){var f=c.grep(a,function(e){return e.nodeType===1});if(Ua.test(b))return c.filter(b,f,!d);else b=c.filter(b,f)}return c.grep(a,function(e){return c.inArray(e,b)>=0===d})};c.fn.extend({find:function(a){for(var b=this.pushStack("","find",a),d=0,f=0,e=this.length;f<e;f++){d=b.length;
+c.find(a,this[f],b);if(f>0)for(var j=d;j<b.length;j++)for(var i=0;i<d;i++)if(b[i]===b[j]){b.splice(j--,1);break}}return b},has:function(a){var b=c(a);return this.filter(function(){for(var d=0,f=b.length;d<f;d++)if(c.contains(this,b[d]))return true})},not:function(a){return this.pushStack(Ia(this,a,false),"not",a)},filter:function(a){return this.pushStack(Ia(this,a,true),"filter",a)},is:function(a){return!!a&&c.filter(a,this).length>0},closest:function(a,b){if(c.isArray(a)){var d=[],f=this[0],e,j=
+{},i;if(f&&a.length){e=0;for(var o=a.length;e<o;e++){i=a[e];j[i]||(j[i]=c.expr.match.POS.test(i)?c(i,b||this.context):i)}for(;f&&f.ownerDocument&&f!==b;){for(i in j){e=j[i];if(e.jquery?e.index(f)>-1:c(f).is(e)){d.push({selector:i,elem:f});delete j[i]}}f=f.parentNode}}return d}var k=c.expr.match.POS.test(a)?c(a,b||this.context):null;return this.map(function(n,r){for(;r&&r.ownerDocument&&r!==b;){if(k?k.index(r)>-1:c(r).is(a))return r;r=r.parentNode}return null})},index:function(a){if(!a||typeof a===
+"string")return c.inArray(this[0],a?c(a):this.parent().children());return c.inArray(a.jquery?a[0]:a,this)},add:function(a,b){a=typeof a==="string"?c(a,b||this.context):c.makeArray(a);b=c.merge(this.get(),a);return this.pushStack(qa(a[0])||qa(b[0])?b:c.unique(b))},andSelf:function(){return this.add(this.prevObject)}});c.each({parent:function(a){return(a=a.parentNode)&&a.nodeType!==11?a:null},parents:function(a){return c.dir(a,"parentNode")},parentsUntil:function(a,b,d){return c.dir(a,"parentNode",
+d)},next:function(a){return c.nth(a,2,"nextSibling")},prev:function(a){return c.nth(a,2,"previousSibling")},nextAll:function(a){return c.dir(a,"nextSibling")},prevAll:function(a){return c.dir(a,"previousSibling")},nextUntil:function(a,b,d){return c.dir(a,"nextSibling",d)},prevUntil:function(a,b,d){return c.dir(a,"previousSibling",d)},siblings:function(a){return c.sibling(a.parentNode.firstChild,a)},children:function(a){return c.sibling(a.firstChild)},contents:function(a){return c.nodeName(a,"iframe")?
+a.contentDocument||a.contentWindow.document:c.makeArray(a.childNodes)}},function(a,b){c.fn[a]=function(d,f){var e=c.map(this,b,d);eb.test(a)||(f=d);if(f&&typeof f==="string")e=c.filter(f,e);e=this.length>1?c.unique(e):e;if((this.length>1||gb.test(f))&&fb.test(a))e=e.reverse();return this.pushStack(e,a,R.call(arguments).join(","))}});c.extend({filter:function(a,b,d){if(d)a=":not("+a+")";return c.find.matches(a,b)},dir:function(a,b,d){var f=[];for(a=a[b];a&&a.nodeType!==9&&(d===w||a.nodeType!==1||!c(a).is(d));){a.nodeType===
+1&&f.push(a);a=a[b]}return f},nth:function(a,b,d){b=b||1;for(var f=0;a;a=a[d])if(a.nodeType===1&&++f===b)break;return a},sibling:function(a,b){for(var d=[];a;a=a.nextSibling)a.nodeType===1&&a!==b&&d.push(a);return d}});var Ja=/ jQuery\d+="(?:\d+|null)"/g,V=/^\s+/,Ka=/(<([\w:]+)[^>]*?)\/>/g,hb=/^(?:area|br|col|embed|hr|img|input|link|meta|param)$/i,La=/<([\w:]+)/,ib=/<tbody/i,jb=/<|&#?\w+;/,ta=/<script|<object|<embed|<option|<style/i,ua=/checked\s*(?:[^=]|=\s*.checked.)/i,Ma=function(a,b,d){return hb.test(d)?
+a:b+"></"+d+">"},F={option:[1,"<select multiple='multiple'>","</select>"],legend:[1,"<fieldset>","</fieldset>"],thead:[1,"<table>","</table>"],tr:[2,"<table><tbody>","</tbody></table>"],td:[3,"<table><tbody><tr>","</tr></tbody></table>"],col:[2,"<table><tbody></tbody><colgroup>","</colgroup></table>"],area:[1,"<map>","</map>"],_default:[0,"",""]};F.optgroup=F.option;F.tbody=F.tfoot=F.colgroup=F.caption=F.thead;F.th=F.td;if(!c.support.htmlSerialize)F._default=[1,"div<div>","</div>"];c.fn.extend({text:function(a){if(c.isFunction(a))return this.each(function(b){var d=
+c(this);d.text(a.call(this,b,d.text()))});if(typeof a!=="object"&&a!==w)return this.empty().append((this[0]&&this[0].ownerDocument||s).createTextNode(a));return c.text(this)},wrapAll:function(a){if(c.isFunction(a))return this.each(function(d){c(this).wrapAll(a.call(this,d))});if(this[0]){var b=c(a,this[0].ownerDocument).eq(0).clone(true);this[0].parentNode&&b.insertBefore(this[0]);b.map(function(){for(var d=this;d.firstChild&&d.firstChild.nodeType===1;)d=d.firstChild;return d}).append(this)}return this},
+wrapInner:function(a){if(c.isFunction(a))return this.each(function(b){c(this).wrapInner(a.call(this,b))});return this.each(function(){var b=c(this),d=b.contents();d.length?d.wrapAll(a):b.append(a)})},wrap:function(a){return this.each(function(){c(this).wrapAll(a)})},unwrap:function(){return this.parent().each(function(){c.nodeName(this,"body")||c(this).replaceWith(this.childNodes)}).end()},append:function(){return this.domManip(arguments,true,function(a){this.nodeType===1&&this.appendChild(a)})},
+prepend:function(){return this.domManip(arguments,true,function(a){this.nodeType===1&&this.insertBefore(a,this.firstChild)})},before:function(){if(this[0]&&this[0].parentNode)return this.domManip(arguments,false,function(b){this.parentNode.insertBefore(b,this)});else if(arguments.length){var a=c(arguments[0]);a.push.apply(a,this.toArray());return this.pushStack(a,"before",arguments)}},after:function(){if(this[0]&&this[0].parentNode)return this.domManip(arguments,false,function(b){this.parentNode.insertBefore(b,
+this.nextSibling)});else if(arguments.length){var a=this.pushStack(this,"after",arguments);a.push.apply(a,c(arguments[0]).toArray());return a}},remove:function(a,b){for(var d=0,f;(f=this[d])!=null;d++)if(!a||c.filter(a,[f]).length){if(!b&&f.nodeType===1){c.cleanData(f.getElementsByTagName("*"));c.cleanData([f])}f.parentNode&&f.parentNode.removeChild(f)}return this},empty:function(){for(var a=0,b;(b=this[a])!=null;a++)for(b.nodeType===1&&c.cleanData(b.getElementsByTagName("*"));b.firstChild;)b.removeChild(b.firstChild);
+return this},clone:function(a){var b=this.map(function(){if(!c.support.noCloneEvent&&!c.isXMLDoc(this)){var d=this.outerHTML,f=this.ownerDocument;if(!d){d=f.createElement("div");d.appendChild(this.cloneNode(true));d=d.innerHTML}return c.clean([d.replace(Ja,"").replace(/=([^="'>\s]+\/)>/g,'="$1">').replace(V,"")],f)[0]}else return this.cloneNode(true)});if(a===true){ra(this,b);ra(this.find("*"),b.find("*"))}return b},html:function(a){if(a===w)return this[0]&&this[0].nodeType===1?this[0].innerHTML.replace(Ja,
+""):null;else if(typeof a==="string"&&!ta.test(a)&&(c.support.leadingWhitespace||!V.test(a))&&!F[(La.exec(a)||["",""])[1].toLowerCase()]){a=a.replace(Ka,Ma);try{for(var b=0,d=this.length;b<d;b++)if(this[b].nodeType===1){c.cleanData(this[b].getElementsByTagName("*"));this[b].innerHTML=a}}catch(f){this.empty().append(a)}}else c.isFunction(a)?this.each(function(e){var j=c(this),i=j.html();j.empty().append(function(){return a.call(this,e,i)})}):this.empty().append(a);return this},replaceWith:function(a){if(this[0]&&
+this[0].parentNode){if(c.isFunction(a))return this.each(function(b){var d=c(this),f=d.html();d.replaceWith(a.call(this,b,f))});if(typeof a!=="string")a=c(a).detach();return this.each(function(){var b=this.nextSibling,d=this.parentNode;c(this).remove();b?c(b).before(a):c(d).append(a)})}else return this.pushStack(c(c.isFunction(a)?a():a),"replaceWith",a)},detach:function(a){return this.remove(a,true)},domManip:function(a,b,d){function f(u){return c.nodeName(u,"table")?u.getElementsByTagName("tbody")[0]||
+u.appendChild(u.ownerDocument.createElement("tbody")):u}var e,j,i=a[0],o=[],k;if(!c.support.checkClone&&arguments.length===3&&typeof i==="string"&&ua.test(i))return this.each(function(){c(this).domManip(a,b,d,true)});if(c.isFunction(i))return this.each(function(u){var z=c(this);a[0]=i.call(this,u,b?z.html():w);z.domManip(a,b,d)});if(this[0]){e=i&&i.parentNode;e=c.support.parentNode&&e&&e.nodeType===11&&e.childNodes.length===this.length?{fragment:e}:sa(a,this,o);k=e.fragment;if(j=k.childNodes.length===
+1?(k=k.firstChild):k.firstChild){b=b&&c.nodeName(j,"tr");for(var n=0,r=this.length;n<r;n++)d.call(b?f(this[n],j):this[n],n>0||e.cacheable||this.length>1?k.cloneNode(true):k)}o.length&&c.each(o,Qa)}return this}});c.fragments={};c.each({appendTo:"append",prependTo:"prepend",insertBefore:"before",insertAfter:"after",replaceAll:"replaceWith"},function(a,b){c.fn[a]=function(d){var f=[];d=c(d);var e=this.length===1&&this[0].parentNode;if(e&&e.nodeType===11&&e.childNodes.length===1&&d.length===1){d[b](this[0]);
+return this}else{e=0;for(var j=d.length;e<j;e++){var i=(e>0?this.clone(true):this).get();c.fn[b].apply(c(d[e]),i);f=f.concat(i)}return this.pushStack(f,a,d.selector)}}});c.extend({clean:function(a,b,d,f){b=b||s;if(typeof b.createElement==="undefined")b=b.ownerDocument||b[0]&&b[0].ownerDocument||s;for(var e=[],j=0,i;(i=a[j])!=null;j++){if(typeof i==="number")i+="";if(i){if(typeof i==="string"&&!jb.test(i))i=b.createTextNode(i);else if(typeof i==="string"){i=i.replace(Ka,Ma);var o=(La.exec(i)||["",
+""])[1].toLowerCase(),k=F[o]||F._default,n=k[0],r=b.createElement("div");for(r.innerHTML=k[1]+i+k[2];n--;)r=r.lastChild;if(!c.support.tbody){n=ib.test(i);o=o==="table"&&!n?r.firstChild&&r.firstChild.childNodes:k[1]==="<table>"&&!n?r.childNodes:[];for(k=o.length-1;k>=0;--k)c.nodeName(o[k],"tbody")&&!o[k].childNodes.length&&o[k].parentNode.removeChild(o[k])}!c.support.leadingWhitespace&&V.test(i)&&r.insertBefore(b.createTextNode(V.exec(i)[0]),r.firstChild);i=r.childNodes}if(i.nodeType)e.push(i);else e=
+c.merge(e,i)}}if(d)for(j=0;e[j];j++)if(f&&c.nodeName(e[j],"script")&&(!e[j].type||e[j].type.toLowerCase()==="text/javascript"))f.push(e[j].parentNode?e[j].parentNode.removeChild(e[j]):e[j]);else{e[j].nodeType===1&&e.splice.apply(e,[j+1,0].concat(c.makeArray(e[j].getElementsByTagName("script"))));d.appendChild(e[j])}return e},cleanData:function(a){for(var b,d,f=c.cache,e=c.event.special,j=c.support.deleteExpando,i=0,o;(o=a[i])!=null;i++)if(d=o[c.expando]){b=f[d];if(b.events)for(var k in b.events)e[k]?
+c.event.remove(o,k):Ca(o,k,b.handle);if(j)delete o[c.expando];else o.removeAttribute&&o.removeAttribute(c.expando);delete f[d]}}});var kb=/z-?index|font-?weight|opacity|zoom|line-?height/i,Na=/alpha\([^)]*\)/,Oa=/opacity=([^)]*)/,ha=/float/i,ia=/-([a-z])/ig,lb=/([A-Z])/g,mb=/^-?\d+(?:px)?$/i,nb=/^-?\d/,ob={position:"absolute",visibility:"hidden",display:"block"},pb=["Left","Right"],qb=["Top","Bottom"],rb=s.defaultView&&s.defaultView.getComputedStyle,Pa=c.support.cssFloat?"cssFloat":"styleFloat",ja=
+function(a,b){return b.toUpperCase()};c.fn.css=function(a,b){return X(this,a,b,true,function(d,f,e){if(e===w)return c.curCSS(d,f);if(typeof e==="number"&&!kb.test(f))e+="px";c.style(d,f,e)})};c.extend({style:function(a,b,d){if(!a||a.nodeType===3||a.nodeType===8)return w;if((b==="width"||b==="height")&&parseFloat(d)<0)d=w;var f=a.style||a,e=d!==w;if(!c.support.opacity&&b==="opacity"){if(e){f.zoom=1;b=parseInt(d,10)+""==="NaN"?"":"alpha(opacity="+d*100+")";a=f.filter||c.curCSS(a,"filter")||"";f.filter=
+Na.test(a)?a.replace(Na,b):b}return f.filter&&f.filter.indexOf("opacity=")>=0?parseFloat(Oa.exec(f.filter)[1])/100+"":""}if(ha.test(b))b=Pa;b=b.replace(ia,ja);if(e)f[b]=d;return f[b]},css:function(a,b,d,f){if(b==="width"||b==="height"){var e,j=b==="width"?pb:qb;function i(){e=b==="width"?a.offsetWidth:a.offsetHeight;f!=="border"&&c.each(j,function(){f||(e-=parseFloat(c.curCSS(a,"padding"+this,true))||0);if(f==="margin")e+=parseFloat(c.curCSS(a,"margin"+this,true))||0;else e-=parseFloat(c.curCSS(a,
+"border"+this+"Width",true))||0})}a.offsetWidth!==0?i():c.swap(a,ob,i);return Math.max(0,Math.round(e))}return c.curCSS(a,b,d)},curCSS:function(a,b,d){var f,e=a.style;if(!c.support.opacity&&b==="opacity"&&a.currentStyle){f=Oa.test(a.currentStyle.filter||"")?parseFloat(RegExp.$1)/100+"":"";return f===""?"1":f}if(ha.test(b))b=Pa;if(!d&&e&&e[b])f=e[b];else if(rb){if(ha.test(b))b="float";b=b.replace(lb,"-$1").toLowerCase();e=a.ownerDocument.defaultView;if(!e)return null;if(a=e.getComputedStyle(a,null))f=
+a.getPropertyValue(b);if(b==="opacity"&&f==="")f="1"}else if(a.currentStyle){d=b.replace(ia,ja);f=a.currentStyle[b]||a.currentStyle[d];if(!mb.test(f)&&nb.test(f)){b=e.left;var j=a.runtimeStyle.left;a.runtimeStyle.left=a.currentStyle.left;e.left=d==="fontSize"?"1em":f||0;f=e.pixelLeft+"px";e.left=b;a.runtimeStyle.left=j}}return f},swap:function(a,b,d){var f={};for(var e in b){f[e]=a.style[e];a.style[e]=b[e]}d.call(a);for(e in b)a.style[e]=f[e]}});if(c.expr&&c.expr.filters){c.expr.filters.hidden=function(a){var b=
+a.offsetWidth,d=a.offsetHeight,f=a.nodeName.toLowerCase()==="tr";return b===0&&d===0&&!f?true:b>0&&d>0&&!f?false:c.curCSS(a,"display")==="none"};c.expr.filters.visible=function(a){return!c.expr.filters.hidden(a)}}var sb=J(),tb=/<script(.|\s)*?\/script>/gi,ub=/select|textarea/i,vb=/color|date|datetime|email|hidden|month|number|password|range|search|tel|text|time|url|week/i,N=/=\?(&|$)/,ka=/\?/,wb=/(\?|&)_=.*?(&|$)/,xb=/^(\w+:)?\/\/([^\/?#]+)/,yb=/%20/g,zb=c.fn.load;c.fn.extend({load:function(a,b,d){if(typeof a!==
+"string")return zb.call(this,a);else if(!this.length)return this;var f=a.indexOf(" ");if(f>=0){var e=a.slice(f,a.length);a=a.slice(0,f)}f="GET";if(b)if(c.isFunction(b)){d=b;b=null}else if(typeof b==="object"){b=c.param(b,c.ajaxSettings.traditional);f="POST"}var j=this;c.ajax({url:a,type:f,dataType:"html",data:b,complete:function(i,o){if(o==="success"||o==="notmodified")j.html(e?c("<div />").append(i.responseText.replace(tb,"")).find(e):i.responseText);d&&j.each(d,[i.responseText,o,i])}});return this},
+serialize:function(){return c.param(this.serializeArray())},serializeArray:function(){return this.map(function(){return this.elements?c.makeArray(this.elements):this}).filter(function(){return this.name&&!this.disabled&&(this.checked||ub.test(this.nodeName)||vb.test(this.type))}).map(function(a,b){a=c(this).val();return a==null?null:c.isArray(a)?c.map(a,function(d){return{name:b.name,value:d}}):{name:b.name,value:a}}).get()}});c.each("ajaxStart ajaxStop ajaxComplete ajaxError ajaxSuccess ajaxSend".split(" "),
+function(a,b){c.fn[b]=function(d){return this.bind(b,d)}});c.extend({get:function(a,b,d,f){if(c.isFunction(b)){f=f||d;d=b;b=null}return c.ajax({type:"GET",url:a,data:b,success:d,dataType:f})},getScript:function(a,b){return c.get(a,null,b,"script")},getJSON:function(a,b,d){return c.get(a,b,d,"json")},post:function(a,b,d,f){if(c.isFunction(b)){f=f||d;d=b;b={}}return c.ajax({type:"POST",url:a,data:b,success:d,dataType:f})},ajaxSetup:function(a){c.extend(c.ajaxSettings,a)},ajaxSettings:{url:location.href,
+global:true,type:"GET",contentType:"application/x-www-form-urlencoded",processData:true,async:true,xhr:A.XMLHttpRequest&&(A.location.protocol!=="file:"||!A.ActiveXObject)?function(){return new A.XMLHttpRequest}:function(){try{return new A.ActiveXObject("Microsoft.XMLHTTP")}catch(a){}},accepts:{xml:"application/xml, text/xml",html:"text/html",script:"text/javascript, application/javascript",json:"application/json, text/javascript",text:"text/plain",_default:"*/*"}},lastModified:{},etag:{},ajax:function(a){function b(){e.success&&
+e.success.call(k,o,i,x);e.global&&f("ajaxSuccess",[x,e])}function d(){e.complete&&e.complete.call(k,x,i);e.global&&f("ajaxComplete",[x,e]);e.global&&!--c.active&&c.event.trigger("ajaxStop")}function f(q,p){(e.context?c(e.context):c.event).trigger(q,p)}var e=c.extend(true,{},c.ajaxSettings,a),j,i,o,k=a&&a.context||e,n=e.type.toUpperCase();if(e.data&&e.processData&&typeof e.data!=="string")e.data=c.param(e.data,e.traditional);if(e.dataType==="jsonp"){if(n==="GET")N.test(e.url)||(e.url+=(ka.test(e.url)?
+"&":"?")+(e.jsonp||"callback")+"=?");else if(!e.data||!N.test(e.data))e.data=(e.data?e.data+"&":"")+(e.jsonp||"callback")+"=?";e.dataType="json"}if(e.dataType==="json"&&(e.data&&N.test(e.data)||N.test(e.url))){j=e.jsonpCallback||"jsonp"+sb++;if(e.data)e.data=(e.data+"").replace(N,"="+j+"$1");e.url=e.url.replace(N,"="+j+"$1");e.dataType="script";A[j]=A[j]||function(q){o=q;b();d();A[j]=w;try{delete A[j]}catch(p){}z&&z.removeChild(C)}}if(e.dataType==="script"&&e.cache===null)e.cache=false;if(e.cache===
+false&&n==="GET"){var r=J(),u=e.url.replace(wb,"$1_="+r+"$2");e.url=u+(u===e.url?(ka.test(e.url)?"&":"?")+"_="+r:"")}if(e.data&&n==="GET")e.url+=(ka.test(e.url)?"&":"?")+e.data;e.global&&!c.active++&&c.event.trigger("ajaxStart");r=(r=xb.exec(e.url))&&(r[1]&&r[1]!==location.protocol||r[2]!==location.host);if(e.dataType==="script"&&n==="GET"&&r){var z=s.getElementsByTagName("head")[0]||s.documentElement,C=s.createElement("script");C.src=e.url;if(e.scriptCharset)C.charset=e.scriptCharset;if(!j){var B=
+false;C.onload=C.onreadystatechange=function(){if(!B&&(!this.readyState||this.readyState==="loaded"||this.readyState==="complete")){B=true;b();d();C.onload=C.onreadystatechange=null;z&&C.parentNode&&z.removeChild(C)}}}z.insertBefore(C,z.firstChild);return w}var E=false,x=e.xhr();if(x){e.username?x.open(n,e.url,e.async,e.username,e.password):x.open(n,e.url,e.async);try{if(e.data||a&&a.contentType)x.setRequestHeader("Content-Type",e.contentType);if(e.ifModified){c.lastModified[e.url]&&x.setRequestHeader("If-Modified-Since",
+c.lastModified[e.url]);c.etag[e.url]&&x.setRequestHeader("If-None-Match",c.etag[e.url])}r||x.setRequestHeader("X-Requested-With","XMLHttpRequest");x.setRequestHeader("Accept",e.dataType&&e.accepts[e.dataType]?e.accepts[e.dataType]+", */*":e.accepts._default)}catch(ga){}if(e.beforeSend&&e.beforeSend.call(k,x,e)===false){e.global&&!--c.active&&c.event.trigger("ajaxStop");x.abort();return false}e.global&&f("ajaxSend",[x,e]);var g=x.onreadystatechange=function(q){if(!x||x.readyState===0||q==="abort"){E||
+d();E=true;if(x)x.onreadystatechange=c.noop}else if(!E&&x&&(x.readyState===4||q==="timeout")){E=true;x.onreadystatechange=c.noop;i=q==="timeout"?"timeout":!c.httpSuccess(x)?"error":e.ifModified&&c.httpNotModified(x,e.url)?"notmodified":"success";var p;if(i==="success")try{o=c.httpData(x,e.dataType,e)}catch(v){i="parsererror";p=v}if(i==="success"||i==="notmodified")j||b();else c.handleError(e,x,i,p);d();q==="timeout"&&x.abort();if(e.async)x=null}};try{var h=x.abort;x.abort=function(){x&&h.call(x);
+g("abort")}}catch(l){}e.async&&e.timeout>0&&setTimeout(function(){x&&!E&&g("timeout")},e.timeout);try{x.send(n==="POST"||n==="PUT"||n==="DELETE"?e.data:null)}catch(m){c.handleError(e,x,null,m);d()}e.async||g();return x}},handleError:function(a,b,d,f){if(a.error)a.error.call(a.context||a,b,d,f);if(a.global)(a.context?c(a.context):c.event).trigger("ajaxError",[b,a,f])},active:0,httpSuccess:function(a){try{return!a.status&&location.protocol==="file:"||a.status>=200&&a.status<300||a.status===304||a.status===
+1223||a.status===0}catch(b){}return false},httpNotModified:function(a,b){var d=a.getResponseHeader("Last-Modified"),f=a.getResponseHeader("Etag");if(d)c.lastModified[b]=d;if(f)c.etag[b]=f;return a.status===304||a.status===0},httpData:function(a,b,d){var f=a.getResponseHeader("content-type")||"",e=b==="xml"||!b&&f.indexOf("xml")>=0;a=e?a.responseXML:a.responseText;e&&a.documentElement.nodeName==="parsererror"&&c.error("parsererror");if(d&&d.dataFilter)a=d.dataFilter(a,b);if(typeof a==="string")if(b===
+"json"||!b&&f.indexOf("json")>=0)a=c.parseJSON(a);else if(b==="script"||!b&&f.indexOf("javascript")>=0)c.globalEval(a);return a},param:function(a,b){function d(i,o){if(c.isArray(o))c.each(o,function(k,n){b||/\[\]$/.test(i)?f(i,n):d(i+"["+(typeof n==="object"||c.isArray(n)?k:"")+"]",n)});else!b&&o!=null&&typeof o==="object"?c.each(o,function(k,n){d(i+"["+k+"]",n)}):f(i,o)}function f(i,o){o=c.isFunction(o)?o():o;e[e.length]=encodeURIComponent(i)+"="+encodeURIComponent(o)}var e=[];if(b===w)b=c.ajaxSettings.traditional;
+if(c.isArray(a)||a.jquery)c.each(a,function(){f(this.name,this.value)});else for(var j in a)d(j,a[j]);return e.join("&").replace(yb,"+")}});var la={},Ab=/toggle|show|hide/,Bb=/^([+-]=)?([\d+-.]+)(.*)$/,W,va=[["height","marginTop","marginBottom","paddingTop","paddingBottom"],["width","marginLeft","marginRight","paddingLeft","paddingRight"],["opacity"]];c.fn.extend({show:function(a,b){if(a||a===0)return this.animate(K("show",3),a,b);else{a=0;for(b=this.length;a<b;a++){var d=c.data(this[a],"olddisplay");
+this[a].style.display=d||"";if(c.css(this[a],"display")==="none"){d=this[a].nodeName;var f;if(la[d])f=la[d];else{var e=c("<"+d+" />").appendTo("body");f=e.css("display");if(f==="none")f="block";e.remove();la[d]=f}c.data(this[a],"olddisplay",f)}}a=0;for(b=this.length;a<b;a++)this[a].style.display=c.data(this[a],"olddisplay")||"";return this}},hide:function(a,b){if(a||a===0)return this.animate(K("hide",3),a,b);else{a=0;for(b=this.length;a<b;a++){var d=c.data(this[a],"olddisplay");!d&&d!=="none"&&c.data(this[a],
+"olddisplay",c.css(this[a],"display"))}a=0;for(b=this.length;a<b;a++)this[a].style.display="none";return this}},_toggle:c.fn.toggle,toggle:function(a,b){var d=typeof a==="boolean";if(c.isFunction(a)&&c.isFunction(b))this._toggle.apply(this,arguments);else a==null||d?this.each(function(){var f=d?a:c(this).is(":hidden");c(this)[f?"show":"hide"]()}):this.animate(K("toggle",3),a,b);return this},fadeTo:function(a,b,d){return this.filter(":hidden").css("opacity",0).show().end().animate({opacity:b},a,d)},
+animate:function(a,b,d,f){var e=c.speed(b,d,f);if(c.isEmptyObject(a))return this.each(e.complete);return this[e.queue===false?"each":"queue"](function(){var j=c.extend({},e),i,o=this.nodeType===1&&c(this).is(":hidden"),k=this;for(i in a){var n=i.replace(ia,ja);if(i!==n){a[n]=a[i];delete a[i];i=n}if(a[i]==="hide"&&o||a[i]==="show"&&!o)return j.complete.call(this);if((i==="height"||i==="width")&&this.style){j.display=c.css(this,"display");j.overflow=this.style.overflow}if(c.isArray(a[i])){(j.specialEasing=
+j.specialEasing||{})[i]=a[i][1];a[i]=a[i][0]}}if(j.overflow!=null)this.style.overflow="hidden";j.curAnim=c.extend({},a);c.each(a,function(r,u){var z=new c.fx(k,j,r);if(Ab.test(u))z[u==="toggle"?o?"show":"hide":u](a);else{var C=Bb.exec(u),B=z.cur(true)||0;if(C){u=parseFloat(C[2]);var E=C[3]||"px";if(E!=="px"){k.style[r]=(u||1)+E;B=(u||1)/z.cur(true)*B;k.style[r]=B+E}if(C[1])u=(C[1]==="-="?-1:1)*u+B;z.custom(B,u,E)}else z.custom(B,u,"")}});return true})},stop:function(a,b){var d=c.timers;a&&this.queue([]);
+this.each(function(){for(var f=d.length-1;f>=0;f--)if(d[f].elem===this){b&&d[f](true);d.splice(f,1)}});b||this.dequeue();return this}});c.each({slideDown:K("show",1),slideUp:K("hide",1),slideToggle:K("toggle",1),fadeIn:{opacity:"show"},fadeOut:{opacity:"hide"}},function(a,b){c.fn[a]=function(d,f){return this.animate(b,d,f)}});c.extend({speed:function(a,b,d){var f=a&&typeof a==="object"?a:{complete:d||!d&&b||c.isFunction(a)&&a,duration:a,easing:d&&b||b&&!c.isFunction(b)&&b};f.duration=c.fx.off?0:typeof f.duration===
+"number"?f.duration:c.fx.speeds[f.duration]||c.fx.speeds._default;f.old=f.complete;f.complete=function(){f.queue!==false&&c(this).dequeue();c.isFunction(f.old)&&f.old.call(this)};return f},easing:{linear:function(a,b,d,f){return d+f*a},swing:function(a,b,d,f){return(-Math.cos(a*Math.PI)/2+0.5)*f+d}},timers:[],fx:function(a,b,d){this.options=b;this.elem=a;this.prop=d;if(!b.orig)b.orig={}}});c.fx.prototype={update:function(){this.options.step&&this.options.step.call(this.elem,this.now,this);(c.fx.step[this.prop]||
+c.fx.step._default)(this);if((this.prop==="height"||this.prop==="width")&&this.elem.style)this.elem.style.display="block"},cur:function(a){if(this.elem[this.prop]!=null&&(!this.elem.style||this.elem.style[this.prop]==null))return this.elem[this.prop];return(a=parseFloat(c.css(this.elem,this.prop,a)))&&a>-10000?a:parseFloat(c.curCSS(this.elem,this.prop))||0},custom:function(a,b,d){function f(j){return e.step(j)}this.startTime=J();this.start=a;this.end=b;this.unit=d||this.unit||"px";this.now=this.start;
+this.pos=this.state=0;var e=this;f.elem=this.elem;if(f()&&c.timers.push(f)&&!W)W=setInterval(c.fx.tick,13)},show:function(){this.options.orig[this.prop]=c.style(this.elem,this.prop);this.options.show=true;this.custom(this.prop==="width"||this.prop==="height"?1:0,this.cur());c(this.elem).show()},hide:function(){this.options.orig[this.prop]=c.style(this.elem,this.prop);this.options.hide=true;this.custom(this.cur(),0)},step:function(a){var b=J(),d=true;if(a||b>=this.options.duration+this.startTime){this.now=
+this.end;this.pos=this.state=1;this.update();this.options.curAnim[this.prop]=true;for(var f in this.options.curAnim)if(this.options.curAnim[f]!==true)d=false;if(d){if(this.options.display!=null){this.elem.style.overflow=this.options.overflow;a=c.data(this.elem,"olddisplay");this.elem.style.display=a?a:this.options.display;if(c.css(this.elem,"display")==="none")this.elem.style.display="block"}this.options.hide&&c(this.elem).hide();if(this.options.hide||this.options.show)for(var e in this.options.curAnim)c.style(this.elem,
+e,this.options.orig[e]);this.options.complete.call(this.elem)}return false}else{e=b-this.startTime;this.state=e/this.options.duration;a=this.options.easing||(c.easing.swing?"swing":"linear");this.pos=c.easing[this.options.specialEasing&&this.options.specialEasing[this.prop]||a](this.state,e,0,1,this.options.duration);this.now=this.start+(this.end-this.start)*this.pos;this.update()}return true}};c.extend(c.fx,{tick:function(){for(var a=c.timers,b=0;b<a.length;b++)a[b]()||a.splice(b--,1);a.length||
+c.fx.stop()},stop:function(){clearInterval(W);W=null},speeds:{slow:600,fast:200,_default:400},step:{opacity:function(a){c.style(a.elem,"opacity",a.now)},_default:function(a){if(a.elem.style&&a.elem.style[a.prop]!=null)a.elem.style[a.prop]=(a.prop==="width"||a.prop==="height"?Math.max(0,a.now):a.now)+a.unit;else a.elem[a.prop]=a.now}}});if(c.expr&&c.expr.filters)c.expr.filters.animated=function(a){return c.grep(c.timers,function(b){return a===b.elem}).length};c.fn.offset="getBoundingClientRect"in s.documentElement?
+function(a){var b=this[0];if(a)return this.each(function(e){c.offset.setOffset(this,a,e)});if(!b||!b.ownerDocument)return null;if(b===b.ownerDocument.body)return c.offset.bodyOffset(b);var d=b.getBoundingClientRect(),f=b.ownerDocument;b=f.body;f=f.documentElement;return{top:d.top+(self.pageYOffset||c.support.boxModel&&f.scrollTop||b.scrollTop)-(f.clientTop||b.clientTop||0),left:d.left+(self.pageXOffset||c.support.boxModel&&f.scrollLeft||b.scrollLeft)-(f.clientLeft||b.clientLeft||0)}}:function(a){var b=
+this[0];if(a)return this.each(function(r){c.offset.setOffset(this,a,r)});if(!b||!b.ownerDocument)return null;if(b===b.ownerDocument.body)return c.offset.bodyOffset(b);c.offset.initialize();var d=b.offsetParent,f=b,e=b.ownerDocument,j,i=e.documentElement,o=e.body;f=(e=e.defaultView)?e.getComputedStyle(b,null):b.currentStyle;for(var k=b.offsetTop,n=b.offsetLeft;(b=b.parentNode)&&b!==o&&b!==i;){if(c.offset.supportsFixedPosition&&f.position==="fixed")break;j=e?e.getComputedStyle(b,null):b.currentStyle;
+k-=b.scrollTop;n-=b.scrollLeft;if(b===d){k+=b.offsetTop;n+=b.offsetLeft;if(c.offset.doesNotAddBorder&&!(c.offset.doesAddBorderForTableAndCells&&/^t(able|d|h)$/i.test(b.nodeName))){k+=parseFloat(j.borderTopWidth)||0;n+=parseFloat(j.borderLeftWidth)||0}f=d;d=b.offsetParent}if(c.offset.subtractsBorderForOverflowNotVisible&&j.overflow!=="visible"){k+=parseFloat(j.borderTopWidth)||0;n+=parseFloat(j.borderLeftWidth)||0}f=j}if(f.position==="relative"||f.position==="static"){k+=o.offsetTop;n+=o.offsetLeft}if(c.offset.supportsFixedPosition&&
+f.position==="fixed"){k+=Math.max(i.scrollTop,o.scrollTop);n+=Math.max(i.scrollLeft,o.scrollLeft)}return{top:k,left:n}};c.offset={initialize:function(){var a=s.body,b=s.createElement("div"),d,f,e,j=parseFloat(c.curCSS(a,"marginTop",true))||0;c.extend(b.style,{position:"absolute",top:0,left:0,margin:0,border:0,width:"1px",height:"1px",visibility:"hidden"});b.innerHTML="<div style='position:absolute;top:0;left:0;margin:0;border:5px solid #000;padding:0;width:1px;height:1px;'><div></div></div><table style='position:absolute;top:0;left:0;margin:0;border:5px solid #000;padding:0;width:1px;height:1px;' cellpadding='0' cellspacing='0'><tr><td></td></tr></table>";
+a.insertBefore(b,a.firstChild);d=b.firstChild;f=d.firstChild;e=d.nextSibling.firstChild.firstChild;this.doesNotAddBorder=f.offsetTop!==5;this.doesAddBorderForTableAndCells=e.offsetTop===5;f.style.position="fixed";f.style.top="20px";this.supportsFixedPosition=f.offsetTop===20||f.offsetTop===15;f.style.position=f.style.top="";d.style.overflow="hidden";d.style.position="relative";this.subtractsBorderForOverflowNotVisible=f.offsetTop===-5;this.doesNotIncludeMarginInBodyOffset=a.offsetTop!==j;a.removeChild(b);
+c.offset.initialize=c.noop},bodyOffset:function(a){var b=a.offsetTop,d=a.offsetLeft;c.offset.initialize();if(c.offset.doesNotIncludeMarginInBodyOffset){b+=parseFloat(c.curCSS(a,"marginTop",true))||0;d+=parseFloat(c.curCSS(a,"marginLeft",true))||0}return{top:b,left:d}},setOffset:function(a,b,d){if(/static/.test(c.curCSS(a,"position")))a.style.position="relative";var f=c(a),e=f.offset(),j=parseInt(c.curCSS(a,"top",true),10)||0,i=parseInt(c.curCSS(a,"left",true),10)||0;if(c.isFunction(b))b=b.call(a,
+d,e);d={top:b.top-e.top+j,left:b.left-e.left+i};"using"in b?b.using.call(a,d):f.css(d)}};c.fn.extend({position:function(){if(!this[0])return null;var a=this[0],b=this.offsetParent(),d=this.offset(),f=/^body|html$/i.test(b[0].nodeName)?{top:0,left:0}:b.offset();d.top-=parseFloat(c.curCSS(a,"marginTop",true))||0;d.left-=parseFloat(c.curCSS(a,"marginLeft",true))||0;f.top+=parseFloat(c.curCSS(b[0],"borderTopWidth",true))||0;f.left+=parseFloat(c.curCSS(b[0],"borderLeftWidth",true))||0;return{top:d.top-
+f.top,left:d.left-f.left}},offsetParent:function(){return this.map(function(){for(var a=this.offsetParent||s.body;a&&!/^body|html$/i.test(a.nodeName)&&c.css(a,"position")==="static";)a=a.offsetParent;return a})}});c.each(["Left","Top"],function(a,b){var d="scroll"+b;c.fn[d]=function(f){var e=this[0],j;if(!e)return null;if(f!==w)return this.each(function(){if(j=wa(this))j.scrollTo(!a?f:c(j).scrollLeft(),a?f:c(j).scrollTop());else this[d]=f});else return(j=wa(e))?"pageXOffset"in j?j[a?"pageYOffset":
+"pageXOffset"]:c.support.boxModel&&j.document.documentElement[d]||j.document.body[d]:e[d]}});c.each(["Height","Width"],function(a,b){var d=b.toLowerCase();c.fn["inner"+b]=function(){return this[0]?c.css(this[0],d,false,"padding"):null};c.fn["outer"+b]=function(f){return this[0]?c.css(this[0],d,false,f?"margin":"border"):null};c.fn[d]=function(f){var e=this[0];if(!e)return f==null?null:this;if(c.isFunction(f))return this.each(function(j){var i=c(this);i[d](f.call(this,j,i[d]()))});return"scrollTo"in
+e&&e.document?e.document.compatMode==="CSS1Compat"&&e.document.documentElement["client"+b]||e.document.body["client"+b]:e.nodeType===9?Math.max(e.documentElement["client"+b],e.body["scroll"+b],e.documentElement["scroll"+b],e.body["offset"+b],e.documentElement["offset"+b]):f===w?c.css(e,d):this.css(d,typeof f==="string"?f:f+"px")}});A.jQuery=A.$=c})(window);
diff -Naur nginx-1.11.3/nginx-push-stream-module/misc/js/pushstream.js nginx-1.11.3-push/nginx-push-stream-module/misc/js/pushstream.js
--- nginx-1.11.3/nginx-push-stream-module/misc/js/pushstream.js	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/misc/js/pushstream.js	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,1145 @@
+/*global PushStream WebSocketWrapper EventSourceWrapper EventSource*/
+/*jshint evil: true, plusplus: false, regexp: false */
+/**
+The MIT License (MIT)
+
+Copyright (c) 2010-2014 Wandenberg Peixoto <wandenberg@gmail.com>, Rog√©rio Carvalho Schneider <stockrt@gmail.com>
+
+This file is part of Nginx Push Stream Module.
+
+Permission is hereby granted, free of charge, to any person obtaining a copy
+of this software and associated documentation files (the "Software"), to deal
+in the Software without restriction, including without limitation the rights
+to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+copies of the Software, and to permit persons to whom the Software is
+furnished to do so, subject to the following conditions:
+
+The above copyright notice and this permission notice shall be included in all
+copies or substantial portions of the Software.
+
+THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+SOFTWARE.
+
+pushstream.js
+
+Created: Nov 01, 2011
+Authors: Wandenberg Peixoto <wandenberg@gmail.com>, Rog√©rio Carvalho Schneider <stockrt@gmail.com>
+ */
+(function (window, document, undefined) {
+  "use strict";
+
+  /* prevent duplicate declaration */
+  if (window.PushStream) { return; }
+
+  var Utils = {};
+
+  var days = ["Sun", "Mon", "Tue", "Wed", "Thu", "Fri", "Sat"];
+  var months = ["Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec"];
+
+  var valueToTwoDigits = function (value) {
+    return ((value < 10) ? '0' : '') + value;
+  };
+
+  Utils.dateToUTCString = function (date) {
+    var time = valueToTwoDigits(date.getUTCHours()) + ':' + valueToTwoDigits(date.getUTCMinutes()) + ':' + valueToTwoDigits(date.getUTCSeconds());
+    return days[date.getUTCDay()] + ', ' + valueToTwoDigits(date.getUTCDate()) + ' ' + months[date.getUTCMonth()] + ' ' + date.getUTCFullYear() + ' ' + time + ' GMT';
+  };
+
+  var extend = function () {
+    var object = arguments[0] || {};
+    for (var i = 0; i < arguments.length; i++) {
+      var settings = arguments[i];
+      for (var attr in settings) {
+        if (!settings.hasOwnProperty || settings.hasOwnProperty(attr)) {
+          object[attr] = settings[attr];
+        }
+      }
+    }
+    return object;
+  };
+
+  var validChars  = /^[\],:{}\s]*$/,
+      validEscape = /\\(?:["\\\/bfnrt]|u[0-9a-fA-F]{4})/g,
+      validTokens = /"[^"\\\n\r]*"|true|false|null|-?\d+(?:\.\d*)?(?:[eE][+\-]?\d+)?/g,
+      validBraces = /(?:^|:|,)(?:\s*\[)+/g;
+
+  var trim = function(value) {
+    return value.replace(/^\s*/, "").replace(/\s*$/, "");
+  };
+
+  Utils.parseJSON = function(data) {
+    if (!data || !isString(data)) {
+      return null;
+    }
+
+    // Make sure leading/trailing whitespace is removed (IE can't handle it)
+    data = trim(data);
+
+    // Attempt to parse using the native JSON parser first
+    if (window.JSON && window.JSON.parse) {
+      try {
+        return window.JSON.parse( data );
+      } catch(e) {
+        throw "Invalid JSON: " + data;
+      }
+    }
+
+    // Make sure the incoming data is actual JSON
+    // Logic borrowed from http://json.org/json2.js
+    if (validChars.test(data.replace(validEscape, "@").replace( validTokens, "]").replace( validBraces, "")) ) {
+      return (new Function("return " + data))();
+    }
+
+    throw "Invalid JSON: " + data;
+  };
+
+  var getControlParams = function(pushstream) {
+    var data = {};
+    data[pushstream.tagArgument] = "";
+    data[pushstream.timeArgument] = "";
+    data[pushstream.eventIdArgument] = "";
+    if (pushstream.messagesControlByArgument) {
+      data[pushstream.tagArgument] = Number(pushstream._etag);
+      if (pushstream._lastModified) {
+        data[pushstream.timeArgument] = pushstream._lastModified;
+      } else if (pushstream._lastEventId) {
+        data[pushstream.eventIdArgument] = pushstream._lastEventId;
+      }
+    }
+    return data;
+  };
+
+  var getTime = function() {
+    return (new Date()).getTime();
+  };
+
+  var currentTimestampParam = function() {
+    return { "_" : getTime() };
+  };
+
+  var objectToUrlParams = function(settings) {
+    var params = settings;
+    if (typeof(settings) === 'object') {
+      params = '';
+      for (var attr in settings) {
+        if (!settings.hasOwnProperty || settings.hasOwnProperty(attr)) {
+          params += '&' + attr + '=' + window.escape(settings[attr]);
+        }
+      }
+      params = params.substring(1);
+    }
+
+    return params || '';
+  };
+
+  var addParamsToUrl = function(url, params) {
+    return url + ((url.indexOf('?') < 0) ? '?' : '&') + objectToUrlParams(params);
+  };
+
+  var isArray = Array.isArray || function(obj) {
+    return Object.prototype.toString.call(obj) === '[object Array]';
+  };
+
+  var isString = function(obj) {
+    return Object.prototype.toString.call(obj) === '[object String]';
+  };
+
+  var isDate = function(obj) {
+    return Object.prototype.toString.call(obj) === '[object Date]';
+  };
+
+  var Log4js = {
+    logger: null,
+    debug : function() { if  (PushStream.LOG_LEVEL === 'debug')                                         { Log4js._log.apply(Log4js._log, arguments); }},
+    info  : function() { if ((PushStream.LOG_LEVEL === 'info')  || (PushStream.LOG_LEVEL === 'debug'))  { Log4js._log.apply(Log4js._log, arguments); }},
+    error : function() {                                                                                  Log4js._log.apply(Log4js._log, arguments); },
+    _initLogger : function() {
+      var console = window.console;
+      if (console && console.log) {
+        if (console.log.apply) {
+          Log4js.logger = console.log;
+        } else if ((typeof console.log === "object") && Function.prototype.bind) {
+          Log4js.logger = Function.prototype.bind.call(console.log, console);
+        } else if ((typeof console.log === "object") && Function.prototype.call) {
+          Log4js.logger = function() {
+            Function.prototype.call.call(console.log, console, Array.prototype.slice.call(arguments));
+          };
+        }
+      }
+    },
+    _log  : function() {
+      if (!Log4js.logger) {
+        Log4js._initLogger();
+      }
+
+      if (Log4js.logger) {
+        try {
+          Log4js.logger.apply(window.console, arguments);
+        } catch(e) {
+          Log4js._initLogger();
+          if (Log4js.logger) {
+            Log4js.logger.apply(window.console, arguments);
+          }
+        }
+      }
+
+      var logElement = document.getElementById(PushStream.LOG_OUTPUT_ELEMENT_ID);
+      if (logElement) {
+        var str = '';
+        for (var i = 0; i < arguments.length; i++) {
+          str += arguments[i] + " ";
+        }
+        logElement.innerHTML += str + '\n';
+
+        var lines = logElement.innerHTML.split('\n');
+        if (lines.length > 100) {
+          logElement.innerHTML = lines.slice(-100).join('\n');
+        }
+      }
+    }
+  };
+
+  var Ajax = {
+    _getXHRObject : function(crossDomain) {
+      var xhr = false;
+      if (crossDomain) {
+        try { xhr = new window.XDomainRequest(); } catch (e) { }
+        if (xhr) {
+          return xhr;
+        }
+      }
+
+      try { xhr = new window.XMLHttpRequest(); }
+      catch (e1) {
+        try { xhr = new window.ActiveXObject("Msxml2.XMLHTTP"); }
+        catch (e2) {
+          try { xhr = new window.ActiveXObject("Microsoft.XMLHTTP"); }
+          catch (e3) {
+            xhr = false;
+          }
+        }
+      }
+      return xhr;
+    },
+
+    _send : function(settings, post) {
+      settings = settings || {};
+      settings.timeout = settings.timeout || 30000;
+      var xhr = Ajax._getXHRObject(settings.crossDomain);
+      if (!xhr||!settings.url) { return; }
+
+      Ajax.clear(settings);
+
+      settings.xhr = xhr;
+
+      if (window.XDomainRequest && (xhr instanceof window.XDomainRequest)) {
+        xhr.onload = function () {
+          if (settings.afterReceive) { settings.afterReceive(xhr); }
+          if (settings.success) { settings.success(xhr.responseText); }
+        };
+
+        xhr.onerror = xhr.ontimeout = function () {
+          if (settings.afterReceive) { settings.afterReceive(xhr); }
+          if (settings.error) { settings.error(xhr.status); }
+        };
+      } else {
+        xhr.onreadystatechange = function () {
+          if (xhr.readyState === 4) {
+            Ajax.clear(settings);
+            if (settings.afterReceive) { settings.afterReceive(xhr); }
+            if(xhr.status === 200) {
+              if (settings.success) { settings.success(xhr.responseText); }
+            } else {
+              if (settings.error) { settings.error(xhr.status); }
+            }
+          }
+        };
+      }
+
+      if (settings.beforeOpen) { settings.beforeOpen(xhr); }
+
+      var params = {};
+      var body = null;
+      var method = "GET";
+      if (post) {
+        body = objectToUrlParams(settings.data);
+        method = "POST";
+      } else {
+        params = settings.data || {};
+      }
+
+      xhr.open(method, addParamsToUrl(settings.url, extend({}, params, currentTimestampParam())), true);
+
+      if (settings.beforeSend) { settings.beforeSend(xhr); }
+
+      var onerror = function() {
+        Ajax.clear(settings);
+        try { xhr.abort(); } catch (e) { /* ignore error on closing */ }
+        settings.error(304);
+      };
+
+      if (post) {
+        if (xhr.setRequestHeader) {
+          xhr.setRequestHeader("Accept", "application/json");
+          xhr.setRequestHeader("Content-type", "application/x-www-form-urlencoded");
+        }
+      } else {
+        settings.timeoutId = window.setTimeout(onerror, settings.timeout + 2000);
+      }
+
+      xhr.send(body);
+      return xhr;
+    },
+
+    _clear_xhr : function(xhr) {
+      if (xhr) {
+        xhr.onreadystatechange = null;
+      }
+    },
+
+    _clear_script : function(script) {
+      // Handling memory leak in IE, removing and dereference the script
+      if (script) {
+        script.onerror = script.onload = script.onreadystatechange = null;
+        if (script.parentNode) { script.parentNode.removeChild(script); }
+      }
+    },
+
+    _clear_timeout : function(settings) {
+      settings.timeoutId = clearTimer(settings.timeoutId);
+    },
+
+    _clear_jsonp : function(settings) {
+      var callbackFunctionName = settings.data.callback;
+      if (callbackFunctionName) {
+        window[callbackFunctionName] = function() { window[callbackFunctionName] = null; };
+      }
+    },
+
+    clear : function(settings) {
+      Ajax._clear_timeout(settings);
+      Ajax._clear_jsonp(settings);
+      Ajax._clear_script(document.getElementById(settings.scriptId));
+      Ajax._clear_xhr(settings.xhr);
+    },
+
+    jsonp : function(settings) {
+      settings.timeout = settings.timeout || 30000;
+      Ajax.clear(settings);
+
+      var head = document.head || document.getElementsByTagName("head")[0];
+      var script = document.createElement("script");
+      var startTime = getTime();
+
+      var onerror = function() {
+        Ajax.clear(settings);
+        var endTime = getTime();
+        settings.error(((endTime - startTime) > settings.timeout/2) ? 304 : 403);
+      };
+
+      var onload = function() {
+        Ajax.clear(settings);
+        settings.load();
+      };
+
+      var onsuccess = function() {
+        settings.afterSuccess = true;
+        settings.success.apply(null, arguments);
+      };
+
+      script.onerror = onerror;
+      script.onload = script.onreadystatechange = function(eventLoad) {
+        if (!script.readyState || /loaded|complete/.test(script.readyState)) {
+          if (settings.afterSuccess) {
+            onload();
+          } else {
+            onerror();
+          }
+        }
+      };
+
+      if (settings.beforeOpen) { settings.beforeOpen({}); }
+      if (settings.beforeSend) { settings.beforeSend({}); }
+
+      settings.timeoutId = window.setTimeout(onerror, settings.timeout + 2000);
+      settings.scriptId = settings.scriptId || getTime();
+      settings.afterSuccess = null;
+
+      settings.data.callback = settings.scriptId + "_onmessage_" + getTime();
+      window[settings.data.callback] = onsuccess;
+
+      script.setAttribute("src", addParamsToUrl(settings.url, extend({}, settings.data, currentTimestampParam())));
+      script.setAttribute("async", "async");
+      script.setAttribute("id", settings.scriptId);
+
+      // Use insertBefore instead of appendChild to circumvent an IE6 bug.
+      head.insertBefore(script, head.firstChild);
+      return settings;
+    },
+
+    load : function(settings) {
+      return Ajax._send(settings, false);
+    },
+
+    post : function(settings) {
+      return Ajax._send(settings, true);
+    }
+  };
+
+  var escapeText = function(text) {
+    return (text) ? window.escape(text) : '';
+  };
+
+  var unescapeText = function(text) {
+    return (text) ? window.unescape(text) : '';
+  };
+
+  Utils.parseMessage = function(messageText, keys) {
+    var msg = messageText;
+    if (isString(messageText)) {
+      msg = Utils.parseJSON(messageText);
+    }
+
+    var message = {
+        id     : msg[keys.jsonIdKey],
+        channel: msg[keys.jsonChannelKey],
+        text   : isString(msg[keys.jsonTextKey]) ? unescapeText(msg[keys.jsonTextKey]) : msg[keys.jsonTextKey],
+        tag    : msg[keys.jsonTagKey],
+        time   : msg[keys.jsonTimeKey],
+        eventid: msg[keys.jsonEventIdKey] || ""
+    };
+
+    return message;
+  };
+
+  var getBacktrack = function(options) {
+    return (options.backtrack) ? ".b" + Number(options.backtrack) : "";
+  };
+
+  var getChannelsPath = function(channels, withBacktrack) {
+    var path = '';
+    for (var channelName in channels) {
+      if (!channels.hasOwnProperty || channels.hasOwnProperty(channelName)) {
+        path += "/" + channelName + (withBacktrack ? getBacktrack(channels[channelName]) : "");
+      }
+    }
+    return path;
+  };
+
+  var getSubscriberUrl = function(pushstream, prefix, extraParams, withBacktrack) {
+    var websocket = pushstream.wrapper.type === WebSocketWrapper.TYPE;
+    var useSSL = pushstream.useSSL;
+    var port = normalizePort(useSSL, pushstream.port);
+    var url = (websocket) ? ((useSSL) ? "wss://" : "ws://") : ((useSSL) ? "https://" : "http://");
+    url += pushstream.host;
+    url += (port ? (":" + port) : "");
+    url += prefix;
+
+    var channels = getChannelsPath(pushstream.channels, withBacktrack);
+    if (pushstream.channelsByArgument) {
+      var channelParam = {};
+      channelParam[pushstream.channelsArgument] = channels.substring(1);
+      extraParams = extend({}, extraParams, channelParam);
+    } else {
+      url += channels;
+    }
+    return addParamsToUrl(url, extraParams);
+  };
+
+  var getPublisherUrl = function(pushstream) {
+    var port = normalizePort(pushstream.useSSL, pushstream.port);
+    var url = (pushstream.useSSL) ? "https://" : "http://";
+    url += pushstream.host;
+    url += (port ? (":" + port) : "");
+    url += pushstream.urlPrefixPublisher;
+    url += "?id=" + getChannelsPath(pushstream.channels, false);
+
+    return url;
+  };
+
+  Utils.extract_xss_domain = function(domain) {
+    // if domain is an ip address return it, else return ate least the last two parts of it
+    if (domain.match(/^(\d{1,3}\.){3}\d{1,3}$/)) {
+      return domain;
+    }
+
+    var domainParts = domain.split('.');
+    // if the domain ends with 3 chars or 2 chars preceded by more than 4 chars,
+    // we can keep only 2 parts, else we have to keep at least 3 (or all domain name)
+    var keepNumber = Math.max(domainParts.length - 1, (domain.match(/(\w{4,}\.\w{2}|\.\w{3,})$/) ? 2 : 3));
+
+    return domainParts.slice(-1 * keepNumber).join('.');
+  };
+
+  var normalizePort = function (useSSL, port) {
+    port = Number(port || (useSSL ? 443 : 80));
+    return ((!useSSL && port === 80) || (useSSL && port === 443)) ? "" : port;
+  };
+
+  Utils.isCrossDomainUrl = function(url) {
+    if (!url) {
+      return false;
+    }
+
+    var parser = document.createElement('a');
+    parser.href = url;
+
+    var srcPort = normalizePort(window.location.protocol === "https:", window.location.port);
+    var dstPort = normalizePort(parser.protocol === "https:", parser.port);
+
+    return (window.location.protocol !== parser.protocol) ||
+           (window.location.hostname !== parser.hostname) ||
+           (srcPort !== dstPort);
+  };
+
+  var linker = function(method, instance) {
+    return function() {
+      return method.apply(instance, arguments);
+    };
+  };
+
+  var clearTimer = function(timer) {
+    if (timer) {
+      window.clearTimeout(timer);
+    }
+    return null;
+  };
+
+  /* common callbacks */
+  var onmessageCallback = function(event) {
+    Log4js.info("[" + this.type + "] message received", arguments);
+    var message = Utils.parseMessage(event.data, this.pushstream);
+    if (message.tag) { this.pushstream._etag = message.tag; }
+    if (message.time) { this.pushstream._lastModified = message.time; }
+    if (message.eventid) { this.pushstream._lastEventId = message.eventid; }
+    this.pushstream._onmessage(message.text, message.id, message.channel, message.eventid, true, message.time);
+  };
+
+  var onopenCallback = function() {
+    this.pushstream._onopen();
+    Log4js.info("[" + this.type + "] connection opened");
+  };
+
+  var onerrorCallback = function(event) {
+    Log4js.info("[" + this.type + "] error (disconnected by server):", event);
+    if ((this.pushstream.readyState === PushStream.OPEN) &&
+        (this.type === EventSourceWrapper.TYPE) &&
+        (event.type === 'error') &&
+        (this.connection.readyState === window.EventSource.CONNECTING)) {
+      // EventSource already has a reconnection function using the last-event-id header
+      return;
+    }
+    this._closeCurrentConnection();
+    this.pushstream._onerror({type: ((event && ((event.type === "load") || ((event.type === "close") && (event.code === 1006)))) || (this.pushstream.readyState === PushStream.CONNECTING)) ? "load" : "timeout"});
+  };
+
+  /* wrappers */
+
+  var WebSocketWrapper = function(pushstream) {
+    if (!window.WebSocket && !window.MozWebSocket) { throw "WebSocket not supported"; }
+    this.type = WebSocketWrapper.TYPE;
+    this.pushstream = pushstream;
+    this.connection = null;
+  };
+
+  WebSocketWrapper.TYPE = "WebSocket";
+
+  WebSocketWrapper.prototype = {
+    connect: function() {
+      this._closeCurrentConnection();
+      var params = extend({}, this.pushstream.extraParams(), currentTimestampParam(), getControlParams(this.pushstream));
+      var url = getSubscriberUrl(this.pushstream, this.pushstream.urlPrefixWebsocket, params, !this.pushstream._useControlArguments());
+      this.connection = (window.WebSocket) ? new window.WebSocket(url) : new window.MozWebSocket(url);
+      this.connection.onerror   = linker(onerrorCallback, this);
+      this.connection.onclose   = linker(onerrorCallback, this);
+      this.connection.onopen    = linker(onopenCallback, this);
+      this.connection.onmessage = linker(onmessageCallback, this);
+      Log4js.info("[WebSocket] connecting to:", url);
+    },
+
+    disconnect: function() {
+      if (this.connection) {
+        Log4js.debug("[WebSocket] closing connection to:", this.connection.url);
+        this.connection.onclose = null;
+        this._closeCurrentConnection();
+        this.pushstream._onclose();
+      }
+    },
+
+    _closeCurrentConnection: function() {
+      if (this.connection) {
+        try { this.connection.close(); } catch (e) { /* ignore error on closing */ }
+        this.connection = null;
+      }
+    },
+
+    sendMessage: function(message) {
+      if (this.connection) { this.connection.send(message); }
+    }
+  };
+
+  var EventSourceWrapper = function(pushstream) {
+    if (!window.EventSource) { throw "EventSource not supported"; }
+    this.type = EventSourceWrapper.TYPE;
+    this.pushstream = pushstream;
+    this.connection = null;
+  };
+
+  EventSourceWrapper.TYPE = "EventSource";
+
+  EventSourceWrapper.prototype = {
+    connect: function() {
+      this._closeCurrentConnection();
+      var params = extend({}, this.pushstream.extraParams(), currentTimestampParam(), getControlParams(this.pushstream));
+      var url = getSubscriberUrl(this.pushstream, this.pushstream.urlPrefixEventsource, params, !this.pushstream._useControlArguments());
+      this.connection = new window.EventSource(url);
+      this.connection.onerror   = linker(onerrorCallback, this);
+      this.connection.onopen    = linker(onopenCallback, this);
+      this.connection.onmessage = linker(onmessageCallback, this);
+      Log4js.info("[EventSource] connecting to:", url);
+    },
+
+    disconnect: function() {
+      if (this.connection) {
+        Log4js.debug("[EventSource] closing connection to:", this.connection.url);
+        this.connection.onclose = null;
+        this._closeCurrentConnection();
+        this.pushstream._onclose();
+      }
+    },
+
+    _closeCurrentConnection: function() {
+      if (this.connection) {
+        try { this.connection.close(); } catch (e) { /* ignore error on closing */ }
+        this.connection = null;
+      }
+    }
+  };
+
+  var StreamWrapper = function(pushstream) {
+    this.type = StreamWrapper.TYPE;
+    this.pushstream = pushstream;
+    this.connection = null;
+    this.url = null;
+    this.frameloadtimer = null;
+    this.pingtimer = null;
+    this.iframeId = "PushStreamManager_" + pushstream.id;
+  };
+
+  StreamWrapper.TYPE = "Stream";
+
+  StreamWrapper.prototype = {
+    connect: function() {
+      this._closeCurrentConnection();
+      var domain = Utils.extract_xss_domain(this.pushstream.host);
+      try {
+        document.domain = domain;
+      } catch(e) {
+        Log4js.error("[Stream] (warning) problem setting document.domain = " + domain + " (OBS: IE8 does not support set IP numbers as domain)");
+      }
+      var params = extend({}, this.pushstream.extraParams(), currentTimestampParam(), {"streamid": this.pushstream.id}, getControlParams(this.pushstream));
+      this.url = getSubscriberUrl(this.pushstream, this.pushstream.urlPrefixStream, params, !this.pushstream._useControlArguments());
+      Log4js.debug("[Stream] connecting to:", this.url);
+      this.loadFrame(this.url);
+    },
+
+    disconnect: function() {
+      if (this.connection) {
+        Log4js.debug("[Stream] closing connection to:", this.url);
+        this._closeCurrentConnection();
+        this.pushstream._onclose();
+      }
+    },
+
+    _clear_iframe: function() {
+      var oldIframe = document.getElementById(this.iframeId);
+      if (oldIframe) {
+        oldIframe.onload = null;
+        oldIframe.src = "about:blank";
+        if (oldIframe.parentNode) { oldIframe.parentNode.removeChild(oldIframe); }
+      }
+    },
+
+    _closeCurrentConnection: function() {
+      this._clear_iframe();
+      if (this.connection) {
+        this.pingtimer = clearTimer(this.pingtimer);
+        this.frameloadtimer = clearTimer(this.frameloadtimer);
+        this.connection = null;
+        this.transferDoc = null;
+        if (typeof window.CollectGarbage === 'function') { window.CollectGarbage(); }
+      }
+    },
+
+    loadFrame: function(url) {
+      this._clear_iframe();
+
+      var ifr = null;
+      if ("ActiveXObject" in window) {
+        var transferDoc = new window.ActiveXObject("htmlfile");
+        transferDoc.open();
+        transferDoc.write("\x3C" + "html" + "\x3E\x3C" + "script" + "\x3E" + "document.domain='" + document.domain + "';\x3C" + "/script" + "\x3E");
+        transferDoc.write("\x3C" + "body" + "\x3E\x3C" + "iframe id='" + this.iframeId + "' src='" + url + "'\x3E\x3C" + "/iframe" + "\x3E\x3C" + "/body" + "\x3E\x3C" + "/html" + "\x3E");
+        transferDoc.parentWindow.PushStream = PushStream;
+        transferDoc.close();
+        ifr = transferDoc.getElementById(this.iframeId);
+        this.transferDoc = transferDoc;
+      } else {
+        ifr = document.createElement("IFRAME");
+        ifr.style.width = "1px";
+        ifr.style.height = "1px";
+        ifr.style.border = "none";
+        ifr.style.position = "absolute";
+        ifr.style.top = "-10px";
+        ifr.style.marginTop = "-10px";
+        ifr.style.zIndex = "-20";
+        ifr.PushStream = PushStream;
+        document.body.appendChild(ifr);
+        ifr.setAttribute("src", url);
+        ifr.setAttribute("id", this.iframeId);
+      }
+
+      ifr.onload = linker(onerrorCallback, this);
+      this.connection = ifr;
+      this.frameloadtimer = window.setTimeout(linker(onerrorCallback, this), this.pushstream.timeout);
+    },
+
+    register: function(iframeWindow) {
+      this.frameloadtimer = clearTimer(this.frameloadtimer);
+      iframeWindow.p = linker(this.process, this);
+      this.connection.onload = linker(this._onframeloaded, this);
+      this.pushstream._onopen();
+      this.setPingTimer();
+      Log4js.info("[Stream] frame registered");
+    },
+
+    process: function(id, channel, text, eventid, time, tag) {
+      this.pingtimer = clearTimer(this.pingtimer);
+      Log4js.info("[Stream] message received", arguments);
+      if (id !== -1) {
+        if (tag) { this.pushstream._etag = tag; }
+        if (time) { this.pushstream._lastModified = time; }
+        if (eventid) { this.pushstream._lastEventId = eventid; }
+      }
+      this.pushstream._onmessage(unescapeText(text), id, channel, eventid || "", true, time);
+      this.setPingTimer();
+    },
+
+    _onframeloaded: function() {
+      Log4js.info("[Stream] frame loaded (disconnected by server)");
+      this.pushstream._onerror({type: "timeout"});
+      this.connection.onload = null;
+      this.disconnect();
+    },
+
+    setPingTimer: function() {
+      if (this.pingtimer) { clearTimer(this.pingtimer); }
+      this.pingtimer = window.setTimeout(linker(onerrorCallback, this), this.pushstream.pingtimeout);
+    }
+  };
+
+  var LongPollingWrapper = function(pushstream) {
+    this.type = LongPollingWrapper.TYPE;
+    this.pushstream = pushstream;
+    this.connection = null;
+    this.opentimer = null;
+    this.messagesQueue = [];
+    this._linkedInternalListen = linker(this._internalListen, this);
+    this.xhrSettings = {
+        timeout: this.pushstream.timeout,
+        data: {},
+        url: null,
+        success: linker(this.onmessage, this),
+        error: linker(this.onerror, this),
+        load: linker(this.onload, this),
+        beforeSend: linker(this.beforeSend, this),
+        afterReceive: linker(this.afterReceive, this)
+    };
+  };
+
+  LongPollingWrapper.TYPE = "LongPolling";
+
+  LongPollingWrapper.prototype = {
+    connect: function() {
+      this.messagesQueue = [];
+      this._closeCurrentConnection();
+      this.urlWithBacktrack = getSubscriberUrl(this.pushstream, this.pushstream.urlPrefixLongpolling, {}, true);
+      this.urlWithoutBacktrack = getSubscriberUrl(this.pushstream, this.pushstream.urlPrefixLongpolling, {}, false);
+      this.xhrSettings.url = this.urlWithBacktrack;
+      this.useJSONP = this.pushstream._crossDomain || this.pushstream.useJSONP;
+      this.xhrSettings.scriptId = "PushStreamManager_" + this.pushstream.id;
+      if (this.useJSONP) {
+        this.pushstream.messagesControlByArgument = true;
+      }
+      this._listen();
+      this.opentimer = window.setTimeout(linker(onopenCallback, this), 150);
+      Log4js.info("[LongPolling] connecting to:", this.xhrSettings.url);
+    },
+
+    _listen: function() {
+      if (this._internalListenTimeout) { clearTimer(this._internalListenTimeout); }
+      this._internalListenTimeout = window.setTimeout(this._linkedInternalListen, 100);
+    },
+
+    _internalListen: function() {
+      if (this.pushstream._keepConnected) {
+        this.xhrSettings.url = this.pushstream._useControlArguments() ? this.urlWithoutBacktrack : this.urlWithBacktrack;
+        this.xhrSettings.data = extend({}, this.pushstream.extraParams(), this.xhrSettings.data, getControlParams(this.pushstream));
+        if (this.useJSONP) {
+          this.connection = Ajax.jsonp(this.xhrSettings);
+        } else if (!this.connection) {
+          this.connection = Ajax.load(this.xhrSettings);
+        }
+      }
+    },
+
+    disconnect: function() {
+      if (this.connection) {
+        Log4js.debug("[LongPolling] closing connection to:", this.xhrSettings.url);
+        this._closeCurrentConnection();
+        this.pushstream._onclose();
+      }
+    },
+
+    _closeCurrentConnection: function() {
+      this.opentimer = clearTimer(this.opentimer);
+      if (this.connection) {
+        try { this.connection.abort(); } catch (e) {
+          try { Ajax.clear(this.connection); } catch (e1) { /* ignore error on closing */ }
+        }
+        this.connection = null;
+        this.xhrSettings.url = null;
+      }
+    },
+
+    beforeSend: function(xhr) {
+      if (!this.pushstream.messagesControlByArgument) {
+        xhr.setRequestHeader("If-None-Match", this.pushstream._etag);
+        xhr.setRequestHeader("If-Modified-Since", this.pushstream._lastModified);
+      }
+    },
+
+    afterReceive: function(xhr) {
+      if (!this.pushstream.messagesControlByArgument) {
+        this.pushstream._etag = xhr.getResponseHeader('Etag');
+        this.pushstream._lastModified = xhr.getResponseHeader('Last-Modified');
+      }
+      this.connection = null;
+    },
+
+    onerror: function(status) {
+      this._closeCurrentConnection();
+      if (this.pushstream._keepConnected) { /* abort(), called by disconnect(), call this callback, but should be ignored */
+        if (status === 304) {
+          this._listen();
+        } else {
+          Log4js.info("[LongPolling] error (disconnected by server):", status);
+          this.pushstream._onerror({type: ((status === 403) || (this.pushstream.readyState === PushStream.CONNECTING)) ? "load" : "timeout"});
+        }
+      }
+    },
+
+    onload: function() {
+      this._listen();
+    },
+
+    onmessage: function(responseText) {
+      if (this._internalListenTimeout) { clearTimer(this._internalListenTimeout); }
+      Log4js.info("[LongPolling] message received", responseText);
+      var lastMessage = null;
+      var messages = isArray(responseText) ? responseText : responseText.replace(/\}\{/g, "}\r\n{").split("\r\n");
+      for (var i = 0; i < messages.length; i++) {
+        if (messages[i]) {
+          lastMessage = Utils.parseMessage(messages[i], this.pushstream);
+          this.messagesQueue.push(lastMessage);
+          if (this.pushstream.messagesControlByArgument && lastMessage.time) {
+            this.pushstream._etag = lastMessage.tag;
+            this.pushstream._lastModified = lastMessage.time;
+          }
+        }
+      }
+
+      this._listen();
+
+      while (this.messagesQueue.length > 0) {
+        var message = this.messagesQueue.shift();
+        this.pushstream._onmessage(message.text, message.id, message.channel, message.eventid, (this.messagesQueue.length === 0), message.time);
+      }
+    }
+  };
+
+  /* mains class */
+
+  var PushStreamManager = [];
+
+  var PushStream = function(settings) {
+    settings = settings || {};
+
+    this.id = PushStreamManager.push(this) - 1;
+
+    this.useSSL = settings.useSSL || false;
+    this.host = settings.host || window.location.hostname;
+    this.port = Number(settings.port || (this.useSSL ? 443 : 80));
+
+    this.timeout = settings.timeout || 30000;
+    this.pingtimeout = settings.pingtimeout || 30000;
+    this.reconnectOnTimeoutInterval = settings.reconnectOnTimeoutInterval || 3000;
+    this.reconnectOnChannelUnavailableInterval = settings.reconnectOnChannelUnavailableInterval || 60000;
+    this.autoReconnect = (settings.autoReconnect !== false);
+
+    this.lastEventId = settings.lastEventId || null;
+    this.messagesPublishedAfter = settings.messagesPublishedAfter;
+    this.messagesControlByArgument = settings.messagesControlByArgument || false;
+    this.tagArgument   = settings.tagArgument  || 'tag';
+    this.timeArgument  = settings.timeArgument || 'time';
+    this.eventIdArgument  = settings.eventIdArgument || 'eventid';
+    this.useJSONP      = settings.useJSONP     || false;
+
+    this._reconnecttimer = null;
+    this._etag = 0;
+    this._lastModified = null;
+    this._lastEventId = null;
+
+    this.urlPrefixPublisher   = settings.urlPrefixPublisher   || '/pub';
+    this.urlPrefixStream      = settings.urlPrefixStream      || '/sub';
+    this.urlPrefixEventsource = settings.urlPrefixEventsource || '/ev';
+    this.urlPrefixLongpolling = settings.urlPrefixLongpolling || '/lp';
+    this.urlPrefixWebsocket   = settings.urlPrefixWebsocket   || '/ws';
+
+    this.jsonIdKey      = settings.jsonIdKey      || 'id';
+    this.jsonChannelKey = settings.jsonChannelKey || 'channel';
+    this.jsonTextKey    = settings.jsonTextKey    || 'text';
+    this.jsonTagKey     = settings.jsonTagKey     || 'tag';
+    this.jsonTimeKey    = settings.jsonTimeKey    || 'time';
+    this.jsonEventIdKey = settings.jsonEventIdKey || 'eventid';
+
+    this.modes = (settings.modes || 'eventsource|websocket|stream|longpolling').split('|');
+    this.wrappers = [];
+    this.wrapper = null;
+
+    this.onchanneldeleted = settings.onchanneldeleted || null;
+    this.onmessage = settings.onmessage || null;
+    this.onerror = settings.onerror || null;
+    this.onstatuschange = settings.onstatuschange || null;
+    this.extraParams    = settings.extraParams    || function() { return {}; };
+
+    this.channels = {};
+    this.channelsCount = 0;
+    this.channelsByArgument   = settings.channelsByArgument   || false;
+    this.channelsArgument     = settings.channelsArgument     || 'channels';
+
+    this._crossDomain = Utils.isCrossDomainUrl(getPublisherUrl(this));
+
+    for (var i = 0; i < this.modes.length; i++) {
+      try {
+        var wrapper = null;
+        switch (this.modes[i]) {
+        case "websocket"  : wrapper = new WebSocketWrapper(this);   break;
+        case "eventsource": wrapper = new EventSourceWrapper(this); break;
+        case "longpolling": wrapper = new LongPollingWrapper(this); break;
+        case "stream"     : wrapper = new StreamWrapper(this);      break;
+        }
+        this.wrappers[this.wrappers.length] = wrapper;
+      } catch(e) { Log4js.info(e); }
+    }
+
+    this.readyState = 0;
+  };
+
+  /* constants */
+  PushStream.LOG_LEVEL = 'error'; /* debug, info, error */
+  PushStream.LOG_OUTPUT_ELEMENT_ID = 'Log4jsLogOutput';
+
+  /* status codes */
+  PushStream.CLOSED        = 0;
+  PushStream.CONNECTING    = 1;
+  PushStream.OPEN          = 2;
+
+  /* main code */
+  PushStream.prototype = {
+    addChannel: function(channel, options) {
+      if (escapeText(channel) !== channel) {
+        throw "Invalid channel name! Channel has to be a set of [a-zA-Z0-9]";
+      }
+      Log4js.debug("entering addChannel");
+      if (typeof(this.channels[channel]) !== "undefined") { throw "Cannot add channel " + channel + ": already subscribed"; }
+      options = options || {};
+      Log4js.info("adding channel", channel, options);
+      this.channels[channel] = options;
+      this.channelsCount++;
+      if (this.readyState !== PushStream.CLOSED) { this.connect(); }
+      Log4js.debug("leaving addChannel");
+    },
+
+    removeChannel: function(channel) {
+      if (this.channels[channel]) {
+        Log4js.info("removing channel", channel);
+        delete this.channels[channel];
+        this.channelsCount--;
+      }
+    },
+
+    removeAllChannels: function() {
+      Log4js.info("removing all channels");
+      this.channels = {};
+      this.channelsCount = 0;
+    },
+
+    _setState: function(state) {
+      if (this.readyState !== state) {
+        Log4js.info("status changed", state);
+        this.readyState = state;
+        if (this.onstatuschange) {
+          this.onstatuschange(this.readyState);
+        }
+      }
+    },
+
+    connect: function() {
+      Log4js.debug("entering connect");
+      if (!this.host)                 { throw "PushStream host not specified"; }
+      if (isNaN(this.port))           { throw "PushStream port not specified"; }
+      if (!this.channelsCount)        { throw "No channels specified"; }
+      if (this.wrappers.length === 0) { throw "No available support for this browser"; }
+
+      this._keepConnected = true;
+      this._lastUsedMode = 0;
+      this._connect();
+
+      Log4js.debug("leaving connect");
+    },
+
+    disconnect: function() {
+      Log4js.debug("entering disconnect");
+      this._keepConnected = false;
+      this._disconnect();
+      this._setState(PushStream.CLOSED);
+      Log4js.info("disconnected");
+      Log4js.debug("leaving disconnect");
+    },
+
+    _useControlArguments :function() {
+      return this.messagesControlByArgument && ((this._lastModified !== null) || (this._lastEventId !== null));
+    },
+
+    _connect: function() {
+      if (this._lastEventId === null) {
+        this._lastEventId = this.lastEventId;
+      }
+      if (this._lastModified === null) {
+        var date = this.messagesPublishedAfter;
+        if (!isDate(date)) {
+          var messagesPublishedAfter = Number(this.messagesPublishedAfter);
+          if (messagesPublishedAfter > 0) {
+            date = new Date();
+            date.setTime(date.getTime() - (messagesPublishedAfter * 1000));
+          } else if (messagesPublishedAfter < 0) {
+            date = new Date(0);
+          }
+        }
+
+        if (isDate(date)) {
+          this._lastModified = Utils.dateToUTCString(date);
+        }
+      }
+
+      this._disconnect();
+      this._setState(PushStream.CONNECTING);
+      this.wrapper = this.wrappers[this._lastUsedMode++ % this.wrappers.length];
+
+      try {
+        this.wrapper.connect();
+      } catch (e) {
+        //each wrapper has a cleanup routine at disconnect method
+        if (this.wrapper) {
+          this.wrapper.disconnect();
+        }
+      }
+    },
+
+    _disconnect: function() {
+      this._reconnecttimer = clearTimer(this._reconnecttimer);
+      if (this.wrapper) {
+        this.wrapper.disconnect();
+      }
+    },
+
+    _onopen: function() {
+      this._reconnecttimer = clearTimer(this._reconnecttimer);
+      this._setState(PushStream.OPEN);
+      if (this._lastUsedMode > 0) {
+        this._lastUsedMode--; //use same mode on next connection
+      }
+    },
+
+    _onclose: function() {
+      this._reconnecttimer = clearTimer(this._reconnecttimer);
+      this._setState(PushStream.CLOSED);
+      this._reconnect(this.reconnectOnTimeoutInterval);
+    },
+
+    _onmessage: function(text, id, channel, eventid, isLastMessageFromBatch, time) {
+      Log4js.debug("message", text, id, channel, eventid, isLastMessageFromBatch, time);
+      if (id === -2) {
+        if (this.onchanneldeleted) { this.onchanneldeleted(channel); }
+      } else if (id > 0) {
+        if (this.onmessage) { this.onmessage(text, id, channel, eventid, isLastMessageFromBatch, time); }
+      }
+    },
+
+    _onerror: function(error) {
+      this._setState(PushStream.CLOSED);
+      this._reconnect((error.type === "timeout") ? this.reconnectOnTimeoutInterval : this.reconnectOnChannelUnavailableInterval);
+      if (this.onerror) { this.onerror(error); }
+    },
+
+    _reconnect: function(timeout) {
+      if (this.autoReconnect && this._keepConnected && !this._reconnecttimer && (this.readyState !== PushStream.CONNECTING)) {
+        Log4js.info("trying to reconnect in", timeout);
+        this._reconnecttimer = window.setTimeout(linker(this._connect, this), timeout);
+      }
+    },
+
+    sendMessage: function(message, successCallback, errorCallback) {
+      message = escapeText(message);
+      if (this.wrapper.type === WebSocketWrapper.TYPE) {
+        this.wrapper.sendMessage(message);
+        if (successCallback) { successCallback(); }
+      } else {
+        Ajax.post({url: getPublisherUrl(this), data: message, success: successCallback, error: errorCallback, crossDomain: this._crossDomain});
+      }
+    }
+  };
+
+  PushStream.sendMessage = function(url, message, successCallback, errorCallback) {
+    Ajax.post({url: url, data: escapeText(message), success: successCallback, error: errorCallback});
+  };
+
+  // to make server header template more clear, it calls register and
+  // by a url parameter we find the stream wrapper instance
+  PushStream.register = function(iframe) {
+    var matcher = iframe.window.location.href.match(/streamid=([0-9]*)&?/);
+    if (matcher[1] && PushStreamManager[matcher[1]]) {
+      PushStreamManager[matcher[1]].wrapper.register(iframe);
+    }
+  };
+
+  PushStream.unload = function() {
+    for (var i = 0; i < PushStreamManager.length; i++) {
+      try { PushStreamManager[i].disconnect(); } catch(e){}
+    }
+  };
+
+  /* make class public */
+  window.PushStream = PushStream;
+  window.PushStreamManager = PushStreamManager;
+
+  if (window.attachEvent) { window.attachEvent("onunload", PushStream.unload); }
+  if (window.addEventListener) { window.addEventListener.call(window, "unload", PushStream.unload, false); }
+
+})(window, document);
diff -Naur nginx-1.11.3/nginx-push-stream-module/misc/mime.types nginx-1.11.3-push/nginx-push-stream-module/misc/mime.types
--- nginx-1.11.3/nginx-push-stream-module/misc/mime.types	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/misc/mime.types	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,73 @@
+
+types {
+    text/html                             html htm shtml;
+    text/css                              css;
+    text/xml                              xml;
+    image/gif                             gif;
+    image/jpeg                            jpeg jpg;
+    application/x-javascript              js;
+    application/atom+xml                  atom;
+    application/rss+xml                   rss;
+
+    text/mathml                           mml;
+    text/plain                            txt;
+    text/vnd.sun.j2me.app-descriptor      jad;
+    text/vnd.wap.wml                      wml;
+    text/x-component                      htc;
+
+    image/png                             png;
+    image/tiff                            tif tiff;
+    image/vnd.wap.wbmp                    wbmp;
+    image/x-icon                          ico;
+    image/x-jng                           jng;
+    image/x-ms-bmp                        bmp;
+    image/svg+xml                         svg;
+
+    application/java-archive              jar war ear;
+    application/mac-binhex40              hqx;
+    application/msword                    doc;
+    application/pdf                       pdf;
+    application/postscript                ps eps ai;
+    application/rtf                       rtf;
+    application/vnd.ms-excel              xls;
+    application/vnd.ms-powerpoint         ppt;
+    application/vnd.wap.wmlc              wmlc;
+    application/vnd.wap.xhtml+xml         xhtml;
+    application/vnd.google-earth.kml+xml  kml;
+    application/vnd.google-earth.kmz      kmz;
+    application/x-cocoa                   cco;
+    application/x-java-archive-diff       jardiff;
+    application/x-java-jnlp-file          jnlp;
+    application/x-makeself                run;
+    application/x-perl                    pl pm;
+    application/x-pilot                   prc pdb;
+    application/x-rar-compressed          rar;
+    application/x-redhat-package-manager  rpm;
+    application/x-sea                     sea;
+    application/x-shockwave-flash         swf;
+    application/x-stuffit                 sit;
+    application/x-tcl                     tcl tk;
+    application/x-x509-ca-cert            der pem crt;
+    application/x-xpinstall               xpi;
+    application/zip                       zip;
+
+    application/octet-stream              bin exe dll;
+    application/octet-stream              deb;
+    application/octet-stream              dmg;
+    application/octet-stream              eot;
+    application/octet-stream              iso img;
+    application/octet-stream              msi msp msm;
+
+    audio/midi                            mid midi kar;
+    audio/mpeg                            mp3;
+    audio/x-realaudio                     ra;
+
+    video/3gpp                            3gpp 3gp;
+    video/mpeg                            mpeg mpg;
+    video/quicktime                       mov;
+    video/x-flv                           flv;
+    video/x-mng                           mng;
+    video/x-ms-asf                        asx asf;
+    video/x-ms-wmv                        wmv;
+    video/x-msvideo                       avi;
+}
diff -Naur nginx-1.11.3/nginx-push-stream-module/misc/nginx.conf nginx-1.11.3-push/nginx-push-stream-module/misc/nginx.conf
--- nginx-1.11.3/nginx-push-stream-module/misc/nginx.conf	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/misc/nginx.conf	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,187 @@
+pid         logs/nginx.pid;
+error_log   logs/nginx-main_error.log debug;
+
+# Development Mode
+master_process      off;
+daemon              off;
+worker_rlimit_core  2500M;
+working_directory /tmp;
+debug_points abort;
+env MOCKEAGAIN_VERBOSE;
+env MOCKEAGAIN_WRITE_TIMEOUT_PATTERN;
+#env MOCKEAGAIN;
+env LD_PRELOAD;
+
+worker_processes    2;
+
+events {
+    worker_connections  1024;
+    use                 poll;
+}
+
+http {
+    postpone_output 1; # only postpone a single byte, default 1460 bytes
+    access_log      logs/nginx-http_access.log;
+
+    push_stream_shared_memory_size                100m;
+    push_stream_max_channel_id_length             200;
+    # max messages to store in memory
+    push_stream_max_messages_stored_per_channel   20;
+    # message ttl
+    push_stream_message_ttl                       5m;
+    # ping frequency
+    push_stream_ping_message_interval             30s;
+    # connection ttl to enable recycle
+    push_stream_subscriber_connection_ttl         15m;
+    # connection ttl for long polling
+    push_stream_longpolling_connection_ttl        30s;
+    push_stream_timeout_with_body                 off;
+
+    # wildcard
+    push_stream_wildcard_channel_prefix         "broad_";
+    push_stream_wildcard_channel_max_qtd        3;
+
+    push_stream_message_template                "{\"id\":~id~,\"channel\":\"~channel~\",\"text\":\"~text~\", \"tag\":\"~tag~\", \"time\":\"~time~\", \"eventid\":\"~event-id~\"}";
+
+    # subscriber may create channels on demand or only authorized (publisher) may do it?
+    push_stream_authorized_channels_only        off;
+
+    push_stream_allowed_origins                 "*";
+
+    server {
+        listen           9080 default_server;
+        #listen          9443 ssl;
+        #ssl_certificate     /usr/local/nginx/ssl/server.crt;
+        #ssl_certificate_key /usr/local/nginx/ssl/server.key;
+        server_name     localhost;
+
+        location /channels-stats {
+            # activate channels statistics mode for this location
+            push_stream_channels_statistics;
+
+            # query string based channel id
+            push_stream_channels_path               $arg_id;
+        }
+
+        location /pub {
+            # activate publisher mode for this location, with admin support
+            push_stream_publisher admin;
+
+            # query string based channel id
+            push_stream_channels_path               $arg_id;
+
+            # store messages in memory
+            push_stream_store_messages              on;
+
+            # Message size limit
+            # client_max_body_size MUST be equal to client_body_buffer_size or
+            # you will be sorry.
+            client_max_body_size                    32k;
+            client_body_buffer_size                 32k;
+        }
+
+        location ~ /sub/(.*) {
+            # activate subscriber mode for this location
+            push_stream_subscriber;
+
+            # positional channel path
+            push_stream_channels_path                   $1;
+            if ($arg_tests = "on") {
+              push_stream_channels_path                 "test_$1";
+            }
+
+            # header to be sent when receiving new subscriber connection
+            push_stream_header_template                 "<html><head><meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\r\n<meta http-equiv=\"Cache-Control\" content=\"no-store\">\r\n<meta http-equiv=\"Cache-Control\" content=\"no-cache\">\r\n<meta http-equiv=\"Pragma\" content=\"no-cache\">\r\n<meta http-equiv=\"Expires\" content=\"Thu, 1 Jan 1970 00:00:00 GMT\">\r\n<script type=\"text/javascript\">\r\nwindow.onError = null;\r\ntry{ document.domain = (window.location.hostname.match(/^(\d{1,3}\.){3}\d{1,3}$/)) ? window.location.hostname : window.location.hostname.split('.').slice(-1 * Math.max(window.location.hostname.split('.').length - 1, (window.location.hostname.match(/(\w{4,}\.\w{2}|\.\w{3,})$/) ? 2 : 3))).join('.');}catch(e){}\r\nparent.PushStream.register(this);\r\n</script>\r\n</head>\r\n<body>";
+
+            # message template
+            push_stream_message_template                "<script>p(~id~,'~channel~','~text~','~event-id~', '~time~', '~tag~');</script>";
+            # footer to be sent when finishing subscriber connection
+            push_stream_footer_template                 "</body></html>";
+            # content-type
+            default_type                                "text/html; charset=utf-8";
+
+            if ($arg_qs = "on") {
+              push_stream_last_received_message_time "$arg_time";
+              push_stream_last_received_message_tag  "$arg_tag";
+              push_stream_last_event_id              "$arg_eventid";
+            }
+        }
+
+        location ~ /ev/(.*) {
+            # activate event source mode for this location
+            push_stream_subscriber eventsource;
+
+            # positional channel path
+            push_stream_channels_path                   $1;
+            if ($arg_tests = "on") {
+              push_stream_channels_path                 "test_$1";
+            }
+
+            if ($arg_qs = "on") {
+              push_stream_last_received_message_time "$arg_time";
+              push_stream_last_received_message_tag  "$arg_tag";
+              push_stream_last_event_id              "$arg_eventid";
+            }
+        }
+
+        location ~ /lp/(.*) {
+            # activate long-polling mode for this location
+            push_stream_subscriber      long-polling;
+
+            # positional channel path
+            push_stream_channels_path         $1;
+            if ($arg_tests = "on") {
+              push_stream_channels_path                 "test_$1";
+            }
+
+            if ($arg_qs = "on") {
+              push_stream_last_received_message_time "$arg_time";
+              push_stream_last_received_message_tag  "$arg_tag";
+              push_stream_last_event_id              "$arg_eventid";
+            }
+        }
+
+        location ~ /jsonp/(.*) {
+            # activate long-polling mode for this location
+            push_stream_subscriber      long-polling;
+
+            push_stream_last_received_message_time "$arg_time";
+            push_stream_last_received_message_tag  "$arg_tag";
+            push_stream_last_event_id              "$arg_eventid";
+
+            # positional channel path
+            push_stream_channels_path         $1;
+            if ($arg_tests = "on") {
+              push_stream_channels_path                 "test_$1";
+            }
+        }
+
+        location ~ /ws/(.*) {
+            # activate websocket mode for this location
+            push_stream_subscriber websocket;
+
+            # positional channel path
+            push_stream_channels_path                   $1;
+            if ($arg_tests = "on") {
+              push_stream_channels_path                 "test_$1";
+            }
+
+            # store messages in memory
+            push_stream_store_messages              on;
+
+            push_stream_websocket_allow_publish     on;
+
+            if ($arg_qs = "on") {
+              push_stream_last_received_message_time "$arg_time";
+              push_stream_last_received_message_tag  "$arg_tag";
+              push_stream_last_event_id              "$arg_eventid";
+            }
+        }
+
+        location / {
+            if (!-f $request_filename) {
+              proxy_pass "http://localhost:8888";
+            }
+        }
+    }
+}
diff -Naur nginx-1.11.3/nginx-push-stream-module/misc/Rakefile nginx-1.11.3-push/nginx-push-stream-module/misc/Rakefile
--- nginx-1.11.3/nginx-push-stream-module/misc/Rakefile	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/misc/Rakefile	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,232 @@
+require 'rubygems'
+require 'erb'
+
+# Set up gems listed in the Gemfile.
+ENV['BUNDLE_GEMFILE'] ||= File.expand_path('./Gemfile', File.dirname(__FILE__))
+require 'bundler/setup' if File.exists?(ENV['BUNDLE_GEMFILE'])
+Bundler.require(:default, :test) if defined?(Bundler)
+
+project_dir = File.expand_path('..', File.dirname(__FILE__))
+base_path = File.expand_path('pushstream/docs/preview', Dir.tmpdir)
+javascript_dir = File.expand_path(Dir["#{project_dir}/**/js"].first)
+
+begin
+  require "rspec/core/rake_task"
+
+  desc "Run all examples"
+  RSpec::Core::RakeTask.new(:spec) do |t|
+    t.rspec_opts = %w[--color]
+    t.pattern = '**/*_spec.rb'
+  end
+rescue LoadError
+  task :spec do
+    abort "RSpec is not available. In order to run rspec, you must: (sudo) gem install rspec"
+  end
+end
+
+begin
+  load 'jasmine/tasks/jasmine.rake'
+
+  task "jasmine:require" => ["jshint", "configure_jasmine", "monitor_js", "test_server"]
+
+  task :configure_jasmine do
+    Jasmine.configure do |config|
+      config.spec_dir = project_dir
+      config.spec_files = lambda { Dir["#{project_dir}/misc/spec/javascripts/helpers/**/*.js"] + Dir["#{project_dir}/misc/js/jquery.min.js"] + Dir["#{project_dir}/misc/**/*[sS]pec.js"] }
+      js_tmp_dir = File.expand_path('pushstream/js', Dir.tmpdir)
+      config.src_dir = js_tmp_dir
+      config.src_files = lambda { Dir["#{js_tmp_dir}/**/*.js"] }
+    end
+  end
+
+  task :monitor_js do
+    def copy_inner_js(modified, added, removed)
+      modified.each do |file|
+        destiny_path = File.dirname(file).gsub(/.*\/js\/?/, File.expand_path('pushstream/js', Dir.tmpdir))
+        FileUtils.mkdir_p(destiny_path)
+        content = File.read file
+        content.gsub!('window.PushStream = PushStream;', "window.PushStream = PushStream;\nwindow.Utils = Utils;")
+        File.open(File.join(destiny_path, File.basename(file)), 'w') {|f| f.write content }
+      end
+    end
+
+    copy_inner_js([File.expand_path('misc/js/pushstream.js', project_dir)], [], [])
+    listener = Listen.to(File.expand_path('misc/js', project_dir), :filter => /\.js$/) do |modified, added, removed|
+      copy_inner_js(modified, added, removed)
+    end
+    listener.start
+  end
+
+  task :test_server do
+    require File.expand_path('misc/spec/spec_helper', project_dir)
+    include NginxTestHelper
+    template = File.read(File.expand_path('misc/nginx.conf', project_dir))
+    template.gsub!(/push_stream_subscriber_connection_ttl.*;/, 'push_stream_subscriber_connection_ttl 3s;')
+    template.gsub!(/push_stream_longpolling_connection_ttl.*;/, 'push_stream_longpolling_connection_ttl 3s;')
+    config = NginxTestHelper::Config.new "jasmine", {:configuration_template => (RUBY_PLATFORM =~ /darwin/) ? template.gsub('epoll', 'kqueue') : template }
+    abort "Could not start test server" if start_server(config).include?("[emerg]")
+  end
+
+rescue LoadError
+  desc "Run javascript tests"
+  task :jasmine do
+    abort "Jasmine is not available. In order to run jasmine, you must: (sudo) gem install jasmine"
+  end
+end
+
+begin
+  require "jshintrb/jshinttask"
+  Jshintrb::JshintTask.new :jshint do |t|
+    t.pattern = "#{javascript_dir}/pushstream.js"
+    t.options = :defaults
+  end
+rescue LoadError
+  desc "Run jshint on js"
+  task :jshint do
+    abort "Jshintrb is not available. In order to run jshint, you must: (sudo) gem install jshintrb"
+  end
+end
+
+namespace :docs do
+
+begin
+  Bundler.require(:default, :docs) if defined?(Bundler)
+
+  task :get_static_files do
+    FileUtils.mkdir_p("#{base_path}/css")
+
+    download_file("https://github.global.ssl.fastly.net/assets/github-f226abc7983f8566b17d24236adae64ba647ffea.css", "#{base_path}/css/github.css") unless File.exists?("#{base_path}/css/github.css")
+    download_file("https://github.global.ssl.fastly.net/assets/github2-6edea06c20f02c9c2ae32842c7455d50c08c3f69.css", "#{base_path}/css/github2.css") unless File.exists?("#{base_path}/css/github2.css")
+  end
+
+  def generate_preview_for(file, project_dir, base_path)
+    template = ERB.new File.read("#{project_dir}/misc/github_template.html.erb")
+    filename = File.basename(file)
+    content = GitHub::Markup.render(file, File.read(file))
+    rendered = template.result(binding)
+    output = File.expand_path(file.gsub(project_dir, "./"), base_path)
+    output_dir = File.dirname(output)
+    FileUtils.mkdir_p(output_dir)
+    File.open(output, 'w') {|f| f.write(rendered) }
+    puts "Preview rendered to #{output}"
+  end
+
+  desc "Generates docs files to preview."
+  task :generate => :get_static_files do
+    Dir.glob("#{project_dir}/**/*.textile").each do |file|
+      generate_preview_for(file, project_dir, base_path)
+    end
+  end
+
+  desc "Watch for changes on doc to generate the preview."
+  task :watch do
+    puts "watching for changes on textile files"
+    Dir.chdir(project_dir) do
+      FileWatcher.new(["**/*.textile"]).watch do |file, event|
+        if(event != :delete)
+          generate_preview_for(file, project_dir, base_path)
+        end
+      end
+    end
+  end
+
+  desc "Convert docs to Nginx wiki format."
+  task :convert_to_wiki do
+    Dir.glob("#{project_dir}/**/*.textile").each do |file|
+      filename = File.basename(file)
+      content = File.read(file)
+
+      output      = file.gsub(project_dir, File.expand_path('pushstream/docs/html', Dir.tmpdir)).gsub(".textile", ".html")
+      output_wiki = file.gsub(project_dir, File.expand_path('pushstream/docs/wiki', Dir.tmpdir)).gsub(".textile", ".wiki")
+      FileUtils.mkdir_p(File.dirname(output))
+      FileUtils.mkdir_p(File.dirname(output_wiki))
+
+      File.open(output, 'w') {|f| f.write(RedCloth.new(content).to_html) }
+      File.open(output_wiki, 'w') {|f| f.write(convert_to_wiki_syntax(content)) }
+      puts "Wiki converted to #{output_wiki}"
+    end
+  end
+rescue LoadError
+  desc "Generates docs files to preview."
+  task :generate do
+    abort "github-markup is not available. In order to run docs:generate, you must: (sudo) gem install github-markup"
+  end
+
+  desc "Convert docs to Nginx wiki format."
+  task :convert_to_wiki do
+    abort "RedCloth or nokogiri is not available. In order to run docs:convert_to_wiki, you must: (sudo) gem install RedCloth nokogiri"
+  end
+end
+
+  def download_file(url, output_file)
+    EventMachine.run do
+      http = EventMachine::HttpRequest.new(url).get
+      http.errback { EM.stop }
+      http.callback do
+        File.open(output_file, "w") { |f| f.write(http.response) } if (http.response_header.status == 200)
+        EM.stop
+      end
+    end
+  end
+
+  def convert_to_wiki_syntax(text)
+    doc = Nokogiri::HTML(RedCloth.new(text).to_html)
+    convert_elements(doc.children.to_a)
+  end
+
+  def convert_elements(nodes)
+    result = ""
+    nodes.each do |node|
+      if node.element? && !node.text?
+        childrens = node.children.to_a
+        unless childrens.empty?
+          result += convert_element(convert_elements(childrens), node)
+        end
+      elsif node.text?
+        result += node.text
+      end
+    end
+    result
+  end
+
+  def convert_element(text, node)
+    tag = node.name
+    text ||= ""
+    case tag
+    when "strong"
+      "'''#{text}'''"
+    when "b"
+      "'''#{text}'''"
+    when "em"
+      "''#{text}''"
+    when "h1"
+      "\n= #{text} ="
+    when "h2"
+      "\n== #{text} =="
+    when "h3"
+      "\n=== #{text} ==="
+    when "h4"
+      "\n==== #{text} ===="
+    when "h5"
+      "\n===== #{text} ====="
+    when "h6"
+      "\n====== #{text} ======"
+    when "p"
+      "\n#{text}"
+    when "a"
+      if node.attributes['href'].value.start_with?("#")
+        "[[#{node.attributes['href'].value}|#{text}]]"
+      else
+        "[#{node.attributes['href'].value} #{text}]"
+      end
+    when "html"
+      text
+    when "body"
+      text
+    when "span"
+      text
+    else
+      "<#{tag}>#{text}</#{tag}>"
+    end
+  end
+end
diff -Naur nginx-1.11.3/nginx-push-stream-module/misc/spec/javascripts/helpers/SpecHelper.js nginx-1.11.3-push/nginx-push-stream-module/misc/spec/javascripts/helpers/SpecHelper.js
--- nginx-1.11.3/nginx-push-stream-module/misc/spec/javascripts/helpers/SpecHelper.js	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/misc/spec/javascripts/helpers/SpecHelper.js	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,59 @@
+(function() {
+  var D = new Date('2011-06-02T09:34:29+02:00');
+  if (!D || +D !== 1307000069000) {
+    Date.fromISO = function(s) {
+      var day, tz, rx = /^(\d{4}\-\d\d\-\d\d([tT ][\d:\.]*)?)([zZ]|([+\-])(\d\d):(\d\d))?$/, p = rx.exec(s) || [];
+      if (p[1]) {
+        day = p[1].split(/\D/);
+        for (var i = 0, L = day.length; i < L; i++) {
+          day[i] = parseInt(day[i], 10) || 0;
+        };
+        day[1] -= 1;
+        day = new Date(Date.UTC.apply(Date, day));
+        if (!day.getDate())
+          return NaN;
+        if (p[5]) {
+          tz = (parseInt(p[5], 10) * 60);
+          if (p[6])
+            tz += parseInt(p[6], 10);
+          if (p[4] == '+')
+            tz *= -1;
+          if (tz)
+            day.setUTCMinutes(day.getUTCMinutes() + tz);
+        }
+        return day;
+      }
+      return NaN;
+    };
+  } else {
+    Date.fromISO = function(s) {
+      return new Date(s);
+    };
+  }
+})();
+
+
+// This is the equivalent of the old waitsFor/runs syntax
+// which was removed from Jasmine 2
+var waitsForAndRuns = function(escapeFunction, runFunction, escapeTime) {
+  // check the escapeFunction every millisecond so as soon as it is met we can escape the function
+  var interval = setInterval(function() {
+    if (escapeFunction()) {
+      clearMe();
+      runFunction();
+    }
+  }, 1);
+
+  // in case we never reach the escapeFunction, we will time out
+  // at the escapeTime
+  var timeOut = setTimeout(function() {
+    clearMe();
+    runFunction();
+  }, escapeTime);
+
+  // clear the interval and the timeout
+  function clearMe(){
+    clearInterval(interval);
+    clearTimeout(timeOut);
+  }
+};
diff -Naur nginx-1.11.3/nginx-push-stream-module/misc/spec/javascripts/PushStreamSpec.js nginx-1.11.3-push/nginx-push-stream-module/misc/spec/javascripts/PushStreamSpec.js
--- nginx-1.11.3/nginx-push-stream-module/misc/spec/javascripts/PushStreamSpec.js	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/misc/spec/javascripts/PushStreamSpec.js	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,1177 @@
+describe("PushStream", function() {
+  var originalTimeout;
+  beforeEach(function() {
+    originalTimeout = jasmine.DEFAULT_TIMEOUT_INTERVAL;
+    jasmine.DEFAULT_TIMEOUT_INTERVAL = 10000;
+  });
+
+  afterEach(function() {
+    jasmine.DEFAULT_TIMEOUT_INTERVAL = originalTimeout;
+  });
+
+  describe("when defining library external interface", function() {
+    it("should has a class named PushStream", function() {
+      expect(new PushStream()).toBeDefined();
+    });
+
+    it("should has a log level constant", function() {
+      expect(PushStream.LOG_LEVEL).toBeDefined();
+    });
+
+    it("should has a log output element id constant", function() {
+      expect(PushStream.LOG_OUTPUT_ELEMENT_ID).toBeDefined();
+    });
+
+    it("should define status code constants", function() {
+      expect(PushStream.CLOSED).toBeDefined();
+      expect(PushStream.CONNECTING).toBeDefined();
+      expect(PushStream.OPEN).toBeDefined();
+    });
+
+    it("should has a PushStream instances manager", function() {
+      expect(PushStreamManager).toBeDefined();
+      expect(PushStreamManager instanceof Array).toBeTruthy();
+    });
+
+  });
+
+  describe("when using default values", function() {
+    var pushstream = null;
+    beforeEach(function() {
+      pushstream = new PushStream();
+    });
+
+    it("should use current hostname", function() {
+      expect(pushstream.host).toBe(window.location.hostname);
+    });
+
+    it("should use port 80", function() {
+      expect(pushstream.port).toBe(80);
+    });
+
+    it("should not use ssl", function() {
+      expect(pushstream.useSSL).toBeFalsy();
+    });
+
+    it("should not use JSONP", function() {
+      expect(pushstream.useJSONP).toBeFalsy();
+    });
+
+    it("should set state as uninitialised", function() {
+      expect(pushstream.readyState).toBe(PushStream.CLOSED);
+    });
+
+    it("should set messagesPublishedAfter as undefined", function() {
+      expect(pushstream.messagesPublishedAfter).toBe(undefined);
+    });
+
+    describe("for operation timeouts", function() {
+      it("should has a connection timeout", function() {
+        expect(pushstream.timeout).toBe(30000);
+      });
+
+      it("should has a ping message timeout", function() {
+        expect(pushstream.pingtimeout).toBe(30000);
+      });
+
+      it("should has a reconnect interval, to be used when a timeout happens", function() {
+        expect(pushstream.reconnectOnTimeoutInterval).toBe(3000);
+      });
+
+      it("should has a reconnect interval, to be used when a channel is unavailable", function() {
+        expect(pushstream.reconnectOnChannelUnavailableInterval).toBe(60000);
+      });
+    });
+
+    describe("for url prefix", function() {
+      it("should use '/pub' for publish message", function() {
+        expect(pushstream.urlPrefixPublisher).toBe('/pub');
+      });
+
+      it("should use '/sub' for stream", function() {
+        expect(pushstream.urlPrefixStream).toBe('/sub');
+      });
+
+      it("should use '/ev' for event source", function() {
+        expect(pushstream.urlPrefixEventsource).toBe('/ev');
+      });
+
+      it("should use '/lp' for long-polling", function() {
+        expect(pushstream.urlPrefixLongpolling).toBe('/lp');
+      });
+
+      it("should use '/ws' for websocket", function() {
+        expect(pushstream.urlPrefixWebsocket).toBe('/ws');
+      });
+    });
+
+    describe("for json keys", function() {
+      it("should has a key for 'id'", function() {
+        expect(pushstream.jsonIdKey).toBe('id');
+      });
+
+      it("should has a key for 'channel'", function() {
+        expect(pushstream.jsonChannelKey).toBe('channel');
+      });
+
+      it("should has a key for 'text'", function() {
+        expect(pushstream.jsonTextKey).toBe('text');
+      });
+
+      it("should has a key for 'tag'", function() {
+        expect(pushstream.jsonTagKey).toBe('tag');
+      });
+
+      it("should has a key for 'time'", function() {
+        expect(pushstream.jsonTimeKey).toBe('time');
+      });
+
+      it("should has a key for 'eventid'", function() {
+        expect(pushstream.jsonEventIdKey).toBe('eventid');
+      });
+    });
+
+    describe("for arguments names", function() {
+      it("should has a argument for 'tag'", function() {
+        expect(pushstream.tagArgument).toBe('tag');
+      });
+
+      it("should has a argument for 'time'", function() {
+        expect(pushstream.timeArgument).toBe('time');
+      });
+
+      it("should has a argument for 'eventid'", function() {
+        expect(pushstream.eventIdArgument).toBe('eventid');
+      });
+
+      it("should has a argument for 'channels'", function() {
+        expect(pushstream.channelsArgument).toBe('channels');
+      });
+    });
+
+    it("should has all modes availables", function() {
+      expect(pushstream.modes).toEqual(['eventsource', 'websocket', 'stream', 'longpolling']);
+    });
+
+    it("should define callbacks attributes", function() {
+      expect(pushstream.onchanneldeleted).toBeDefined();
+      expect(pushstream.onmessage).toBeDefined();
+      expect(pushstream.onerror).toBeDefined();
+      expect(pushstream.onstatuschange).toBeDefined();
+    });
+
+    it("should has an empty channels list", function() {
+      expect(pushstream.channels).toEqual({});
+      expect(pushstream.channelsCount).toBe(0);
+    });
+
+    it("should use the url path to send channels names instead of a query string parameter", function() {
+      expect(pushstream.channelsByArgument).toBeFalsy();
+    });
+
+    it("should use headers to set values to request old messages or indicate the last received message instead of a query string parameter", function() {
+      expect(pushstream.messagesControlByArgument).toBeFalsy();
+    });
+  });
+
+  describe("when manipulating channels", function() {
+    var pushstream = null;
+    beforeEach(function() {
+      pushstream = new PushStream();
+    });
+
+    describe("and is not connected", function() {
+
+      describe("and is adding a channel", function() {
+        it("should keep channel name", function() {
+          pushstream.addChannel("ch1");
+          expect(pushstream.channels.ch1).toBeDefined();
+        });
+
+        it("should keep channel options", function() {
+          var options = {key:"value"};
+          pushstream.addChannel("ch2", options);
+          expect(pushstream.channels.ch2).toBe(options);
+        });
+
+        it("should increment channels counter", function() {
+          var count = pushstream.channelsCount;
+          pushstream.addChannel("ch3");
+          expect(pushstream.channelsCount).toBe(count + 1);
+        });
+      });
+
+      describe("and is removing a channel", function() {
+        beforeEach(function() {
+          pushstream.addChannel("ch1", {key:"value1"});
+          pushstream.addChannel("ch2", {key:"value2"});
+          pushstream.addChannel("ch3");
+        });
+
+        it("should remove channel name and options", function() {
+          pushstream.removeChannel("ch2");
+          expect(pushstream.channels.ch1).toEqual({key:"value1"});
+          expect(pushstream.channels.ch2).not.toBeDefined();
+          expect(pushstream.channels.ch3).toBeDefined();
+        });
+
+        it("should decrement channels counter", function() {
+          var count = pushstream.channelsCount;
+          pushstream.removeChannel("ch2");
+          expect(pushstream.channelsCount).toBe(count - 1);
+        });
+      });
+
+      describe("and is removing all channels", function() {
+        beforeEach(function() {
+          pushstream.addChannel("ch1", {key:"value1"});
+          pushstream.addChannel("ch2", {key:"value2"});
+          pushstream.addChannel("ch3");
+        });
+
+        it("should remove channels names and options", function() {
+          pushstream.removeAllChannels();
+          expect(pushstream.channels.ch1).not.toBeDefined();
+          expect(pushstream.channels.ch2).not.toBeDefined();
+          expect(pushstream.channels.ch3).not.toBeDefined();
+        });
+
+        it("should reset channels counter", function() {
+          pushstream.removeAllChannels();
+          expect(pushstream.channelsCount).toBe(0);
+        });
+      });
+    });
+  });
+
+  it("should define an id as a sequential number based on PushStreamManager size", function() {
+    var p1 = new PushStream();
+    var p2 = new PushStream();
+    expect(p1.id).toBe(p2.id - 1);
+    expect(p2.id).toBe(PushStreamManager.length - 1);
+  });
+
+  describe("when checking available modes", function() {
+    var eventsourceClass = null;
+
+    beforeEach(function() {
+      eventsourceClass = window.EventSource;
+      window.EventSource = null;
+    });
+
+    afterEach(function() { window.EventSource = eventsourceClass; });
+
+    it("should use only connection modes supported by the browser on the given order", function() {
+      var pushstream = new PushStream({modes: "stream|eventsource|longpolling"});
+      expect(pushstream.wrappers.length).toBe(2);
+      expect(pushstream.wrappers[0].type).toBe("Stream");
+      expect(pushstream.wrappers[1].type).toBe("LongPolling");
+    });
+  });
+
+  function itShouldHaveCommonBehavior(mode, useJSONP) {
+    var pushstream = null;
+    var channelName = null;
+    var port = 9080;
+    var nginxServer = "localhost:" + port;
+    var jsonp = useJSONP || false;
+    var urlPrefixLongpolling = useJSONP ? '/jsonp' : '/lp';
+
+    beforeEach(function() {
+      for (var i = 0; i < PushStreamManager.length; i++) {
+        PushStreamManager[i].disconnect();
+      }
+      channelName = "ch_" + new Date().getTime() + "_" + Math.floor((Math.random() * 1000) + 1);
+    });
+
+    afterEach(function() {
+      for (var i = 0; i < PushStreamManager.length; i++) {
+        PushStreamManager[i].disconnect();
+      }
+    });
+
+    describe("when connecting", function() {
+      it("should call onstatuschange callback", function(done) {
+        var status = [];
+        pushstream = new PushStream({
+          modes: mode,
+          port: port,
+          useJSONP: jsonp,
+          urlPrefixLongpolling: urlPrefixLongpolling,
+          onstatuschange: function(st) {
+            status.push(st);
+          }
+        });
+        pushstream.addChannel(channelName);
+
+        pushstream.connect();
+
+        waitsForAndRuns(
+          function() { return status.length >= 2; },
+
+          function() {
+            expect(status).toEqual([PushStream.CONNECTING, PushStream.OPEN]);
+            setTimeout(function() {
+              $.ajax({
+                url: "http://" + nginxServer + "/pub?id=" + channelName,
+                success: function(data) {
+                  expect(data.subscribers).toBe("1");
+                  done();
+                }
+              });
+            }, 1000);
+          },
+
+          1000
+        );
+      });
+    });
+
+    describe("when receiving a message", function() {
+      it("should call onmessage callback", function(done) {
+        var receivedMessage = false;
+        pushstream = new PushStream({
+          modes: mode,
+          port: port,
+          useJSONP: jsonp,
+          urlPrefixLongpolling: urlPrefixLongpolling,
+          onmessage: function(text, id, channel, eventid, isLastMessageFromBatch, time) {
+            expect([text, id, channel, eventid, isLastMessageFromBatch]).toEqual(["a test message", 1, channelName, "", true]);
+            expect(new Date(time).getTime()).toBeLessThan(new Date().getTime());
+            receivedMessage = true;
+          }
+        });
+        pushstream.addChannel(channelName);
+
+        pushstream.connect();
+
+        setTimeout(function() {
+          $.post("http://" + nginxServer + "/pub?id=" + channelName, "a test message");
+        }, 500);
+
+        waitsForAndRuns(
+          function() { return receivedMessage; },
+          function() { done(); },
+          1000
+        );
+      });
+    });
+
+    describe("when disconnecting", function() {
+      it("should call onstatuschange callback with CLOSED status", function(done) {
+        var status = null;
+        pushstream = new PushStream({
+          modes: mode,
+          port: port,
+          useJSONP: jsonp,
+          urlPrefixLongpolling: urlPrefixLongpolling,
+          onstatuschange: function(st) {
+            status = st;
+          }
+        });
+        pushstream.addChannel(channelName);
+
+        pushstream.connect();
+
+        setTimeout(function() {
+          $.ajax({
+            url: "http://" + nginxServer + "/pub?id=" + channelName,
+            success: function(data) {
+              expect(data.subscribers).toBe("1");
+              pushstream.disconnect();
+            }
+          });
+        }, 500);
+
+
+        waitsForAndRuns(
+          function() { return status == PushStream.CLOSED; },
+
+          function() {
+            expect(pushstream.readyState).toBe(PushStream.CLOSED);
+            done();
+          },
+
+          1000
+        );
+      });
+    });
+
+    if ((mode === "websocket") || (mode === "stream")) {
+      describe("when the connection timeout", function() {
+        it("should call onerror callback with a timeout error type", function(done) {
+          var error = null;
+          pushstream = new PushStream({
+            modes: mode,
+            port: port,
+            onerror: function(err) {
+              error = err;
+            }
+          });
+          pushstream.addChannel(channelName);
+
+          pushstream.connect();
+
+          waitsForAndRuns(
+            function() { return error !== null; },
+
+            function() {
+              expect(pushstream.readyState).toBe(PushStream.CLOSED);
+              expect(error.type).toBe("timeout");
+              done();
+            },
+
+            6000
+          );
+        });
+      });
+
+      describe("when reconnecting", function() {
+        it("should reconnect after disconnected by the server", function(done) {
+          var status = [];
+          pushstream = new PushStream({
+            modes: mode,
+            port: port,
+            useJSONP: jsonp,
+            urlPrefixLongpolling: urlPrefixLongpolling,
+            reconnectOnTimeoutInterval: 500,
+            reconnectOnChannelUnavailableInterval: 500,
+            onstatuschange: function(st) {
+              if (PushStream.OPEN === st) {
+                status.push(st);
+              }
+            }
+          });
+          pushstream.addChannel(channelName);
+
+          pushstream.connect();
+
+          waitsForAndRuns(
+            function() { return status.length >= 2; },
+
+            function() {
+              expect(status).toEqual([PushStream.OPEN, PushStream.OPEN]);
+              setTimeout(function() {
+                $.ajax({
+                  url: "http://" + nginxServer + "/pub?id=" + channelName,
+                  success: function(data) {
+                    expect(data.subscribers).toBe("1");
+                    done();
+                  }
+                });
+              }, 1000);
+            },
+
+            7000
+          );
+        });
+
+        it("should not reconnect after disconnected by the server if autoReconnect is off", function(done) {
+          var status = [];
+          pushstream = new PushStream({
+            modes: mode,
+            port: port,
+            useJSONP: jsonp,
+            urlPrefixLongpolling: urlPrefixLongpolling,
+            reconnectOnTimeoutInterval: 500,
+            reconnectOnChannelUnavailableInterval: 500,
+            autoReconnect: false,
+            onstatuschange: function(st) {
+              status.push(st);
+            }
+          });
+          pushstream.addChannel(channelName);
+
+          pushstream.connect();
+
+          waitsForAndRuns(
+            function() { return status.length >= 3; },
+
+            function() {
+              expect(status).toEqual([PushStream.CONNECTING, PushStream.OPEN, PushStream.CLOSED]);
+              setTimeout(function() {
+                $.ajax({
+                  url: "http://" + nginxServer + "/pub?id=" + channelName,
+                  success: function(data) {
+                    expect(data.subscribers).toBe("0");
+                    done();
+                  }
+                });
+              }, 2000);
+            },
+
+            7000
+          );
+        });
+      });
+    }
+
+    describe("when adding a new channel", function() {
+      it("should reconnect", function(done) {
+        var status = [];
+        var messages = [];
+        pushstream = new PushStream({
+          modes: mode,
+          port: port,
+          useJSONP: jsonp,
+          urlPrefixLongpolling: '/jsonp',
+          onstatuschange: function(st) {
+            status.push(st);
+          },
+          onmessage: function(text, id, channel, eventid, isLastMessageFromBatch) {
+            messages.push([text, id, channel, eventid, isLastMessageFromBatch]);
+          }
+        });
+        pushstream.addChannel(channelName);
+
+        pushstream.connect();
+
+        setTimeout(function() {
+          pushstream.addChannel("other_" + channelName);
+        }, 200);
+
+        waitsForAndRuns(
+          function() { return pushstream.channelsCount >= 2; },
+
+          function() {
+            setTimeout(function() {
+              $.post("http://" + nginxServer + "/pub?id=" + channelName, "a test message", function() {
+                setTimeout(function() {
+                  $.post("http://" + nginxServer + "/pub?id=" + "other_" + channelName, "message on other channel");
+                }, 700);
+              });
+            }, 700);
+          },
+
+          300
+        );
+
+        waitsForAndRuns(
+          function() { return messages.length >= 2; },
+
+          function() {
+            expect(status).toEqual([PushStream.CONNECTING, PushStream.OPEN, PushStream.CLOSED, PushStream.CONNECTING, PushStream.OPEN]);
+            expect(messages[0]).toEqual(["a test message", 1, channelName, "", true]);
+            expect(messages[1]).toEqual(["message on other channel", 1, "other_" + channelName, "", true]);
+            done();
+          },
+
+          2500
+        );
+      });
+    });
+
+    describe("when deleting a channel", function() {
+      it("should call onchanneldeleted callback", function(done) {
+        var channel = null;
+        pushstream = new PushStream({
+          modes: mode,
+          port: port,
+          useJSONP: jsonp,
+          urlPrefixLongpolling: urlPrefixLongpolling,
+          onchanneldeleted: function(ch) {
+            channel = ch;
+          }
+        });
+        pushstream.addChannel(channelName);
+
+        pushstream.connect();
+
+        setTimeout(function() {
+           $.ajax({type: "DELETE", url: "http://" + nginxServer + "/pub?id=" + channelName});
+        }, 500);
+
+        waitsForAndRuns(
+          function() { return channel !== null; },
+
+          function() {
+            $.post("http://" + nginxServer + "/pub?id=" + channelName, "a test message", function() {
+              $.ajax({
+                url: "http://" + nginxServer + "/pub?id=" + channelName,
+                success: function(data) {
+                  expect(data.published_messages).toBe("1");
+                }
+              });
+            });
+            expect(channel).toBe(channelName);
+            done();
+          },
+
+          1000
+        );
+      });
+    });
+
+    describe("when sending extra params", function() {
+      it("should call extraParams function", function(done) {
+        var receivedMessage = false;
+        pushstream = new PushStream({
+          modes: mode,
+          port: port,
+          useJSONP: jsonp,
+          urlPrefixLongpolling: urlPrefixLongpolling,
+          extraParams: function() {
+            return {"tests":"on"};
+          },
+          onmessage: function(text, id, channel, eventid, isLastMessageFromBatch) {
+            expect([text, id, channel, eventid, isLastMessageFromBatch]).toEqual(["a test message", 1, "test_" + channelName, "", true]);
+            receivedMessage = true;
+          }
+        });
+        pushstream.addChannel(channelName);
+
+        pushstream.connect();
+
+        setTimeout(function() {
+          $.post("http://" + nginxServer + "/pub?id=" + "test_" + channelName, "a test message");
+        }, 500);
+
+        waitsForAndRuns(
+          function() { return receivedMessage; },
+          function() { done(); },
+          1000
+        );
+      });
+    });
+
+    describe("when an error on connecting happens", function() {
+      it("should call onerror callback with a load error type", function(done) {
+        var error = null;
+        pushstream = new PushStream({
+          modes: mode,
+          port: port,
+          useJSONP: jsonp,
+          urlPrefixStream: '/pub',
+          urlPrefixEventsource: '/pub',
+          urlPrefixLongpolling: '/pub',
+          urlPrefixWebsocket: '/pub',
+          onerror: function(err) {
+            error = err;
+          }
+        });
+        pushstream.addChannel(channelName);
+
+        pushstream.connect();
+
+        waitsForAndRuns(
+          function() { return error !== null; },
+
+          function() {
+            expect(pushstream.readyState).toBe(PushStream.CLOSED);
+            expect(error.type).toBe("load");
+            done();
+          },
+
+          3000
+        );
+      });
+    });
+
+    describe("when getting old messages", function() {
+      it("should be possible use time", function(done) {
+        var messages = [];
+        var receivedMessage = receivedMessage2 = false;
+        var finished = false;
+        pushstream = new PushStream({
+          messagesControlByArgument: true,
+          messagesPublishedAfter: 1,
+          modes: mode,
+          port: port,
+          useJSONP: jsonp,
+          urlPrefixLongpolling: urlPrefixLongpolling,
+          extraParams: function() {
+            return {"qs":"on"};
+          },
+          onmessage: function(text, id, channel, eventid, isLastMessageFromBatch, time) {
+            messages.push([text, id, channel, eventid, isLastMessageFromBatch, time]);
+            if (messages.length == 1) {
+              receivedMessage = true;
+              pushstream.disconnect();
+            }
+            if (messages.length >= 2) {
+              receivedMessage2 = true;
+              pushstream.disconnect();
+            }
+          }
+        });
+        pushstream.addChannel(channelName);
+
+        $.post("http://" + nginxServer + "/pub?id=" + channelName, "a test message", function() {
+          pushstream.connect();
+        });
+
+        waitsForAndRuns(
+          function() { return receivedMessage; },
+
+          function() {
+            setTimeout(function() {
+              $.ajax({
+                url: "http://" + nginxServer + "/pub?id=" + channelName,
+                success: function(data) {
+                  expect(data.subscribers).toBe("0");
+                  $.post("http://" + nginxServer + "/pub?id=" + channelName, "another test message", function() {
+                    pushstream.connect();
+                  });
+                }
+              });
+            }, 1500);
+          },
+
+          2000
+        );
+
+        waitsForAndRuns(
+          function() { return receivedMessage2; },
+
+          function() {
+            setTimeout(function() {
+              expect(messages[0].slice(0, -1)).toEqual(["a test message", 1, channelName, "", true]);
+              expect(messages[1].slice(0, -1)).toEqual(["another test message", 2, channelName, "", true]);
+              expect(new Date(messages[0][messages[0].length - 1]).getTime()).toBeLessThan(new Date(messages[1][messages[1].length - 1]).getTime());
+              finished = true;
+            }, 500);
+          },
+
+          3000
+        );
+
+        waitsForAndRuns(
+          function() { return finished; },
+          function() { done(); },
+          5000
+        );
+      });
+
+      it("should be possible use a Date object", function(done) {
+        var messages = [];
+        var receivedMessage = receivedMessage2 = false;
+        var finished = false;
+        var now = new Date();
+        pushstream = new PushStream({
+          messagesControlByArgument: true,
+          messagesPublishedAfter: new Date(now.getTime() - 1000),
+          modes: mode,
+          port: port,
+          useJSONP: jsonp,
+          urlPrefixLongpolling: urlPrefixLongpolling,
+          extraParams: function() {
+            return {"qs":"on"};
+          },
+          onmessage: function(text, id, channel, eventid, isLastMessageFromBatch) {
+            messages.push([text, id, channel, eventid, isLastMessageFromBatch]);
+            if (messages.length == 1) {
+              receivedMessage = true;
+              pushstream.disconnect();
+            }
+            if (messages.length >= 2) {
+              receivedMessage2 = true;
+              pushstream.disconnect();
+            }
+          }
+        });
+        pushstream.addChannel(channelName);
+
+        $.post("http://" + nginxServer + "/pub?id=" + channelName, "a test message", function() {
+          pushstream.connect();
+        });
+
+        waitsForAndRuns(
+          function() { return receivedMessage; },
+
+          function() {
+            setTimeout(function() {
+              $.ajax({
+                url: "http://" + nginxServer + "/pub?id=" + channelName,
+                success: function(data) {
+                  expect(data.subscribers).toBe("0");
+                  $.post("http://" + nginxServer + "/pub?id=" + channelName, "another test message", function() {
+                    pushstream.connect();
+                  });
+                }
+              });
+            }, 1500);
+          },
+
+          2000
+        );
+
+        waitsForAndRuns(
+          function() { return receivedMessage2; },
+
+          function() {
+            setTimeout(function() {
+              expect(messages[0]).toEqual(["a test message", 1, channelName, "", true]);
+              expect(messages[1]).toEqual(["another test message", 2, channelName, "", true]);
+              finished = true;
+            }, 500);
+          },
+
+          3000
+        );
+
+        waitsForAndRuns(
+          function() { return finished; },
+          function() { done(); },
+          5000
+        );
+      });
+
+      it("should be possible use a negative value to get messages since epoch time", function(done) {
+        var messages = [];
+        var receivedMessage = receivedMessage2 = false;
+        var finished = false;
+        pushstream = new PushStream({
+          messagesControlByArgument: true,
+          messagesPublishedAfter: -10,
+          modes: mode,
+          port: port,
+          useJSONP: jsonp,
+          urlPrefixLongpolling: urlPrefixLongpolling,
+          extraParams: function() {
+            return {"qs":"on"};
+          },
+          onmessage: function(text, id, channel, eventid, isLastMessageFromBatch) {
+            messages.push([text, id, channel, eventid, isLastMessageFromBatch]);
+            if (messages.length == 2) {
+              receivedMessage = true;
+              // set a delay to wait for a ping message on streaming
+              setTimeout(function() {
+                pushstream.disconnect();
+              }, (pushstream.wrapper.type === "LongPolling") ? 5 : 1500);
+            }
+            if (messages.length >= 4) {
+              receivedMessage2 = true;
+              pushstream.disconnect();
+            }
+          }
+        });
+        pushstream.addChannel(channelName);
+
+        $.post("http://" + nginxServer + "/pub?id=" + channelName, "a test message 1", function() {
+          $.post("http://" + nginxServer + "/pub?id=" + channelName, "a test message 2", function() {
+            pushstream.connect();
+          });
+        });
+
+        waitsForAndRuns(
+          function() { return receivedMessage; },
+
+          function() {
+            setTimeout(function() {
+              $.ajax({
+                url: "http://" + nginxServer + "/pub?id=" + channelName,
+                success: function(data) {
+                  expect(data.subscribers).toBe("0");
+                  $.post("http://" + nginxServer + "/pub?id=" + channelName, "another test message 1", function() {
+                    $.post("http://" + nginxServer + "/pub?id=" + channelName, "another test message 2", function() {
+                      pushstream.connect();
+                    });
+                  });
+                }
+              });
+            }, 1500);
+          },
+
+          2000
+        );
+
+        waitsForAndRuns(
+          function() { return receivedMessage2; },
+
+          function() {
+            setTimeout(function() {
+              expect(messages[0]).toEqual(["a test message 1", 1, channelName, "", (pushstream.wrapper.type === "LongPolling") ? false : true]);
+              expect(messages[1]).toEqual(["a test message 2", 2, channelName, "", true]);
+              expect(messages[2]).toEqual(["another test message 1", 3, channelName, "", (pushstream.wrapper.type === "LongPolling") ? false : true]);
+              expect(messages[3]).toEqual(["another test message 2", 4, channelName, "", true]);
+              finished = true;
+            }, 500);
+          },
+
+          3000
+        );
+
+        waitsForAndRuns(
+          function() { return finished; },
+          function() { done(); },
+          5000
+        );
+      });
+
+      it("should be possible use backtrack", function(done) {
+        var messages = [];
+        var receivedMessage = receivedMessage2 = false;
+        var finished = false;
+        pushstream = new PushStream({
+          modes: mode,
+          port: port,
+          useJSONP: jsonp,
+          urlPrefixLongpolling: urlPrefixLongpolling,
+          extraParams: function() {
+            return {"qs":"on"};
+          },
+          onmessage: function(text, id, channel, eventid, isLastMessageFromBatch) {
+            messages.push([text, id, channel, eventid, isLastMessageFromBatch]);
+            if (messages.length == 1) {
+              receivedMessage = true;
+              pushstream.disconnect();
+            }
+            if (messages.length >= 2) {
+              receivedMessage2 = true;
+              pushstream.disconnect();
+            }
+          }
+        });
+        pushstream.addChannel(channelName, {backtrack: 1});
+
+        $.post("http://" + nginxServer + "/pub?id=" + channelName, "a test message 1", function() {
+          $.post("http://" + nginxServer + "/pub?id=" + channelName, "a test message 2", function() {
+            pushstream.connect();
+          });
+        });
+
+        waitsForAndRuns(
+          function() { return receivedMessage; },
+
+          function() {
+            setTimeout(function() {
+              $.ajax({
+                url: "http://" + nginxServer + "/pub?id=" + channelName,
+                success: function(data) {
+                  expect(data.subscribers).toBe("0");
+                  $.post("http://" + nginxServer + "/pub?id=" + channelName, "another test message 1", function() {
+                    $.post("http://" + nginxServer + "/pub?id=" + channelName, "another test message 2", function() {
+                      pushstream.connect();
+                    });
+                  });
+                }
+              });
+            }, 1500);
+          },
+
+          2000
+        );
+
+        waitsForAndRuns(
+          function() { return receivedMessage2; },
+
+          function() {
+            setTimeout(function() {
+              expect(messages[0]).toEqual(["a test message 2", 2, channelName, "", true]);
+              if (jsonp) {
+                expect(messages[1]).toEqual(["another test message 1", 3, channelName, "", false]);
+                expect(messages[2]).toEqual(["another test message 2", 4, channelName, "", true]);
+              } else {
+                expect(messages[1]).toEqual(["another test message 2", 4, channelName, "", true]);
+              }
+              finished = true;
+            }, 500);
+          },
+
+          3000
+        );
+
+        waitsForAndRuns(
+          function() { return finished; },
+          function() { done(); },
+          5000
+        );
+      });
+
+      it("should be possible use event_id", function(done) {
+        var messages = [];
+        var receivedMessage = receivedMessage2 = false;
+        var finished = false;
+        pushstream = new PushStream({
+          messagesControlByArgument: true,
+          lastEventId: "some_event_id",
+          modes: mode,
+          port: port,
+          useJSONP: jsonp,
+          urlPrefixLongpolling: urlPrefixLongpolling,
+          extraParams: function() {
+            return {"qs":"on"};
+          },
+          onmessage: function(text, id, channel, eventid, isLastMessageFromBatch) {
+            messages.push([text, id, channel, eventid, isLastMessageFromBatch]);
+            if (messages.length == 1) {
+              receivedMessage = true;
+              pushstream.disconnect();
+            }
+            if (messages.length >= 3) {
+              receivedMessage2 = true;
+              pushstream.disconnect();
+            }
+          }
+        });
+        pushstream.addChannel(channelName);
+
+        $.post("http://" + nginxServer + "/pub?id=" + channelName, "a test message 1", function() {
+          $.ajax({ url: "http://" + nginxServer + "/pub?id=" + channelName,
+            type: "POST", data: "a test message 2",
+            beforeSend: function(req) { req.setRequestHeader("Event-Id", "some_event_id"); },
+            success: function() {
+              $.ajax({ url: "http://" + nginxServer + "/pub?id=" + channelName,
+                type: "POST", data: "a test message 3",
+                beforeSend: function(req) { req.setRequestHeader("Event-Id", "some_event_id_2"); },
+                success: function() {
+                  pushstream.connect();
+                }
+              });
+            }
+          });
+        });
+
+        waitsForAndRuns(
+          function() { return receivedMessage; },
+
+          function() {
+            setTimeout(function() {
+              $.ajax({
+                url: "http://" + nginxServer + "/pub?id=" + channelName,
+                success: function(data) {
+                  expect(data.subscribers).toBe("0");
+                  $.post("http://" + nginxServer + "/pub?id=" + channelName, "another test message 1", function() {
+                    $.ajax({
+                      url: "http://" + nginxServer + "/pub?id=" + channelName,
+                      type: "post",
+                      data: "another test message 2",
+                      beforeSend: function(req) { req.setRequestHeader("Event-Id", "some_other_event_id"); },
+                      success: function() {
+                        pushstream.connect();
+                      }
+                    });
+                  });
+                }
+              });
+            }, 1500);
+          },
+
+          2000
+        );
+
+        waitsForAndRuns(
+          function() { return receivedMessage2; },
+
+          function() {
+            setTimeout(function() {
+              expect(messages[0]).toEqual(["a test message 3", 3, channelName, "some_event_id_2", true]);
+              expect(messages[1]).toEqual(["another test message 1", 4, channelName, "", (pushstream.wrapper.type !== "LongPolling")]);
+              expect(messages[2]).toEqual(["another test message 2", 5, channelName, "some_other_event_id", true]);
+              finished = true;
+            }, 500);
+          },
+
+          3000
+        );
+
+        waitsForAndRuns(
+          function() { return finished; },
+          function() { done(); },
+          5000
+        );
+      });
+
+      it("should be possible mix backtrack and time", function(done) {
+        var messages = [];
+        var receivedMessage = receivedMessage2 = false;
+        var finished = false;
+        pushstream = new PushStream({
+          messagesControlByArgument: true,
+          modes: mode,
+          port: port,
+          useJSONP: jsonp,
+          urlPrefixLongpolling: urlPrefixLongpolling,
+          extraParams: function() {
+            return {"qs":"on"};
+          },
+          onmessage: function(text, id, channel, eventid, isLastMessageFromBatch) {
+            messages.push([text, id, channel, eventid, isLastMessageFromBatch]);
+            if (messages.length >= 3) {
+              receivedMessage2 = true;
+              pushstream.disconnect();
+            }
+            if (messages.length == 1) {
+              receivedMessage = true;
+              pushstream.disconnect();
+            }
+          }
+        });
+        pushstream.addChannel(channelName, {backtrack: 1});
+
+        $.post("http://" + nginxServer + "/pub?id=" + channelName, "a test message 1", function() {
+          $.post("http://" + nginxServer + "/pub?id=" + channelName, "a test message 2", function() {
+            pushstream.connect();
+          });
+        });
+
+        waitsForAndRuns(
+          function() { return receivedMessage; },
+
+          function() {
+            setTimeout(function() {
+              $.ajax({
+                url: "http://" + nginxServer + "/pub?id=" + channelName,
+                success: function(data) {
+                  expect(data.subscribers).toBe("0");
+                  $.post("http://" + nginxServer + "/pub?id=" + channelName, "another test message 1", function() {
+                    $.post("http://" + nginxServer + "/pub?id=" + channelName, "another test message 2", function() {
+                      pushstream.connect();
+                    });
+                  });
+                }
+              });
+            }, 1500);
+          },
+
+          2000
+        );
+
+        waitsForAndRuns(
+          function() { return receivedMessage2; },
+
+          function() {
+            setTimeout(function() {
+              expect(messages[0]).toEqual(["a test message 2", 2, channelName, "", true]);
+              expect(messages[1]).toEqual(["another test message 1", 3, channelName, "", (pushstream.wrapper.type !== "LongPolling")]);
+              expect(messages[2]).toEqual(["another test message 2", 4, channelName, "", true]);
+              finished = true;
+            }, 500);
+          },
+
+          3000
+        );
+
+        waitsForAndRuns(
+          function() { return finished; },
+          function() { done(); },
+          5000
+        );
+      });
+    });
+  };
+
+  describe("on Stream mode", function() {
+    itShouldHaveCommonBehavior('stream');
+  });
+
+  describe("on EventSource mode", function() {
+    if (window.EventSource) {
+      itShouldHaveCommonBehavior('eventsource');
+    }
+  });
+
+  describe("on WebSocket mode", function() {
+    if (window.WebSocket || window.MozWebSocket) {
+      itShouldHaveCommonBehavior('websocket');
+    }
+  });
+
+  describe("on LongPolling mode", function() {
+    itShouldHaveCommonBehavior('longpolling');
+  });
+
+  describe("on JSONP mode", function() {
+    itShouldHaveCommonBehavior('longpolling', true);
+  });
+});
diff -Naur nginx-1.11.3/nginx-push-stream-module/misc/spec/javascripts/support/jasmine_helper.rb nginx-1.11.3-push/nginx-push-stream-module/misc/spec/javascripts/support/jasmine_helper.rb
--- nginx-1.11.3/nginx-push-stream-module/misc/spec/javascripts/support/jasmine_helper.rb	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/misc/spec/javascripts/support/jasmine_helper.rb	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,8 @@
+Jasmine.configure do |config|
+  project_dir = File.expand_path('../../../../misc/..', File.dirname(__FILE__))
+  config.spec_dir = project_dir
+  config.spec_files = lambda { Dir["#{project_dir}/misc/spec/javascripts/helpers/**/*.js"] + Dir["#{project_dir}/misc/js/jquery.min.js"] + Dir["#{project_dir}/misc/**/*[sS]pec.js"] }
+  js_tmp_dir = File.expand_path('pushstream/js', Dir.tmpdir)
+  config.src_dir = js_tmp_dir
+  config.src_files = lambda { Dir["#{js_tmp_dir}/**/*.js"] }
+end
diff -Naur nginx-1.11.3/nginx-push-stream-module/misc/spec/javascripts/support/jasmine.yml nginx-1.11.3-push/nginx-push-stream-module/misc/spec/javascripts/support/jasmine.yml
--- nginx-1.11.3/nginx-push-stream-module/misc/spec/javascripts/support/jasmine.yml	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/misc/spec/javascripts/support/jasmine.yml	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,124 @@
+# src_files
+#
+# Return an array of filepaths relative to src_dir to include before jasmine specs.
+# Default: []
+#
+# EXAMPLE:
+#
+# src_files:
+#   - lib/source1.js
+#   - lib/source2.js
+#   - dist/**/*.js
+#
+src_files:
+  - public/javascripts/**/*.js
+
+# stylesheets
+#
+# Return an array of stylesheet filepaths relative to src_dir to include before jasmine specs.
+# Default: []
+#
+# EXAMPLE:
+#
+# stylesheets:
+#   - css/style.css
+#   - stylesheets/*.css
+#
+stylesheets:
+  - stylesheets/**/*.css
+
+# helpers
+#
+# Return an array of filepaths relative to spec_dir to include before jasmine specs.
+# Default: ["helpers/**/*.js"]
+#
+# EXAMPLE:
+#
+# helpers:
+#   - helpers/**/*.js
+#
+helpers:
+  - 'helpers/**/*.js'
+
+# spec_files
+#
+# Return an array of filepaths relative to spec_dir to include.
+# Default: ["**/*[sS]pec.js"]
+#
+# EXAMPLE:
+#
+# spec_files:
+#   - **/*[sS]pec.js
+#
+spec_files:
+  - '**/*[sS]pec.js'
+
+# src_dir
+#
+# Source directory path. Your src_files must be returned relative to this path. Will use root if left blank.
+# Default: project root
+#
+# EXAMPLE:
+#
+# src_dir: public
+#
+src_dir:
+
+# spec_dir
+#
+# Spec directory path. Your spec_files must be returned relative to this path.
+# Default: spec/javascripts
+#
+# EXAMPLE:
+#
+# spec_dir: spec/javascripts
+#
+spec_dir:
+
+# spec_helper
+#
+# Ruby file that Jasmine server will require before starting.
+# Returned relative to your root path
+# Default spec/javascripts/support/jasmine_helper.rb
+#
+# EXAMPLE:
+#
+# spec_helper: spec/javascripts/support/jasmine_helper.rb
+#
+spec_helper: spec/javascripts/support/jasmine_helper.rb
+
+# boot_dir
+#
+# Boot directory path. Your boot_files must be returned relative to this path.
+# Default: Built in boot file
+#
+# EXAMPLE:
+#
+# boot_dir: spec/javascripts/support/boot
+#
+boot_dir:
+
+# boot_files
+#
+# Return an array of filepaths relative to boot_dir to include in order to boot Jasmine
+# Default: Built in boot file
+#
+# EXAMPLE
+#
+# boot_files:
+#   - '**/*.js'
+#
+boot_files:
+
+# rack_options
+#
+# Extra options to be passed to the rack server
+# by default, Port and AccessLog are passed.
+#
+# This is an advanced options, and left empty by default
+#
+# EXAMPLE
+#
+# rack_options:
+#   server: 'thin'
+
diff -Naur nginx-1.11.3/nginx-push-stream-module/misc/spec/javascripts/UtilsSpec.js nginx-1.11.3-push/nginx-push-stream-module/misc/spec/javascripts/UtilsSpec.js
--- nginx-1.11.3/nginx-push-stream-module/misc/spec/javascripts/UtilsSpec.js	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/misc/spec/javascripts/UtilsSpec.js	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,177 @@
+describe("Utils", function() {
+  var jsonKeys = {
+    jsonIdKey      : 'id',
+    jsonChannelKey : 'channel',
+    jsonTextKey    : 'text',
+    jsonTagKey     : 'tag',
+    jsonTimeKey    : 'time',
+    jsonEventIdKey : 'eventid'
+  };
+
+  beforeEach(function() {
+  });
+
+  describe("when formatting dates to UTC string", function() {
+    it("should return the string with two digits for day", function () {
+      expect(Utils.dateToUTCString(Date.fromISO("2012-11-09T12:00:00-03:00"))).toBe("Fri, 09 Nov 2012 15:00:00 GMT");
+      expect(Utils.dateToUTCString(Date.fromISO("2012-11-10T12:00:00-03:00"))).toBe("Sat, 10 Nov 2012 15:00:00 GMT");
+    });
+
+    it("should return the string with two digits for hour", function () {
+      expect(Utils.dateToUTCString(Date.fromISO("2012-11-09T06:00:00-03:00"))).toBe("Fri, 09 Nov 2012 09:00:00 GMT");
+      expect(Utils.dateToUTCString(Date.fromISO("2012-11-10T07:00:00-03:00"))).toBe("Sat, 10 Nov 2012 10:00:00 GMT");
+    });
+
+    it("should return the string with two digits for minute", function () {
+      expect(Utils.dateToUTCString(Date.fromISO("2012-11-09T06:09:00-03:00"))).toBe("Fri, 09 Nov 2012 09:09:00 GMT");
+      expect(Utils.dateToUTCString(Date.fromISO("2012-11-10T07:10:00-03:00"))).toBe("Sat, 10 Nov 2012 10:10:00 GMT");
+    });
+
+    it("should return the string with two digits for second", function () {
+      expect(Utils.dateToUTCString(Date.fromISO("2012-11-09T06:09:09-03:00"))).toBe("Fri, 09 Nov 2012 09:09:09 GMT");
+      expect(Utils.dateToUTCString(Date.fromISO("2012-11-10T07:10:10-03:00"))).toBe("Sat, 10 Nov 2012 10:10:10 GMT");
+    });
+
+    it("should return the right text for months", function () {
+      expect(Utils.dateToUTCString(Date.fromISO("2012-01-09T06:09:09-03:00"))).toBe("Mon, 09 Jan 2012 09:09:09 GMT");
+      expect(Utils.dateToUTCString(Date.fromISO("2012-02-09T06:09:09-03:00"))).toBe("Thu, 09 Feb 2012 09:09:09 GMT");
+      expect(Utils.dateToUTCString(Date.fromISO("2012-03-09T06:09:09-03:00"))).toBe("Fri, 09 Mar 2012 09:09:09 GMT");
+      expect(Utils.dateToUTCString(Date.fromISO("2012-04-09T06:09:09-03:00"))).toBe("Mon, 09 Apr 2012 09:09:09 GMT");
+      expect(Utils.dateToUTCString(Date.fromISO("2012-05-09T06:09:09-03:00"))).toBe("Wed, 09 May 2012 09:09:09 GMT");
+      expect(Utils.dateToUTCString(Date.fromISO("2012-06-09T06:09:09-03:00"))).toBe("Sat, 09 Jun 2012 09:09:09 GMT");
+      expect(Utils.dateToUTCString(Date.fromISO("2012-07-09T06:09:09-03:00"))).toBe("Mon, 09 Jul 2012 09:09:09 GMT");
+      expect(Utils.dateToUTCString(Date.fromISO("2012-08-09T06:09:09-03:00"))).toBe("Thu, 09 Aug 2012 09:09:09 GMT");
+      expect(Utils.dateToUTCString(Date.fromISO("2012-09-09T06:09:09-03:00"))).toBe("Sun, 09 Sep 2012 09:09:09 GMT");
+      expect(Utils.dateToUTCString(Date.fromISO("2012-10-09T06:09:09-03:00"))).toBe("Tue, 09 Oct 2012 09:09:09 GMT");
+      expect(Utils.dateToUTCString(Date.fromISO("2012-11-09T06:09:09-03:00"))).toBe("Fri, 09 Nov 2012 09:09:09 GMT");
+      expect(Utils.dateToUTCString(Date.fromISO("2012-12-09T06:09:09-03:00"))).toBe("Sun, 09 Dec 2012 09:09:09 GMT");
+    });
+
+    it("should return the right text for days", function () {
+      expect(Utils.dateToUTCString(Date.fromISO("2012-01-01T06:09:09-03:00"))).toBe("Sun, 01 Jan 2012 09:09:09 GMT");
+      expect(Utils.dateToUTCString(Date.fromISO("2012-01-02T06:09:09-03:00"))).toBe("Mon, 02 Jan 2012 09:09:09 GMT");
+      expect(Utils.dateToUTCString(Date.fromISO("2012-01-03T06:09:09-03:00"))).toBe("Tue, 03 Jan 2012 09:09:09 GMT");
+      expect(Utils.dateToUTCString(Date.fromISO("2012-01-04T06:09:09-03:00"))).toBe("Wed, 04 Jan 2012 09:09:09 GMT");
+      expect(Utils.dateToUTCString(Date.fromISO("2012-01-05T06:09:09-03:00"))).toBe("Thu, 05 Jan 2012 09:09:09 GMT");
+      expect(Utils.dateToUTCString(Date.fromISO("2012-01-06T06:09:09-03:00"))).toBe("Fri, 06 Jan 2012 09:09:09 GMT");
+      expect(Utils.dateToUTCString(Date.fromISO("2012-01-07T06:09:09-03:00"))).toBe("Sat, 07 Jan 2012 09:09:09 GMT");
+    });
+  });
+
+  describe("when parse JSON", function() {
+    it("should return null when data is null", function () {
+      expect(Utils.parseJSON(null)).toBe(null);
+    });
+
+    it("should return null when data is undefined", function () {
+      expect(Utils.parseJSON(undefined)).toBe(null);
+    });
+
+    it("should return null when data is not a string", function () {
+      expect(Utils.parseJSON({})).toBe(null);
+    });
+
+    if (window.JSON) {
+      describe("when have a default implementation for JSON.parse", function () {
+        var jsonImplementation = null;
+        beforeEach(function() {
+          jsonImplementation = window.JSON;
+          // window.JSON = null;
+        });
+
+        afterEach(function() {
+          window.JSON = jsonImplementation;
+        });
+
+        it("should use the browser default implementation when available", function () {
+          spyOn(window.JSON, "parse");
+          Utils.parseJSON('{"a":1}');
+          expect(window.JSON.parse).toHaveBeenCalledWith('{"a":1}');
+        });
+
+        it("should parse a well formed json string", function () {
+          expect(Utils.parseJSON('{"a":1}')["a"]).toBe(1);
+        });
+
+        it("should parse when the string has leading spaces", function () {
+          expect(Utils.parseJSON('  {"a":1}')["a"]).toBe(1);
+        });
+
+        it("should parse when the string has trailing spaces", function () {
+          expect(Utils.parseJSON('{"a":1}  ')["a"]).toBe(1);
+        });
+
+        it("should raise error when string is a invalid json", function () {
+          expect(function () { Utils.parseJSON('{"a":1[]}'); }).toThrow('Invalid JSON: {"a":1[]}');
+        });
+      });
+    }
+
+    describe("when do not have a default implementation for JSON.parse", function () {
+      var jsonImplementation = null;
+      beforeEach(function() {
+        jsonImplementation = window.JSON;
+        window.JSON = null;
+      });
+
+      afterEach(function() {
+        window.JSON = jsonImplementation;
+      });
+
+      it("should parse a well formed json string", function () {
+        expect(Utils.parseJSON('{"a":1}')["a"]).toBe(1);
+      });
+
+      it("should parse when the string has leading spaces", function () {
+        expect(Utils.parseJSON('  {"a":1}')["a"]).toBe(1);
+      });
+
+      it("should parse when the string has trailing spaces", function () {
+        expect(Utils.parseJSON('{"a":1}  ')["a"]).toBe(1);
+      });
+
+      it("should raise error when string is a invalid json", function () {
+        expect(function () { Utils.parseJSON('{"a":1[]}'); }).toThrow('Invalid JSON: {"a":1[]}');
+      });
+    });
+  });
+
+  describe("when extract xss domain", function() {
+    it("should return the ip address when domain is only an ip", function() {
+      expect(Utils.extract_xss_domain("201.10.32.52")).toBe("201.10.32.52");
+    });
+
+    it("should return the full domain when it has only two parts", function() {
+      expect(Utils.extract_xss_domain("domain.com")).toBe("domain.com");
+    });
+
+    it("should return the last two parts when domain has three parts", function() {
+      expect(Utils.extract_xss_domain("example.domain.com")).toBe("domain.com");
+    });
+
+    it("should return all parts minus the first one when domain has more than three parts", function() {
+      expect(Utils.extract_xss_domain("another.example.domain.com")).toBe("example.domain.com");
+    });
+  });
+
+  describe("when parsing a message", function() {
+    it("should accept a simple string as text", function() {
+      var message = Utils.parseMessage('{"id":31,"channel":"54x19","text":"some simple string"}', jsonKeys);
+      expect(message.text).toBe("some simple string");
+    });
+
+    it("should accept a json as text", function() {
+      var message = Utils.parseMessage('{"id":31,"channel":"54x19","text":{"id":"500516b7639e4029b8000001","type":"Player","change":{"loc":[54.34772390000001,18.5610535],"version":7}}}', jsonKeys);
+      expect(message.text.id).toBe("500516b7639e4029b8000001");
+      expect(message.text.type).toBe("Player");
+      expect(message.text.change.loc[0]).toBe(54.34772390000001);
+      expect(message.text.change.loc[1]).toBe(18.5610535);
+      expect(message.text.change.version).toBe(7);
+    });
+
+    it("should accept an escaped json as text", function() {
+      var message = Utils.parseMessage('{"id":31,"channel":"54x19","text":"%7B%22id%22%3A%22500516b7639e4029b8000001%22%2C%22type%22%3A%22Player%22%2C%22change%22%3A%7B%22loc%22%3A%5B54.34772390000001%2C18.5610535%5D%2C%22version%22%3A7%7D%7D"}', jsonKeys);
+      expect(message.text).toBe('{"id":"500516b7639e4029b8000001","type":"Player","change":{"loc":[54.34772390000001,18.5610535],"version":7}}');
+    });
+  });
+});
diff -Naur nginx-1.11.3/nginx-push-stream-module/misc/spec/mix/channel_statistics_spec.rb nginx-1.11.3-push/nginx-push-stream-module/misc/spec/mix/channel_statistics_spec.rb
--- nginx-1.11.3/nginx-push-stream-module/misc/spec/mix/channel_statistics_spec.rb	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/misc/spec/mix/channel_statistics_spec.rb	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,791 @@
+require 'spec_helper'
+
+describe "Channel Statistics" do
+  let(:config) do
+   {}
+  end
+
+shared_examples_for "statistics location" do
+  it "should return 404 for a nonexistent channel" do
+    channel = 'ch_test_get_channel_statistics_whithout_created_channel'
+
+    nginx_run_server(config) do |conf|
+      EventMachine.run do
+        pub_1 = EventMachine::HttpRequest.new(nginx_address + '/channels-stats?id=' + channel.to_s).get :head => headers
+        pub_1.callback do
+          expect(pub_1).to be_http_status(404).without_body
+          EventMachine.stop
+        end
+      end
+    end
+  end
+
+  it "should return channels statistics for an existent channel" do
+    channel = 'ch_test_get_channel_statistics_to_existing_channel'
+    body = 'body'
+    actual_response = ''
+
+    nginx_run_server(config) do |conf|
+      #create channel
+      publish_message(channel, headers, body)
+
+      EventMachine.run do
+        pub_2 = EventMachine::HttpRequest.new(nginx_address + '/channels-stats?id=' + channel.to_s).get :head => headers, :decoding => false
+        pub_2.stream do |chunk|
+          actual_response << chunk
+        end
+        pub_2.callback do
+          expect(pub_2).to be_http_status(200)
+
+          if (conf.gzip == "on")
+            expect(pub_2.response_header["CONTENT_ENCODING"]).to eql("gzip")
+            actual_response = Zlib::GzipReader.new(StringIO.new(actual_response)).read
+          end
+
+          response = JSON.parse(actual_response)
+          expect(response["channel"].to_s).to eql(channel)
+          expect(response["published_messages"]).to eql(1)
+          expect(response["stored_messages"]).to eql(1)
+          expect(response["subscribers"]).to eql(0)
+          EventMachine.stop
+        end
+      end
+    end
+  end
+
+  it "should return channels statistics for an existent channel with subscriber" do
+    channel = 'ch_test_get_channel_statistics_to_existing_channel_with_subscriber'
+    body = 'body'
+
+    nginx_run_server(config) do |conf|
+      create_channel_by_subscribe(channel, headers) do
+        pub_1 = EventMachine::HttpRequest.new(nginx_address + '/channels-stats?id=' + channel.to_s).get :head => headers
+        pub_1.callback do
+          expect(pub_1).to be_http_status(200)
+          response = JSON.parse(pub_1.response)
+          expect(response["channel"].to_s).to eql(channel)
+          expect(response["published_messages"]).to eql(0)
+          expect(response["stored_messages"]).to eql(0)
+          expect(response["subscribers"]).to eql(1)
+          EventMachine.stop
+        end
+      end
+    end
+  end
+
+  it "should return detailed channels statistics without existing channels" do
+    nginx_run_server(config) do |conf|
+      EventMachine.run do
+        pub_2 = EventMachine::HttpRequest.new(nginx_address + '/channels-stats?id=ALL').get :head => headers
+        pub_2.callback do
+          expect(pub_2).to be_http_status(200)
+          response = JSON.parse(pub_2.response)
+          expect(response["infos"].length).to eql(0)
+          EventMachine.stop
+        end
+      end
+    end
+  end
+
+  it "should return detailed channels statistics for an existent channel" do
+    channel = 'ch_test_get_detailed_channels_statistics_to_existing_channel'
+    body = 'body'
+    actual_response = ''
+
+    nginx_run_server(config) do |conf|
+      #create channel
+      publish_message(channel, headers, body)
+
+      EventMachine.run do
+        pub_2 = EventMachine::HttpRequest.new(nginx_address + '/channels-stats?id=ALL').get :head => headers, :decoding => false
+        pub_2.stream do |chunk|
+          actual_response << chunk
+        end
+        pub_2.callback do
+          expect(pub_2).to be_http_status(200)
+
+          if (conf.gzip == "on")
+            expect(pub_2.response_header["CONTENT_ENCODING"]).to eql("gzip")
+            actual_response = Zlib::GzipReader.new(StringIO.new(actual_response)).read
+          end
+
+          response = JSON.parse(actual_response)
+          expect(response["infos"].length).to eql(1)
+          expect(response["infos"][0]["channel"].to_s).to eql(channel)
+          expect(response["infos"][0]["published_messages"]).to eql(1)
+          expect(response["infos"][0]["stored_messages"]).to eql(1)
+          expect(response["infos"][0]["subscribers"]).to eql(0)
+          EventMachine.stop
+        end
+      end
+    end
+  end
+
+  it "should return detailed channels statistics for an existent wildcard channel" do
+    channel = 'bd_test_get_detailed_channels_statistics_to_existing_wildcard_channel'
+    body = 'body'
+
+    nginx_run_server(config.merge(:wildcard_channel_prefix => 'bd_', :wildcard_channel_max_qtd => 1)) do |conf|
+      #create channel
+      publish_message(channel, headers, body)
+
+      EventMachine.run do
+        pub_2 = EventMachine::HttpRequest.new(nginx_address + '/channels-stats?id=ALL').get :head => headers
+        pub_2.callback do
+          expect(pub_2).to be_http_status(200)
+          response = JSON.parse(pub_2.response)
+          expect(response["infos"].length).to eql(1)
+          expect(response["channels"]).to eql(0)
+          expect(response["wildcard_channels"]).to eql(1)
+          expect(response["infos"][0]["channel"].to_s).to eql(channel)
+          expect(response["infos"][0]["published_messages"]).to eql(1)
+          expect(response["infos"][0]["stored_messages"]).to eql(1)
+          expect(response["infos"][0]["subscribers"]).to eql(0)
+          EventMachine.stop
+        end
+      end
+    end
+  end
+
+  it "should return detailed channels statistics for an existent channel with subscriber" do
+    channel = 'ch_test_detailed_channels_statistics_to_existing_channel_with_subscriber'
+    body = 'body'
+
+    nginx_run_server(config) do |conf|
+      create_channel_by_subscribe(channel, headers) do
+        pub_1 = EventMachine::HttpRequest.new(nginx_address + '/channels-stats?id=ALL').get :head => headers
+        pub_1.callback do
+          expect(pub_1).to be_http_status(200)
+          response = JSON.parse(pub_1.response)
+          expect(response["infos"].length).to eql(1)
+          expect(response["infos"][0]["channel"].to_s).to eql(channel)
+          expect(response["infos"][0]["published_messages"]).to eql(0)
+          expect(response["infos"][0]["stored_messages"]).to eql(0)
+          expect(response["infos"][0]["subscribers"]).to eql(1)
+          EventMachine.stop
+        end
+      end
+    end
+  end
+
+  it "should return summarized channels statistics for a nonexistent channel" do
+    nginx_run_server(config) do |conf|
+      EventMachine.run do
+        pub_1 = EventMachine::HttpRequest.new(nginx_address + '/channels-stats').get :head => headers
+        pub_1.callback do
+          expect(pub_1).to be_http_status(200)
+          response = JSON.parse(pub_1.response)
+          expect(response.has_key?("channels")).to be_truthy
+          expect(response["channels"]).to eql(0)
+          EventMachine.stop
+        end
+      end
+    end
+  end
+
+  it "should return summarized channels statistics for an existent channel" do
+    channel = 'ch_test_get_summarized_channels_statistics_to_existing_channel'
+    body = 'body'
+    actual_response = ''
+
+    nginx_run_server(config) do |conf|
+      #create channel
+      publish_message(channel, headers, body)
+
+      EventMachine.run do
+        pub_2 = EventMachine::HttpRequest.new(nginx_address + '/channels-stats').get :head => headers, :decoding => false
+        pub_2.stream do |chunk|
+          actual_response << chunk
+        end
+        pub_2.callback do
+          expect(pub_2).to be_http_status(200)
+
+          if (conf.gzip == "on")
+            expect(pub_2.response_header["CONTENT_ENCODING"]).to eql("gzip")
+            actual_response = Zlib::GzipReader.new(StringIO.new(actual_response)).read
+          end
+
+          response = JSON.parse(actual_response)
+          expect(response.has_key?("channels")).to be_truthy
+          expect(response["channels"]).to eql(1)
+          expect(response["published_messages"]).to eql(1)
+          expect(response["subscribers"]).to eql(0)
+          EventMachine.stop
+        end
+      end
+    end
+  end
+
+  it "should return summarized channels statistics for an existent wildcard channel" do
+    channel = 'bd_test_get_summarized_channels_statistics_to_existing_wildcard_channel'
+    body = 'body'
+
+    nginx_run_server(config.merge(:wildcard_channel_prefix => 'bd_', :wildcard_channel_max_qtd => 1)) do |conf|
+      #create channel
+      publish_message(channel, headers, body)
+
+      EventMachine.run do
+        pub_2 = EventMachine::HttpRequest.new(nginx_address + '/channels-stats').get :head => headers
+        pub_2.callback do
+          expect(pub_2).to be_http_status(200)
+          response = JSON.parse(pub_2.response)
+          expect(response.has_key?("channels")).to be_truthy
+          expect(response["channels"]).to eql(0)
+          expect(response["wildcard_channels"]).to eql(1)
+          expect(response["published_messages"]).to eql(1)
+          expect(response["subscribers"]).to eql(0)
+          EventMachine.stop
+        end
+      end
+    end
+  end
+
+  it "should return summarized channels statistics for an existent channel with subscriber" do
+    channel = 'ch_test_summarized_channels_statistics_to_existing_channel_with_subscriber'
+    body = 'body'
+
+    nginx_run_server(config) do |conf|
+      create_channel_by_subscribe(channel, headers) do
+        pub_1 = EventMachine::HttpRequest.new(nginx_address + '/channels-stats').get :head => headers
+        pub_1.callback do
+          expect(pub_1).to be_http_status(200)
+          response = JSON.parse(pub_1.response)
+          expect(response.has_key?("channels")).to be_truthy
+          expect(response["channels"]).to eql(1)
+          expect(response["published_messages"]).to eql(0)
+          expect(response["subscribers"]).to eql(1)
+          EventMachine.stop
+        end
+      end
+    end
+  end
+
+  it "should check accepted methods" do
+    nginx_run_server(config) do |conf|
+      EventMachine.run do
+        multi = EventMachine::MultiRequest.new
+
+        multi.add(:a, EventMachine::HttpRequest.new(nginx_address + '/channels-stats').get)
+        multi.add(:b, EventMachine::HttpRequest.new(nginx_address + '/channels-stats').put(:body => 'body'))
+        multi.add(:c, EventMachine::HttpRequest.new(nginx_address + '/channels-stats').post)
+        multi.add(:d, EventMachine::HttpRequest.new(nginx_address + '/channels-stats').delete)
+        multi.add(:e, EventMachine::HttpRequest.new(nginx_address + '/channels-stats').head)
+
+        multi.callback do
+          expect(multi.responses[:callback].length).to eql(5)
+
+          expect(multi.responses[:callback][:a]).not_to be_http_status(405)
+          expect(multi.responses[:callback][:a].req.method).to eql("GET")
+
+          expect(multi.responses[:callback][:b]).to be_http_status(405)
+          expect(multi.responses[:callback][:b].req.method).to eql("PUT")
+
+          expect(multi.responses[:callback][:c]).to be_http_status(405)
+          expect(multi.responses[:callback][:c].req.method).to eql("POST")
+
+          expect(multi.responses[:callback][:d]).to be_http_status(405)
+          expect(multi.responses[:callback][:d].req.method).to eql("DELETE")
+
+          expect(multi.responses[:callback][:e]).to be_http_status(405)
+          expect(multi.responses[:callback][:e].req.method).to eql("HEAD")
+
+          EventMachine.stop
+        end
+      end
+    end
+  end
+
+  it "should check accepted content types" do
+    channel = 'ch_test_accepted_content_types'
+    body = 'body'
+
+    nginx_run_server(config) do |conf|
+      #create channel
+      publish_message(channel, headers, body)
+
+      EventMachine.run do
+        multi = EventMachine::MultiRequest.new
+
+        multi.add(:a, EventMachine::HttpRequest.new(nginx_address + '/channels-stats').get) # default content_type
+        multi.add(:b, EventMachine::HttpRequest.new(nginx_address + '/channels-stats').get(:head => {'accept' => 'text/plain'}))
+        multi.add(:c, EventMachine::HttpRequest.new(nginx_address + '/channels-stats').get(:head => {'accept' => 'application/json'}))
+        multi.add(:d, EventMachine::HttpRequest.new(nginx_address + '/channels-stats').get(:head => {'accept' => 'application/yaml'}))
+        multi.add(:e, EventMachine::HttpRequest.new(nginx_address + '/channels-stats').get(:head => {'accept' => 'application/xml'}))
+        multi.add(:f, EventMachine::HttpRequest.new(nginx_address + '/channels-stats').get(:head => {'accept' => 'text/x-json'}))
+        multi.add(:g, EventMachine::HttpRequest.new(nginx_address + '/channels-stats').get(:head => {'accept' => 'text/x-yaml'}))
+
+        multi.callback do
+          expect(multi.responses[:callback].length).to eql(7)
+
+          expect(multi.responses[:callback][:a]).to be_http_status(200).with_body
+          expect(multi.responses[:callback][:a].req.method).to eql("GET")
+          expect(multi.responses[:callback][:a].response_header["CONTENT_TYPE"]).to eql("application/json")
+
+          expect(multi.responses[:callback][:b]).to be_http_status(200).with_body
+          expect(multi.responses[:callback][:b].req.method).to eql("GET")
+          expect(multi.responses[:callback][:b].response_header["CONTENT_TYPE"]).to eql("text/plain")
+
+          expect(multi.responses[:callback][:c]).to be_http_status(200).with_body
+          expect(multi.responses[:callback][:c].req.method).to eql("GET")
+          expect(multi.responses[:callback][:c].response_header["CONTENT_TYPE"]).to eql("application/json")
+
+          expect(multi.responses[:callback][:d]).to be_http_status(200).with_body
+          expect(multi.responses[:callback][:d].req.method).to eql("GET")
+          expect(multi.responses[:callback][:d].response_header["CONTENT_TYPE"]).to eql("application/yaml")
+
+          expect(multi.responses[:callback][:e]).to be_http_status(200).with_body
+          expect(multi.responses[:callback][:e].req.method).to eql("GET")
+          expect(multi.responses[:callback][:e].response_header["CONTENT_TYPE"]).to eql("application/xml")
+
+          expect(multi.responses[:callback][:f]).to be_http_status(200).with_body
+          expect(multi.responses[:callback][:f].req.method).to eql("GET")
+          expect(multi.responses[:callback][:f].response_header["CONTENT_TYPE"]).to eql("text/x-json")
+
+          expect(multi.responses[:callback][:g]).to be_http_status(200).with_body
+          expect(multi.responses[:callback][:g].req.method).to eql("GET")
+          expect(multi.responses[:callback][:g].response_header["CONTENT_TYPE"]).to eql("text/x-yaml")
+
+          EventMachine.stop
+        end
+      end
+    end
+  end
+
+  it "should return detailed channels statistics for many channels" do
+    channel = 'ch_test_get_detailed_channels_statistics_to_many_channels_'
+    body = 'body'
+    number_of_channels = 20000
+
+    nginx_run_server(config.merge(:shared_memory_size => '200m', :keepalive_requests => 1000), :timeout => 15) do |conf|
+      #create channels
+      0.step(number_of_channels - 1, 1000) do |i|
+        socket = open_socket(nginx_host, nginx_port)
+        1.upto(1000) do |j|
+          headers, body = post_in_socket("/pub?id=#{channel}#{i + j}", body, socket, {:wait_for => "}\r\n"})
+          expect(headers).to include("HTTP/1.1 200 OK")
+        end
+        socket.close
+      end
+
+      EventMachine.run do
+        pub_2 = EventMachine::HttpRequest.new(nginx_address + '/channels-stats?id=ALL').get :head => headers
+        pub_2.callback do
+          expect(pub_2).to be_http_status(200)
+          response = JSON.parse(pub_2.response)
+          expect(response["infos"].length).to eql(number_of_channels)
+          EventMachine.stop
+        end
+      end
+    end
+  end
+
+  it "should return detailed channels statistics for a nonexistent channel using prefix id" do
+    nginx_run_server(config) do |conf|
+      EventMachine.run do
+        pub_2 = EventMachine::HttpRequest.new(nginx_address + '/channels-stats?id=prefix_*').get :head => headers
+        pub_2.callback do
+          expect(pub_2).to be_http_status(200)
+          response = JSON.parse(pub_2.response)
+          expect(response["infos"].length).to eql(0)
+          EventMachine.stop
+        end
+      end
+    end
+  end
+
+  it "should return detailed channels statistics for an existent channel using prefix id" do
+    channel = 'ch_test_get_detailed_channels_statistics_to_existing_channel_using_prefix'
+    channel_1 = 'another_ch_test_get_detailed_channels_statistics_to_existing_channel_using_prefix'
+    body = 'body'
+
+    nginx_run_server(config) do |conf|
+      #create channels
+      publish_message(channel, headers, body)
+      publish_message(channel_1, headers, body)
+
+      EventMachine.run do
+        pub_2 = EventMachine::HttpRequest.new(nginx_address + '/channels-stats?id=ch_test_*').get :head => headers
+        pub_2.callback do
+          expect(pub_2).to be_http_status(200)
+          response = JSON.parse(pub_2.response)
+          expect(response["infos"].length).to eql(1)
+          expect(response["infos"][0]["channel"].to_s).to eql(channel)
+          expect(response["infos"][0]["published_messages"]).to eql(1)
+          expect(response["infos"][0]["stored_messages"]).to eql(1)
+          expect(response["infos"][0]["subscribers"]).to eql(0)
+          EventMachine.stop
+        end
+      end
+    end
+  end
+
+  it "should return detailed channels statistics using prefix id with same behavior as ALL" do
+    channel = 'ch_test_get_detailed_channels_statistics_using_prefix_as_same_behavior_ALL'
+    channel_1 = 'another_ch_test_get_detailed_channels_statistics_using_prefix_as_same_behavior_ALL'
+    body = 'body'
+
+    nginx_run_server(config) do |conf|
+      #create channels
+      publish_message(channel, headers, body)
+      publish_message(channel_1, headers, body)
+
+      EventMachine.run do
+        pub_2 = EventMachine::HttpRequest.new(nginx_address + '/channels-stats?id=*').get :head => headers
+        pub_2.callback do
+          expect(pub_2).to be_http_status(200)
+          response = JSON.parse(pub_2.response)
+          expect(response["infos"].length).to eql(2)
+          expect(response["infos"][0]["channel"].to_s).to eql(channel)
+          expect(response["infos"][0]["published_messages"]).to eql(1)
+          expect(response["infos"][0]["stored_messages"]).to eql(1)
+          expect(response["infos"][0]["subscribers"]).to eql(0)
+          expect(response["infos"][1]["channel"].to_s).to eql(channel_1)
+          expect(response["infos"][1]["published_messages"]).to eql(1)
+          expect(response["infos"][1]["stored_messages"]).to eql(1)
+          expect(response["infos"][1]["subscribers"]).to eql(0)
+          EventMachine.stop
+        end
+      end
+    end
+  end
+
+  it "should return detailed channels statistics for an existent wildcard channel using prefix id" do
+    channel = 'bd_test_get_detailed_channels_statistics_to_existing_wildcard_channel_using_prefix'
+    body = 'body'
+
+    nginx_run_server(config.merge(:wildcard_channel_prefix => 'bd_', :wildcard_channel_max_qtd => 1)) do |conf|
+      #create channels
+      publish_message(channel, headers, body)
+
+      EventMachine.run do
+        pub_2 = EventMachine::HttpRequest.new(nginx_address + '/channels-stats?id=bd_test_*').get :head => headers
+        pub_2.callback do
+          expect(pub_2).to be_http_status(200)
+          response = JSON.parse(pub_2.response)
+          expect(response["infos"].length).to eql(1)
+          expect(response["channels"]).to eql(0)
+          expect(response["wildcard_channels"]).to eql(1)
+          expect(response["infos"][0]["channel"].to_s).to eql(channel)
+          expect(response["infos"][0]["published_messages"]).to eql(1)
+          expect(response["infos"][0]["stored_messages"]).to eql(1)
+          expect(response["infos"][0]["subscribers"]).to eql(0)
+          EventMachine.stop
+        end
+      end
+    end
+  end
+
+  it "should return detailed channels statistics for an existent channel using prefix id with subscriber" do
+    channel = 'ch_test_detailed_channels_statistics_to_existing_channel_with_subscriber_using_prefix'
+    body = 'body'
+
+    nginx_run_server(config) do |conf|
+      create_channel_by_subscribe(channel, headers) do
+        pub_1 = EventMachine::HttpRequest.new(nginx_address + '/channels-stats?id=ch_test_*').get :head => headers
+        pub_1.callback do
+          expect(pub_1).to be_http_status(200)
+          response = JSON.parse(pub_1.response)
+          expect(response["infos"].length).to eql(1)
+          expect(response["infos"][0]["channel"].to_s).to eql(channel)
+          expect(response["infos"][0]["published_messages"]).to eql(0)
+          expect(response["infos"][0]["stored_messages"]).to eql(0)
+          expect(response["infos"][0]["subscribers"]).to eql(1)
+          EventMachine.stop
+        end
+      end
+    end
+  end
+
+  it "should return detailed channels statistics for many channels using prefix id" do
+    channel = 'ch_test_get_detailed_channels_statistics_to_many_channels_using_prefix_'
+    body = 'body'
+    number_of_channels = 20000
+
+    nginx_run_server(config.merge(:shared_memory_size => '200m', :keepalive_requests => 1000), :timeout => 15) do |conf|
+      #create channels
+      0.step(number_of_channels - 1, 1000) do |i|
+        socket = open_socket(nginx_host, nginx_port)
+        1.upto(1000) do |j|
+          headers, body = post_in_socket("/pub?id=#{channel}#{i + j}", body, socket, {:wait_for => "}\r\n"})
+          expect(headers).to include("HTTP/1.1 200 OK")
+        end
+        socket.close
+      end
+
+      EventMachine.run do
+        pub_2 = EventMachine::HttpRequest.new(nginx_address + '/channels-stats?id=ch_test_get_detailed_channels_statistics_to_many_channels_using_prefix_10*').get :head => headers
+        pub_2.callback do
+          expect(pub_2).to be_http_status(200)
+          response = JSON.parse(pub_2.response)
+          expect(response["infos"].length).to eql(1111)
+          EventMachine.stop
+        end
+      end
+    end
+  end
+
+  it "should return uptime in detailed channels statistics" do
+    channel = 'ch_test_get_uptime_in_detailed_channels_statistics'
+    body = 'body'
+
+    nginx_run_server(config) do |conf|
+      #create channel
+      publish_message(channel, headers, body)
+
+      EventMachine.run do
+        pub_2 = EventMachine::HttpRequest.new(nginx_address + '/channels-stats?id=ALL').get :head => headers
+        pub_2.callback do
+          expect(pub_2).to be_http_status(200)
+          response = JSON.parse(pub_2.response)
+          expect(response["hostname"].to_s).not_to be_empty
+          expect(response["time"].to_s).not_to be_empty
+          expect(response["channels"].to_s).not_to be_empty
+          expect(response["wildcard_channels"].to_s).not_to be_empty
+          expect(response["uptime"].to_s).not_to be_empty
+          expect(response["infos"].to_s).not_to be_empty
+
+          sleep(2)
+          pub_3 = EventMachine::HttpRequest.new(nginx_address + '/channels-stats?id=ALL').get :head => headers
+          pub_3.callback do
+            expect(pub_3).to be_http_status(200)
+            response = JSON.parse(pub_3.response)
+            expect(response["uptime"]).to be_in_the_interval(2, 3)
+            EventMachine.stop
+          end
+        end
+      end
+    end
+  end
+
+  it "should return uptime in summarized channels statistics" do
+    channel = 'ch_test_get_uptime_in_summarized_channels_statistics'
+    body = 'body'
+
+    nginx_run_server(config) do |conf|
+      #create channel
+      publish_message(channel, headers, body)
+
+      EventMachine.run do
+        pub_2 = EventMachine::HttpRequest.new(nginx_address + '/channels-stats').get :head => headers
+        pub_2.callback do
+          expect(pub_2).to be_http_status(200)
+          response = JSON.parse(pub_2.response)
+          expect(response["hostname"].to_s).not_to be_empty
+          expect(response["time"].to_s).not_to be_empty
+          expect(response["channels"].to_s).not_to be_empty
+          expect(response["wildcard_channels"].to_s).not_to be_empty
+          expect(response["subscribers"].to_s).not_to be_empty
+          expect(response["uptime"].to_s).not_to be_empty
+          expect(response["by_worker"].to_s).not_to be_empty
+          expect(response["by_worker"][0]["pid"].to_s).not_to be_empty
+          expect(response["by_worker"][0]["subscribers"].to_s).not_to be_empty
+          expect(response["by_worker"][0]["uptime"].to_s).not_to be_empty
+
+          sleep(2)
+          pub_3 = EventMachine::HttpRequest.new(nginx_address + '/channels-stats').get :head => headers
+          pub_3.callback do
+            expect(pub_3).to be_http_status(200)
+            response = JSON.parse(pub_3.response)
+            expect(response["uptime"]).to be_in_the_interval(2, 3)
+            expect(response["by_worker"][0]["uptime"]).to be_in_the_interval(2, 3)
+            EventMachine.stop
+          end
+        end
+      end
+    end
+  end
+
+  it "should return the number of messages in the trash in summarized channels statistics" do
+    channel = 'ch_test_get_messages_in_trash_in_summarized_channels_statistics'
+    body = 'body'
+
+    nginx_run_server(config.merge(:message_ttl => '1s'), :timeout => 15) do |conf|
+      #create channel
+      publish_message(channel, headers, body)
+
+      EventMachine.run do
+        pub_2 = EventMachine::HttpRequest.new(nginx_address + '/channels-stats').get :head => headers
+        pub_2.callback do
+          expect(pub_2).to be_http_status(200)
+          response = JSON.parse(pub_2.response)
+          expect(response["stored_messages"]).to eql(1)
+          expect(response["messages_in_trash"]).to eql(0)
+
+          sleep(5)
+          pub_3 = EventMachine::HttpRequest.new(nginx_address + '/channels-stats').get :head => headers
+          pub_3.callback do
+            expect(pub_3).to be_http_status(200)
+            response = JSON.parse(pub_3.response)
+            expect(response["stored_messages"]).to eql(0)
+            expect(response["messages_in_trash"]).to eql(1)
+            EventMachine.stop
+          end
+        end
+      end
+    end
+  end
+
+  it "should return the number of channels in the trash in summarized channels statistics" do
+    channel = 'ch_test_get_channels_in_trash_in_summarized_channels_statistics'
+    body = 'body'
+
+    nginx_run_server(config.merge(:publisher_mode => 'admin', :wildcard_channel_prefix => 'bd_', :wildcard_channel_max_qtd => 1), :timeout => 55) do |conf|
+      #create channel
+      publish_message(channel, headers, body)
+      publish_message("#{channel}_1", headers, body)
+      publish_message("bd_#{channel}_1", headers, body)
+
+      EventMachine.run do
+        pub_2 = EventMachine::HttpRequest.new(nginx_address + '/channels-stats').get :head => headers
+        pub_2.callback do
+          expect(pub_2).to be_http_status(200)
+          response = JSON.parse(pub_2.response)
+          expect(response["channels"]).to eql(2)
+          expect(response["wildcard_channels"]).to eql(1)
+          expect(response["channels_in_trash"]).to eql(0)
+
+          pub = EventMachine::HttpRequest.new(nginx_address + '/pub?id=' + channel.to_s).delete :head => headers
+          pub.callback do
+            expect(pub).to be_http_status(200).without_body
+
+            sleep(5)
+
+            pub_3 = EventMachine::HttpRequest.new(nginx_address + '/channels-stats').get :head => headers
+            pub_3.callback do
+              expect(pub_3).to be_http_status(200)
+              response = JSON.parse(pub_3.response)
+              expect(response["channels"]).to eql(1)
+              expect(response["wildcard_channels"]).to eql(1)
+              expect(response["channels_in_trash"]).to eql(1)
+              EventMachine.stop
+            end
+          end
+        end
+      end
+    end
+  end
+
+  it "should not cache the response" do
+    channel = 'ch_test_not_cache_the_response'
+
+    nginx_run_server(config) do |conf|
+      EventMachine.run do
+        pub_1 = EventMachine::HttpRequest.new(nginx_address + '/channels-stats?id=' + channel.to_s).get :head => headers
+        pub_1.callback do
+          expect(pub_1.response_header["EXPIRES"]).to eql("Thu, 01 Jan 1970 00:00:01 GMT")
+          expect(pub_1.response_header["CACHE_CONTROL"]).to eql("no-cache, no-store, must-revalidate")
+          EventMachine.stop
+        end
+      end
+    end
+  end
+
+  context "when sending multiple channels ids" do
+    it "should return detailed channels statistics for existent channels" do
+      body = 'body'
+      actual_response = ''
+
+      nginx_run_server(config) do |conf|
+        #create channels
+        publish_message("ch1", headers, body)
+        publish_message("ch2", headers, body)
+        publish_message("ch3", headers, body)
+
+        EventMachine.run do
+          pub_2 = EventMachine::HttpRequest.new(nginx_address + '/channels-stats?id=ch3/ch1').get :head => headers, :decoding => false
+          pub_2.stream do |chunk|
+            actual_response << chunk
+          end
+          pub_2.callback do
+            expect(pub_2).to be_http_status(200)
+
+            if (conf.gzip == "on")
+              expect(pub_2.response_header["CONTENT_ENCODING"]).to eql("gzip")
+              actual_response = Zlib::GzipReader.new(StringIO.new(actual_response)).read
+            end
+
+            response = JSON.parse(actual_response)
+            expect(response["infos"].length).to eql(2)
+            expect(response["infos"][0]["channel"].to_s).to eql("ch3")
+            expect(response["infos"][0]["published_messages"]).to eql(1)
+            expect(response["infos"][0]["stored_messages"]).to eql(1)
+            expect(response["infos"][0]["subscribers"]).to eql(0)
+
+            expect(response["infos"][1]["channel"].to_s).to eql("ch1")
+            expect(response["infos"][1]["published_messages"]).to eql(1)
+            expect(response["infos"][1]["stored_messages"]).to eql(1)
+            expect(response["infos"][1]["subscribers"]).to eql(0)
+            EventMachine.stop
+          end
+        end
+      end
+    end
+
+    it "should return detailed channels statistics for unexistent channel" do
+      body = 'body'
+      actual_response = ''
+
+      nginx_run_server(config) do |conf|
+        #create channels
+        publish_message("ch1", headers, body)
+        publish_message("ch2", headers, body)
+        publish_message("ch3", headers, body)
+
+        EventMachine.run do
+          pub_2 = EventMachine::HttpRequest.new(nginx_address + '/channels-stats?id=ch3/ch4/ch2').get :head => headers, :decoding => false
+          pub_2.stream do |chunk|
+            actual_response << chunk
+          end
+          pub_2.callback do
+            expect(pub_2).to be_http_status(200)
+
+            if (conf.gzip == "on")
+              expect(pub_2.response_header["CONTENT_ENCODING"]).to eql("gzip")
+              actual_response = Zlib::GzipReader.new(StringIO.new(actual_response)).read
+            end
+
+            response = JSON.parse(actual_response)
+            expect(response["infos"].length).to eql(2)
+            expect(response["infos"][0]["channel"].to_s).to eql("ch3")
+            expect(response["infos"][0]["published_messages"]).to eql(1)
+            expect(response["infos"][0]["stored_messages"]).to eql(1)
+            expect(response["infos"][0]["subscribers"]).to eql(0)
+
+            expect(response["infos"][1]["channel"].to_s).to eql("ch2")
+            expect(response["infos"][1]["published_messages"]).to eql(1)
+            expect(response["infos"][1]["stored_messages"]).to eql(1)
+            expect(response["infos"][1]["subscribers"]).to eql(0)
+            EventMachine.stop
+          end
+        end
+      end
+    end
+  end
+end
+
+  context "when getting statistics" do
+    context "without gzip" do
+      let(:config) do
+       {:gzip => "off"}
+      end
+
+      let(:headers) do
+        {'accept' => 'application/json'}
+      end
+
+      it_should_behave_like "statistics location"
+    end
+
+    context "with gzip" do
+      let(:config) do
+       {:gzip => "on"}
+      end
+
+      let(:headers) do
+        {'accept' => 'application/json', 'accept-encoding' => 'gzip, compressed'}
+      end
+
+      it_should_behave_like "statistics location"
+    end
+  end
+end
diff -Naur nginx-1.11.3/nginx-push-stream-module/misc/spec/mix/cleanup_memory_spec.rb nginx-1.11.3-push/nginx-push-stream-module/misc/spec/mix/cleanup_memory_spec.rb
--- nginx-1.11.3/nginx-push-stream-module/misc/spec/mix/cleanup_memory_spec.rb	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/misc/spec/mix/cleanup_memory_spec.rb	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,614 @@
+require 'spec_helper'
+
+describe "Cleanup Memory" do
+  old_cld_trap = nil
+  before do
+    old_cld_trap = Signal.trap("CLD", "IGNORE")
+  end
+
+  after do
+    Signal.trap("CLD", old_cld_trap)
+  end
+
+  shared_examples_for "executing on normal conditions" do
+
+    it "should cleanup memory used for published message", :cleanup => true do
+      channel = 'ch_test_message_cleanup'
+      body = 'message to create a channel'
+      expected_time_for_clear = 25
+
+      nginx_run_server(config.merge(:max_messages_stored_per_channel => 100), :timeout => test_timeout) do |conf|
+        stored_messages_setp_1 = 0
+        published_messages_setp_1 = 0
+        published_messages_setp_2 = 0
+
+        EventMachine.run do
+          # ensure channel will not be cleaned up
+          sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers
+
+          publish_messages_until_fill_the_memory(channel, body) do |status, content|
+
+            start = Time.now
+            pub_2 = EventMachine::HttpRequest.new(nginx_address + '/channels-stats').get :head => headers
+            pub_2.callback do
+              expect(pub_2).to be_http_status(200).with_body
+              result = JSON.parse(pub_2.response)
+              stored_messages_setp_1 = result["stored_messages"].to_i
+              published_messages_setp_1 = result["published_messages"].to_i
+              messages_in_trash = result["messages_in_trash"].to_i
+
+              expect(stored_messages_setp_1).to eql(conf.max_messages_stored_per_channel)
+              expect(published_messages_setp_1).to be > (conf.max_messages_stored_per_channel)
+              expect(stored_messages_setp_1).not_to eql(0)
+              expect(published_messages_setp_1).to eql(stored_messages_setp_1 + messages_in_trash)
+
+              wait_until_trash_is_empty(start, expected_time_for_clear, {:check_stored_messages => true}) do
+                execute_changes_on_environment(conf) do
+                  # connect a subscriber on new worker
+                  sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers
+
+                  publish_messages_until_fill_the_memory(channel, body) do |status2, content2|
+                    start = Time.now
+                    pub_2 = EventMachine::HttpRequest.new(nginx_address + '/channels-stats').get :head => headers
+                    pub_2.callback do
+                      expect(pub_2).to be_http_status(200).with_body
+                      published_messages_setp_2 = JSON.parse(pub_2.response)["published_messages"].to_i
+                      fail("Don't publish more messages") if published_messages_setp_1 == published_messages_setp_2
+
+                      wait_until_trash_is_empty(start, expected_time_for_clear, {:check_stored_messages => true}) do
+                        publish_messages_until_fill_the_memory(channel, body) do |status3, content3|
+                          pub_4 = EventMachine::HttpRequest.new(nginx_address + '/channels-stats').get :head => headers
+                          pub_4.callback do
+                            expect(pub_4).to be_http_status(200).with_body
+                            result = JSON.parse(pub_4.response)
+                            expect(result["stored_messages"].to_i).to eql(stored_messages_setp_1)
+                            expect(result["published_messages"].to_i - published_messages_setp_2).to eql(published_messages_setp_1)
+
+                            EventMachine.stop
+                          end
+                        end
+                      end
+                    end
+                  end
+                end
+              end
+            end
+          end
+        end
+      end
+    end
+
+    it "should discard old messages", :cleanup => true do
+      channel = 'ch_test_discard_old_messages'
+      body = 'message to create a channel'
+      messages_to_publish = 10
+
+      count = 0
+      stored_messages_setp_1 = 0
+      nginx_run_server(config, :timeout => test_timeout) do |conf|
+        EventMachine.run do
+          fill_memory_timer = EventMachine::PeriodicTimer.new(messages_to_publish / 12.to_f) do # publish messages before cleanup timer be executed
+            if (count < messages_to_publish)
+              publish_message_inline(channel, headers, body)
+            elsif (count == messages_to_publish)
+              pub_1 = EventMachine::HttpRequest.new(nginx_address + '/channels-stats?id=' + channel.to_s).get :head => headers
+              pub_1.callback do
+                fill_memory_timer.cancel
+                expect(pub_1).to be_http_status(200).with_body
+                stored_messages_setp_1 = JSON.parse(pub_1.response)["stored_messages"].to_i
+                expect(stored_messages_setp_1).to eql(messages_to_publish)
+
+                execute_changes_on_environment(conf) do
+                  EM.add_timer(3) do # wait cleanup timer to be executed one time
+                    pub_2 = EventMachine::HttpRequest.new(nginx_address + '/channels-stats?id=' + channel.to_s).get :head => headers
+                    pub_2.callback do
+                      expect(pub_2).to be_http_status(200).with_body
+                      stored_messages_setp_2 = JSON.parse(pub_2.response)["stored_messages"].to_i
+                      expect(stored_messages_setp_2).to be <= stored_messages_setp_1
+                      expect(stored_messages_setp_2).to be > 0
+
+                      EventMachine.stop
+                    end
+                  end
+                end
+              end
+            end
+            count += 1
+          end
+        end
+      end
+    end
+
+    it "should cleanup message memory without max messages stored per channel", :cleanup => true do
+      channel = 'ch_test_message_cleanup_without_max_messages_stored_per_channel'
+      body = 'message to create a channel'
+      expected_time_for_clear = 25
+
+      nginx_run_server(config, :timeout => test_timeout) do |conf|
+        stored_messages_setp_1 = 0
+        published_messages_setp_1 = 0
+        published_messages_setp_2 = 0
+
+        EventMachine.run do
+          # ensure channel will not be cleaned up
+          sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers
+
+          publish_messages_until_fill_the_memory(channel, body) do |status, content|
+            start = Time.now
+            pub_2 = EventMachine::HttpRequest.new(nginx_address + '/channels-stats').get :head => headers
+            pub_2.callback do
+              expect(pub_2).to be_http_status(200).with_body
+              result = JSON.parse(pub_2.response)
+              stored_messages_setp_1 = result["stored_messages"].to_i
+              published_messages_setp_1 = result["published_messages"].to_i
+              fail("Limited the number of stored messages") if stored_messages_setp_1 <= 100
+              fail("Don't create any message") if stored_messages_setp_1 == 0
+
+              execute_changes_on_environment(conf) do
+                # connect a subscriber on new worker
+                sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers
+
+                wait_until_trash_is_empty(start, expected_time_for_clear, {:check_stored_messages => true}) do
+                  publish_messages_until_fill_the_memory(channel, body) do |status2, content2|
+                    start = Time.now
+                    pub_2 = EventMachine::HttpRequest.new(nginx_address + '/channels-stats?id=' + channel.to_s).get :head => headers
+                    pub_2.callback do
+                      expect(pub_2).to be_http_status(200).with_body
+                      published_messages_setp_2 = JSON.parse(pub_2.response)["published_messages"].to_i
+                      fail("Don't publish more messages") if published_messages_setp_1 == published_messages_setp_2
+
+                      wait_until_trash_is_empty(start, expected_time_for_clear, {:check_stored_messages => true}) do
+                        publish_messages_until_fill_the_memory(channel, body) do |status3, content3|
+                          pub_4 = EventMachine::HttpRequest.new(nginx_address + '/channels-stats?id=' + channel.to_s).get :head => headers
+                          pub_4.callback do
+                            expect(pub_4).to be_http_status(200).with_body
+                            result = JSON.parse(pub_4.response)
+                            expect(result["stored_messages"].to_i).to eql(stored_messages_setp_1)
+                            expect(result["published_messages"].to_i - published_messages_setp_2).to eql(published_messages_setp_1)
+                            EventMachine.stop
+                          end
+                        end
+                      end
+                    end
+                  end
+                end
+              end
+            end
+          end
+        end
+      end
+    end
+
+    it "should cleanup memory used for create channels", :cleanup => true do
+      channel = 'ch_test_channel_cleanup_%d'
+      body = 'message to create a channel'
+
+      nginx_run_server(config.merge(:message_ttl => '2s'), :timeout => test_timeout) do |conf|
+        channels_setp_1 = 0
+        channels_setp_2 = 0
+        published_messages_setp_1 = 0
+        expected_time_for_clear = 45
+
+        EventMachine.run do
+          publish_messages_until_fill_the_memory(channel, body) do |status, content|
+            start = Time.now
+            pub_2 = EventMachine::HttpRequest.new(nginx_address + '/channels-stats').get :head => headers
+            pub_2.callback do
+              expect(pub_2).to be_http_status(200).with_body
+              channels_setp_1 = JSON.parse(pub_2.response)["channels"].to_i
+              fail("Don't create any channel") if channels_setp_1 == 0
+
+              execute_changes_on_environment(conf) do
+                wait_until_trash_is_empty(start, expected_time_for_clear, {:check_stored_messages => true, :check_channels => true}) do
+                  publish_messages_until_fill_the_memory(channel, body) do |status2, content2|
+                    start = Time.now
+                    pub_2 = EventMachine::HttpRequest.new(nginx_address + '/channels-stats').get :head => headers
+                    pub_2.callback do
+                      expect(pub_2).to be_http_status(200).with_body
+                      fail("Don't create more channel") if published_messages_setp_1 == JSON.parse(pub_2.response)["published_messages"].to_i
+
+                      wait_until_trash_is_empty(start, expected_time_for_clear, {:check_stored_messages => true, :check_channels => true}) do
+                        publish_messages_until_fill_the_memory(channel, body) do |status3, content3|
+                          pub_4 = EventMachine::HttpRequest.new(nginx_address + '/channels-stats').get :head => headers
+                          pub_4.callback do
+                            expect(pub_4).to be_http_status(200).with_body
+                            channels_setp_2 = JSON.parse(pub_4.response)["channels"].to_i
+
+                            expect(channels_setp_2).to eql(channels_setp_1)
+                            EventMachine.stop
+                          end
+                        end
+                      end
+                    end
+                  end
+                end
+              end
+            end
+          end
+        end
+      end
+    end
+
+    it "should cleanup memory used for publish messages with store 'off' and with subscriber", :cleanup => true do
+      channel = 'ch_test_message_cleanup_with_store_off_with_subscriber'
+      body = 'message to create a channel'
+      expected_time_for_clear = 15
+
+      nginx_run_server(config.merge(:store_messages => 'off'), :timeout => test_timeout) do |conf|
+        published_messages_setp_1 = 0
+        published_messages_setp_2 = 0
+
+        EventMachine.run do
+          # ensure channel will not be cleaned up
+          sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers
+
+          publish_messages_until_fill_the_memory(channel, body) do |status, content|
+            start = Time.now
+            pub_2 = EventMachine::HttpRequest.new(nginx_address + '/channels-stats?id=' + channel.to_s).get :head => headers
+            pub_2.callback do
+              expect(pub_2).to be_http_status(200).with_body
+              result = JSON.parse(pub_2.response)
+              published_messages_setp_1 = result["published_messages"].to_i
+
+              execute_changes_on_environment(conf) do
+                # connect a subscriber on new worker
+                sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers
+
+                wait_until_trash_is_empty(start, expected_time_for_clear, {:check_stored_messages => true}) do
+
+                  publish_messages_until_fill_the_memory(channel, body) do |status2, content2|
+                    start = Time.now
+                    pub_2 = EventMachine::HttpRequest.new(nginx_address + '/channels-stats?id=' + channel.to_s).get :head => headers
+                    pub_2.callback do
+                      expect(pub_2).to be_http_status(200).with_body
+                      published_messages_setp_2 = JSON.parse(pub_2.response)["published_messages"].to_i
+                      expect(published_messages_setp_2).not_to eql(published_messages_setp_1)
+
+                      wait_until_trash_is_empty(start, expected_time_for_clear, {:check_stored_messages => true}) do
+
+                        publish_messages_until_fill_the_memory(channel, body) do |status3, content3|
+                          pub_4 = EventMachine::HttpRequest.new(nginx_address + '/channels-stats?id=' + channel.to_s).get :head => headers
+                          pub_4.callback do
+                            expect(pub_4).to be_http_status(200).with_body
+                            result = JSON.parse(pub_4.response)
+                            expect(result["published_messages"].to_i - published_messages_setp_2).to eql(published_messages_setp_1)
+                            EventMachine.stop
+                          end
+                        end
+                      end
+                    end
+                  end
+                end
+              end
+            end
+          end
+        end
+      end
+    end
+
+    it "should cleanup memory used for publish messages with store 'off' and without subscriber", :cleanup => true do
+      channel = 'ch_test_message_cleanup_with_store_off_without_subscriber %d'
+      body = 'message to create a channel'
+      expected_time_for_clear = 45
+
+      nginx_run_server(config.merge(:store_messages => 'off'), :timeout => test_timeout) do |conf|
+        published_messages_setp_1 = 0
+        published_messages_setp_2 = 0
+
+        EventMachine.run do
+          publish_messages_until_fill_the_memory(channel, body) do |status, content|
+
+            start = Time.now
+            pub_2 = EventMachine::HttpRequest.new(nginx_address + '/channels-stats').get :head => headers
+            pub_2.callback do
+              expect(pub_2).to be_http_status(200).with_body
+              result = JSON.parse(pub_2.response)
+              published_messages_setp_1 = result["published_messages"].to_i
+
+              execute_changes_on_environment(conf) do
+                wait_until_trash_is_empty(start, expected_time_for_clear, {:check_stored_messages => true, :check_channels => true}) do
+                  publish_messages_until_fill_the_memory(channel, body) do |status2, content2|
+                    start = Time.now
+                    pub_2 = EventMachine::HttpRequest.new(nginx_address + '/channels-stats').get :head => headers
+                    pub_2.callback do
+                      expect(pub_2).to be_http_status(200).with_body
+                      published_messages_setp_2 = JSON.parse(pub_2.response)["published_messages"].to_i
+                      fail("Don't create more channel") if published_messages_setp_1 == published_messages_setp_2
+
+                      wait_until_trash_is_empty(start, expected_time_for_clear, {:check_stored_messages => true, :check_channels => true}) do
+                        publish_messages_until_fill_the_memory(channel, body) do |status3, content3|
+                          pub_4 = EventMachine::HttpRequest.new(nginx_address + '/channels-stats').get :head => headers
+                          pub_4.callback do
+                            expect(pub_4).to be_http_status(200).with_body
+                            result = JSON.parse(pub_4.response)
+                            expect(result["published_messages"].to_i - published_messages_setp_2).to eql(published_messages_setp_1)
+                            EventMachine.stop
+                          end
+                        end
+                      end
+                    end
+                  end
+                end
+              end
+            end
+          end
+        end
+      end
+    end
+
+    it "should cleanup memory used after delete created channels", :cleanup => true do
+      channel = 'ch_test_channel_cleanup_after_delete'
+      body = 'message to create a channel'
+      expected_time_for_clear = 15
+
+      nginx_run_server(config.merge(:publisher_mode => 'admin'), :timeout => test_timeout) do |conf|
+        published_messages_setp_1 = 0
+
+        EventMachine.run do
+          i = 0
+          fill_memory_timer = EventMachine::PeriodicTimer.new(0.001) do
+            pub_1 = EventMachine::HttpRequest.new(nginx_address + '/pub?id=' + channel.to_s + i.to_s).post :body => body, :head => headers
+            pub_1.callback do
+              if pub_1.response_header.status == 500
+                fill_memory_timer.cancel
+                start = Time.now
+                i.times do |j|
+                  pub = EventMachine::HttpRequest.new(nginx_address + '/pub?id=' + channel.to_s + j.to_s).delete :head => headers
+                end
+                pub_2 = EventMachine::HttpRequest.new(nginx_address + '/channels-stats').get :head => headers
+                pub_2.callback do
+                  expect(pub_2).to be_http_status(200).with_body
+                  result = JSON.parse(pub_2.response)
+                  published_messages_setp_1 = result["published_messages"].to_i
+                  fail("Don't create any message") if published_messages_setp_1 == 0
+
+                  execute_changes_on_environment(conf) do
+                    wait_until_trash_is_empty(start, expected_time_for_clear, {:check_stored_messages => true, :check_channels => true}) do
+                      i = 0
+                      fill_memory_timer = EventMachine::PeriodicTimer.new(0.001) do
+                        pub_1 = EventMachine::HttpRequest.new(nginx_address + '/pub?id=' + channel.to_s + i.to_s).post :body => body, :head => headers
+                        pub_1.callback do
+                          if pub_1.response_header.status == 500
+                            fill_memory_timer.cancel
+                            pub_2 = EventMachine::HttpRequest.new(nginx_address + '/channels-stats').get :head => headers
+                            pub_2.callback do
+                              expect(pub_2).to be_http_status(200).with_body
+                              result = JSON.parse(pub_2.response)
+                              expect(result["published_messages"].to_i / 2).to eql(published_messages_setp_1)
+                              EventMachine.stop
+                            end
+                          end
+                        end
+                        i += 1
+                      end
+                    end
+                  end
+                end
+              end
+            end
+            i += 1
+          end
+        end
+      end
+    end
+
+    it "should cleanup memory used after delete created channels with same id", :cleanup => true do
+      channel = 'ch_test_channel_cleanup_after_delete_same_id'
+      body = 'message to create a channel'
+      expected_time_for_clear = 15
+
+      nginx_run_server(config.merge(:publisher_mode => 'admin'), :timeout => test_timeout) do |conf|
+        published_messages_setp_1 = 0
+
+        EventMachine.run do
+          create_and_delete_channel_in_loop(channel, body, headers) do
+            pub_2 = EventMachine::HttpRequest.new(nginx_address + '/channels-stats').get :head => headers
+            pub_2.callback do
+              expect(pub_2).to be_http_status(200).with_body
+              result = JSON.parse(pub_2.response)
+              published_messages_setp_1 = result["published_messages"].to_i
+              fail("Don't create any message") if published_messages_setp_1 == 0
+
+              execute_changes_on_environment(conf) do
+                wait_until_trash_is_empty(Time.now, expected_time_for_clear, {:check_stored_messages => true, :check_channels => true}) do
+                  create_and_delete_channel_in_loop(channel, body, headers) do
+                    pub_2 = EventMachine::HttpRequest.new(nginx_address + '/channels-stats').get :head => headers
+                    pub_2.callback do
+                      expect(pub_2).to be_http_status(200).with_body
+                      result = JSON.parse(pub_2.response)
+                      expect(result["published_messages"].to_i / 2).to eql(published_messages_setp_1)
+                      EventMachine.stop
+                    end
+                  end
+                end
+              end
+            end
+          end
+        end
+      end
+    end
+
+  end
+
+  def create_and_delete_channel(channel, body, headers, &block)
+    pub_1 = EventMachine::HttpRequest.new(nginx_address + '/pub?id=' + channel.to_s).post :body => body, :head => headers
+    pub_1.callback do
+      pub = EventMachine::HttpRequest.new(nginx_address + '/pub?id=' + channel.to_s).delete :head => headers
+      pub.callback do
+        if pub_1.response_header.status == 200
+          block.call((pub.response_header.status == 200) ? :success : :error)
+        else
+          block.call(:error)
+        end
+      end
+    end
+  end
+
+  def create_and_delete_channel_in_loop(channel, body, headers, &block)
+    create_and_delete_channel(channel, body, headers) do |status|
+      if status == :success
+        create_and_delete_channel_in_loop(channel, body, headers, &block)
+      else
+        block.call unless block.nil?
+      end
+    end
+  end
+
+  def wait_until_trash_is_empty(start_time, expected_time_for_clear, options={}, &block)
+    check_timer = EventMachine::PeriodicTimer.new(1) do
+      stats = EventMachine::HttpRequest.new("#{nginx_address}/channels-stats").get :head => headers
+      stats.callback do
+        expect(stats).to be_http_status(200).with_body
+        result = JSON.parse(stats.response)
+        if (result["messages_in_trash"].to_i == 0) && (result["channels_in_trash"].to_i == 0)
+          if (!options[:check_stored_messages] || (result["stored_messages"].to_i == 0)) && (!options[:check_channels] || (result["channels"].to_i == 0))
+            check_timer.cancel
+            stop = Time.now
+            expect(stop - start_time).to be_within(5).of(expected_time_for_clear)
+
+            block.call
+          end
+        end
+      end
+    end
+  end
+
+  let(:test_timeout) { 260 }
+
+  let(:config) do
+    {
+      :master_process => 'on',
+      :daemon => 'on',
+      :shared_memory_size => "129k",
+      :message_ttl => '10s',
+      :max_messages_stored_per_channel => nil,
+      :keepalive_requests => 200
+    }
+  end
+
+  let(:headers) do
+    {'accept' => 'text/html'}
+  end
+
+  context "when moving inactive channels to trash" do
+    it "should wait 30s by default" do
+      channel = 'ch_move_inactive_channels'
+      body = 'body'
+
+      nginx_run_server(config.merge(:store_messages => "off"), :timeout => 40) do |conf|
+        EventMachine.run do
+          pub_1 = EventMachine::HttpRequest.new(nginx_address + '/pub?id=' + channel.to_s).post :head => headers, :body => body
+          pub_1.callback do
+            expect(pub_1).to be_http_status(200).with_body
+
+            start = Time.now
+            timer = EventMachine::PeriodicTimer.new(1) do
+              stats = EventMachine::HttpRequest.new(nginx_address + '/channels-stats').get :head => headers
+              stats.callback do
+                expect(stats).to be_http_status(200).with_body
+                response = JSON.parse(stats.response)
+
+                if response["channels"].to_i != 1
+                  stop = Time.now
+                  expect(time_diff_sec(start, stop)).to be_within(5).of(30)
+                  expect(response["channels_in_trash"].to_i).to eql(1)
+                  expect(response["channels"].to_i).to eql(0)
+                  EventMachine.stop
+                end
+              end
+            end
+          end
+        end
+      end
+    end
+
+    it "should be possible change the default value" do
+      channel = 'ch_move_inactive_channels_with_custom_value'
+      body = 'body'
+
+      nginx_run_server(config.merge(:store_messages => "off", :channel_inactivity_time => "5s"), :timeout => 10) do |conf|
+        EventMachine.run do
+          pub_1 = EventMachine::HttpRequest.new(nginx_address + '/pub?id=' + channel.to_s).post :head => headers, :body => body
+          pub_1.callback do
+            expect(pub_1).to be_http_status(200).with_body
+
+            start = Time.now
+            timer = EventMachine::PeriodicTimer.new(1) do
+              stats = EventMachine::HttpRequest.new(nginx_address + '/channels-stats').get :head => headers
+              stats.callback do
+                expect(stats).to be_http_status(200).with_body
+                response = JSON.parse(stats.response)
+
+                if response["channels"].to_i != 1
+                  stop = Time.now
+                  expect(time_diff_sec(start, stop)).to be_within(3).of(5)
+                  expect(response["channels_in_trash"].to_i).to eql(1)
+                  expect(response["channels"].to_i).to eql(0)
+                  EventMachine.stop
+                end
+              end
+            end
+          end
+        end
+      end
+    end
+    #after the last published message
+  end
+
+  context "when nothing strange occur" do
+    def execute_changes_on_environment(conf, &block)
+      #nothing strange happens
+      block.call
+    end
+
+    it_should_behave_like "executing on normal conditions"
+  end
+
+  context "when a worker is killed" do
+    def execute_changes_on_environment(conf, &block)
+      pub = EventMachine::HttpRequest.new(nginx_address + '/channels-stats').get :timeout => 30
+      pub.callback do
+        expect(pub).to be_http_status(200).with_body
+        resp_1 = JSON.parse(pub.response)
+        expect(resp_1["by_worker"].count).to eql(conf.workers)
+        pids = resp_1["by_worker"].map{ |info| info['pid'].to_i }
+
+        # send kill signal
+        pids.each{ |pid| `kill -9 #{ pid } > /dev/null 2>&1` }
+
+        while pids.all?{ |pid| `ps -p #{ pid } > /dev/null 2>&1; echo $?`.to_i == 0 }
+          sleep(0.1)
+        end
+
+        block.call unless block.nil?
+      end
+
+    end
+
+    it_should_behave_like "executing on normal conditions"
+  end
+
+  context "when the server is reloaded" do
+    def execute_changes_on_environment(conf, &block)
+      pub = EventMachine::HttpRequest.new(nginx_address + '/channels-stats').get :timeout => 30
+      pub.callback do
+        expect(pub).to be_http_status(200).with_body
+        resp_1 = JSON.parse(pub.response)
+        expect(resp_1["by_worker"].count).to eql(conf.workers)
+        pids = resp_1["by_worker"].map{ |info| info['pid'].to_i }
+
+        # send reload signal
+        pids.each{ |pid| `#{ nginx_executable } -c #{ conf.configuration_filename } -s reload > /dev/null 2>&1` }
+
+        while pids.all?{ |pid| `ps -p #{ pid } > /dev/null 2>&1; echo $?`.to_i == 0 }
+          sleep(0.1)
+        end
+
+        block.call unless block.nil?
+      end
+
+    end
+
+    it_should_behave_like "executing on normal conditions"
+  end
+end
diff -Naur nginx-1.11.3/nginx-push-stream-module/misc/spec/mix/events_channel_spec.rb nginx-1.11.3-push/nginx-push-stream-module/misc/spec/mix/events_channel_spec.rb
--- nginx-1.11.3/nginx-push-stream-module/misc/spec/mix/events_channel_spec.rb	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/misc/spec/mix/events_channel_spec.rb	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,473 @@
+require 'spec_helper'
+
+describe "Events channel" do
+  let(:config) do
+   {
+     events_channel_id: "events",
+     allow_connections_to_events_channel: "on",
+     message_template: "text: ~text~\\nchannel: ~channel~",
+     header_template: nil,
+     footer_template: nil,
+     publisher_mode: "admin",
+     ping_message_interval: nil,
+     store_messages: "off"
+   }
+  end
+
+  it "should send an event when a channel is created" do
+    channel = 'ch_test_send_event_channel_created'
+    body = 'any content'
+
+    nginx_run_server(config) do |conf|
+      EventMachine.run do
+        sub_1 = EventMachine::HttpRequest.new("#{nginx_address}/sub/#{conf.events_channel_id}").get head: headers
+        sub_1.stream do |chunk|
+          expect(chunk).to eql(%(text: {"type": "channel_created", "channel": "#{channel}"}\nchannel: #{conf.events_channel_id}))
+          EventMachine.stop
+        end
+
+        EM.add_timer(0.5) do
+          pub_1 = EventMachine::HttpRequest.new("#{nginx_address}/pub?id=#{channel}").post head: headers, body: body
+          pub_1.callback do
+            expect(pub_1).to be_http_status(200).with_body
+          end
+        end
+      end
+    end
+  end
+
+  it "should send an event when a channel is deleted" do
+    channel = 'ch_test_send_event_channel_deleted'
+    body = 'any content'
+
+    nginx_run_server(config) do |conf|
+      EventMachine.run do
+        pub_1 = EventMachine::HttpRequest.new("#{nginx_address}/pub?id=#{channel}").post head: headers, body: body
+        pub_1.callback do
+          expect(pub_1).to be_http_status(200).with_body
+
+          sub_1 = EventMachine::HttpRequest.new("#{nginx_address}/sub/#{conf.events_channel_id}").get head: headers
+          sub_1.stream do |chunk|
+            expect(chunk).to eql(%(text: {"type": "channel_destroyed", "channel": "#{channel}"}\nchannel: #{conf.events_channel_id}))
+            EventMachine.stop
+          end
+
+          EM.add_timer(0.5) do
+            pub_2 = EventMachine::HttpRequest.new("#{nginx_address}/pub?id=#{channel}").delete head: headers
+            pub_2.callback do
+              expect(pub_2).to be_http_status(200).without_body
+            end
+          end
+        end
+      end
+    end
+  end
+
+  it "should send an event when a channel is collected by inactivity" do
+    channel = 'ch_test_send_event_channel_collected'
+    body = 'any content'
+
+    nginx_run_server(config, timeout: 40) do |conf|
+      EventMachine.run do
+        pub_1 = EventMachine::HttpRequest.new("#{nginx_address}/pub?id=#{channel}").post head: headers, body: body
+        pub_1.callback do
+          expect(pub_1).to be_http_status(200).with_body
+
+          sub_1 = EventMachine::HttpRequest.new("#{nginx_address}/sub/#{conf.events_channel_id}", inactivity_timeout: 40).get head: headers
+          sub_1.stream do |chunk|
+            expect(chunk).to eql(%(text: {"type": "channel_destroyed", "channel": "#{channel}"}\nchannel: #{conf.events_channel_id}))
+            EventMachine.stop
+          end
+        end
+      end
+    end
+  end
+
+  it "should send an event when a client subscribe to a channel" do
+    channel = 'ch_test_send_event_client_subscribed'
+    body = 'any content'
+
+    nginx_run_server(config) do |conf|
+      EventMachine.run do
+        pub_1 = EventMachine::HttpRequest.new("#{nginx_address}/pub?id=#{channel}").post head: headers, body: body
+        pub_1.callback do
+          expect(pub_1).to be_http_status(200).with_body
+
+          sub_1 = EventMachine::HttpRequest.new("#{nginx_address}/sub/#{conf.events_channel_id}").get head: headers
+          sub_1.stream do |chunk|
+            expect(chunk).to eql(%(text: {"type": "client_subscribed", "channel": "#{channel}"}\nchannel: #{conf.events_channel_id}))
+            EventMachine.stop
+          end
+
+          EM.add_timer(0.5) do
+            sub_2 = EventMachine::HttpRequest.new("#{nginx_address}/sub/#{channel}").get head: headers
+          end
+        end
+      end
+    end
+  end
+
+  it "should send an event when a websocket client subscribe to a channel" do
+    channel = 'ch_test_send_event_websocket_client_subscribed'
+    body = 'any content'
+
+    nginx_run_server(config.merge(subscriber_mode: "websocket")) do |conf|
+      EventMachine.run do
+        pub_1 = EventMachine::HttpRequest.new("#{nginx_address}/pub?id=#{channel}").post head: headers, body: body
+        pub_1.callback do
+          expect(pub_1).to be_http_status(200).with_body
+
+          sub_1 = WebSocket::EventMachine::Client.connect(uri: "ws://#{nginx_host}:#{nginx_port}/sub/#{conf.events_channel_id}")
+          sub_1.onmessage do |text, type|
+            expect(text).to eql(%(text: {"type": "client_subscribed", "channel": "#{channel}"}\nchannel: #{conf.events_channel_id}))
+            EventMachine.stop
+          end
+
+          EM.add_timer(0.5) do
+            ws = WebSocket::EventMachine::Client.connect(uri: "ws://#{nginx_host}:#{nginx_port}/sub/#{channel}")
+          end
+        end
+      end
+    end
+  end
+
+  it "should send an event when a long-polling client subscribe to a channel" do
+    channel = 'ch_test_send_event_client_subscribed'
+    body = 'any content'
+
+    nginx_run_server(config.merge(subscriber_mode: "long-polling")) do |conf|
+      EventMachine.run do
+        pub_1 = EventMachine::HttpRequest.new("#{nginx_address}/pub?id=#{channel}").post head: headers, body: body
+        pub_1.callback do
+          expect(pub_1).to be_http_status(200).with_body
+
+          response = ''
+          sub_1 = EventMachine::HttpRequest.new("#{nginx_address}/sub/#{conf.events_channel_id}").get head: headers
+          sub_1.stream { |chunk| response += chunk }
+          sub_1.callback do
+            expect(response).to eql(%(text: {"type": "client_subscribed", "channel": "#{channel}"}\nchannel: #{conf.events_channel_id}))
+            EventMachine.stop
+          end
+
+          EM.add_timer(0.5) do
+            sub_2 = EventMachine::HttpRequest.new("#{nginx_address}/sub/#{channel}").get head: headers
+          end
+        end
+      end
+    end
+  end
+
+  it "should send an event when a client unsubscribe to a channel by timeout" do
+    channel = 'ch_test_send_event_client_unsubscribed'
+    body = 'any content'
+
+    nginx_run_server(config.merge(subscriber_connection_ttl: "5s"), timeout: 15) do |conf|
+      EventMachine.run do
+        sub_1 = EventMachine::HttpRequest.new("#{nginx_address}/sub/#{channel}", inactivity_timeout: 10).get head: headers
+
+        EM.add_timer(2) do
+          sub_2 = EventMachine::HttpRequest.new("#{nginx_address}/sub/#{conf.events_channel_id}", inactivity_timeout: 10).get head: headers
+          sub_2.stream do |chunk|
+            expect(chunk).to eql(%(text: {"type": "client_unsubscribed", "channel": "#{channel}"}\nchannel: #{conf.events_channel_id}))
+            EventMachine.stop
+          end
+        end
+      end
+    end
+  end
+
+  it "should send an event when a client unsubscribe to a channel by delete" do
+    channel = 'ch_test_send_event_client_unsubscribed'
+    body = 'any content'
+
+    nginx_run_server(config.merge(subscriber_connection_ttl: "50s"), timeout: 15) do |conf|
+      EventMachine.run do
+        sub_1 = EventMachine::HttpRequest.new("#{nginx_address}/sub/#{channel}").get head: headers
+
+        EM.add_timer(0.5) do
+          sub_2 = EventMachine::HttpRequest.new("#{nginx_address}/sub/#{conf.events_channel_id}").get head: headers
+          sub_2.stream do |chunk|
+            expect(chunk).to eql(%(text: {"type": "client_unsubscribed", "channel": "#{channel}"}\nchannel: #{conf.events_channel_id}))
+            EventMachine.stop
+          end
+        end
+
+        EM.add_timer(1) do
+          pub_1 = EventMachine::HttpRequest.new("#{nginx_address}/pub?id=#{channel}").delete head: headers
+          pub_1.callback do
+            expect(pub_1).to be_http_status(200).without_body
+          end
+        end
+      end
+    end
+  end
+
+  it "should never collect the events channel by inactivity" do
+    channel = 'ch_test_not_collect_events_channel'
+    body = 'any content'
+
+    nginx_run_server(config.merge(store_messages: 'on', message_ttl: '5s'), timeout: 120) do |conf|
+      EventMachine.run do
+        pub_1 = EventMachine::HttpRequest.new("#{nginx_address}/pub?id=#{channel}").post head: headers, body: body
+        pub_1.callback do
+          expect(pub_1).to be_http_status(200).with_body
+
+          pub_2 = EventMachine::HttpRequest.new("#{nginx_address}/pub?id=#{channel}").get head: headers
+          pub_2.callback do
+            expect(pub_2).to be_http_status(200).with_body
+            response = JSON.parse(pub_2.response)
+            expect(response["channel"].to_s).to eql(channel)
+            expect(response["published_messages"].to_i).to eql(1)
+            expect(response["stored_messages"].to_i).to eql(1)
+            expect(response["subscribers"].to_i).to eql(0)
+
+            pub_3 = EventMachine::HttpRequest.new("#{nginx_address}/pub?id=#{conf.events_channel_id}").get head: headers
+            pub_3.callback do
+              expect(pub_3).to be_http_status(200).with_body
+              response = JSON.parse(pub_3.response)
+              expect(response["channel"].to_s).to eql(conf.events_channel_id)
+              expect(response["published_messages"].to_i).to eql(1)
+              expect(response["stored_messages"].to_i).to eql(1)
+              expect(response["subscribers"].to_i).to eql(0)
+            end
+          end
+        end
+
+        EM.add_timer(35) do
+          pub_4 = EventMachine::HttpRequest.new("#{nginx_address}/pub?id=#{channel}").get head: headers
+          pub_4.callback do
+            expect(pub_4).to be_http_status(404).without_body
+
+            pub_5 = EventMachine::HttpRequest.new("#{nginx_address}/pub?id=#{conf.events_channel_id}").get head: headers
+            pub_5.callback do
+              expect(pub_5).to be_http_status(200).with_body
+              response = JSON.parse(pub_5.response)
+              expect(response["channel"].to_s).to eql(conf.events_channel_id)
+              expect(response["published_messages"].to_i).to eql(2)
+              expect(response["stored_messages"].to_i).to eql(1)
+              expect(response["subscribers"].to_i).to eql(0)
+            end
+          end
+
+          EM.add_timer(35) do
+            pub_6 = EventMachine::HttpRequest.new("#{nginx_address}/pub?id=#{conf.events_channel_id}").get head: headers
+            pub_6.callback do
+              expect(pub_6).to be_http_status(200).with_body
+              response = JSON.parse(pub_6.response)
+              expect(response["channel"].to_s).to eql(conf.events_channel_id)
+              expect(response["published_messages"].to_i).to eql(2)
+              expect(response["stored_messages"].to_i).to eql(0)
+              expect(response["subscribers"].to_i).to eql(0)
+              EventMachine.stop
+            end
+          end
+        end
+      end
+    end
+  end
+
+  it "should use a exclusive mutex lock for events channel" do
+    channel = 'ch_test_exclusive_lock_events_channel'
+
+    nginx_run_server(config.merge(header_template: 'H', subscriber_connection_ttl: '25s'), timeout: 50) do |conf|
+      EventMachine.run do
+        subscriber_in_loop_with_limit(channel, headers, 1, 20) do
+          EM.add_timer(5) do
+            pub_2 = EventMachine::HttpRequest.new("#{nginx_address}/pub?id=#{conf.events_channel_id}").get head: headers
+            pub_2.callback do
+              expect(pub_2).to be_http_status(200).with_body
+              response = JSON.parse(pub_2.response)
+              expect(response["channel"].to_s).to eql(conf.events_channel_id)
+              expect(response["published_messages"].to_i).to eql(40)
+              expect(response["stored_messages"].to_i).to eql(20)
+              expect(response["subscribers"].to_i).to eql(0)
+            end
+
+            EM.add_timer(10) do
+              10.times do |i|
+                pub_1 = EventMachine::HttpRequest.new("#{nginx_address}/pub?id=#{channel}_#{i + 1}").delete head: headers
+                pub_1.callback do
+                  expect(pub_1).to be_http_status(200).without_body
+                end
+              end
+
+              EM.add_timer(5) do
+                pub_2 = EventMachine::HttpRequest.new("#{nginx_address}/pub?id=#{conf.events_channel_id}").get head: headers
+                pub_2.callback do
+                  expect(pub_2).to be_http_status(200).with_body
+                  response = JSON.parse(pub_2.response)
+                  expect(response["channel"].to_s).to eql(conf.events_channel_id)
+                  expect(response["published_messages"].to_i).to eql(60)
+                  expect(response["stored_messages"].to_i).to eql(20)
+                  expect(response["subscribers"].to_i).to eql(0)
+                end
+
+                EM.add_timer(25) do
+                  pub_3 = EventMachine::HttpRequest.new("#{nginx_address}/channels-stats?id=ALL").get head: headers
+                  pub_3.callback do
+                    expect(pub_3).to be_http_status(200)
+                    response = JSON.parse(pub_3.response)
+                    expect(response["infos"].length).to eql(1)
+                    expect(response["infos"][0]["channel"].to_s).to eql(conf.events_channel_id)
+                    expect(response["infos"][0]["published_messages"].to_i).to eql(80)
+                    expect(response["infos"][0]["stored_messages"].to_i).to eql(20)
+                    expect(response["infos"][0]["subscribers"].to_i).to eql(0)
+                    EventMachine.stop
+                  end
+                end
+              end
+            end
+          end
+        end
+      end
+    end
+  end
+
+  it "should not accept publish outside messages to events channel" do
+    body = 'any content'
+    extra_config = {
+      subscriber_mode: "websocket",
+      extra_location: %q(
+        location ~ /ws/(.*)? {
+            # activate websocket mode for this location
+            push_stream_subscriber websocket;
+
+            # positional channel path
+            push_stream_channels_path               $1;
+
+            # allow subscriber to publish
+            push_stream_websocket_allow_publish on;
+            # store messages
+            push_stream_store_messages on;
+        }
+      )
+    }
+
+    nginx_run_server(config.merge(extra_config)) do |conf|
+      EventMachine.run do
+        pub_1 = EventMachine::HttpRequest.new("#{nginx_address}/pub?id=#{conf.events_channel_id}").post head: headers, body: body
+        pub_1.callback do
+          expect(pub_1).to be_http_status(403).without_body
+
+          received_message = false
+          sub_1 = WebSocket::EventMachine::Client.connect(uri: "ws://#{nginx_host}:#{nginx_port}/ws/#{conf.events_channel_id}/other_valid_channel")
+          sub_1.onmessage do |text, type|
+            next if received_message
+            received_message = true
+            expect(text).to eql(%(text: {"type": "client_subscribed", "channel": "other_valid_channel"}\nchannel: #{conf.events_channel_id}))
+            sub_1.send body
+
+            pub_2 = EventMachine::HttpRequest.new("#{nginx_address}/pub?id=#{conf.events_channel_id}").get head: headers
+            pub_2.callback do
+              expect(pub_2).to be_http_status(200).with_body
+              response = JSON.parse(pub_2.response)
+              expect(response["channel"].to_s).to eql(conf.events_channel_id)
+              expect(response["published_messages"].to_i).to eql(2)
+              expect(response["stored_messages"].to_i).to eql(2)
+              expect(response["subscribers"].to_i).to eql(1)
+
+              pub_3 = EventMachine::HttpRequest.new("#{nginx_address}/pub?id=other_valid_channel").get head: headers
+              pub_3.callback do
+                expect(pub_3).to be_http_status(200).with_body
+                response = JSON.parse(pub_3.response)
+                expect(response["channel"].to_s).to eql("other_valid_channel")
+                expect(response["published_messages"].to_i).to eql(1)
+                expect(response["stored_messages"].to_i).to eql(1)
+                expect(response["subscribers"].to_i).to eql(1)
+                EventMachine.stop
+              end
+            end
+          end
+        end
+      end
+    end
+  end
+
+  it "should not accept delete events channel" do
+    nginx_run_server(config) do |conf|
+      EventMachine.run do
+        pub_1 = EventMachine::HttpRequest.new("#{nginx_address}/pub?id=#{conf.events_channel_id}").delete head: headers
+        pub_1.callback do
+          expect(pub_1).to be_http_status(403).without_body
+
+          pub_2 = EventMachine::HttpRequest.new("#{nginx_address}/pub?id=#{conf.events_channel_id}").get head: headers
+          pub_2.callback do
+            expect(pub_2).to be_http_status(200).with_body
+            response = JSON.parse(pub_2.response)
+            expect(response["channel"].to_s).to eql(conf.events_channel_id)
+            expect(response["published_messages"].to_i).to eql(0)
+            expect(response["stored_messages"].to_i).to eql(0)
+            expect(response["subscribers"].to_i).to eql(0)
+            EventMachine.stop
+          end
+        end
+      end
+    end
+  end
+
+  it "should not accept subscribe to events channel when access is not authorized" do
+    extra_config = {
+      allow_connections_to_events_channel: "off",
+      extra_location: %(
+        location ~ /sub_to_events_channel_only_here/(.*) {
+          push_stream_subscriber;
+          push_stream_channels_path $1;
+          push_stream_allow_connections_to_events_channel "on";
+        }
+
+        location ~ /ws/(.*) {
+          push_stream_subscriber websocket;
+          push_stream_channels_path $1;
+        }
+
+        location ~ /ws_to_events_channel_only_here/(.*) {
+          push_stream_subscriber websocket;
+          push_stream_channels_path $1;
+          push_stream_allow_connections_to_events_channel "on";
+        }
+      )
+    }
+
+    nginx_run_server(config.merge(extra_config)) do |conf|
+      EventMachine.run do
+        sub_1 = EventMachine::HttpRequest.new("#{nginx_address}/sub/#{conf.events_channel_id}/other_valid_channel").get head: headers
+        sub_1.callback do
+          expect(sub_1).to be_http_status(403).without_body
+
+          sub_2 = WebSocket::EventMachine::Client.connect(uri: "ws://#{nginx_host}:#{nginx_port}/ws/#{conf.events_channel_id}/other_valid_channel")
+          sub_2.onclose do |code, reason|
+            received_message = false
+            sub_3 = EventMachine::HttpRequest.new("#{nginx_address}/sub_to_events_channel_only_here/#{conf.events_channel_id}/other_valid_channel").get head: headers
+            sub_3.stream do |chunck|
+              next if received_message
+              received_message = true
+
+              expect(chunck).to eql(%(text: {"type": "client_subscribed", "channel": "other_valid_channel"}\nchannel: #{conf.events_channel_id}))
+
+              sub_4 = WebSocket::EventMachine::Client.connect(uri: "ws://#{nginx_host}:#{nginx_port}/ws_to_events_channel_only_here/#{conf.events_channel_id}/other_valid_channel")
+              sub_4.onmessage do |text, type|
+                expect(text).to eql(%(text: {"type": "client_subscribed", "channel": "other_valid_channel"}\nchannel: #{conf.events_channel_id}))
+                EventMachine.stop
+              end
+            end
+          end
+        end
+      end
+    end
+  end
+
+  def subscriber_in_loop_with_limit(channel, headers, index, limit, &block)
+    called = false
+    sub = EventMachine::HttpRequest.new("#{nginx_address}/sub/#{channel}_#{index}", inactivity_timeout: 60).get head: headers
+    sub.stream do |chunk|
+      if index == limit
+        block.call
+      else
+        unless called
+          called = true
+          subscriber_in_loop_with_limit(channel, headers, index + 1, limit, &block)
+         end
+      end
+    end
+  end
+end
diff -Naur nginx-1.11.3/nginx-push-stream-module/misc/spec/mix/keepalive_spec.rb nginx-1.11.3-push/nginx-push-stream-module/misc/spec/mix/keepalive_spec.rb
--- nginx-1.11.3/nginx-push-stream-module/misc/spec/mix/keepalive_spec.rb	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/misc/spec/mix/keepalive_spec.rb	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,132 @@
+require 'spec_helper'
+
+describe "Keepalive" do
+  let(:config) do
+    {
+      :shared_memory_size => '256m',
+      :keepalive_requests => 500,
+      :header_template => '',
+      :message_template => '~text~',
+      :footer_template => '',
+      :publisher_mode => 'admin'
+    }
+  end
+
+  it "should create many channels on the same socket" do
+    channel = 'ch_test_create_many_channels_'
+    body = 'channel started'
+    channels_to_be_created = 4000
+
+    nginx_run_server(config, :timeout => 25) do |conf|
+      http_single = Net::HTTP::Persistent.new "single_channel"
+      http_double = Net::HTTP::Persistent.new "double_channel"
+      uri = URI.parse nginx_address
+
+      0.step(channels_to_be_created - 1, 500) do |i|
+        1.upto(500) do |j|
+          post_single = Net::HTTP::Post.new "/pub?id=#{channel}#{i + j}"
+          post_single.body = body
+          response_single = http_single.request(uri, post_single)
+          expect(response_single.code).to eql("200")
+          expect(response_single.body).to eql(%({"channel": "#{channel}#{i + j}", "published_messages": 1, "stored_messages": 1, "subscribers": 0}\r\n))
+
+          post_double = Net::HTTP::Post.new "/pub?id=#{channel}#{i + j}/#{channel}#{i}_#{j}"
+          post_double.body = body
+          response_double = http_double.request(uri, post_double)
+          expect(response_double.code).to eql("200")
+          expect(response_double.body).to match_the_pattern(/"hostname": "[^"]*", "time": "\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}", "channels": #{(i + j) * 2}, "wildcard_channels": 0, "uptime": [0-9]*, "infos": \[\r\n/)
+          expect(response_double.body).to match_the_pattern(/"channel": "#{channel}#{i + j}", "published_messages": 2, "stored_messages": 2, "subscribers": 0},\r\n/)
+          expect(response_double.body).to match_the_pattern(/"channel": "#{channel}#{i}_#{j}", "published_messages": 1, "stored_messages": 1, "subscribers": 0}\r\n/)
+        end
+      end
+    end
+  end
+
+  it "should create many channels on the same socket without info on response" do
+    channel = 'ch_test_create_many_channels_'
+    body = 'channel started'
+    channels_to_be_created = 4000
+
+    nginx_run_server(config.merge({:channel_info_on_publish => "off"}), :timeout => 25) do |conf|
+      uri = URI.parse nginx_address
+      0.step(channels_to_be_created - 1, 500) do |i|
+        http = Net::HTTP::Persistent.new
+        1.upto(500) do |j|
+          post = Net::HTTP::Post.new "/pub?id=#{channel}#{i + j}"
+          post.body = body
+          response = http.request(uri, post)
+          expect(response.code).to eql("200")
+          expect(response.body).to eql("")
+        end
+      end
+    end
+  end
+
+  it "should execute different operations using the same socket" do
+    channel = 'ch_test_different_operation_with_keepalive'
+    content = 'message to be sent'
+
+    nginx_run_server(config) do |conf|
+      socket = open_socket(nginx_host, nginx_port)
+
+      headers, body = get_in_socket("/pub", socket)
+      expect(body).to eql("")
+      expect(headers).to include("No channel id provided.")
+
+      headers, body = post_in_socket("/pub?id=#{channel}", content, socket, {:wait_for => "}\r\n"})
+      expect(body).to eql("{\"channel\": \"#{channel}\", \"published_messages\": 1, \"stored_messages\": 1, \"subscribers\": 0}\r\n")
+
+      headers, body = get_in_socket("/channels-stats", socket)
+
+      expect(body).to match_the_pattern(/"channels": 1, "wildcard_channels": 0, "published_messages": 1, "stored_messages": 1, "messages_in_trash": 0, "channels_in_trash": 0, "subscribers": 0, "uptime": [0-9]*, "by_worker": \[\r\n/)
+      expect(body).to match_the_pattern(/\{"pid": "[0-9]*", "subscribers": 0, "uptime": [0-9]*\}/)
+
+      socket.print("DELETE /pub?id=#{channel}_1 HTTP/1.1\r\nHost: test\r\n\r\n")
+      headers, body = read_response_on_socket(socket)
+      expect(headers).to include("HTTP/1.1 404 Not Found")
+
+      headers, body = get_in_socket("/channels-stats?id=ALL", socket)
+
+      expect(body).to match_the_pattern(/"hostname": "[^"]*", "time": "\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}", "channels": 1, "wildcard_channels": 0, "uptime": [0-9]*, "infos": \[\r\n/)
+      expect(body).to match_the_pattern(/"channel": "#{channel}", "published_messages": 1, "stored_messages": 1, "subscribers": 0}\r\n/)
+
+      headers, body = get_in_socket("/pub?id=#{channel}", socket)
+      expect(body).to eql("{\"channel\": \"#{channel}\", \"published_messages\": 1, \"stored_messages\": 1, \"subscribers\": 0}\r\n")
+
+      headers, body = post_in_socket("/pub?id=#{channel}/broad_#{channel}", content, socket, {:wait_for => "}\r\n"})
+      expect(body).to match_the_pattern(/"hostname": "[^"]*", "time": "\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}", "channels": 1, "wildcard_channels": 1, "uptime": [0-9]*, "infos": \[\r\n/)
+      expect(body).to match_the_pattern(/"channel": "#{channel}", "published_messages": 2, "stored_messages": 2, "subscribers": 0},\r\n/)
+      expect(body).to match_the_pattern(/"channel": "broad_#{channel}", "published_messages": 1, "stored_messages": 1, "subscribers": 0}\r\n/)
+
+      headers, body = get_in_socket("/channels-stats?id=#{channel}", socket)
+      expect(body).to match_the_pattern(/{"channel": "#{channel}", "published_messages": 2, "stored_messages": 2, "subscribers": 0}\r\n/)
+
+      socket.print("DELETE /pub?id=#{channel} HTTP/1.1\r\nHost: test\r\n\r\n")
+      headers, body = read_response_on_socket(socket)
+      expect(headers).to include("X-Nginx-PushStream-Explain: Channel deleted.")
+
+      socket.close
+    end
+  end
+
+  it "should accept subscribe many times using the same socket" do
+    channel = 'ch_test_subscribe_with_keepalive'
+    body_prefix = 'message to be sent'
+    get_messages = "GET /sub/#{channel} HTTP/1.1\r\nHost: test\r\n\r\n"
+
+    nginx_run_server(config.merge(:store_messages => 'off', :subscriber_mode => 'long-polling'), :timeout => 5) do |conf|
+      socket = open_socket(nginx_host, nginx_port)
+      socket_pub = open_socket(nginx_host, nginx_port)
+
+      1.upto(500) do |j|
+        socket.print(get_messages)
+        post_in_socket("/pub?id=#{channel}", "#{body_prefix} #{j.to_s.rjust(3, '0')}", socket_pub, {:wait_for => "}\r\n"})
+        headers, body = read_response_on_socket(socket, "\r\n0\r\n\r\n")
+        expect(body).to eql("16\r\nmessage to be sent #{j.to_s.rjust(3, '0')}\r\n0\r\n\r\n")
+      end
+
+      socket.close
+      socket_pub.close
+    end
+  end
+end
diff -Naur nginx-1.11.3/nginx-push-stream-module/misc/spec/mix/measure_memory_spec.rb nginx-1.11.3-push/nginx-push-stream-module/misc/spec/mix/measure_memory_spec.rb
--- nginx-1.11.3/nginx-push-stream-module/misc/spec/mix/measure_memory_spec.rb	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/misc/spec/mix/measure_memory_spec.rb	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,163 @@
+require 'spec_helper'
+
+describe "Measure Memory" do
+  let(:config) do
+    {
+      :shared_memory_size => "2m",
+      :message_ttl => "60m",
+      :max_messages_stored_per_channel => nil,
+      :keepalive_requests => 15000,
+      :header_template => nil,
+      :message_template => nil,
+      :footer_template => nil,
+      :ping_message_interval => nil
+    }
+  end
+
+  message_estimate_size = 168
+  channel_estimate_size = 270
+  subscriber_estimate_size = 154
+  subscriber_estimate_system_size = 6528
+
+  it "should check message size" do
+    channel = 'ch_test_message_size'
+    body = '1'
+
+    nginx_run_server(config, :timeout => 30) do |conf|
+      shared_size = conf.shared_memory_size.to_i * 1024 * 1024
+
+      post_channel_message = "POST /pub?id=#{channel} HTTP/1.1\r\nHost: localhost\r\nContent-Length: #{body.size}\r\n\r\n#{body}"
+      socket = open_socket(nginx_host, nginx_port)
+
+      while (true) do
+        socket.print(post_channel_message)
+        resp_headers, resp_body = read_response_on_socket(socket, "}\r\n")
+        break unless resp_headers.match(/200 OK/)
+      end
+      socket.close
+
+      EventMachine.run do
+        pub_2 = EventMachine::HttpRequest.new(nginx_address + '/channels-stats').get
+        pub_2.callback do
+          expect(pub_2).to be_http_status(200).with_body
+
+          resp = JSON.parse(pub_2.response)
+          expected_message = shared_size / (message_estimate_size + body.size)
+          expect(resp["published_messages"].to_i).to be_within(80).of(expected_message)
+          EventMachine.stop
+        end
+      end
+    end
+  end
+
+  it "should check channel size" do
+    body = '1'
+
+    nginx_run_server(config, :timeout => 150) do |conf|
+      shared_size = conf.shared_memory_size.to_i * 1024 * 1024
+
+      socket = open_socket(nginx_host, nginx_port)
+
+      channel = 1000
+      while (true) do
+        post_channel_message = "POST /pub?id=#{channel} HTTP/1.1\r\nHost: localhost\r\nContent-Length: #{body.size}\r\n\r\n#{body}"
+        socket.print(post_channel_message)
+        resp_headers, resp_body = read_response_on_socket(socket, "}\r\n")
+        break unless resp_headers.match(/200 OK/)
+        channel += 1
+      end
+      socket.close
+
+      EventMachine.run do
+        pub_2 = EventMachine::HttpRequest.new(nginx_address + '/channels-stats').get
+        pub_2.callback do
+          expect(pub_2).to be_http_status(200).with_body
+
+          resp = JSON.parse(pub_2.response)
+          expected_channel = (shared_size - ((body.size + message_estimate_size) * resp["published_messages"].to_i)) / (channel_estimate_size + 4) # 4 channel id size
+          expect(resp["channels"].to_i).to be_within(10).of(expected_channel)
+          EventMachine.stop
+        end
+      end
+    end
+  end
+
+  it "should check subscriber size" do
+    nginx_run_server(config.merge({:shared_memory_size => "128k", :header_template => "H"})) do |conf|
+      shared_size = conf.shared_memory_size.to_i * 1024 #shm size is in kbytes for this test
+
+      EventMachine.run do
+        subscriber_in_loop(1000, headers) do
+          pub_2 = EventMachine::HttpRequest.new(nginx_address + '/channels-stats').get :head => headers
+          pub_2.callback do
+            expect(pub_2).to be_http_status(200).with_body
+
+            resp = JSON.parse(pub_2.response)
+            expected_subscriber = (shared_size - ((channel_estimate_size + 4) * resp["channels"].to_i)) / subscriber_estimate_size # 4 channel id size
+            expect(resp["subscribers"].to_i).to be_within(10).of(expected_subscriber)
+            EventMachine.stop
+          end
+        end
+      end
+    end
+  end
+
+  it "should check subscriber system size" do
+    channel = 'ch_test_subscriber_system_size'
+
+    nginx_run_server(config.merge({:header_template => "H", :master_process => 'off', :daemon => 'off'}), :timeout => 15) do |conf|
+      #warming up
+      EventMachine.run do
+        sub = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_i.to_s).get :head => headers
+        sub.stream do |chunk|
+          EventMachine.stop
+        end
+      end
+
+      per_subscriber = 0
+      EventMachine.run do
+        memory_1 = `ps -o rss= -p #{File.read conf.pid_file}`.split(' ')[0].to_i
+        subscriber_in_loop_with_limit(channel, headers, 1000, 1099) do
+          sleep(1)
+          memory_2 = `ps -o rss= -p #{File.read conf.pid_file}`.split(' ')[0].to_i
+
+          per_subscriber = ((memory_2 - memory_1).to_f / 100) * 1000
+
+          EventMachine.stop
+        end
+      end
+
+      expect(per_subscriber).to be_within(100).of(subscriber_estimate_system_size)
+    end
+  end
+end
+
+def subscriber_in_loop(channel, headers, &block)
+  called = false
+  sub = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_i.to_s).get :head => headers
+  sub.stream do |chunk|
+    next if called
+    called = true
+    subscriber_in_loop(channel.to_i + 1, headers, &block)
+  end
+  sub.callback do
+    block.call
+  end
+end
+
+def subscriber_in_loop_with_limit(channel, headers, start, limit, &block)
+  called = false
+  sub = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_i.to_s).get :head => headers
+  sub.stream do |chunk|
+    if start == limit
+      block.call
+    else
+      next if called
+      called = true
+      subscriber_in_loop_with_limit(channel, headers, start + 1, limit, &block)
+    end
+  end
+  sub.callback do
+    block.call
+  end
+end
diff -Naur nginx-1.11.3/nginx-push-stream-module/misc/spec/mix/send_signals_spec.rb nginx-1.11.3-push/nginx-push-stream-module/misc/spec/mix/send_signals_spec.rb
--- nginx-1.11.3/nginx-push-stream-module/misc/spec/mix/send_signals_spec.rb	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/misc/spec/mix/send_signals_spec.rb	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,262 @@
+require 'spec_helper'
+
+describe "Send Signals" do
+  old_cld_trap = nil
+  before do
+    old_cld_trap = Signal.trap("CLD", "IGNORE")
+  end
+
+  after do
+    Signal.trap("CLD", old_cld_trap)
+  end
+
+  let(:config) do
+    {
+      :master_process => 'on',
+      :daemon => 'on',
+      :workers => 1,
+      :header_template => 'HEADER',
+      :footer_template => 'FOOTER',
+      :message_ttl => '60s',
+      :subscriber_connection_ttl => '65s'
+    }
+  end
+
+  it "should disconnect subscribers when receives TERM signal" do
+    channel = 'ch_test_send_term_signal'
+    body = 'body'
+    response = ''
+
+    nginx_run_server(config, :timeout => 5) do |conf|
+      EventMachine.run do
+        sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers.merge('X-Nginx-PushStream-Mode' => 'long-polling')
+        sub_1.callback do
+          expect(sub_1).to be_http_status(304).without_body
+          expect(Time.parse(sub_1.response_header['LAST_MODIFIED'].to_s).utc.to_i).to be_in_the_interval(Time.now.utc.to_i-1, Time.now.utc.to_i)
+          expect(sub_1.response_header['ETAG'].to_s).to eql("0")
+        end
+
+        sub_2 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers
+        sub_2.stream do |chunk|
+          # send stop signal
+          `#{ nginx_executable } -c #{ conf.configuration_filename } -s stop > /dev/null 2>&1`
+          response += chunk
+        end
+        sub_2.callback do
+          expect(response).to include("FOOTER")
+          EventMachine.stop
+        end
+      end
+    end
+  end
+
+
+  it "should reload normaly when receives HUP signal" do
+    channel = 'ch_test_send_hup_signal'
+    body = 'body'
+    response = response2 = ''
+    pid = pid2 = 0
+    open_sockets_1 = 0
+    socket = nil
+
+    nginx_run_server(config, :timeout => 60) do |conf|
+      error_log_pre = File.readlines(conf.error_log)
+
+      EventMachine.run do
+        # create subscriber
+        sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers
+        sub_1.stream do |chunk|
+          response = response + chunk
+          if response.strip == conf.header_template
+            # check statistics
+            pub_1 = EventMachine::HttpRequest.new(nginx_address + '/channels-stats').get :head => headers
+            pub_1.callback do
+              expect(pub_1).to be_http_status(200).with_body
+              resp_1 = JSON.parse(pub_1.response)
+              expect(resp_1.has_key?("channels")).to be_truthy
+              expect(resp_1["channels"].to_i).to eql(1)
+              expect(resp_1["by_worker"].count).to eql(1)
+              pid = resp_1["by_worker"][0]['pid'].to_i
+
+              open_sockets_1 = `lsof -p #{Process.getpgid pid} | grep socket | wc -l`.strip
+
+              socket = open_socket(nginx_host, nginx_port)
+              socket.print "GET /sub/#{channel} HTTP/1.1\r\nHost: test\r\nX-Nginx-PushStream-Mode: long-polling\r\n\r\n"
+
+              # send reload signal
+              `#{ nginx_executable } -c #{ conf.configuration_filename } -s reload > /dev/null 2>&1`
+            end
+          end
+        end
+
+        # check if first worker die
+        timer = EM.add_periodic_timer(0.5) do
+
+          # check statistics again
+          pub_4 = EventMachine::HttpRequest.new(nginx_address + '/channels-stats').get :head => headers
+          pub_4.callback do
+            resp_3 = JSON.parse(pub_4.response)
+            expect(resp_3.has_key?("by_worker")).to be_truthy
+
+            old_process_running = Process.getpgid(pid) rescue false
+            if !old_process_running && (resp_3["by_worker"].count == 1) && (pid != resp_3["by_worker"][0]['pid'].to_i)
+              timer.cancel
+
+              # publish a message
+              pub_2 = EventMachine::HttpRequest.new(nginx_address + '/pub?id=' + channel.to_s).post :head => headers, :body => body
+              pub_2.callback do
+                # add new subscriber
+                sub_2 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s + '.b1').get :head => headers
+                sub_2.stream do |chunk|
+                  response2 = response2 + chunk
+                  if response2.strip == conf.header_template
+                    # check statistics again
+                    pub_3 = EventMachine::HttpRequest.new(nginx_address + '/channels-stats').get :head => headers
+                    pub_3.callback do
+
+                      resp_2 = JSON.parse(pub_3.response)
+                      expect(resp_2.has_key?("channels")).to be_truthy
+                      expect(resp_2["channels"].to_i).to eql(1)
+                      expect(resp_2["published_messages"].to_i).to eql(1)
+                      expect(resp_2["subscribers"].to_i).to eql(1)
+
+                      open_sockets_2 = `lsof -p #{Process.getpgid resp_3["by_worker"][0]['pid'].to_i} | grep socket | wc -l`.strip
+                      expect(open_sockets_2).to eql(open_sockets_1)
+
+                      EventMachine.stop
+
+                      # send stop signal
+                      `#{ nginx_executable } -c #{ conf.configuration_filename } -s stop > /dev/null 2>&1`
+
+                      error_log_pos = File.readlines(conf.error_log)
+                      expect((error_log_pos - error_log_pre).join).not_to include("open socket")
+                      socket.close unless socket.nil?
+                    end
+                  end
+                end
+              end
+            end
+          end
+        end
+      end
+    end
+  end
+
+  shared_examples_for "reload server" do
+    it "should reload fast" do
+      channel = 'ch_test_send_hup_signal'
+      pid = pid2 = 0
+
+      nginx_run_server(config.merge(custom_config), :timeout => 5) do |conf|
+        EventMachine.run do
+          # create subscriber
+          sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers
+          sub_1.stream do |chunk|
+          end
+
+          EM.add_timer(1) do
+            # check statistics
+            pub_1 = EventMachine::HttpRequest.new(nginx_address + '/channels-stats').get :head => headers
+            pub_1.callback do
+              expect(pub_1).to be_http_status(200).with_body
+              resp_1 = JSON.parse(pub_1.response)
+              expect(resp_1["subscribers"].to_i).to eql(1)
+              expect(resp_1["channels"].to_i).to eql(1)
+              expect(resp_1["by_worker"].count).to eql(1)
+              pid = resp_1["by_worker"][0]['pid'].to_i
+
+              # send reload signal
+              `#{ nginx_executable } -c #{ conf.configuration_filename } -s reload > /dev/null 2>&1`
+
+              # check if first worker die
+              EM.add_periodic_timer(1) do
+
+                # check statistics
+                pub_4 = EventMachine::HttpRequest.new(nginx_address + '/channels-stats').get :head => headers
+                pub_4.callback do
+                  resp_3 = JSON.parse(pub_4.response)
+                  expect(resp_3.has_key?("by_worker")).to be_truthy
+
+                  if resp_3["by_worker"].count == 1
+                    expect(resp_3["subscribers"].to_i).to eql(0)
+                    expect(resp_3["channels"].to_i).to eql(1)
+                    pid2 = resp_3["by_worker"][0]['pid'].to_i
+
+                    expect(pid).not_to eql(pid2)
+                    EventMachine.stop
+                  end
+                end
+              end
+            end
+          end
+        end
+      end
+    end
+  end
+
+  context "with a big ping message interval" do
+    let(:custom_config) do
+      {
+        :ping_message_interval => "10m",
+        :subscriber_connection_ttl => '10s'
+      }
+    end
+
+    it_should_behave_like "reload server"
+  end
+
+  context "with a big subscriber connection ttl" do
+    let(:custom_config) do
+      {
+        :ping_message_interval => "1s",
+        :subscriber_connection_ttl => '10m'
+      }
+    end
+
+    it_should_behave_like "reload server"
+  end
+
+  it "should ignore changes on shared memory size when doing a reload" do
+    channel = 'ch_test_reload_with_different_shared_memory_size'
+    body = 'body'
+    response = response2 = ''
+    pid = pid2 = 0
+
+    nginx_run_server(config, :timeout => 10) do |conf|
+      EventMachine.run do
+        publish_message(channel, {}, body)
+        # check statistics
+        pub_1 = EventMachine::HttpRequest.new(nginx_address + '/channels-stats').get :head => headers
+        pub_1.callback do
+          expect(pub_1).to be_http_status(200).with_body
+          resp_1 = JSON.parse(pub_1.response)
+          expect(resp_1.has_key?("channels")).to be_truthy
+          expect(resp_1["channels"].to_i).to eql(1)
+          expect(resp_1["published_messages"].to_i).to eql(1)
+
+          conf.configuration[:shared_memory_size] = '20m'
+          conf.create_configuration_file
+
+          # send reload signal
+          `#{ nginx_executable } -c #{ conf.configuration_filename } -s reload > /dev/null 2>&1`
+
+          sleep 5
+
+          pub_2 = EventMachine::HttpRequest.new(nginx_address + '/channels-stats').get :head => headers
+          pub_2.callback do
+            expect(pub_2).to be_http_status(200).with_body
+            resp_2 = JSON.parse(pub_2.response)
+            expect(resp_2.has_key?("channels")).to be_truthy
+            expect(resp_2["channels"].to_i).to eql(1)
+            expect(resp_2["published_messages"].to_i).to eql(1)
+
+            error_log = File.read(conf.error_log)
+            expect(error_log).to include("Cannot change memory area size without restart, ignoring change")
+
+            EventMachine.stop
+          end
+        end
+      end
+    end
+  end
+end
diff -Naur nginx-1.11.3/nginx-push-stream-module/misc/spec/mix/setup_parameters_spec.rb nginx-1.11.3-push/nginx-push-stream-module/misc/spec/mix/setup_parameters_spec.rb
--- nginx-1.11.3/nginx-push-stream-module/misc/spec/mix/setup_parameters_spec.rb	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/misc/spec/mix/setup_parameters_spec.rb	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,117 @@
+require 'spec_helper'
+
+describe "Setup Parameters" do
+  it "should not accept '0' as ping message interval" do
+    expect(nginx_test_configuration({:ping_message_interval => 0})).to include("push_stream_ping_message_interval cannot be zero")
+  end
+
+  it "should not accept a blank message template" do
+    expect(nginx_test_configuration({:message_template => ""})).to include("push_stream_message_template cannot be blank")
+  end
+
+  it "should not accept '0' as subscriber connection ttl" do
+    expect(nginx_test_configuration({:subscriber_connection_ttl => 0})).to include("push_stream_subscriber_connection_ttl cannot be zero")
+  end
+
+  it "should not accept '0' as long polling subscriber connection ttl" do
+    expect(nginx_test_configuration({:longpolling_connection_ttl => 0})).to include("push_stream_longpolling_connection_ttl cannot be zero")
+  end
+
+  it "should not accept '0' as max channel id length" do
+    expect(nginx_test_configuration({:max_channel_id_length => 0})).to include("push_stream_max_channel_id_length cannot be zero")
+  end
+
+  it "should not accept '0' as message ttl" do
+    expect(nginx_test_configuration({:message_ttl => 0})).to include("push_stream_message_ttl cannot be zero")
+  end
+
+  it "should not accept '0' as max subscribers per channel" do
+    expect(nginx_test_configuration({:max_subscribers_per_channel => 0})).to include("push_stream_max_subscribers_per_channel cannot be zero")
+  end
+
+  it "should not accept '0' as max messages stored per channel" do
+    expect(nginx_test_configuration({:max_messages_stored_per_channel => 0})).to include("push_stream_max_messages_stored_per_channel cannot be zero")
+  end
+
+  it "should not accept '0' as max number of channels" do
+    expect(nginx_test_configuration({:max_number_of_channels => 0})).to include("push_stream_max_number_of_channels cannot be zero")
+  end
+
+  it "should not accept '0' as max number of wildcard channels" do
+    expect(nginx_test_configuration({:max_number_of_wildcard_channels => 0})).to include("push_stream_max_number_of_wildcard_channels cannot be zero")
+  end
+
+  it "should not accept '0' as max wildcard channels" do
+    expect(nginx_test_configuration({:wildcard_channel_max_qtd => 0})).to include("push_stream_wildcard_channel_max_qtd cannot be zero")
+  end
+
+  it "should not set max wildcard channels without set boadcast channel prefix" do
+    expect(nginx_test_configuration({:wildcard_channel_max_qtd => 1, :wildcard_channel_prefix => ""})).to include("cannot set wildcard channel max qtd if push_stream_wildcard_channel_prefix is not set or blank")
+  end
+
+  it "should not accept '0' as max number of wildcard channels" do
+    config = {:max_number_of_wildcard_channels => 3, :wildcard_channel_max_qtd => 4, :wildcard_channel_prefix => "broad_"}
+    expect(nginx_test_configuration(config)).to include("max number of wildcard channels cannot be smaller than value in push_stream_wildcard_channel_max_qtd")
+  end
+
+  it "should accept a configuration without http block" do
+    config = {
+      :configuration_template => %q{
+        pid                     <%= pid_file %>;
+        error_log               <%= error_log %> debug;
+        # Development Mode
+        master_process  off;
+        daemon          off;
+        worker_processes        <%= nginx_workers %>;
+
+        events {
+            worker_connections  1024;
+            use                 <%= (RUBY_PLATFORM =~ /darwin/) ? 'kqueue' : 'epoll' %>;
+        }
+      }
+    }
+    expect(nginx_test_configuration(config)).to include("ngx_http_push_stream_module will not be used with this configuration.")
+  end
+
+  it "should not accept an invalid push mode" do
+    expect(nginx_test_configuration({:subscriber_mode => "unknown"})).to include("invalid push_stream_subscriber mode value: unknown, accepted values (streaming, polling, long-polling, eventsource, websocket)")
+  end
+
+  it "should accept the known push modes" do
+    expect(nginx_test_configuration({:subscriber_mode => ""})).not_to include("invalid push_stream_subscriber mode value")
+    expect(nginx_test_configuration({:subscriber_mode => "streaming"})).not_to include("invalid push_stream_subscriber mode value")
+    expect(nginx_test_configuration({:subscriber_mode => "polling"})).not_to include("invalid push_stream_subscriber mode value")
+    expect(nginx_test_configuration({:subscriber_mode => "long-polling"})).not_to include("invalid push_stream_subscriber mode value")
+    expect(nginx_test_configuration({:subscriber_mode => "eventsource"})).not_to include("invalid push_stream_subscriber mode value")
+    expect(nginx_test_configuration({:subscriber_mode => "websocket"})).not_to include("invalid push_stream_subscriber mode value")
+  end
+
+  it "should not accept an invalid publisher mode" do
+    expect(nginx_test_configuration({:publisher_mode => "unknown"})).to include("invalid push_stream_publisher mode value: unknown, accepted values (normal, admin)")
+  end
+
+  it "should accept the known publisher modes" do
+    expect(nginx_test_configuration({:publisher_mode => ""})).not_to include("invalid push_stream_publisher mode value")
+    expect(nginx_test_configuration({:publisher_mode => "normal"})).not_to include("invalid push_stream_publisher mode value")
+    expect(nginx_test_configuration({:publisher_mode => "admin"})).not_to include("invalid push_stream_publisher mode value")
+  end
+
+  it "should not accept an invalid pattern for padding by user agent" do
+    expect(nginx_test_configuration({:padding_by_user_agent => "user_agent,as,df"})).to include("padding pattern not match the value user_agent,as,df")
+    expect(nginx_test_configuration({:padding_by_user_agent => "user_agent;10;0"})).to include("padding pattern not match the value user_agent;10;0")
+    expect(nginx_test_configuration({:padding_by_user_agent => "user_agent,10,0:other_user_agent;20;0:another_user_agent,30,0"})).to include("error applying padding pattern to other_user_agent;20;0:another_user_agent,30,0")
+  end
+
+  it "should not accept an invalid shared memory size" do
+    expect(nginx_test_configuration({:shared_memory_size => nil})).to include("push_stream_shared_memory_size must be set.")
+  end
+
+  it "should not accept a small shared memory size" do
+    expect(nginx_test_configuration({:shared_memory_size => "100k"})).to include("The push_stream_shared_memory_size value must be at least")
+  end
+
+  it "should not accept an invalid channels path value" do
+    expect(nginx_test_configuration({:channels_path => nil})).to include("push stream module: push_stream_channels_path must be set.")
+    expect(nginx_test_configuration({:channels_path_for_pub => nil})).to include("push stream module: push_stream_channels_path must be set.")
+  end
+end
diff -Naur nginx-1.11.3/nginx-push-stream-module/misc/spec/mix/wildcard_properties_spec.rb nginx-1.11.3-push/nginx-push-stream-module/misc/spec/mix/wildcard_properties_spec.rb
--- nginx-1.11.3/nginx-push-stream-module/misc/spec/mix/wildcard_properties_spec.rb	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/misc/spec/mix/wildcard_properties_spec.rb	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,61 @@
+require 'spec_helper'
+
+describe "Wildcard Properties" do
+  let(:config) do
+    {
+      :authorized_channels_only => "on",
+      :header_template => 'connected',
+      :wildcard_channel_prefix => "XXX_"
+    }
+  end
+
+  it "should identify wildcard channels by prefix" do
+    channel = 'ch_test_wildcard_channel_prefix'
+    channel_broad = 'XXX_123'
+    channel_broad_fail = 'YYY_123'
+
+    body = 'wildcard channel prefix'
+
+    nginx_run_server(config) do |conf|
+      EventMachine.run do
+        pub = EventMachine::HttpRequest.new(nginx_address + '/pub?id=' + channel.to_s ).post :head => headers, :body => body
+        pub.callback do
+          sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s + '/' + channel_broad_fail).get :head => headers
+          sub_1.callback do |chunk|
+            expect(sub_1).to be_http_status(403).without_body
+
+            sub_2 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s + '/' + channel_broad).get :head => headers
+            sub_2.stream do |chunk2|
+              expect(chunk2).to eql(conf.header_template)
+              EventMachine.stop
+            end
+          end
+        end
+      end
+    end
+  end
+
+  it "should limit the number of wildcard channels in the same request" do
+    channel = 'ch_test_wildcard_channel_max_qtd'
+    channel_broad1 = 'XXX_123'
+    channel_broad2 = 'XXX_321'
+    channel_broad3 = 'XXX_213'
+    body = 'wildcard channel prefix'
+
+    nginx_run_server(config.merge(:wildcard_channel_max_qtd => 2)) do |conf|
+      EventMachine.run do
+        pub = EventMachine::HttpRequest.new(nginx_address + '/pub?id=' + channel.to_s ).post :head => headers, :body => body
+        pub.callback do
+          sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s + '/' + channel_broad1 + '/' + channel_broad2  + '/' + channel_broad3).get :head => headers
+          sub_1.callback do |chunk|
+            expect(sub_1).to be_http_status(403).without_body
+            sub_2 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s + '/' + channel_broad1 + '/' + channel_broad2).get :head => headers
+            sub_2.stream do
+              EventMachine.stop
+            end
+          end
+        end
+      end
+    end
+  end
+end
diff -Naur nginx-1.11.3/nginx-push-stream-module/misc/spec/nginx_configuration.rb nginx-1.11.3-push/nginx-push-stream-module/misc/spec/nginx_configuration.rb
--- nginx-1.11.3/nginx-push-stream-module/misc/spec/nginx_configuration.rb	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/misc/spec/nginx_configuration.rb	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,202 @@
+module NginxConfiguration
+  def self.default_configuration
+    {
+      :disable_start_stop_server => false,
+      :master_process => 'on',
+      :daemon => 'on',
+      :workers => 2,
+
+      :gzip => 'off',
+
+      :content_type => 'text/html',
+
+      :keepalive_requests => nil,
+      :ping_message_interval => '10s',
+      :header_template_file => nil,
+      :header_template => %{<html><head><meta http-equiv=\\"Content-Type\\" content=\\"text/html; charset=utf-8\\">\\r\\n<meta http-equiv=\\"Cache-Control\\" content=\\"no-store\\">\\r\\n<meta http-equiv=\\"Cache-Control\\" content=\\"no-cache\\">\\r\\n<meta http-equiv=\\"Expires\\" content=\\"Thu, 1 Jan 1970 00:00:00 GMT\\">\\r\\n<script type=\\"text/javascript\\">\\r\\nwindow.onError = null;\\r\\ndocument.domain = \\'<%= nginx_host %>\\';\\r\\nparent.PushStream.register(this);\\r\\n</script>\\r\\n</head>\\r\\n<body onload=\\"try { parent.PushStream.reset(this) } catch (e) {}\\">},
+      :message_template => "<script>p(~id~,'~channel~','~text~');</script>",
+      :footer_template => "</body></html>",
+
+      :store_messages => 'on',
+
+      :subscriber_connection_ttl => nil,
+      :longpolling_connection_ttl => nil,
+      :timeout_with_body => 'off',
+      :message_ttl => '50m',
+
+      :max_channel_id_length => 200,
+      :max_subscribers_per_channel => nil,
+      :max_messages_stored_per_channel => 20,
+      :max_number_of_channels => nil,
+      :max_number_of_wildcard_channels => nil,
+
+      :wildcard_channel_max_qtd => 3,
+      :wildcard_channel_prefix => 'broad_',
+
+      :subscriber_mode => nil,
+      :publisher_mode => nil,
+      :padding_by_user_agent => nil,
+
+      :shared_memory_size => '10m',
+
+      :channel_deleted_message_text => nil,
+      :ping_message_text => nil,
+      :last_received_message_time => nil,
+      :last_received_message_tag => nil,
+      :last_event_id => nil,
+      :user_agent => nil,
+
+      :authorized_channels_only => 'off',
+      :allowed_origins => nil,
+
+      :client_max_body_size => '32k',
+      :client_body_buffer_size => '32k',
+
+      :channel_info_on_publish => "on",
+      :channel_inactivity_time => nil,
+
+      :channel_id => '$arg_id',
+      :channels_path_for_pub => '$arg_id',
+      :channels_path => '$1',
+
+      :events_channel_id => nil,
+      :allow_connections_to_events_channel => nil,
+
+      :extra_location => '',
+      :extra_configuration => ''
+    }
+  end
+
+
+  def self.template_configuration
+  %(
+pid               <%= pid_file %>;
+error_log         <%= error_log %> info;
+
+# Development Mode
+master_process    <%= master_process %>;
+daemon            <%= daemon %>;
+worker_processes  <%= workers %>;
+worker_rlimit_core  2500M;
+working_directory <%= File.join(nginx_tests_tmp_dir, "cores", config_id) %>;
+debug_points abort;
+
+events {
+  worker_connections  256;
+  use                 <%= (RUBY_PLATFORM =~ /darwin/) ? 'kqueue' : 'epoll' %>;
+}
+
+http {
+  default_type    application/octet-stream;
+
+  access_log      <%= access_log %>;
+
+
+  gzip             <%= gzip %>;
+  gzip_buffers     16 4k;
+  gzip_proxied     any;
+  gzip_types       text/plain text/css application/x-javascript text/xml application/xml application/xml+rss text/javascript application/json;
+  gzip_comp_level  9;
+  gzip_http_version   1.0;
+
+  tcp_nopush                      on;
+  tcp_nodelay                     on;
+  keepalive_timeout               100;
+  <%= write_directive("keepalive_requests", keepalive_requests) %>
+  send_timeout                    10;
+  client_body_timeout             10;
+  client_header_timeout           10;
+  sendfile                        on;
+  client_header_buffer_size       1k;
+  large_client_header_buffers     2 4k;
+  client_max_body_size            1k;
+  client_body_buffer_size         1k;
+  ignore_invalid_headers          on;
+  client_body_in_single_buffer    on;
+  client_body_temp_path           <%= client_body_temp %>;
+
+  <%= write_directive("push_stream_ping_message_interval", ping_message_interval, "ping frequency") %>
+
+  <%= write_directive("push_stream_message_template", message_template, "message template") %>
+
+  <%= write_directive("push_stream_subscriber_connection_ttl", subscriber_connection_ttl, "timeout for subscriber connections") %>
+  <%= write_directive("push_stream_longpolling_connection_ttl", longpolling_connection_ttl, "timeout for long polling connections") %>
+  <%= write_directive("push_stream_timeout_with_body", timeout_with_body) %>
+  <%= write_directive("push_stream_header_template", header_template, "header to be sent when receiving new subscriber connection") %>
+  <%= write_directive("push_stream_header_template_file", header_template_file, "file with the header to be sent when receiving new subscriber connection") %>
+  <%= write_directive("push_stream_message_ttl", message_ttl, "message ttl") %>
+  <%= write_directive("push_stream_footer_template", footer_template, "footer to be sent when finishing subscriber connection") %>
+
+  <%= write_directive("push_stream_max_channel_id_length", max_channel_id_length) %>
+  <%= write_directive("push_stream_max_subscribers_per_channel", max_subscribers_per_channel, "max subscribers per channel") %>
+  <%= write_directive("push_stream_max_messages_stored_per_channel", max_messages_stored_per_channel, "max messages to store in memory") %>
+  <%= write_directive("push_stream_max_number_of_channels", max_number_of_channels) %>
+  <%= write_directive("push_stream_max_number_of_wildcard_channels", max_number_of_wildcard_channels) %>
+
+  <%= write_directive("push_stream_wildcard_channel_max_qtd", wildcard_channel_max_qtd) %>
+  <%= write_directive("push_stream_wildcard_channel_prefix", wildcard_channel_prefix) %>
+
+  <%= write_directive("push_stream_padding_by_user_agent", padding_by_user_agent) %>
+
+  <%= write_directive("push_stream_authorized_channels_only", authorized_channels_only, "subscriber may create channels on demand or only authorized (publisher) may do it?") %>
+
+  <%= write_directive("push_stream_shared_memory_size", shared_memory_size) %>
+
+  <%= write_directive("push_stream_user_agent", user_agent) %>
+
+  <%= write_directive("push_stream_allowed_origins", allowed_origins) %>
+
+  <%= write_directive("push_stream_last_received_message_time", last_received_message_time) %>
+  <%= write_directive("push_stream_last_received_message_tag", last_received_message_tag) %>
+  <%= write_directive("push_stream_last_event_id", last_event_id) %>
+
+  <%= write_directive("push_stream_channel_deleted_message_text", channel_deleted_message_text) %>
+
+  <%= write_directive("push_stream_ping_message_text", ping_message_text) %>
+  <%= write_directive("push_stream_channel_inactivity_time", channel_inactivity_time) %>
+
+  <%= write_directive("push_stream_events_channel_id", events_channel_id) %>
+  <%= write_directive("push_stream_allow_connections_to_events_channel", allow_connections_to_events_channel) %>
+
+  server {
+    listen        <%= nginx_port %>;
+    server_name   <%= nginx_host %>;
+
+    location /channels-stats {
+      # activate channels statistics mode for this location
+      push_stream_channels_statistics;
+
+      <%= write_directive("push_stream_channels_path", channels_path_for_pub) %>
+    }
+
+    location /pub {
+      # activate publisher mode for this location
+      push_stream_publisher <%= publisher_mode unless publisher_mode.nil? || publisher_mode == "normal" %>;
+
+      <%= write_directive("push_stream_channels_path", channels_path_for_pub) %>
+      <%= write_directive("push_stream_store_messages", store_messages, "store messages") %>
+      <%= write_directive("push_stream_channel_info_on_publish", channel_info_on_publish, "channel_info_on_publish") %>
+
+      # client_max_body_size MUST be equal to client_body_buffer_size or
+      # you will be sorry.
+      client_max_body_size                    <%= client_max_body_size %>;
+      client_body_buffer_size                 <%= client_body_buffer_size %>;
+    }
+
+    location ~ /sub/(.*)? {
+      # activate subscriber mode for this location
+      push_stream_subscriber <%= subscriber_mode unless subscriber_mode.nil? || subscriber_mode == "streaming" %>;
+
+      # positional channel path
+      <%= write_directive("push_stream_channels_path", channels_path) %>
+      <%= write_directive("default_type", content_type, "content-type") %>
+    }
+
+    <%= extra_location %>
+  }
+}
+
+<%= extra_configuration %>
+  )
+  end
+end
diff -Naur nginx-1.11.3/nginx-push-stream-module/misc/spec/publisher/channel_id_collision_spec.rb nginx-1.11.3-push/nginx-push-stream-module/misc/spec/publisher/channel_id_collision_spec.rb
--- nginx-1.11.3/nginx-push-stream-module/misc/spec/publisher/channel_id_collision_spec.rb	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/misc/spec/publisher/channel_id_collision_spec.rb	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,30 @@
+require 'spec_helper'
+
+describe "Publisher Channel id collision" do
+
+  it "should create and retrieve channels with ids that collide" do
+    channels = ["A", "plumless", "buckeroo", "B", "fc0591", "123rainerbommert", "C", "a1sellers", "advertees", "D"]
+
+    nginx_run_server do |conf|
+      channels.each do |channel|
+        EventMachine.run do
+          pub = EventMachine::HttpRequest.new(nginx_address + '/pub?id=' + channel).post :body => 'x'
+          pub.callback do
+            expect(pub).to be_http_status(200)
+            EventMachine.stop
+          end
+        end
+      end
+
+      channels.each do |channel|
+        EventMachine.run do
+          pub = EventMachine::HttpRequest.new(nginx_address + '/channels-stats?id=' + channel).get :timeout => 30
+          pub.callback do
+            expect(pub).to be_http_status(200)
+            EventMachine.stop
+          end
+        end
+      end
+    end
+  end
+end
diff -Naur nginx-1.11.3/nginx-push-stream-module/misc/spec/publisher/properties_spec.rb nginx-1.11.3-push/nginx-push-stream-module/misc/spec/publisher/properties_spec.rb
--- nginx-1.11.3/nginx-push-stream-module/misc/spec/publisher/properties_spec.rb	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/misc/spec/publisher/properties_spec.rb	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,1165 @@
+require 'spec_helper'
+
+describe "Publisher Properties" do
+
+  shared_examples_for "publisher location" do
+    it "should not accept access without a channel id" do
+      nginx_run_server(config) do |conf|
+        EventMachine.run do
+          pub = EventMachine::HttpRequest.new(nginx_address + '/pub?id=').get :head => headers
+          pub.callback do
+            expect(pub).to be_http_status(400).without_body
+            expect(pub.response_header['X_NGINX_PUSHSTREAM_EXPLAIN']).to eql("No channel id provided.")
+            EventMachine.stop
+          end
+        end
+      end
+    end
+
+    it "should not accept 'get' access to a nonexistent channel" do
+      channel_1 = 'ch_test_access_whith_channel_id_to_absent_channel_1'
+      channel_2 = 'ch_test_access_whith_channel_id_to_absent_channel_2'
+      body = 'body'
+
+      nginx_run_server(config) do |conf|
+        EventMachine.run do
+          pub_1 = EventMachine::HttpRequest.new(nginx_address + '/pub?id=' + channel_1.to_s).get :head => headers
+          pub_1.callback do
+            expect(pub_1).to be_http_status(404).without_body
+            EventMachine.stop
+          end
+        end
+
+        EventMachine.run do
+          pub_2 = EventMachine::HttpRequest.new(nginx_address + '/pub?id=' + channel_2.to_s ).post :head => headers, :body => body
+          pub_2.callback do
+            expect(pub_2).to be_http_status(200).with_body
+            response = JSON.parse(pub_2.response)
+            expect(response["channel"].to_s).to eql(channel_2)
+            EventMachine.stop
+          end
+        end
+      end
+    end
+
+    it "should accept 'get' access to an existent channel" do
+      channel = 'ch_test_access_whith_channel_id_to_existing_channel'
+      body = 'body'
+
+      nginx_run_server(config) do |conf|
+        #create channel
+        EventMachine.run do
+          pub_1 = EventMachine::HttpRequest.new(nginx_address + '/pub?id=' + channel.to_s).post :head => headers, :body => body
+          pub_1.callback do
+            expect(pub_1).to be_http_status(200).with_body
+            response = JSON.parse(pub_1.response)
+            expect(response["channel"].to_s).to eql(channel)
+            EventMachine.stop
+          end
+        end
+
+        EventMachine.run do
+          pub_2 = EventMachine::HttpRequest.new(nginx_address + '/pub?id=' + channel.to_s).get :head => headers
+          pub_2.callback do
+            expect(pub_2).to be_http_status(200).with_body
+            response = JSON.parse(pub_2.response)
+            expect(response["channel"].to_s).to eql(channel)
+            EventMachine.stop
+          end
+        end
+      end
+    end
+
+    it "should check accepted methods" do
+      nginx_run_server(config) do |conf|
+        # testing OPTIONS method, EventMachine::HttpRequest does not have support to it
+        socket = open_socket(nginx_host, nginx_port)
+        socket.print("OPTIONS /pub?id=ch_test_accepted_methods HTTP/1.0\r\n\r\n")
+        headers, body = read_response_on_socket(socket)
+        expect(headers).to match_the_pattern(/HTTP\/1\.1 200 OK/)
+        expect(headers).to match_the_pattern(/Content-Length: 0/)
+        socket.close
+
+        EventMachine.run do
+          multi = EventMachine::MultiRequest.new
+
+          multi.add(:a, EventMachine::HttpRequest.new(nginx_address + '/pub?id=ch_test_accepted_methods_1').get)
+          multi.add(:b, EventMachine::HttpRequest.new(nginx_address + '/pub?id=ch_test_accepted_methods_2').put(:body => 'body'))
+          multi.add(:c, EventMachine::HttpRequest.new(nginx_address + '/pub?id=ch_test_accepted_methods_3').post)
+          multi.add(:d, EventMachine::HttpRequest.new(nginx_address + '/pub?id=ch_test_accepted_methods_4').delete)
+          multi.add(:e, EventMachine::HttpRequest.new(nginx_address + '/pub?id=ch_test_accepted_methods_5').head)
+
+          multi.callback do
+            expect(multi.responses[:callback].length).to eql(5)
+
+            expect(multi.responses[:callback][:a]).not_to be_http_status(405)
+            expect(multi.responses[:callback][:a].req.method).to eql("GET")
+
+            expect(multi.responses[:callback][:b]).not_to be_http_status(405)
+            expect(multi.responses[:callback][:b].req.method).to eql("PUT")
+
+            expect(multi.responses[:callback][:c]).not_to be_http_status(405)
+            expect(multi.responses[:callback][:c].req.method).to eql("POST")
+
+            expect(multi.responses[:callback][:d].req.method).to eql("DELETE")
+            if conf.publisher_mode == 'admin'
+              expect(multi.responses[:callback][:d]).not_to be_http_status(405)
+            else
+              expect(multi.responses[:callback][:d]).to be_http_status(405)
+              expect(multi.responses[:callback][:d].response_header['ALLOW']).to eql(accepted_methods)
+            end
+
+            expect(multi.responses[:callback][:e]).to be_http_status(405)
+            expect(multi.responses[:callback][:e].req.method).to eql("HEAD")
+            expect(multi.responses[:callback][:e].response_header['ALLOW']).to eql(accepted_methods)
+
+            EventMachine.stop
+          end
+        end
+      end
+    end
+
+    it "should not accept create a channel with id 'ALL'" do
+      channel = 'ALL'
+      body = 'body'
+
+      nginx_run_server(config) do |conf|
+        EventMachine.run do
+          pub_1 = EventMachine::HttpRequest.new(nginx_address + '/pub?id=' + channel.to_s).post :head => headers, :body => body
+          pub_1.callback do
+            expect(pub_1).to be_http_status(403).without_body
+            expect(pub_1.response_header['X_NGINX_PUSHSTREAM_EXPLAIN']).to eql("Channel id not authorized for this method.")
+            EventMachine.stop
+          end
+        end
+      end
+    end
+
+    it "should not accept create a channel with id containing wildcard" do
+      channel_1 = 'abcd*efgh'
+      channel_2 = '*abcdefgh'
+      channel_3 = 'abcdefgh*'
+      body = 'body'
+
+      nginx_run_server(config) do |conf|
+        EventMachine.run do
+          multi = EventMachine::MultiRequest.new
+
+          multi.add(:a, EventMachine::HttpRequest.new(nginx_address + '/pub?id=' + channel_1).post(:head => headers, :body => body))
+          multi.add(:b, EventMachine::HttpRequest.new(nginx_address + '/pub?id=' + channel_2).post(:head => headers, :body => body))
+          multi.add(:c, EventMachine::HttpRequest.new(nginx_address + '/pub?id=' + channel_3).post(:head => headers, :body => body))
+          multi.callback do
+            expect(multi.responses[:callback].length).to eql(3)
+            multi.responses[:callback].each do |name, response|
+              expect(response).to be_http_status(403).without_body
+              expect(response.response_header['X_NGINX_PUSHSTREAM_EXPLAIN']).to eql("Channel id not authorized for this method.")
+            end
+
+            EventMachine.stop
+          end
+        end
+      end
+    end
+
+    it "should not accept a message larger than max body size" do
+      channel = 'ch_test_post_message_larger_than_max_body_size_should_be_rejected'
+      body = '^'
+      (1..40).each do |n|
+        body += '0123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789|'
+      end
+      body += '$'
+
+      nginx_run_server(config.merge(:client_max_body_size => '2k', :client_body_buffer_size => '1k')) do |conf|
+        EventMachine.run do
+          pub_1 = EventMachine::HttpRequest.new(nginx_address + '/pub?id=' + channel.to_s).post :head => headers, :body => body
+          pub_1.callback do
+            expect(pub_1).to be_http_status(413)
+            EventMachine.stop
+          end
+        end
+      end
+    end
+
+    it "should accept a message larger than max buffer size and smaller than max body size" do
+      channel = 'ch_test_post_message_larger_than_body_buffer_size_should_be_accepted'
+      body = '^'
+      (1..80).each do |n|
+        body += '0123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789|'
+      end
+      body += '$'
+
+      nginx_run_server(config.merge(:client_max_body_size => '10k', :client_body_buffer_size => '1k')) do |conf|
+        EventMachine.run do
+          pub_1 = EventMachine::HttpRequest.new(nginx_address + '/pub?id=' + channel.to_s).post :head => headers, :body => body
+          pub_1.callback do
+            expect(pub_1).to be_http_status(200).with_body
+            fail("Let a file on client body temp dir") unless Dir.entries(conf.client_body_temp).select {|f| f if File.file?(File.expand_path(f, conf.client_body_temp)) }.empty?
+            EventMachine.stop
+          end
+        end
+      end
+    end
+
+    it "should accept a message smaller than max body size" do
+      channel = 'ch_test_post_message_shorter_than_body_buffer_size_should_be_accepted'
+      body = '^'
+      (1..40).each do |n|
+        body += '0123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789|'
+      end
+      body += '$'
+
+      nginx_run_server(config.merge(:client_max_body_size => '10k', :client_body_buffer_size => '6k')) do |conf|
+        EventMachine.run do
+          pub_1 = EventMachine::HttpRequest.new(nginx_address + '/pub?id=' + channel.to_s).post :head => headers, :body => body
+          pub_1.callback do
+            expect(pub_1).to be_http_status(200).with_body
+            fail("Let a file on client body temp dir") unless Dir.entries(conf.client_body_temp).select {|f| f if File.file?(File.expand_path(f, conf.client_body_temp)) }.empty?
+            EventMachine.stop
+          end
+        end
+      end
+    end
+
+    it "should store messages" do
+      body = 'published message'
+      channel = 'ch_test_stored_messages'
+
+      nginx_run_server(config.merge(:store_messages => "on")) do |conf|
+        EventMachine.run do
+          pub_1 = EventMachine::HttpRequest.new(nginx_address + '/pub?id=' + channel.to_s ).post :head => headers, :body => body
+          pub_1.callback do
+            response = JSON.parse(pub_1.response)
+            expect(response["stored_messages"].to_i).to eql(1)
+
+            pub_2 = EventMachine::HttpRequest.new(nginx_address + '/pub?id=' + channel.to_s ).post :head => headers, :body => body
+            pub_2.callback do
+              response = JSON.parse(pub_2.response)
+              expect(response["stored_messages"].to_i).to eql(2)
+              EventMachine.stop
+            end
+          end
+        end
+      end
+    end
+
+    it "should not store messages when it is 'off'" do
+      body = 'published message'
+      channel = 'ch_test_not_stored_messages'
+
+      nginx_run_server(config.merge(:store_messages => "off")) do |conf|
+        EventMachine.run do
+          pub = EventMachine::HttpRequest.new(nginx_address + '/pub?id=' + channel.to_s ).post :head => headers, :body => body
+          pub.callback do
+            response = JSON.parse(pub.response)
+            expect(response["stored_messages"].to_i).to eql(0)
+            EventMachine.stop
+          end
+        end
+      end
+    end
+
+    it "should limit the number of stored messages" do
+      body_prefix = 'published message '
+      channel = 'ch_test_max_stored_messages'
+      messagens_to_publish = 10
+
+      nginx_run_server(config.merge(:store_messages => "on", :max_messages_stored_per_channel => 4)) do |conf|
+        EventMachine.run do
+          i = 0
+          stored_messages = 0
+          EM.add_periodic_timer(0.001) do
+            i += 1
+            if i <= messagens_to_publish
+              pub = EventMachine::HttpRequest.new(nginx_address + '/pub?id=' + channel.to_s ).post :head => headers, :body => body_prefix + i.to_s
+              pub.callback do
+                response = JSON.parse(pub.response)
+                stored_messages = response["stored_messages"].to_i
+              end
+            else
+              expect(stored_messages).to eql(conf.max_messages_stored_per_channel)
+              EventMachine.stop
+            end
+          end
+        end
+      end
+    end
+
+    it "should limit the size of channel id" do
+      body = 'published message'
+      channel = '123456'
+
+      nginx_run_server(config.merge(:max_channel_id_length => 5)) do |conf|
+        EventMachine.run do
+          pub = EventMachine::HttpRequest.new(nginx_address + '/pub?id=' + channel.to_s ).post :head => headers, :body => body
+          pub.callback do
+            expect(pub).to be_http_status(400).without_body
+            expect(pub.response_header['X_NGINX_PUSHSTREAM_EXPLAIN']).to eql("Channel id is too large.")
+            EventMachine.stop
+          end
+        end
+      end
+    end
+
+    it "should limit the number of channels" do
+      body = 'published message'
+      channel = 'ch_test_max_number_of_channels_'
+
+      nginx_run_server(config.merge(:max_number_of_channels => 1)) do |conf|
+        EventMachine.run do
+          pub = EventMachine::HttpRequest.new(nginx_address + '/pub?id=' + channel.to_s + 1.to_s).post :head => headers, :body => body
+          pub.callback do
+            expect(pub).to be_http_status(200).with_body
+            EventMachine.stop
+          end
+        end
+
+        EventMachine.run do
+          pub = EventMachine::HttpRequest.new(nginx_address + '/pub?id=' + channel.to_s + 2.to_s).post :head => headers, :body => body
+          pub.callback do
+            expect(pub).to be_http_status(403).without_body
+            expect(pub.response_header['X_NGINX_PUSHSTREAM_EXPLAIN']).to eql("Number of channels were exceeded.")
+            EventMachine.stop
+          end
+        end
+      end
+    end
+
+    it "should limit the number of wildcard channels" do
+      body = 'published message'
+      channel = 'bd_test_max_number_of_wildcard_channels_'
+
+      nginx_run_server(config.merge(:max_number_of_wildcard_channels => 1, :wildcard_channel_prefix => 'bd_', :wildcard_channel_max_qtd => 1)) do |conf|
+        EventMachine.run do
+          pub = EventMachine::HttpRequest.new(nginx_address + '/pub?id=' + channel.to_s + 1.to_s).post :head => headers, :body => body
+          pub.callback do
+            expect(pub).to be_http_status(200).with_body
+            EventMachine.stop
+          end
+        end
+
+        EventMachine.run do
+          pub = EventMachine::HttpRequest.new(nginx_address + '/pub?id=' + channel.to_s + 2.to_s).post :head => headers, :body => body
+          pub.callback do
+            expect(pub).to be_http_status(403).without_body
+            expect(pub.response_header['X_NGINX_PUSHSTREAM_EXPLAIN']).to eql("Number of channels were exceeded.")
+            EventMachine.stop
+          end
+        end
+      end
+    end
+
+    it "should not receive acess control allow headers by default" do
+      channel = 'test_access_control_allow_headers'
+
+      nginx_run_server(config) do |conf|
+        EventMachine.run do
+          pub = EventMachine::HttpRequest.new(nginx_address + '/pub?id=' + channel).get :head => headers
+          pub.callback do
+            expect(pub.response_header['ACCESS_CONTROL_ALLOW_ORIGIN']).to be_nil
+            expect(pub.response_header['ACCESS_CONTROL_ALLOW_METHODS']).to be_nil
+            expect(pub.response_header['ACCESS_CONTROL_ALLOW_HEADERS']).to be_nil
+
+            EventMachine.stop
+          end
+        end
+      end
+    end
+
+    context "when allow origin directive is set" do
+      it "should receive acess control allow headers" do
+        channel = 'test_access_control_allow_headers'
+
+        nginx_run_server(config.merge(:allowed_origins => "custom.domain.com")) do |conf|
+          EventMachine.run do
+            pub = EventMachine::HttpRequest.new(nginx_address + '/pub?id=' + channel).get :head => headers
+            pub.callback do
+              expect(pub.response_header['ACCESS_CONTROL_ALLOW_ORIGIN']).to eql("custom.domain.com")
+              expect(pub.response_header['ACCESS_CONTROL_ALLOW_METHODS']).to eql(accepted_methods)
+              expect(pub.response_header['ACCESS_CONTROL_ALLOW_HEADERS']).to eql("If-Modified-Since,If-None-Match,Etag,Event-Id,Event-Type,Last-Event-Id")
+
+              EventMachine.stop
+            end
+          end
+        end
+      end
+
+      it "should accept a complex value" do
+        channel = 'test_access_control_allow_origin_as_complex'
+
+        nginx_run_server(config.merge(:allowed_origins => "$arg_domain")) do |conf|
+          EventMachine.run do
+            pub = EventMachine::HttpRequest.new(nginx_address + '/pub?id=' + channel + '&domain=test.com').get :head => headers
+            pub.callback do
+              expect(pub.response_header['ACCESS_CONTROL_ALLOW_ORIGIN']).to eql("test.com")
+              expect(pub.response_header['ACCESS_CONTROL_ALLOW_METHODS']).to eql(accepted_methods)
+              expect(pub.response_header['ACCESS_CONTROL_ALLOW_HEADERS']).to eql("If-Modified-Since,If-None-Match,Etag,Event-Id,Event-Type,Last-Event-Id")
+
+              EventMachine.stop
+            end
+          end
+        end
+      end
+    end
+
+    it "should not receive channel info after publish a message when disabled" do
+      body = 'published message'
+      channel = 'ch_test_skip_channel_info'
+
+      nginx_run_server(config.merge(:channel_info_on_publish => "off")) do |conf|
+        EventMachine.run do
+          pub_1 = EventMachine::HttpRequest.new(nginx_address + '/pub?id=' + channel.to_s ).post :head => headers, :body => body
+          pub_1.callback do
+            expect(pub_1).to be_http_status(200).without_body
+
+            EventMachine.stop
+          end
+        end
+      end
+    end
+
+    it "should accept channel id inside an if block" do
+      merged_config = config.merge({
+        :header_template => nil,
+        :footer_template => nil,
+        :subscriber_connection_ttl => '1s',
+        :extra_location => %{
+          location /pub2 {
+            push_stream_publisher #{config[:publisher_mode]};
+
+            push_stream_channels_path            $arg_id;
+            if ($arg_test) {
+              push_stream_channels_path          test_$arg_id;
+            }
+          }
+        }
+      })
+
+      channel = 'channel_id_inside_if_block'
+      body = 'published message'
+      resp_1 = ""
+      resp_2 = ""
+
+      nginx_run_server(merged_config) do |conf|
+        EventMachine.run do
+          sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers
+          sub_1.stream do |chunk|
+            resp_1 += chunk
+          end
+
+          sub_2 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + 'test_' + channel.to_s).get :head => headers
+          sub_2.stream do |chunk|
+            resp_2 += chunk
+          end
+
+          EM.add_timer(2) do
+            expect(resp_1).to eql("<script>p(1,'channel_id_inside_if_block','published message');</script>")
+            expect(resp_2).to eql("<script>p(1,'test_channel_id_inside_if_block','published message');</script>")
+            EventMachine.stop
+          end
+
+          EM.add_timer(0.5) do
+            post_to('/pub2?id=' + channel.to_s, headers, body)
+            post_to('/pub2?id=' + channel.to_s + '&test=1', headers, body)
+          end
+        end
+      end
+    end
+
+    it "should accept store messages inside an if block" do
+      merged_config = config.merge({
+        :header_template => nil,
+        :footer_template => nil,
+        :subscriber_connection_ttl => '1s',
+        :extra_location => %{
+          location /pub2 {
+            push_stream_publisher #{config[:publisher_mode]};
+            push_stream_channels_path            $arg_id;
+
+            push_stream_store_messages               off;
+            if ($arg_test) {
+              push_stream_store_messages             on;
+            }
+          }
+        }
+      })
+
+      channel = 'store_messages_inside_if_block'
+      body = 'published message'
+      resp_1 = ""
+      resp_2 = ""
+
+      nginx_run_server(merged_config) do |conf|
+        EventMachine.run do
+          pub_1 = EventMachine::HttpRequest.new(nginx_address + '/pub2?id=' + channel.to_s).post :head => headers, :body => body
+          pub_1.callback do
+            expect(pub_1).to be_http_status(200)
+            response = JSON.parse(pub_1.response)
+            expect(response["published_messages"].to_i).to eql(1)
+            expect(response["stored_messages"].to_i).to eql(0)
+
+            pub_2 = EventMachine::HttpRequest.new(nginx_address + '/pub2?id=' + channel.to_s + '&test=1').post :head => headers, :body => body
+            pub_2.callback do
+              expect(pub_2).to be_http_status(200)
+              response = JSON.parse(pub_2.response)
+              expect(response["published_messages"].to_i).to eql(2)
+              expect(response["stored_messages"].to_i).to eql(1)
+
+              EventMachine.stop
+            end
+          end
+        end
+      end
+    end
+
+    it "should not cache the response" do
+      channel = 'ch_test_not_cache_the_response'
+
+      nginx_run_server(config) do |conf|
+        EventMachine.run do
+          pub_1 = EventMachine::HttpRequest.new(nginx_address + '/pub?id=' + channel.to_s).get :head => headers
+          pub_1.callback do
+            expect(pub_1.response_header["EXPIRES"]).to eql("Thu, 01 Jan 1970 00:00:01 GMT")
+            expect(pub_1.response_header["CACHE_CONTROL"]).to eql("no-cache, no-store, must-revalidate")
+            EventMachine.stop
+          end
+        end
+      end
+    end
+
+    it "should accept respond get requests with gzip" do
+      channel = 'test_receive_get_response_with_gzip'
+      body = 'body'
+
+      actual_response = ''
+      nginx_run_server(config.merge(:gzip => "on"), :timeout => 5) do |conf|
+        EventMachine.run do
+          #create channel
+          publish_message(channel, {}, body)
+
+          pub = EventMachine::HttpRequest.new(nginx_address + '/pub?id=' + channel).get :head => headers.merge({'accept' => 'application/json', 'accept-encoding' => 'gzip, compressed'}), :decoding => false
+          pub.stream do |chunk|
+            actual_response << chunk
+          end
+          pub.callback do
+            expect(pub.response_header.status).to eql(200)
+            expect(pub.response_header.content_length).not_to eql(0)
+            expect(pub.response_header["CONTENT_ENCODING"]).to eql("gzip")
+
+            actual_response = Zlib::GzipReader.new(StringIO.new(actual_response)).read
+            response = JSON.parse(actual_response)
+            expect(response["channel"].to_s).to eql(channel)
+            EventMachine.stop
+          end
+        end
+      end
+    end
+
+    it "should accept respond post requests with gzip" do
+      channel = 'test_receive_post_response_with_gzip'
+      body = 'body'
+
+      actual_response = ''
+      nginx_run_server(config.merge(:gzip => "on"), :timeout => 5) do |conf|
+        EventMachine.run do
+          pub = EventMachine::HttpRequest.new(nginx_address + '/pub?id=' + channel).post :body => body, :head => headers.merge({'accept' => 'application/json', 'accept-encoding' => 'gzip, compressed'}), :decoding => false
+          pub.stream do |chunk|
+            actual_response << chunk
+          end
+          pub.callback do
+            expect(pub.response_header.status).to eql(200)
+            expect(pub.response_header.content_length).not_to eql(0)
+            expect(pub.response_header["CONTENT_ENCODING"]).to eql("gzip")
+
+            actual_response = Zlib::GzipReader.new(StringIO.new(actual_response)).read
+            response = JSON.parse(actual_response)
+            expect(response["channel"].to_s).to eql(channel)
+            EventMachine.stop
+          end
+        end
+      end
+    end
+
+    it "should published message on different channels on same post" do
+      body = 'body'
+      channel = 'ch_test_publish_message_on_different_channels_on_same_post'
+      messages = 0
+
+      nginx_run_server(config.merge({:message_template => "~text~|~channel~", :header_template => nil})) do |conf|
+        EventMachine.run do
+          sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s + "_1").get :head => headers
+          sub_1.stream do |chunk|
+            expect(chunk).to eql("#{body}|#{channel.to_s + "_1"}")
+            messages += 1
+          end
+
+          sub_2 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s + "_2").get :head => headers
+          sub_2.stream do |chunk|
+            expect(chunk).to eql("#{body}|#{channel.to_s + "_2"}")
+            messages += 1
+          end
+
+          sub_3 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s + "_3").get :head => headers
+          sub_3.stream do |chunk|
+            expect(chunk).to eql("#{body}|#{channel.to_s + "_3"}")
+            messages += 1
+          end
+
+          EM.add_periodic_timer(0.5) { EventMachine.stop if messages >= 3 }
+
+          EM.add_timer(0.5) do
+            post_to('/pub?id=' + channel.to_s + '_1/' + channel.to_s + '_2/' + channel.to_s + '_3', headers, body)
+          end
+        end
+      end
+    end
+  end
+
+  context "when is on normal mode" do
+    let(:config) do
+      {}
+    end
+
+    let(:headers) do
+      {'accept' => 'text/html'}
+    end
+
+    let(:accepted_methods) do
+      "GET, POST, PUT"
+    end
+
+    it_should_behave_like "publisher location"
+  end
+
+  context "when is on admin mode" do
+    let(:config) do
+      {:publisher_mode => 'admin'}
+    end
+
+    let(:headers) do
+      {'accept' => 'text/html'}
+    end
+
+    let(:accepted_methods) { "GET, POST, PUT, DELETE" }
+
+    it_should_behave_like "publisher location"
+
+    it "should return error when channel does not exists" do
+      channel = 'test_delete_channel_non_existent'
+
+      nginx_run_server(config) do |conf|
+        EventMachine.run do
+          pub = EventMachine::HttpRequest.new(nginx_address + '/pub?id=' + channel.to_s).get :head => headers
+          pub.callback do
+            expect(pub).to be_http_status(404).without_body
+
+            pub_1 = EventMachine::HttpRequest.new(nginx_address + '/pub?id=' + channel.to_s).delete :head => headers
+            pub_1.callback do
+              expect(pub_1).to be_http_status(404).without_body
+              expect(pub_1.response_header['X_NGINX_PUSHSTREAM_EXPLAIN']).to be_nil
+              EventMachine.stop
+            end
+          end
+        end
+      end
+    end
+
+    it "should return error when channel id is not specified" do
+      channel = 'test_delete_channel_whithout_send_id'
+
+      nginx_run_server(config) do |conf|
+        EventMachine.run do
+          pub = EventMachine::HttpRequest.new(nginx_address + '/pub?id=').delete :head => headers
+          pub.callback do
+            expect(pub).to be_http_status(400).without_body
+            expect(pub.response_header['X_NGINX_PUSHSTREAM_EXPLAIN']).to eql("No channel id provided.")
+            EventMachine.stop
+          end
+        end
+      end
+    end
+
+    it "should return error when channel id is bigger than allowed" do
+      channel = 'test_delete_channel_whith_big_id'
+
+      nginx_run_server(config.merge(:max_channel_id_length => 5)) do |conf|
+        EventMachine.run do
+          pub = EventMachine::HttpRequest.new(nginx_address + '/pub?id=' + channel.to_s ).delete :head => headers
+          pub.callback do
+            expect(pub).to be_http_status(400).without_body
+            expect(pub.response_header['X_NGINX_PUSHSTREAM_EXPLAIN']).to eql("Channel id is too large.")
+            EventMachine.stop
+          end
+        end
+      end
+    end
+
+    it "should delete a channel without subscribers" do
+      channel = 'test_delete_channel_whithout_subscribers'
+      body = 'published message'
+
+      nginx_run_server(config) do |conf|
+        publish_message(channel, headers, body)
+
+        EventMachine.run do
+          pub = EventMachine::HttpRequest.new(nginx_address + '/pub?id=' + channel.to_s).delete :head => headers
+          pub.callback do
+            expect(pub).to be_http_status(200).without_body
+            expect(pub.response_header['X_NGINX_PUSHSTREAM_EXPLAIN']).to eql("Channel deleted.")
+
+            stats = EventMachine::HttpRequest.new(nginx_address + '/channels-stats').get :head => headers
+            stats.callback do
+              expect(stats).to be_http_status(200).with_body
+              response = JSON.parse(stats.response)
+              expect(response["channels"].to_s).not_to be_empty
+              expect(response["channels"].to_i).to eql(0)
+              EventMachine.stop
+            end
+          end
+        end
+      end
+    end
+
+    it "should delete a channel with subscriber" do
+      channel = 'test_delete_channel_whith_subscriber_in_one_channel'
+      body = 'published message'
+
+      configuration = config.merge({
+        :header_template => " ", # send a space as header to has a chunk received
+        :footer_template => nil,
+        :ping_message_interval => nil,
+        :message_template => '{\"id\":\"~id~\", \"channel\":\"~channel~\", \"text\":\"~text~\"}'
+      })
+
+      resp = ""
+      nginx_run_server(configuration) do |conf|
+        EventMachine.run do
+          sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers
+          sub_1.stream do |chunk|
+
+            resp = resp + chunk
+            if resp.strip.empty?
+              stats = EventMachine::HttpRequest.new(nginx_address + '/channels-stats').get :head => {'accept' => 'application/json'}
+              stats.callback do
+                expect(stats).to be_http_status(200).with_body
+                response = JSON.parse(stats.response)
+                expect(response["subscribers"].to_i).to eql(1)
+                expect(response["channels"].to_i).to eql(1)
+                pub = EventMachine::HttpRequest.new(nginx_address + '/pub?id=' + channel.to_s).delete :head => headers
+                pub.callback do
+                  expect(pub).to be_http_status(200).without_body
+                  expect(pub.response_header['X_NGINX_PUSHSTREAM_EXPLAIN']).to eql("Channel deleted.")
+                end
+              end
+            else
+              response = JSON.parse(resp)
+              expect(response["channel"]).to eql(channel)
+              expect(response["id"].to_i).to eql(-2)
+              expect(response["text"]).to eql("Channel deleted")
+
+              stats = EventMachine::HttpRequest.new(nginx_address + '/channels-stats').get :head => {'accept' => 'application/json'}
+              stats.callback do
+                expect(stats).to be_http_status(200).with_body
+                response = JSON.parse(stats.response)
+                expect(response["subscribers"].to_i).to eql(0)
+                expect(response["channels"].to_i).to eql(0)
+              end
+              EventMachine.stop
+            end
+          end
+        end
+      end
+    end
+
+    it "should delete a channel with a custom message" do
+      channel = 'test_delete_channel_whith_subscriber_in_one_channel'
+      body = 'published message'
+
+      configuration = config.merge({
+        :header_template => " ", # send a space as header to has a chunk received
+        :footer_template => nil,
+        :ping_message_interval => nil,
+        :message_template => '{\"id\":\"~id~\", \"channel\":\"~channel~\", \"text\":\"~text~\"}'
+      })
+
+      resp = ""
+      nginx_run_server(configuration, :timeout => 5) do |conf|
+        EventMachine.run do
+          sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers, :timeout => 30
+          sub_1.stream do |chunk|
+
+            resp = resp + chunk
+            if resp.strip.empty?
+              stats = EventMachine::HttpRequest.new(nginx_address + '/channels-stats').get :head => {'accept' => 'application/json'}, :timeout => 30
+              stats.callback do
+                expect(stats.response_header.status).to eql(200)
+                expect(stats.response_header.content_length).not_to eql(0)
+                response = JSON.parse(stats.response)
+                expect(response["subscribers"].to_i).to eql(1)
+                expect(response["channels"].to_i).to eql(1)
+                pub = EventMachine::HttpRequest.new(nginx_address + '/pub?id=' + channel.to_s).delete :head => headers, :body => "custom channel delete message", :timeout => 30
+                pub.callback do
+                  expect(pub.response_header.status).to eql(200)
+                  expect(pub.response_header.content_length).to eql(0)
+                  expect(pub.response_header['X_NGINX_PUSHSTREAM_EXPLAIN']).to eql("Channel deleted.")
+                end
+              end
+            else
+              response = JSON.parse(resp)
+              expect(response["channel"]).to eql(channel)
+              expect(response["id"].to_i).to eql(-2)
+              expect(response["text"]).to eql("custom channel delete message")
+
+              stats = EventMachine::HttpRequest.new(nginx_address + '/channels-stats').get :head => {'accept' => 'application/json'}, :timeout => 30
+              stats.callback do
+                expect(stats.response_header.status).to eql(200)
+                expect(stats.response_header.content_length).not_to eql(0)
+                response = JSON.parse(stats.response)
+                expect(response["subscribers"].to_i).to eql(0)
+                expect(response["channels"].to_i).to eql(0)
+              end
+              EventMachine.stop
+            end
+          end
+        end
+      end
+    end
+
+    it "should delete a channel with subscriber in two channels" do
+      channel_1 = 'test_delete_channel_whith_subscriber_in_two_channels_1'
+      channel_2 = 'test_delete_channel_whith_subscriber_in_two_channels_2'
+      stage1_complete = stage2_complete = false
+      body = 'published message'
+
+      configuration = config.merge({
+        :header_template => " ", # send a space as header to has a chunk received
+        :footer_template => nil,
+        :ping_message_interval => nil,
+        :message_template => '{\"id\":\"~id~\", \"channel\":\"~channel~\", \"text\":\"~text~\"}|'
+      })
+
+      resp = ""
+      nginx_run_server(configuration) do |conf|
+        EventMachine.run do
+          sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel_1.to_s + '/' + channel_2.to_s).get :head => headers
+          sub_1.stream do |chunk|
+
+            resp = resp + chunk
+            if resp.strip.empty?
+              stats = EventMachine::HttpRequest.new(nginx_address + '/channels-stats').get :head => {'accept' => 'application/json'}
+              stats.callback do
+                expect(stats).to be_http_status(200).with_body
+                response = JSON.parse(stats.response)
+                expect(response["subscribers"].to_i).to eql(1)
+                expect(response["channels"].to_i).to eql(2)
+
+                pub = EventMachine::HttpRequest.new(nginx_address + '/pub?id=' + channel_1.to_s).delete :head => headers
+                pub.callback do
+                  expect(pub).to be_http_status(200).without_body
+                  expect(pub.response_header['X_NGINX_PUSHSTREAM_EXPLAIN']).to eql("Channel deleted.")
+                end
+              end
+            else
+              if !stage1_complete
+                stage1_complete = true
+                response = JSON.parse(resp.split("|")[0])
+                expect(response["channel"]).to eql(channel_1)
+                expect(response["id"].to_i).to eql(-2)
+                expect(response["text"]).to eql("Channel deleted")
+
+                stats = EventMachine::HttpRequest.new(nginx_address + '/channels-stats').get :head => {'accept' => 'application/json'}
+                stats.callback do
+                  expect(stats).to be_http_status(200).with_body
+                  response = JSON.parse(stats.response)
+                  expect(response["subscribers"].to_i).to eql(1)
+                  expect(response["channels"].to_i).to eql(1)
+
+                  pub = EventMachine::HttpRequest.new(nginx_address + '/pub?id=' + channel_2.to_s).post :head => headers, :body=> body
+                  pub.callback do
+                    expect(pub).to be_http_status(200).with_body
+                  end
+                end
+              elsif !stage2_complete
+                stage2_complete = true
+                response = JSON.parse(resp.split("|")[1])
+                expect(response["channel"]).to eql(channel_2)
+                expect(response["id"].to_i).to eql(1)
+                expect(response["text"]).to eql(body)
+
+                pub = EventMachine::HttpRequest.new(nginx_address + '/pub?id=' + channel_2.to_s).delete :head => headers
+                pub.callback do
+                  expect(pub).to be_http_status(200).without_body
+                  expect(pub.response_header['X_NGINX_PUSHSTREAM_EXPLAIN']).to eql("Channel deleted.")
+                end
+              else
+                response = JSON.parse(resp.split("|")[2])
+                expect(response["channel"]).to eql(channel_2)
+                expect(response["id"].to_i).to eql(-2)
+                expect(response["text"]).to eql("Channel deleted")
+
+                stats = EventMachine::HttpRequest.new(nginx_address + '/channels-stats').get :head => {'accept' => 'application/json'}
+                stats.callback do
+                  expect(stats).to be_http_status(200).with_body
+                  response = JSON.parse(stats.response)
+                  expect(response["subscribers"].to_i).to eql(0)
+                  expect(response["channels"].to_i).to eql(0)
+                  EventMachine.stop
+                end
+              end
+            end
+          end
+        end
+      end
+    end
+
+    it "should delete channels with subscribers" do
+      channel_1 = 'test_delete_channels_whith_subscribers_1'
+      channel_2 = 'test_delete_channels_whith_subscribers_2'
+      body = 'published message'
+
+      configuration = config.merge({
+        :header_template => nil,
+        :footer_template => "FOOTER",
+        :ping_message_interval => nil,
+        :message_template => '{\"id\":\"~id~\", \"channel\":\"~channel~\", \"text\":\"~text~\"}'
+      })
+
+      nginx_run_server(configuration, :timeout => 10) do |conf|
+        EventMachine.run do
+          resp_1 = ""
+          sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel_1.to_s).get :head => headers
+          sub_1.stream do |chunk|
+            resp_1 += chunk
+          end
+          sub_1.callback do
+            expect(resp_1).to eql("{\"id\":\"-2\", \"channel\":\"test_delete_channels_whith_subscribers_1\", \"text\":\"Channel deleted\"}FOOTER")
+          end
+
+          resp_2 = ""
+          sub_2 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel_2.to_s).get :head => headers
+          sub_2.stream do |chunk|
+            resp_2 += chunk
+          end
+          sub_2.callback do
+            expect(resp_2).to eql("{\"id\":\"-2\", \"channel\":\"test_delete_channels_whith_subscribers_2\", \"text\":\"Channel deleted\"}FOOTER")
+          end
+
+          EM.add_timer(0.5) do
+            stats = EventMachine::HttpRequest.new(nginx_address + '/channels-stats').get :head => {'accept' => 'application/json'}
+            stats.callback do
+              expect(stats).to be_http_status(200).with_body
+              response = JSON.parse(stats.response)
+              expect(response["subscribers"].to_i).to eql(2)
+              expect(response["channels"].to_i).to eql(2)
+            end
+          end
+
+          EM.add_timer(1.5) do
+            pub_1 = EventMachine::HttpRequest.new(nginx_address + '/pub?id=' + channel_1.to_s).delete :head => headers
+            pub_1.callback do
+              expect(pub_1).to be_http_status(200).without_body
+              expect(pub_1.response_header['X_NGINX_PUSHSTREAM_EXPLAIN']).to eql("Channel deleted.")
+            end
+
+            pub_2 = EventMachine::HttpRequest.new(nginx_address + '/pub?id=' + channel_2.to_s).delete :head => headers
+            pub_2.callback do
+              expect(pub_2).to be_http_status(200).without_body
+              expect(pub_2.response_header['X_NGINX_PUSHSTREAM_EXPLAIN']).to eql("Channel deleted.")
+            end
+          end
+
+          EM.add_timer(5) do
+            stats_2 = EventMachine::HttpRequest.new(nginx_address + '/channels-stats').get :head => {'accept' => 'application/json'}
+            stats_2.callback do
+              expect(stats_2).to be_http_status(200).with_body
+              response = JSON.parse(stats_2.response)
+              expect(response["subscribers"].to_i).to eql(0)
+              expect(response["channels"].to_i).to eql(0)
+              EventMachine.stop
+            end
+          end
+        end
+      end
+    end
+
+    it "should receive footer template when channel is deleted" do
+      channel = 'ch_test_receive_footer_template_when_channel_is_deleted'
+      body = 'published message'
+
+      configuration = config.merge({
+        :header_template => "HEADER_TEMPLATE",
+        :footer_template => "FOOTER_TEMPLATE",
+        :ping_message_interval => nil,
+        :message_template => '~text~'
+      })
+
+      resp = ""
+      nginx_run_server(configuration) do |conf|
+        EventMachine.run do
+          sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers
+          sub_1.stream do |chunk|
+
+            resp = resp + chunk
+            if resp == conf.header_template
+              pub = EventMachine::HttpRequest.new(nginx_address + '/pub?id=' + channel.to_s).delete :head => headers
+              pub.callback do
+                expect(pub).to be_http_status(200).without_body
+                expect(pub.response_header['X_NGINX_PUSHSTREAM_EXPLAIN']).to eql("Channel deleted.")
+              end
+            end
+          end
+          sub_1.callback do
+            expect(resp).to eql("#{conf.header_template}Channel deleted#{conf.footer_template}")
+            EventMachine.stop
+          end
+        end
+      end
+    end
+
+    it "should receive different header and footer template by location when channel is deleted" do
+      channel = 'ch_test_different_header_and_footer_template_by_location'
+      body = 'published message'
+
+      configuration = config.merge({
+        :header_template => "HEADER_TEMPLATE",
+        :footer_template => "FOOTER_TEMPLATE",
+        :ping_message_interval => nil,
+        :message_template => '~text~',
+        :extra_location => %{
+          location ~ /sub2/(.*)? {
+              # activate subscriber mode for this location
+              push_stream_subscriber;
+
+              # positional channel path
+              push_stream_channels_path          $1;
+              push_stream_header_template "<html><body>";
+              push_stream_footer_template "</body></html>";
+              push_stream_message_template "|~text~|";
+          }
+        }
+      })
+
+      resp = ""
+      resp2 = ""
+      nginx_run_server(configuration) do |conf|
+        EventMachine.run do
+          sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers
+          sub_1.stream do |chunk|
+            resp = resp + chunk
+          end
+
+          sub_2 = EventMachine::HttpRequest.new(nginx_address + '/sub2/' + channel.to_s).get :head => headers
+          sub_2.stream do |chunk|
+            resp2 = resp2 + chunk
+          end
+
+          EM.add_timer(1) do
+            pub = EventMachine::HttpRequest.new(nginx_address + '/pub?id=' + channel.to_s).delete :head => headers
+            pub.callback do
+              expect(pub).to be_http_status(200).without_body
+              expect(pub.response_header['X_NGINX_PUSHSTREAM_EXPLAIN']).to eql("Channel deleted.")
+            end
+          end
+
+          EM.add_timer(2) do
+            expect(resp).to eql("#{conf.header_template}Channel deleted#{conf.footer_template}")
+            expect(resp2).to eql("<html><body>|Channel deleted|</body></html>")
+            EventMachine.stop
+          end
+        end
+      end
+    end
+
+    it "should receive custom delete message text when channel is deleted" do
+      channel = 'test_custom_channel_deleted_message_text'
+      body = 'published message'
+
+      configuration = config.merge({
+        :header_template => " ", # send a space as header to has a chunk received
+        :footer_template => nil,
+        :ping_message_interval => nil,
+        :message_template => '{\"id\":\"~id~\", \"channel\":\"~channel~\", \"text\":\"~text~\"}',
+        :channel_deleted_message_text => "Channel has gone away."
+      })
+
+      resp = ""
+      nginx_run_server(configuration) do |conf|
+        EventMachine.run do
+          sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers
+          sub_1.stream do |chunk|
+
+            resp = resp + chunk
+            if resp.strip.empty?
+              pub = EventMachine::HttpRequest.new(nginx_address + '/pub?id=' + channel.to_s).delete :head => headers
+              pub.callback do
+                expect(pub).to be_http_status(200).without_body
+                expect(pub.response_header['X_NGINX_PUSHSTREAM_EXPLAIN']).to eql("Channel deleted.")
+              end
+            else
+              response = JSON.parse(resp)
+              expect(response["channel"]).to eql(channel)
+              expect(response["id"].to_i).to eql(-2)
+              expect(response["text"]).to eql(conf.channel_deleted_message_text)
+              EventMachine.stop
+            end
+          end
+        end
+      end
+    end
+
+    it "should delete channels on same request" do
+      body = 'published message'
+
+      nginx_run_server(config) do |conf|
+        publish_message("ch1", headers, body)
+        publish_message("ch2", headers, body)
+
+        EventMachine.run do
+          pub = EventMachine::HttpRequest.new(nginx_address + '/pub?id=ch1/ch2').delete :head => headers
+          pub.callback do
+            expect(pub).to be_http_status(200).without_body
+            expect(pub.response_header['X_NGINX_PUSHSTREAM_EXPLAIN']).to eql("Channel deleted.")
+
+            stats = EventMachine::HttpRequest.new(nginx_address + '/channels-stats').get :head => headers
+            stats.callback do
+              expect(stats).to be_http_status(200).with_body
+              response = JSON.parse(stats.response)
+              expect(response["channels"].to_s).not_to be_empty
+              expect(response["channels"].to_i).to eql(0)
+              EventMachine.stop
+            end
+          end
+        end
+      end
+    end
+
+    it "should delete channels on same request even when one of them does not exists" do
+      body = 'published message'
+
+      nginx_run_server(config) do |conf|
+        publish_message("ch1", headers, body)
+        publish_message("ch2", headers, body)
+        publish_message("ch3", headers, body)
+
+        EventMachine.run do
+          pub = EventMachine::HttpRequest.new(nginx_address + '/pub?id=ch3/ch4/ch1').delete :head => headers
+          pub.callback do
+            expect(pub).to be_http_status(200).without_body
+            expect(pub.response_header['X_NGINX_PUSHSTREAM_EXPLAIN']).to eql("Channel deleted.")
+
+            stats = EventMachine::HttpRequest.new(nginx_address + '/channels-stats?id=ALL').get :head => headers
+            stats.callback do
+              expect(stats).to be_http_status(200).with_body
+              response = JSON.parse(stats.response)
+              expect(response["channels"].to_s).not_to be_empty
+              expect(response["channels"].to_i).to eql(1)
+              expect(response["infos"][0]["channel"]).to eql("ch2")
+              expect(response["infos"][0]["published_messages"]).to eql(1)
+              expect(response["infos"][0]["stored_messages"]).to eql(1)
+              EventMachine.stop
+            end
+          end
+        end
+      end
+    end
+  end
+end
diff -Naur nginx-1.11.3/nginx-push-stream-module/misc/spec/publisher/publish_messages_spec.rb nginx-1.11.3-push/nginx-push-stream-module/misc/spec/publisher/publish_messages_spec.rb
--- nginx-1.11.3/nginx-push-stream-module/misc/spec/publisher/publish_messages_spec.rb	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/misc/spec/publisher/publish_messages_spec.rb	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,361 @@
+require 'spec_helper'
+
+describe "Publisher Publishing Messages" do
+  let(:config) do
+    {
+      :header_template => nil,
+      :message_template => "~text~",
+      :footer_template => nil,
+      :ping_message_interval => nil
+    }
+  end
+
+  it "should receive the published message" do
+    body = 'published unique message'
+    channel = 'ch_test_publish_messages'
+
+    nginx_run_server(config) do |conf|
+      EventMachine.run do
+        sub = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers
+        sub.stream do |chunk|
+          expect(chunk).to eql(body)
+          EventMachine.stop
+        end
+
+        publish_message_inline(channel, headers, body)
+      end
+    end
+  end
+
+  it "should publish a message with PUT method" do
+    body = 'published unique message'
+    channel = 'ch_test_publish_messages_with_put'
+
+    nginx_run_server(config, :timeout => 5) do |conf|
+      EventMachine.run do
+        sub = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers
+        sub.stream do |chunk|
+          expect(chunk).to eql(body)
+          EventMachine.stop
+        end
+
+        EM.add_timer(0.5) do
+          EventMachine::HttpRequest.new(nginx_address + '/pub?id=' + channel.to_s ).put :head => headers, :body => body, :timeout => 30
+        end
+      end
+    end
+  end
+
+  it "should accept messages with different bytes" do
+    channel = 'ch_test_publish_messages_with_different_bytes'
+
+    nginx_run_server(config.merge(:client_max_body_size => '130k', :client_body_buffer_size => '130k', :subscriber_connection_ttl => "1s")) do |conf|
+      ranges = [0..255]
+      ranges.each do |range|
+        bytes = []
+        range.each do |i|
+          0.upto(255) do |j|
+            bytes << "%s%s" % [i.chr, j.chr]
+          end
+        end
+
+        body = bytes.join('')
+        response = ''
+
+        EventMachine.run do
+          sub = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers
+          sub.stream do |chunk|
+            response += chunk
+          end
+
+          sub.callback do
+            expect(response.bytes.to_a).to eql(body.bytes.to_a)
+            EventMachine.stop
+          end
+
+          publish_message_inline(channel, headers, body)
+        end
+      end
+    end
+  end
+
+  it "should receive large messages" do
+    channel = 'ch_test_publish_large_messages'
+    small_message = "^|" + ("0123456789" * 1020) + "|$"
+    large_message = "^|" + ("0123456789" * 419430) + "|$"
+
+    response_sub = ''
+    response_sub_1 = ''
+
+    nginx_run_server(config.merge(client_max_body_size: '5m', client_body_buffer_size: '1m', subscriber_connection_ttl: '5s', shared_memory_size: '15m'), timeout: 10) do |conf|
+      EventMachine.run do
+        start = Time.now
+        sub = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers
+        sub.stream do |chunk|
+          response_sub += chunk
+
+          if response_sub.include?('A')
+            expect(response_sub).to eql(large_message + 'A')
+            response_sub = ''
+
+            # check if getting old messages works fine too
+            sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s + ".b1").get :head => headers
+            sub_1.stream do |chunk_1|
+              response_sub_1 += chunk_1
+
+              if response_sub_1.include?('A')
+                expect(response_sub_1).to eql(large_message + 'A')
+                response_sub_1 = ''
+
+                publish_message_inline(channel, headers, small_message + 'B')
+              end
+            end
+
+            sub_1.callback do
+              fail("should not disconnect the client")
+            end
+          end
+        end
+
+        sub.callback do
+          fail("should not disconnect the client")
+        end
+
+        EM.add_timer(3) do
+          if response_sub.include?('B') && response_sub_1.include?('B')
+            expect(response_sub).to eql(small_message + 'B')
+            expect(response_sub_1).to eql(small_message + 'B')
+
+            expect(large_message.size).to eql(4194304) # 4mb
+            expect(small_message.size).to eql(10204) # 10k
+            EventMachine.stop
+          end
+        end
+
+        publish_message_inline(channel, headers, large_message + 'A')
+      end
+    end
+  end
+
+  it "should format message with text contains huge number of template patterns" do
+    channel = 'ch_test_publish_messages_with_template_patterns'
+    body = "|~id~|~channel~|~text~|~event-id~|~tag~" * 20000 + "|"
+    response = ''
+
+    nginx_run_server(config.merge(:client_max_body_size => '2000k', :client_body_buffer_size => '2000k', :message_template => '{\"id\": \"~id~\", \"channel\": \"~channel~\", \"text\": \"~text~\", \"event_id\": \"~event-id~\",\"tag\": \"~tag~\"}'), :timeout => 15) do |conf|
+      EventMachine.run do
+        start = Time.now
+        pub = EventMachine::HttpRequest.new(nginx_address + '/pub?id=' + channel.to_s ).post :head => headers, :body => body
+        pub.stream do |chunk|
+          response += chunk
+        end
+        pub.callback do
+          expect(Time.now - start).to be < 0.1 #should fast proccess message
+          expect(response.strip).to eql('{"channel": "ch_test_publish_messages_with_template_patterns", "published_messages": 1, "stored_messages": 1, "subscribers": 0}')
+          EventMachine.stop
+        end
+      end
+    end
+  end
+
+  it "should publish many messages in the same channel" do
+    body_prefix = 'published_message_'
+    channel = 'ch_test_publish_many_messages_in_the_same_channel'
+    messagens_to_publish = 1500
+
+    response = ""
+    nginx_run_server(config.merge(:max_reserved_memory => "256m", :keepalive_requests => 500, :message_template => "~text~|")) do |conf|
+      EventMachine.run do
+        sub = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers
+        sub.stream do |chunk|
+          response += chunk
+          recieved_messages = response.split("|")
+
+          if recieved_messages.length == messagens_to_publish
+            expect(recieved_messages.last).to eql(body_prefix + messagens_to_publish.to_s)
+            EventMachine.stop
+          end
+        end
+
+        EM.add_timer(0.5) do
+          0.step(messagens_to_publish - 1, 500) do |i|
+            socket = open_socket(nginx_host, nginx_port)
+            1.upto(500) do |j|
+              resp_headers, body = post_in_socket("/pub?id=#{channel}", "#{body_prefix}#{i+j}", socket, {:wait_for => "}\r\n"})
+              fail("Message was not published: " + body_prefix + (i+j).to_s) unless resp_headers.include?("HTTP/1.1 200 OK")
+            end
+            socket.close
+          end
+        end
+      end
+    end
+  end
+
+  it "should set an event id to the message through header parameter" do
+    event_id = 'event_id_with_generic_text_01'
+    body = 'test message'
+    channel = 'ch_test_set_an_event_id_to_the_message_through_header_parameter'
+    response = ''
+
+    nginx_run_server(config.merge(:message_template => '{\"id\": \"~id~\", \"channel\": \"~channel~\", \"text\": \"~text~\", \"event_id\": \"~event-id~\"}')) do |conf|
+      EventMachine.run do
+        sub = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get
+        sub.stream do |chunk|
+          response = JSON.parse(chunk)
+          expect(response["id"].to_i).to eql(1)
+          expect(response["channel"]).to eql(channel)
+          expect(response["text"]).to eql(body)
+          expect(response["event_id"]).to eql(event_id)
+          EventMachine.stop
+        end
+
+        publish_message_inline(channel, headers.merge('Event-Id' => event_id), body)
+      end
+    end
+  end
+
+  it "should set an event type to the message through header parameter" do
+    event_type = 'event_type_with_generic_text_01'
+    body = 'test message'
+    channel = 'ch_test_set_an_event_type_to_the_message_through_header_parameter'
+    response = ''
+
+    nginx_run_server(config.merge(:message_template => '{\"id\": \"~id~\", \"channel\": \"~channel~\", \"text\": \"~text~\", \"event_type\": \"~event-type~\"}')) do |conf|
+      EventMachine.run do
+        sub = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get
+        sub.stream do |chunk|
+          response = JSON.parse(chunk)
+          expect(response["id"].to_i).to eql(1)
+          expect(response["channel"]).to eql(channel)
+          expect(response["text"]).to eql(body)
+          expect(response["event_type"]).to eql(event_type)
+          EventMachine.stop
+        end
+
+        publish_message_inline(channel, headers.merge('Event-type' => event_type), body)
+      end
+    end
+  end
+
+  it "should ignore event id header parameter which not match exactly" do
+    event_id = 'event_id_with_generic_text_01'
+    body = 'test message'
+    channel = 'ch_test_set_an_event_id_to_the_message_through_header_parameter'
+    response = ''
+
+    nginx_run_server(config.merge(:message_template => '{\"id\": \"~id~\", \"channel\": \"~channel~\", \"text\": \"~text~\", \"event_id\": \"~event-id~\"}')) do |conf|
+      EventMachine.run do
+        sub = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get
+        sub.stream do |chunk|
+          response = JSON.parse(chunk)
+          expect(response["id"].to_i).to eql(1)
+          expect(response["channel"]).to eql(channel)
+          expect(response["text"]).to eql(body)
+          expect(response["event_id"]).to eql("")
+          EventMachine.stop
+        end
+
+        publish_message_inline(channel, headers.merge('Event-Ids' => event_id), body)
+      end
+
+      EventMachine.run do
+        sub = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get
+        sub.stream do |chunk|
+          response = JSON.parse(chunk)
+          expect(response["id"].to_i).to eql(2)
+          expect(response["channel"]).to eql(channel)
+          expect(response["text"]).to eql(body)
+          expect(response["event_id"]).to eql("")
+          EventMachine.stop
+        end
+
+        publish_message_inline(channel, headers.merge('Event-I' => event_id), body)
+      end
+    end
+  end
+
+  it "should expose message publish time through message template" do
+    body = 'test message'
+    channel = 'ch_test_expose_message_publish_time_through_message_template'
+    response = ''
+    now = nil
+
+    nginx_run_server(config.merge(:message_template => '{\"id\": \"~id~\", \"channel\": \"~channel~\", \"text\": \"~text~\", \"publish_time\": \"~time~\"}')) do |conf|
+      EventMachine.run do
+        sub = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get
+        sub.stream do |chunk|
+          response = JSON.parse(chunk)
+          expect(response["id"].to_i).to eql(1)
+          expect(response["channel"]).to eql(channel)
+          expect(response["text"]).to eql(body)
+          expect(response["publish_time"].size).to eql(29)
+          publish_time = Time.parse(response["publish_time"])
+          expect(publish_time.to_i).to be_in_the_interval(now.to_i, now.to_i + 1)
+
+          EventMachine.stop
+        end
+
+        now = Time.now
+        publish_message_inline(channel, headers, body)
+      end
+    end
+  end
+
+  it "should expose message tag through message template" do
+    body = 'test message'
+    channel = 'ch_test_expose_message_tag_through_message_template'
+    response = ''
+
+    nginx_run_server(config.merge(:message_template => '{\"id\": \"~id~\", \"channel\": \"~channel~\", \"text\": \"~text~\", \"tag\": \"~tag~\"}\r\n')) do |conf|
+      EventMachine.run do
+        sub = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get
+        sub.stream do |chunk|
+          response += chunk
+          lines = response.split("\r\n")
+          if lines.size > 1
+            lines.each_with_index do |line, i|
+              resp = JSON.parse(line)
+              expect(resp["id"].to_i).to eql(i + 1)
+              expect(resp["channel"]).to eql(channel)
+              expect(resp["text"]).to eql(body)
+              expect(resp["tag"].to_i).to eql(i + 1)
+            end
+            EventMachine.stop
+          end
+        end
+
+        publish_message_inline(channel, headers, body)
+        publish_message_inline(channel, headers, body)
+      end
+    end
+  end
+
+  it "should expose message size through message template" do
+    body = 'test message'
+    channel = 'ch_test_expose_message_size_through_message_template'
+    response = ''
+
+    nginx_run_server(config.merge(:message_template => '{\"id\": \"~id~\", \"channel\": \"~channel~\", \"text\": \"~text~\", \"size\": \"~size~\"}\r\n')) do |conf|
+      EventMachine.run do
+        sub = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get
+        sub.stream do |chunk|
+          response += chunk
+          lines = response.split("\r\n")
+          if lines.size > 1
+            lines.each_with_index do |line, i|
+              resp = JSON.parse(line)
+              expect(resp["id"].to_i).to eql(i + 1)
+              expect(resp["channel"]).to eql(channel)
+              expect(resp["text"]).to eql(body + ("a" * i))
+              expect(resp["size"].to_i).to eql(body.size + i)
+            end
+            EventMachine.stop
+          end
+        end
+
+        publish_message_inline(channel, headers, body)
+        publish_message_inline(channel, headers, body + "a")
+      end
+    end
+  end
+end
diff -Naur nginx-1.11.3/nginx-push-stream-module/misc/spec/spec_helper.rb nginx-1.11.3-push/nginx-push-stream-module/misc/spec/spec_helper.rb
--- nginx-1.11.3/nginx-push-stream-module/misc/spec/spec_helper.rb	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/misc/spec/spec_helper.rb	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,79 @@
+require 'rubygems'
+
+# Set up gems listed in the Gemfile.
+ENV['BUNDLE_GEMFILE'] ||= File.expand_path('../Gemfile', File.dirname(__FILE__))
+
+require 'bundler/setup' if File.exists?(ENV['BUNDLE_GEMFILE'])
+Bundler.require(:default, :test) if defined?(Bundler)
+
+require File.expand_path('nginx_configuration', File.dirname(__FILE__))
+
+Signal.trap("CLD", "IGNORE")
+
+RSpec.configure do |config|
+  config.after(:each) do
+    non_time_wait_connections = `netstat -an | grep ":#{nginx_port} " | grep -v TIME_WAIT | grep -v LISTEN | grep -v ESTABLISHED`.chomp.split("\n")
+    abort "There are sockects on non time wait state: #{non_time_wait_connections.join("\n")}" if non_time_wait_connections.count > 0
+    NginxTestHelper::Config.delete_config_and_log_files(config_id) if has_passed?
+  end
+  config.order = "random"
+end
+
+def publish_message_inline(channel, headers, body, delay=0.01, &block)
+  EM.add_timer(delay) do
+    pub = EventMachine::HttpRequest.new(nginx_address + '/pub?id=' + channel.to_s).post :head => headers, :body => body
+    pub.callback do
+      expect(pub).to be_http_status(200)
+      block.call(pub) unless block.nil?
+    end
+  end
+end
+
+def publish_message(channel, headers, body)
+  http = Net::HTTP.new(nginx_host, nginx_port)
+  req = Net::HTTP::Post.new("/pub?id=#{channel}", headers)
+  req.body = body
+  res = http.request(req)
+  content = res.body
+  if res.get_fields("content-encoding").to_a.include?("gzip")
+    content = Zlib::GzipReader.new(StringIO.new(content)).read
+  end
+  response = JSON.parse(content)
+  expect(response["channel"].to_s).to eql(channel)
+end
+
+def post_to(path, headers, body)
+  http = Net::HTTP.new(nginx_host, nginx_port)
+  req = Net::HTTP::Post.new(path, headers)
+  req.body = body
+  http.request(req)
+end
+
+def create_channel_by_subscribe(channel, headers, timeout=60, &block)
+  EventMachine.run do
+    sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s, :connect_timeout => timeout, :inactivity_timeout => timeout).get :head => headers.merge({"accept-encoding" => ""})
+    sub_1.stream do |chunk|
+      block.call
+    end
+
+    sub_1.callback do
+      EventMachine.stop
+    end
+  end
+end
+
+def publish_messages_until_fill_the_memory(channel, body, &block)
+  i = 0
+  resp_headers, resp_body = nil
+  socket = open_socket(nginx_host, nginx_port)
+  while (true) do
+    socket.print("POST /pub?id=#{channel.to_s % (i)} HTTP/1.1\r\nHost: localhost\r\nContent-Length: #{body.size}\r\n\r\n#{body}")
+    resp_headers, resp_body = read_response_on_socket(socket, "}\r\n")
+    break unless resp_headers.match(/200 OK/)
+    i += 1
+  end
+  socket.close
+
+  status = resp_headers.match(/HTTP[^ ]* ([^ ]*)/)[1]
+  block.call(status, resp_body) unless block.nil?
+end
diff -Naur nginx-1.11.3/nginx-push-stream-module/misc/spec/subscriber/comunication_properties_spec.rb nginx-1.11.3-push/nginx-push-stream-module/misc/spec/subscriber/comunication_properties_spec.rb
--- nginx-1.11.3/nginx-push-stream-module/misc/spec/subscriber/comunication_properties_spec.rb	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/misc/spec/subscriber/comunication_properties_spec.rb	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,147 @@
+require 'spec_helper'
+
+describe "Comunication Properties" do
+  let(:config) do
+    {
+      :authorized_channels_only => "off",
+      :header_template => "connected",
+      :message_ttl => "12s",
+      :message_template => "~text~",
+      :ping_message_interval => "1s"
+    }
+  end
+
+  it "should not block to connected to a nonexistent channel" do
+    channel = 'ch_test_all_authorized'
+
+    nginx_run_server(config) do |conf|
+      EventMachine.run do
+        sub = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers
+        sub.stream do |chunk|
+          expect(chunk).to eql(conf.header_template)
+          EventMachine.stop
+        end
+      end
+    end
+  end
+
+  it "should block to connected to a nonexistent channel when authorized only is 'on'" do
+    channel = 'ch_test_only_authorized'
+    body = 'message to create a channel'
+
+    nginx_run_server(config.merge(:authorized_channels_only => "on")) do |conf|
+      EventMachine.run do
+        sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers
+        sub_1.callback do |chunk|
+          expect(sub_1).to be_http_status(403).without_body
+          expect(sub_1.response_header['X_NGINX_PUSHSTREAM_EXPLAIN']).to eql("Subscriber could not create channels.")
+
+          pub = EventMachine::HttpRequest.new(nginx_address + '/pub?id=' + channel.to_s ).post :head => headers, :body => body
+          pub.callback do
+            sub_2 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers
+            sub_2.stream do |chunk2|
+              expect(chunk2).to eql(conf.header_template)
+              EventMachine.stop
+            end
+          end
+        end
+      end
+    end
+  end
+
+  it "should discard messages published a more time than the value configured to message ttl" do
+    channel = 'ch_test_message_ttl'
+    body = 'message to test buffer timeout '
+    response_1 = response_2 = response_3 = ""
+    sub_1 = sub_2 = sub_3 = nil
+
+    nginx_run_server(config, :timeout => 20) do |conf|
+      EventMachine.run do
+        pub = EventMachine::HttpRequest.new(nginx_address + '/pub?id=' + channel.to_s ).post :head => headers, :body => body
+        time_2 = EM.add_timer(2) do
+          sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s + '.b1').get :head => headers
+          sub_1.stream do |chunk|
+            response_1 += chunk unless response_1.include?(body)
+            sub_1.close if response_1.include?(body)
+          end
+        end
+
+        EM.add_timer(6) do
+          sub_2 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s + '.b1').get :head => headers
+          sub_2.stream do |chunk|
+            response_2 += chunk unless response_2.include?(body)
+            sub_2.close if response_2.include?(body)
+          end
+        end
+
+        #message will be certainly expired at 15 seconds
+        EM.add_timer(16) do
+          sub_3 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s + '.b1').get :head => headers
+          sub_3.stream do |chunk|
+            response_3 += chunk unless response_3.include?(body)
+            sub_3.close if response_3.include?(body)
+          end
+        end
+
+        EM.add_timer(17) do
+          expect(response_1).to eql("#{conf.header_template}#{body}")
+          expect(response_2).to eql("#{conf.header_template}#{body}")
+          expect(response_3).to eql("#{conf.header_template}")
+          EventMachine.stop
+        end
+      end
+    end
+  end
+
+  it "should apply the message template to published message with the available keyworkds" do
+    channel = 'ch_test_message_template'
+    body = 'message to create a channel'
+
+    response = ""
+    nginx_run_server(config.merge(:message_template => '|{\"duplicated\":\"~channel~\", \"channel\":\"~channel~\", \"message\":\"~text~\", \"message_id\":\"~id~\"}')) do |conf|
+      publish_message(channel, headers, body)
+
+      EventMachine.run do
+        sub = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s + '.b1').get :head => headers
+        sub.stream do |chunk|
+          response += chunk
+
+          lines = response.split("|")
+
+          if lines.length >= 3
+            expect(lines[0]).to eql("#{conf.header_template}")
+            expect(lines[1]).to eql("{\"duplicated\":\"#{channel}\", \"channel\":\"#{channel}\", \"message\":\"#{body}\", \"message_id\":\"1\"}")
+            expect(lines[2]).to eql("{\"duplicated\":\"\", \"channel\":\"\", \"message\":\" \", \"message_id\":\"-1\"}")
+            EventMachine.stop
+          end
+        end
+      end
+    end
+  end
+
+  it "should not be in loop when channel or published message contains one of the keywords" do
+    channel = 'ch_test_message_and_channel_with_same_pattern_of_the_template~channel~~channel~~channel~~text~~text~~text~'
+    body = '~channel~~channel~~channel~~text~~text~~text~'
+
+    response = ""
+    nginx_run_server(config.merge(:message_template => '|{\"channel\":\"~channel~\", \"message\":\"~text~\", \"message_id\":\"~id~\"}')) do |conf|
+      publish_message(channel, headers, body)
+
+      EventMachine.run do
+        sub = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s + '.b1').get :head => headers
+        sub.stream do |chunk|
+          response += chunk
+
+          lines = response.split("|")
+
+          if lines.length >= 3
+            expect(lines[0]).to eql("#{conf.header_template}")
+            expect(lines[1]).to eql("{\"channel\":\"ch_test_message_and_channel_with_same_pattern_of_the_template~channel~~channel~~channel~~text~~text~~text~\", \"message\":\"~channel~~channel~~channel~~text~~text~~text~\", \"message_id\":\"1\"}")
+            expect(lines[2]).to eql("{\"channel\":\"\", \"message\":\" \", \"message_id\":\"-1\"}")
+            EventMachine.stop
+          end
+        end
+      end
+    end
+  end
+end
diff -Naur nginx-1.11.3/nginx-push-stream-module/misc/spec/subscriber/connection_cleanup_spec.rb nginx-1.11.3-push/nginx-push-stream-module/misc/spec/subscriber/connection_cleanup_spec.rb
--- nginx-1.11.3/nginx-push-stream-module/misc/spec/subscriber/connection_cleanup_spec.rb	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/misc/spec/subscriber/connection_cleanup_spec.rb	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,115 @@
+require 'spec_helper'
+
+describe "Subscriber Connection Cleanup" do
+  let(:config) do
+    {
+      :subscriber_connection_ttl => '17s',
+      :header_template => 'HEADER_TEMPLATE',
+      :footer_template => 'FOOTER_TEMPLATE',
+      :ping_message_interval => '3s'
+    }
+  end
+
+  it "should disconnect the subscriber after the configured connection ttl be reached" do
+    channel = 'ch_test_subscriber_connection_timeout'
+
+    nginx_run_server(config.merge(:ping_message_interval => nil), :timeout => 25) do |conf|
+      start = Time.now
+      response = ''
+
+      EventMachine.run do
+        sub = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s, :inactivity_timeout => 20).get :head => headers
+
+        sub.stream do |chunk|
+          response += chunk
+          expect(response).to include(conf.header_template)
+        end
+
+        sub.callback do
+          stop = Time.now
+          expect(time_diff_sec(start, stop)).to be_in_the_interval(17, 17.5)
+          expect(response).to include(conf.footer_template)
+          EventMachine.stop
+        end
+      end
+    end
+  end
+
+  it "should disconnect the subscriber after the configured connection ttl be reached with ping message" do
+    channel = 'ch_test_subscriber_connection_timeout_with_ping_message'
+
+    nginx_run_server(config.merge(:header_template => nil, :footer_template => nil), :timeout => 25) do |conf|
+      start = Time.now
+      chunks_received = 0
+
+      EventMachine.run do
+        sub = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers
+
+        sub.stream do |chunk|
+          chunks_received += 1
+        end
+
+        sub.callback do
+          stop = Time.now
+          expect(time_diff_sec(start, stop)).to be_in_the_interval(17, 17.5)
+          expect(chunks_received).to be_eql(5)
+          EventMachine.stop
+        end
+      end
+    end
+  end
+
+  it "should disconnect each subscriber after the configured connection ttl be reached starting when it connects" do
+    channel = 'ch_test_multiple_subscribers_connection_timeout'
+
+    nginx_run_server(config.merge(:subscriber_connection_ttl => '5s', :ping_message_interval => nil), :timeout => 25) do |conf|
+      EventMachine.run do
+        response_1 = ''
+        sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers
+        sub_1.stream do |chunk|
+          response_1 += chunk
+          expect(response_1).to include(conf.header_template)
+        end
+        sub_1.callback do
+          expect(response_1).to include(conf.footer_template)
+        end
+
+        sleep(2)
+
+        response_2 = ''
+        sub_2 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers
+        sub_2.stream do |chunk|
+          response_2 += chunk
+          expect(response_2).to include(conf.header_template)
+        end
+        sub_2.callback do
+          expect(response_2).to include(conf.footer_template)
+
+          response_4 = ''
+          sub_4 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers
+          sub_4.stream do |chunk|
+            response_4 += chunk
+            expect(response_4).to include(conf.header_template)
+          end
+          sub_4.callback do
+            expect(response_4).to include(conf.footer_template)
+            EventMachine.stop
+          end
+        end
+
+        sleep(6)
+
+        response_3 = ''
+        sub_3 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers
+        sub_3.stream do |chunk|
+          response_3 += chunk
+          expect(response_3).to include(conf.header_template)
+        end
+        sub_3.callback do
+          expect(response_3).to include(conf.footer_template)
+        end
+
+      end
+    end
+  end
+end
diff -Naur nginx-1.11.3/nginx-push-stream-module/misc/spec/subscriber/event_source_spec.rb nginx-1.11.3-push/nginx-push-stream-module/misc/spec/subscriber/event_source_spec.rb
--- nginx-1.11.3/nginx-push-stream-module/misc/spec/subscriber/event_source_spec.rb	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/misc/spec/subscriber/event_source_spec.rb	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,435 @@
+require 'spec_helper'
+
+describe "Subscriber Event Source" do
+  let(:config) do
+    {
+      :subscriber_mode => 'eventsource',
+      :header_template => nil,
+      :message_template => nil,
+      :footer_template => nil,
+      :ping_message_interval => nil
+    }
+  end
+
+  it "should use content type as 'event stream'" do
+    channel = 'ch_test_content_type_should_be_event_stream'
+
+    nginx_run_server(config.merge(:header_template => "header")) do |conf|
+      EventMachine.run do
+        source = EventMachine::EventSource.new(nginx_address + '/sub/' + channel.to_s)
+        source.open do
+          EventMachine.stop
+        end
+
+        sub = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get
+        sub.stream do |chunk|
+          expect(sub.response_header["CONTENT_TYPE"]).to eql("text/event-stream; charset=utf-8")
+          source.start
+        end
+      end
+    end
+  end
+
+  it "should split header lines and prefix them by a colon" do
+    channel = 'ch_test_each_line_on_header_template_should_be_prefixed_by_a_colon'
+
+    nginx_run_server(config.merge(:header_template => "header line 1\nheader line 2\rheader line 3\r\nheader line 4")) do |conf|
+      EventMachine.run do
+        sub = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get
+        sub.stream do |chunk|
+          expect(chunk).to eql(": header line 1\n: header line 2\n: header line 3\n: header line 4\n")
+          EventMachine.stop
+        end
+      end
+    end
+  end
+
+  it "should treat escaped new lines on header as single lines" do
+    channel = 'ch_test_escaped_new_lines_on_header_template_should_be_treated_as_single_line'
+
+    nginx_run_server(config.merge(:header_template => "header line 1\\\\nheader line 2")) do |conf|
+      EventMachine.run do
+        sub = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get
+        sub.stream do |chunk|
+          expect(chunk).to eql(": header line 1\\nheader line 2\n")
+          EventMachine.stop
+        end
+      end
+    end
+  end
+
+  it "should split footer lines and prefix them by a colon" do
+    channel = 'ch_test_each_line_on_footer_template_should_be_prefixed_by_a_colon'
+    response = ''
+
+    nginx_run_server(config.merge(:subscriber_connection_ttl => '1s', :footer_template => "footer line 1\nfooter line 2\rfooter line 3\r\nfooter line 4")) do |conf|
+      EventMachine.run do
+        sub = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get
+        sub.stream do |chunk|
+          response += chunk
+        end
+        sub.callback do
+          expect(response).to eql(": \n: footer line 1\n: footer line 2\n: footer line 3\n: footer line 4\n")
+          EventMachine.stop
+        end
+      end
+    end
+  end
+
+  it "should treat escaped new lines on footer as single lines" do
+    channel = 'ch_test_escaped_new_lines_on_footer_template_should_be_treated_as_single_line'
+    response = ''
+
+    nginx_run_server(config.merge(:subscriber_connection_ttl => '1s', :footer_template => "footer line 1\\\\nfooter line 2")) do |conf|
+      EventMachine.run do
+        sub = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get
+        sub.stream do |chunk|
+          response += chunk
+        end
+        sub.callback do
+          expect(response).to eql(": \n: footer line 1\\nfooter line 2\n")
+          EventMachine.stop
+        end
+      end
+    end
+  end
+
+  it "should use default message template without event id" do
+    body = 'test message'
+    channel = 'ch_test_default_message_template_without_event_id'
+    response = ''
+
+    nginx_run_server(config) do |conf|
+      EventMachine.run do
+        source = EventMachine::EventSource.new(nginx_address + '/sub/_' + channel.to_s)
+        source.message do |message|
+          expect(message).to eql(body)
+          publish_message_inline(channel, headers, body)
+        end
+        source.start
+
+        sub = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get
+        sub.stream do |chunk|
+          response += chunk
+          if response.include?("data: ")
+            expect(response).to eql(": \ndata: #{body}\n\n")
+            EventMachine.stop
+          end
+        end
+
+        publish_message_inline("_#{channel}", headers, body)
+      end
+    end
+  end
+
+  it "should use default message template without event type" do
+    body = 'test message'
+    channel = 'ch_test_default_message_template_without_event_type'
+    response = ''
+
+    nginx_run_server(config) do |conf|
+      EventMachine.run do
+        source = EventMachine::EventSource.new(nginx_address + '/sub/_' + channel.to_s)
+        source.message do |message|
+          expect(message).to eql(body)
+          publish_message_inline(channel, headers, body)
+        end
+        source.start
+
+        sub = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get
+        sub.stream do |chunk|
+          response += chunk
+          if response.include?("data: ")
+            expect(response).to eql(": \ndata: #{body}\n\n")
+            EventMachine.stop
+          end
+        end
+
+        publish_message_inline("_#{channel}", headers, body)
+      end
+    end
+  end
+
+  it "should use default message template with event id" do
+    event_id = 'event_id_with_generic_text_01'
+    body = 'test message'
+    channel = 'ch_test_default_message_template_with_event_id'
+    response = ''
+
+    nginx_run_server(config) do |conf|
+      EventMachine.run do
+        source = EventMachine::EventSource.new(nginx_address + '/sub/_' + channel.to_s)
+        source.message do |message|
+          expect(message).to eql(body)
+          expect(source.last_event_id).to eql(event_id)
+          publish_message_inline(channel, headers.merge('Event-Id' => event_id), body)
+        end
+        source.start
+
+        sub = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get
+        sub.stream do |chunk|
+          response += chunk
+          if response.include?("data: ")
+            expect(response).to eql(": \nid: #{event_id}\ndata: #{body}\n\n")
+            EventMachine.stop
+          end
+        end
+
+        publish_message_inline("_#{channel}", headers.merge('Event-Id' => event_id), body)
+      end
+    end
+  end
+
+  it "should use default message template with event type" do
+    event_type = 'event_type_with_generic_text_01'
+    body = 'test message'
+    channel = 'ch_test_default_message_template_with_event_type'
+    response = ''
+
+    nginx_run_server(config) do |conf|
+      EventMachine.run do
+        source = EventMachine::EventSource.new(nginx_address + '/sub/_' + channel.to_s)
+        source.on event_type do |message|
+          expect(message).to eql(body)
+          publish_message_inline(channel, headers.merge('Event-type' => event_type), body)
+        end
+        source.start
+
+        sub = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get
+        sub.stream do |chunk|
+          response += chunk
+          if response.include?("data: ")
+            expect(response).to eql(": \nevent: #{event_type}\ndata: #{body}\n\n")
+            EventMachine.stop
+          end
+        end
+
+        publish_message_inline("_#{channel}", headers.merge('Event-type' => event_type), body)
+      end
+    end
+  end
+
+  it "should use custom message template without event id" do
+    body = 'test message'
+    channel = 'ch_test_custom_message_template_without_event_id'
+    response = ''
+
+    nginx_run_server(config.merge(:message_template => '{\"id\":\"~id~\", \"message\":\"~text~\"}')) do |conf|
+      EventMachine.run do
+        source = EventMachine::EventSource.new(nginx_address + '/sub/_' + channel.to_s)
+        source.message do |message|
+          expect(message).to eql(%({"id":"1", "message":"#{body}"}))
+          publish_message_inline(channel, headers, body)
+        end
+        source.start
+
+        sub = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get
+        sub.stream do |chunk|
+          response += chunk
+          if response.include?("data: ")
+            expect(response).to eql(%(: \ndata: {"id":"1", "message":"#{body}"}\n\n))
+            EventMachine.stop
+          end
+        end
+
+        publish_message_inline("_#{channel}", headers, body)
+      end
+    end
+  end
+
+  it "should use custom message template without event type" do
+    body = 'test message'
+    channel = 'ch_test_custom_message_template_without_event_type'
+    response = ''
+
+    nginx_run_server(config.merge(:message_template => '{\"id\":\"~id~\", \"message\":\"~text~\"}')) do |conf|
+      EventMachine.run do
+        source = EventMachine::EventSource.new(nginx_address + '/sub/_' + channel.to_s)
+        source.message do |message|
+          expect(message).to eql(%({"id":"1", "message":"#{body}"}))
+          publish_message_inline(channel, headers, body)
+        end
+        source.start
+
+        sub = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get
+        sub.stream do |chunk|
+          response += chunk
+          if response.include?("data: ")
+            expect(response).to eql(%(: \ndata: {"id":"1", "message":"#{body}"}\n\n))
+            EventMachine.stop
+          end
+        end
+
+        publish_message_inline("_#{channel}", headers, body)
+      end
+    end
+  end
+
+  it "should use custom message template with event id" do
+    event_id = 'event_id_with_generic_text_01'
+    body = 'test message'
+    channel = 'ch_test_custom_message_template_with_event_id'
+    response = ''
+
+    nginx_run_server(config.merge(:message_template => '{\"id\":\"~id~\", \"message\":\"~text~\"}')) do |conf|
+      EventMachine.run do
+        source = EventMachine::EventSource.new(nginx_address + '/sub/_' + channel.to_s)
+        source.message do |message|
+          expect(message).to eql(%({"id":"1", "message":"#{body}"}))
+          expect(source.last_event_id).to eql(event_id)
+          publish_message_inline(channel, headers.merge('Event-Id' => event_id), body)
+        end
+        source.start
+
+        sub = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get
+        sub.stream do |chunk|
+          response += chunk
+          if response.include?("data: ")
+            expect(response).to eql(%(: \nid: #{event_id}\ndata: {"id":"1", "message":"#{body}"}\n\n))
+            EventMachine.stop
+          end
+        end
+
+        publish_message_inline("_#{channel}", headers.merge('Event-Id' => event_id), body)
+      end
+    end
+  end
+
+  it "should use custom message template with event type" do
+    event_type = 'event_type_with_generic_text_01'
+    body = 'test message'
+    channel = 'ch_test_custom_message_template_with_event_type'
+    response = ''
+
+    nginx_run_server(config.merge(:message_template => '{\"id\":\"~id~\", \"message\":\"~text~\"}')) do |conf|
+      EventMachine.run do
+        source = EventMachine::EventSource.new(nginx_address + '/sub/_' + channel.to_s)
+        source.on event_type do |message|
+          expect(message).to eql(%({"id":"1", "message":"#{body}"}))
+          publish_message_inline(channel, headers.merge('Event-type' => event_type), body)
+        end
+        source.start
+
+        sub = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get
+        sub.stream do |chunk|
+          response += chunk
+          if response.include?("data: ")
+            expect(response).to eql(%(: \nevent: #{event_type}\ndata: {"id":"1", "message":"#{body}"}\n\n))
+            EventMachine.stop
+          end
+        end
+
+        publish_message_inline("_#{channel}", headers.merge('Event-type' => event_type), body)
+      end
+    end
+  end
+
+  it "should apply the message template to each line on posted message" do
+    body = "line 1\nline 2\rline 3\r\nline 4"
+    channel = 'ch_test_each_line_on_posted_message_should_be_applied_to_template'
+
+    nginx_run_server(config) do |conf|
+      EventMachine.run do
+        source = EventMachine::EventSource.new(nginx_address + '/sub/_' + channel.to_s)
+        source.message do |message|
+          expect(message).to eql("line 1\nline 2\nline 3\nline 4")
+          publish_message_inline(channel, headers, body)
+        end
+        source.start
+
+        sub = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get
+        sub.stream do |chunk|
+          if chunk.include?("line 4")
+            expect(chunk).to eql("data: line 1\ndata: line 2\ndata: line 3\ndata: line 4\n\n")
+            EventMachine.stop
+          end
+        end
+
+        publish_message_inline("_#{channel}", headers, body)
+      end
+    end
+  end
+
+  it "should treat escaped new lines on posted message as single lines" do
+    body = "line 1\\nline 2"
+    channel = 'ch_test_escaped_new_lines_on_posted_message_should_be_treated_as_single_line'
+
+    nginx_run_server(config) do |conf|
+      EventMachine.run do
+        source = EventMachine::EventSource.new(nginx_address + '/sub/_' + channel.to_s)
+        source.message do |message|
+          expect(message).to eql(body)
+          publish_message_inline(channel, headers, body)
+        end
+        source.start
+
+        sub = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get
+        sub.stream do |chunk|
+          if chunk.include?("line 2")
+            expect(chunk).to eql("data: line 1\\nline 2\n\n")
+            EventMachine.stop
+          end
+        end
+
+        publish_message_inline("_#{channel}", headers, body)
+      end
+    end
+  end
+
+  it "should receive ping message" do
+    channel = 'ch_test_ping_message_on_event_source'
+
+    nginx_run_server(config.merge(:ping_message_interval => '1s', :message_template => '{\"id\":\"~id~\", \"message\":\"~text~\"}')) do |conf|
+      EventMachine.run do
+        sub = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get
+        sub.stream do |chunk|
+          if chunk.include?("-1")
+            expect(chunk).to eql(": -1\n")
+            EventMachine.stop
+          end
+        end
+      end
+    end
+  end
+
+  it "should not reaplly formatter to header, message or footer template when inside an if" do
+    channel = 'ch_test_not_reaplly_formatter_on_header_message_footer_template'
+    body = 'test message'
+    response = ''
+    extra_location = %(
+      location ~ /ev/(.*) {
+        push_stream_subscriber "eventsource";
+        push_stream_channels_path "$1";
+        if ($arg_tests = "on") {
+          push_stream_channels_path "test_$1";
+        }
+      }
+    )
+
+    nginx_run_server(config.merge(:extra_location => extra_location, :header_template => "header", :message_template => "msg ~text~", :footer_template => "footer", :subscriber_connection_ttl => '1s')) do |conf|
+      EventMachine.run do
+        sub = EventMachine::HttpRequest.new(nginx_address + '/ev/' + channel.to_s).get
+        sub.stream do |chunk|
+          response += chunk
+          if response.include?("footer")
+            expect(response).to eql(": header\ndata: msg #{body}\n\n: footer\n")
+
+            response = ''
+            sub_1 = EventMachine::HttpRequest.new(nginx_address + '/ev/' + channel.to_s + '?tests=on').get
+            sub_1.stream do |chunk_1|
+              response += chunk_1
+              if response.include?("footer")
+                expect(response).to eql(": header\ndata: msg #{body}\n\n: footer\n")
+                EventMachine.stop
+              end
+            end
+
+            publish_message_inline("test_" + channel, headers, body)
+          end
+        end
+
+        publish_message_inline(channel, headers, body)
+      end
+    end
+  end
+end
diff -Naur nginx-1.11.3/nginx-push-stream-module/misc/spec/subscriber/long_polling_spec.rb nginx-1.11.3-push/nginx-push-stream-module/misc/spec/subscriber/long_polling_spec.rb
--- nginx-1.11.3/nginx-push-stream-module/misc/spec/subscriber/long_polling_spec.rb	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/misc/spec/subscriber/long_polling_spec.rb	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,408 @@
+require 'spec_helper'
+
+describe "Subscriber Properties" do
+
+  shared_examples_for "long polling location" do
+
+    it "should disconnect after receive a message" do
+      channel = 'ch_test_disconnect_after_receive_a_message_when_longpolling_is_on'
+      body = 'body'
+      response = ""
+
+      nginx_run_server(config) do |conf|
+        EventMachine.run do
+          sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers
+          sub_1.stream do |chunk|
+            response += chunk
+          end
+          sub_1.callback do |chunk|
+            expect(response).to eql("#{body}")
+
+            sent_headers = headers.merge({'If-Modified-Since' => sub_1.response_header['LAST_MODIFIED'], 'If-None-Match' => sub_1.response_header['ETAG']})
+            response = ""
+            sub_2 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => sent_headers
+            sub_2.stream do |chunk2|
+              response += chunk2
+            end
+            sub_2.callback do
+              expect(response).to eql("#{body} 1")
+              EventMachine.stop
+            end
+
+            publish_message_inline(channel, {}, body + " 1")
+          end
+
+          publish_message_inline(channel, {}, body)
+        end
+      end
+    end
+
+    it "should disconnect after receive old messages" do
+      channel = 'ch_test_disconnect_after_receive_old_messages_by_last_event_id_when_longpolling_is_on'
+      response = ""
+
+      nginx_run_server(config) do |conf|
+        EventMachine.run do
+          publish_message(channel, {'Event-Id' => 'event 1'}, 'msg 1')
+          publish_message(channel, {'Event-Id' => 'event 2'}, 'msg 2')
+          publish_message(channel, {}, 'msg 3')
+          publish_message(channel, {'Event-Id' => 'event 3'}, 'msg 4')
+
+          sub = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers.merge({'Last-Event-Id' => 'event 2'})
+          sub.stream do |chunk|
+            response += chunk
+          end
+          sub.callback do |chunk|
+            expect(response).to eql("msg 3msg 4")
+            EventMachine.stop
+          end
+        end
+      end
+    end
+
+    it "should disconnect after timeout is reached" do
+      channel = 'ch_test_disconnect_long_polling_subscriber_when_longpolling_timeout_is_set'
+
+      start = Time.now
+      nginx_run_server(config.merge(:subscriber_connection_ttl => "10s"), :timeout => 30) do |conf|
+        EventMachine.run do
+          sub = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s, :inactivity_timeout => 15).get :head => headers
+          sub.callback do
+            stop = Time.now
+            expect(time_diff_sec(start, stop)).to be_in_the_interval(10, 10.5)
+            expect(sub).to be_http_status(304).without_body
+            expect(Time.parse(sub.response_header['LAST_MODIFIED'].to_s).utc.to_i).to be_in_the_interval(Time.now.utc.to_i-1, Time.now.utc.to_i)
+            expect(sub.response_header['ETAG'].to_s).to eql("W/0")
+            EventMachine.stop
+          end
+        end
+      end
+    end
+
+    it "should overwrite subscriber timeout with long polling timeout" do
+      channel = 'ch_test_disconnect_long_polling_subscriber_when_longpolling_timeout_is_set'
+
+      start = Time.now
+      nginx_run_server(config.merge(:subscriber_connection_ttl => "10s", :longpolling_connection_ttl => "5s"), :timeout => 10) do |conf|
+        EventMachine.run do
+          sub = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers
+          sub.callback do
+            stop = Time.now
+            expect(time_diff_sec(start, stop)).to be_in_the_interval(5, 5.5)
+            expect(sub).to be_http_status(304).without_body
+            expect(Time.parse(sub.response_header['LAST_MODIFIED'].to_s).utc.to_i).to be_in_the_interval(Time.now.utc.to_i-1, Time.now.utc.to_i)
+            expect(sub.response_header['ETAG'].to_s).to eql("W/0")
+            EventMachine.stop
+          end
+        end
+      end
+    end
+
+    it "should disconnet after timeout be reached when only long polling timeout is set" do
+      channel = 'ch_test_disconnect_long_polling_subscriber_when_only_longpolling_timeout_is_set'
+
+      start = Time.now
+      nginx_run_server(config.merge(:subscriber_connection_ttl => nil, :longpolling_connection_ttl => "3s")) do |conf|
+        EventMachine.run do
+          sub = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers
+          sub.callback do
+            stop = Time.now
+            expect(time_diff_sec(start, stop)).to be_in_the_interval(3, 3.5)
+            expect(sub).to be_http_status(304).without_body
+            expect(Time.parse(sub.response_header['LAST_MODIFIED'].to_s).utc.to_i).to be_in_the_interval(Time.now.utc.to_i-1, Time.now.utc.to_i)
+            expect(sub.response_header['ETAG'].to_s).to eql("W/0")
+            EventMachine.stop
+          end
+        end
+      end
+    end
+
+    it "should not receive ping message" do
+      channel = 'ch_test_not_receive_ping_message'
+
+      start = Time.now
+      nginx_run_server(config.merge(:subscriber_connection_ttl => "5s", :ping_message_interval => "1s"), :timeout => 10) do |conf|
+        EventMachine.run do
+          sub = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers
+          sub.callback do
+            stop = Time.now
+            expect(time_diff_sec(start, stop)).to be_in_the_interval(5, 5.5)
+            expect(sub).to be_http_status(304).without_body
+            EventMachine.stop
+          end
+        end
+      end
+    end
+
+    it "should receive a timed out message when timeout_with_body is on" do
+      channel = 'ch_test_disconnect_long_polling_subscriber_when_longpolling_timeout_is_set'
+      callback_function_name = "callback_function"
+
+      start = Time.now
+      nginx_run_server(config.merge(:subscriber_connection_ttl => "1s", :timeout_with_body => 'on', :message_template => '{\"id\":\"~id~\", \"message\":\"~text~\", \"channel\":\"~channel~\", \"tag\":\"~tag~\", \"time\":\"~time~\"}'), :timeout => 30) do |conf|
+        EventMachine.run do
+          sub = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers
+          sub.callback do
+            stop = Time.now
+            expect(time_diff_sec(start, stop)).to be_in_the_interval(1, 1.5)
+            expect(sub).to be_http_status(200)
+            response = JSON.parse(sub.response)
+            expect(response["id"]).to eql("-3")
+            expect(response["message"]).to eql("Timed out")
+            expect(response["channel"]).to eql("")
+            expect(response["tag"]).to eql("0")
+            expect(response["time"]).to eql("Thu, 01 Jan 1970 00:00:00 GMT")
+            expect(Time.parse(sub.response_header['LAST_MODIFIED'].to_s).utc.to_i).to be_in_the_interval(Time.now.utc.to_i-1, Time.now.utc.to_i)
+            expect(sub.response_header['ETAG'].to_s).to eql("W/0")
+
+            sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s + '?callback=' + callback_function_name).get :head => headers
+            sub_1.callback do
+              expect(sub_1.response).to eql(%(callback_function([{"id":"-3", "message":"Timed out", "channel":"", "tag":"0", "time":"Thu, 01 Jan 1970 00:00:00 GMT"}]);))
+              EventMachine.stop
+            end
+          end
+        end
+      end
+    end
+
+    it "should receive messages when connected in more than one channel" do
+      channel_1 = 'ch_test_receiving_messages_when_connected_in_more_then_one_channel_1'
+      channel_2 = 'ch_test_receiving_messages_when_connected_in_more_then_one_channel_2'
+      body = 'published message'
+
+      nginx_run_server(config.merge(:store_messages => "on", :message_template => '{\"id\":\"~id~\", \"message\":\"~text~\", \"channel\":\"~channel~\"}')) do |conf|
+        EventMachine.run do
+          sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel_1.to_s + '/' + channel_2.to_s).get :head => headers.merge({'If-Modified-Since' => 'Thu, 1 Jan 1970 00:00:00 GMT', 'If-None-Match' => 0})
+          sub_1.callback do
+            expect(sub_1).to be_http_status(200)
+            response = JSON.parse(sub_1.response)
+            expect(response["channel"]).to eql(channel_1)
+
+            sub_2 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel_1.to_s + '/' + channel_2.to_s).get :head => headers.merge({'If-Modified-Since' => sub_1.response_header['LAST_MODIFIED'], 'If-None-Match' => sub_1.response_header['ETAG']})
+            sub_2.callback do
+              expect(sub_2).to be_http_status(200)
+              response = JSON.parse(sub_2.response)
+              expect(response["channel"]).to eql(channel_2)
+              expect(sub_2.response_header['ETAG'].sub("W/", "").to_i).to eql(sub_1.response_header['ETAG'].sub("W/", "").to_i + 1)
+
+              EventMachine.stop
+            end
+          end
+
+          EM.add_timer(0.5) do
+            publish_message(channel_1.to_s, headers, body)
+            publish_message(channel_2.to_s, headers, body)
+          end
+        end
+      end
+    end
+
+    it "should accept delete a channel with a long polling subscriber" do
+      channel = 'ch_test_delete_channel_with_long_polling_subscriber'
+      callback_function_name = "callback_function"
+
+      resp = ""
+      nginx_run_server(config.merge(:publisher_mode => 'admin', :message_template => '{\"id\":\"~id~\", \"message\":\"~text~\", \"channel\":\"~channel~\"}')) do |conf|
+        EventMachine.run do
+          sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers
+          sub_1.callback do
+            expect(sub_1).to be_http_status(200)
+            response = JSON.parse(sub_1.response)
+            expect(response["channel"]).to eql(channel)
+            expect(response["id"].to_i).to eql(-2)
+          end
+
+          sub_2 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s + '?callback=' + callback_function_name).get :head => headers
+          sub_2.callback do
+            expect(sub_2.response).to eql(%(#{callback_function_name}([{"id":"-2", "message":"Channel deleted", "channel":"ch_test_delete_channel_with_long_polling_subscriber"}]);))
+            EventMachine.stop
+          end
+
+          EM.add_timer(0.5) do
+            pub = EventMachine::HttpRequest.new(nginx_address + '/pub?id=' + channel.to_s).delete :head => headers
+            pub.callback do
+              expect(pub).to be_http_status(200).without_body
+              expect(pub.response_header['X_NGINX_PUSHSTREAM_EXPLAIN']).to eql("Channel deleted.")
+            end
+          end
+        end
+      end
+    end
+
+    it "should accept a callback parameter to be used with JSONP" do
+      channel = 'ch_test_return_message_using_function_name_specified_in_callback_parameter'
+      body = 'body'
+      response = ""
+      callback_function_name = "callback_function"
+
+      nginx_run_server(config) do |conf|
+        EventMachine.run do
+          sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s + '?callback=' + callback_function_name).get :head => headers
+          sub_1.callback do
+            expect(sub_1.response).to eql("#{callback_function_name}([#{body}]);")
+            EventMachine.stop
+          end
+
+          publish_message_inline(channel, {}, body)
+        end
+      end
+    end
+
+    it "should return old messages using function name specified in callback parameter grouping in one answer" do
+      channel = 'ch_test_return_old_messages_using_function_name_specified_in_callback_parameter_grouping_in_one_answer'
+      body = 'body'
+      response = ""
+      callback_function_name = "callback_function"
+
+      nginx_run_server(config) do |conf|
+        EventMachine.run do
+          publish_message(channel, {'Event-Id' => 'event_id'}, body)
+          publish_message(channel, {}, body + "1")
+
+          sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s + '.b2' + '?callback=' + callback_function_name).get :head => headers
+          sub_1.callback do
+            expect(sub_1.response).to eql("#{callback_function_name}([#{body},#{body + "1"}]);")
+
+            sub_2 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s + '?callback=' + callback_function_name).get :head => headers.merge({'Last-Event-Id' => 'event_id'})
+            sub_2.callback do
+              expect(sub_2.response).to eql("#{callback_function_name}([#{body + "1"}]);")
+
+              sub_3 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s + '?callback=' + callback_function_name).get :head => headers.merge({'If-Modified-Since' => Time.at(0).utc.strftime("%a, %d %b %Y %T %Z")})
+              sub_3.callback do
+                expect(sub_3.response).to eql("#{callback_function_name}([#{body},#{body + "1"}]);")
+
+                EventMachine.stop
+              end
+            end
+          end
+        end
+      end
+    end
+
+    it "should return messages from different channels on JSONP response" do
+      channel_1 = 'ch_test_jsonp_ch1'
+      channel_2 = 'ch_test_jsonp_ch2'
+      channel_3 = 'ch_test_jsonp_ch3'
+      body = 'body'
+      response = ""
+      callback_function_name = "callback_function"
+
+      nginx_run_server(config) do |conf|
+        EventMachine.run do
+          publish_message(channel_1, {}, body + "1_1")
+          publish_message(channel_2, {}, body + "1_2")
+          publish_message(channel_3, {}, body + "1_3")
+          publish_message(channel_1, {}, body + "2_1")
+          publish_message(channel_2, {}, body + "2_2")
+          publish_message(channel_3, {}, body + "2_3")
+          publish_message(channel_1, {}, body + "3_1")
+          publish_message(channel_2, {}, body + "3_2")
+          publish_message(channel_3, {}, body + "3_3")
+
+          sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel_1.to_s + '.b3/' + channel_2.to_s + '.b3/' + channel_3.to_s + '.b3' + '?callback=' + callback_function_name).get :head => headers
+          sub_1.callback do
+            expect(sub_1.response).to eql("#{callback_function_name}([#{body}1_1,#{body}2_1,#{body}3_1,#{body}1_2,#{body}2_2,#{body}3_2,#{body}1_3,#{body}2_3,#{body}3_3]);")
+            EventMachine.stop
+          end
+        end
+      end
+    end
+
+    it "should force content_type to be application/javascript when using function name specified in callback parameter" do
+      channel = 'test_force_content_type_to_be_application_javascript_when_using_function_name_specified_in_callback_parameter_when_polling'
+      body = 'body'
+      response = ""
+      callback_function_name = "callback_function"
+
+      nginx_run_server(config.merge({:content_type => "anything/value"})) do |conf|
+        EventMachine.run do
+          sent_headers = headers.merge({'accept' => 'otherknown/value'})
+          sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s + '?callback=' + callback_function_name).get :head => sent_headers
+          sub_1.callback do
+            expect(sub_1.response_header['CONTENT_TYPE']).to eql('application/javascript')
+            EventMachine.stop
+          end
+          publish_message_inline(channel, {}, body)
+        end
+      end
+    end
+
+    it "should not cache the response" do
+      channel = 'ch_test_not_cache_the_response'
+
+      nginx_run_server(config.merge(:longpolling_connection_ttl => '1s')) do |conf|
+        EventMachine.run do
+          sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers
+          sub_1.callback do
+            expect(sub_1.response_header["EXPIRES"]).to eql("Thu, 01 Jan 1970 00:00:01 GMT")
+            expect(sub_1.response_header["CACHE_CONTROL"]).to eql("no-cache, no-store, must-revalidate")
+            EventMachine.stop
+          end
+        end
+      end
+    end
+
+    it "should accept return content gzipped" do
+      channel = 'ch_test_get_content_gzipped'
+      body = 'body'
+      actual_response = ''
+
+      nginx_run_server(config.merge({:gzip => "on"})) do |conf|
+        EventMachine.run do
+          sent_headers = headers.merge({'accept-encoding' => 'gzip, compressed'})
+          sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => sent_headers, :decoding => false
+          sub_1.stream do |chunk|
+            actual_response << chunk
+          end
+          sub_1.callback do
+            expect(sub_1).to be_http_status(200)
+
+            expect(sub_1.response_header["ETAG"]).to match(/W\/\d+/)
+            expect(sub_1.response_header["CONTENT_ENCODING"]).to eql("gzip")
+            actual_response = Zlib::GzipReader.new(StringIO.new(actual_response)).read
+
+            expect(actual_response).to eql("#{body}")
+            EventMachine.stop
+          end
+          publish_message_inline(channel, {}, body)
+        end
+      end
+    end
+  end
+
+  context "when using subscriber push mode config" do
+    let(:config) do
+      {
+        :ping_message_interval => nil,
+        :header_template => nil,
+        :footer_template => nil,
+        :message_template => nil,
+        :subscriber_mode => 'long-polling'
+      }
+    end
+
+    let(:headers) do
+      {'accept' => 'text/html'}
+    end
+
+    it_should_behave_like "long polling location"
+  end
+
+  context "when using push mode header" do
+    let(:config) do
+      {
+        :ping_message_interval => nil,
+        :header_template => nil,
+        :footer_template => nil,
+        :message_template => nil,
+        :subscriber_mode => nil
+      }
+    end
+
+    let(:headers) do
+      {'accept' => 'text/html', 'X-Nginx-PushStream-Mode' => 'long-polling'}
+    end
+
+    it_should_behave_like "long polling location"
+  end
+end
diff -Naur nginx-1.11.3/nginx-push-stream-module/misc/spec/subscriber/padding_by_user_agent_spec.rb nginx-1.11.3-push/nginx-push-stream-module/misc/spec/subscriber/padding_by_user_agent_spec.rb
--- nginx-1.11.3/nginx-push-stream-module/misc/spec/subscriber/padding_by_user_agent_spec.rb	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/misc/spec/subscriber/padding_by_user_agent_spec.rb	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,207 @@
+require 'spec_helper'
+
+describe "Subscriber Padding by user agent" do
+  let(:default_config) do
+    {
+      :padding_by_user_agent => "[T|t]est 1,0,508",
+      :user_agent => nil,
+      :subscriber_connection_ttl => '1s',
+      :header_template => nil,
+      :message_template => nil,
+      :footer_template => nil
+    }
+  end
+
+  shared_examples_for "apply padding" do
+    it "should apply a padding to the header" do
+      channel = 'ch_test_header_padding'
+
+      nginx_run_server(config.merge(:header_template => "0123456789", :padding_by_user_agent => "[T|t]est 1,1024,508:[T|t]est 2,4097,0")) do |conf|
+        EventMachine.run do
+          expected_size = conf.header_template.size + header_delta
+
+          sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers.merge("User-Agent" => "Test 1")
+          sub_1.callback do
+            expect(sub_1).to be_http_status(200)
+            expect(sub_1.response.size).to eql(1100 + expected_size)
+            expect(sub_1.response).to match padding_pattern
+
+            sub_2 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers.merge("User-Agent" => "Test 2")
+            sub_2.callback do
+              expect(sub_2).to be_http_status(200)
+              expect(sub_2.response.size).to eql(4097 + expected_size)
+
+              sub_3 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers.merge("User-Agent" => "Test 3")
+              sub_3.callback do
+                expect(sub_3).to be_http_status(200)
+                expect(sub_3.response.size).to eql(expected_size)
+
+                EventMachine.stop
+              end
+            end
+          end
+        end
+      end
+    end
+
+    it "should apply a padding to the message" do
+      channel = 'ch_test_message_padding'
+
+      body = "0123456789"
+
+      nginx_run_server(config) do |conf|
+        EventMachine.run do
+          expected_size = body.size + header_delta + body_delta
+
+          sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers.merge("User-Agent" => "Test 1")
+          sub_1.callback {
+            expect(sub_1).to be_http_status(200)
+            expect(sub_1.response.size).to eql(500 + expected_size)
+            expect(sub_1.response).to match padding_pattern
+
+            sub_2 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers.merge("User-Agent" => "Test 2")
+            sub_2.callback {
+              expect(sub_2).to be_http_status(200)
+              expect(sub_2.response.size).to eql(expected_size)
+
+              sub_3 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers.merge("User-Agent" => "Test 3")
+              sub_3.callback {
+                expect(sub_3).to be_http_status(200)
+                expect(sub_3.response.size).to eql(expected_size)
+
+                EventMachine.stop
+              }
+              publish_message_inline(channel, headers, body)
+            }
+            publish_message_inline(channel, headers, body)
+          }
+          publish_message_inline(channel, headers, body)
+        end
+      end
+    end
+
+    it "should apply a padding to the message with different sizes" do
+      channel = 'ch_test_message_padding_with_different_sizes'
+
+      nginx_run_server(config.merge(:padding_by_user_agent => "[T|t]est 1,0,545"), :timeout => 10) do |conf|
+        EventMachine.run do
+          i = 1
+          expected_padding = 545
+          expected_size = header_delta + body_delta
+
+          sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers.merge("User-Agent" => "Test 1")
+          sub_1.callback do
+            expect(sub_1).to be_http_status(200)
+            expect(sub_1.response.size).to eql(expected_padding + i + expected_size)
+            expect(sub_1.response).to match padding_pattern
+
+            i = 105
+            expected_padding = 600 - ((i/100).to_i * 100)
+
+            sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers.merge("User-Agent" => "Test 1")
+            sub_1.callback do
+              expect(sub_1).to be_http_status(200)
+              expect(sub_1.response.size).to eql(expected_padding + i + expected_size)
+
+              i = 221
+              expected_padding = 600 - ((i/100).to_i * 100)
+
+              sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers.merge("User-Agent" => "Test 1")
+              sub_1.callback do
+                expect(sub_1).to be_http_status(200)
+                expect(sub_1.response.size).to eql(expected_padding + i + expected_size)
+
+                i = 331
+                expected_padding = 600 - ((i/100).to_i * 100)
+
+                sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers.merge("User-Agent" => "Test 1")
+                sub_1.callback do
+                  expect(sub_1).to be_http_status(200)
+                  expect(sub_1.response.size).to eql(expected_padding + i + expected_size)
+
+                  i = 435
+                  expected_padding = 600 - ((i/100).to_i * 100)
+
+                  sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers.merge("User-Agent" => "Test 1")
+                  sub_1.callback do
+                    expect(sub_1).to be_http_status(200)
+                    expect(sub_1.response.size).to eql(expected_padding + i + expected_size)
+
+                    i = 502
+                    expected_padding = 600 - ((i/100).to_i * 100)
+
+                    sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers.merge("User-Agent" => "Test 1")
+                    sub_1.callback do
+                      expect(sub_1).to be_http_status(200)
+                      expect(sub_1.response.size).to eql(expected_padding + i + expected_size)
+
+                      i = 550
+
+                      sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers.merge("User-Agent" => "Test 1")
+                      sub_1.callback do
+                        expect(sub_1).to be_http_status(200)
+                        expect(sub_1.response.size).to eql(i + expected_size)
+
+                        EventMachine.stop
+                      end
+                      publish_message_inline(channel, headers, "_" * i)
+                    end
+                    publish_message_inline(channel, headers, "_" * i)
+                  end
+                  publish_message_inline(channel, headers, "_" * i)
+                end
+                publish_message_inline(channel, headers, "_" * i)
+              end
+              publish_message_inline(channel, headers, "_" * i)
+            end
+            publish_message_inline(channel, headers, "_" * i)
+          end
+          publish_message_inline(channel, headers, "_" * i)
+        end
+      end
+    end
+
+    it "should accept the user agent set by a complex value" do
+      channel = 'ch_test_user_agent_by_complex_value'
+
+      nginx_run_server(config.merge(:padding_by_user_agent => "[T|t]est 1,1024,512", :user_agent => "$arg_ua", :header_template => "0123456789"), :timeout => 10) do |conf|
+        EventMachine.run do
+          expected_size = conf.header_template.size + header_delta
+
+          sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s + '?ua=test 1').get :head => headers
+          sub_1.callback do
+            expect(sub_1).to be_http_status(200)
+            expect(sub_1.response.size).to eql(1024 + expected_size)
+            expect(sub_1.response).to match padding_pattern
+
+            sub_2 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s + '?ua=test 2').get :head => headers
+            sub_2.callback do
+              expect(sub_2).to be_http_status(200)
+              expect(sub_2.response.size).to eql(expected_size)
+
+              EventMachine.stop
+            end
+          end
+        end
+      end
+    end
+  end
+
+  describe "for non EventSource mode" do
+    let(:config) { default_config }
+    let(:padding_pattern) { /(\r\n)+\r\n\r\n\r\n$/ }
+    let(:header_delta) { 0 }
+    let(:body_delta) { 0 }
+
+    it_should_behave_like "apply padding"
+  end
+
+  describe "for EventSource mode" do
+    let(:config) { default_config.merge(:subscriber_mode => "eventsource") }
+    let(:padding_pattern) { /(:::)+\n$/ }
+    let(:header_delta) { 3 }
+    let(:body_delta) { 8 }
+
+    it_should_behave_like "apply padding"
+  end
+end
diff -Naur nginx-1.11.3/nginx-push-stream-module/misc/spec/subscriber/polling_spec.rb nginx-1.11.3-push/nginx-push-stream-module/misc/spec/subscriber/polling_spec.rb
--- nginx-1.11.3/nginx-push-stream-module/misc/spec/subscriber/polling_spec.rb	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/misc/spec/subscriber/polling_spec.rb	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,214 @@
+require 'spec_helper'
+
+describe "Subscriber Properties" do
+
+  shared_examples_for "polling location" do
+
+    describe "when has no messages" do
+
+      it "should receive a 304" do
+        channel = 'ch_test_receive_a_304_when_has_no_messages'
+
+        nginx_run_server(config) do |conf|
+          EventMachine.run do
+            sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers
+            sub_1.callback do
+              expect(sub_1).to be_http_status(304).without_body
+              expect(sub_1.response_header['LAST_MODIFIED'].to_s).to eql("")
+              expect(sub_1.response_header['ETAG'].to_s).to eql("")
+              EventMachine.stop
+            end
+          end
+        end
+      end
+
+      it "should receive a 304 keeping sent headers" do
+        channel = 'ch_test_receive_a_304_when_has_no_messages_keeping_headers'
+
+        sent_headers = headers.merge({'If-Modified-Since' => Time.now.utc.strftime("%a, %d %b %Y %T %Z"), 'If-None-Match' => 'W/3'})
+        nginx_run_server(config) do |conf|
+          EventMachine.run do
+            sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => sent_headers
+            sub_1.callback do
+              expect(sub_1).to be_http_status(304).without_body
+              expect(Time.parse(sub_1.response_header['LAST_MODIFIED'].to_s)).to eql(Time.parse(sent_headers['If-Modified-Since']))
+              expect(sub_1.response_header['ETAG'].to_s).to eql(sent_headers['If-None-Match'])
+              EventMachine.stop
+            end
+          end
+        end
+      end
+
+    end
+
+    describe "when has messages" do
+
+      it "should receive specific headers" do
+        channel = 'ch_test_receive_specific_headers_when_has_messages'
+        body = 'body'
+
+        nginx_run_server(config) do |conf|
+          EventMachine.run do
+            publish_message(channel, {}, body)
+
+            sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers.merge({'If-Modified-Since' => Time.at(0).utc.strftime("%a, %d %b %Y %T %Z")})
+            sub_1.callback do
+              expect(sub_1).to be_http_status(200)
+              expect(sub_1.response_header['LAST_MODIFIED'].to_s).not_to eql("")
+              expect(sub_1.response_header['ETAG'].to_s).to eql("W/1")
+              expect(sub_1.response).to eql("#{body}")
+              EventMachine.stop
+            end
+          end
+        end
+      end
+
+      it "should accept a callback parameter to works with JSONP" do
+        channel = 'ch_test_return_message_using_function_name_specified_in_callback_parameter_when_polling'
+        body = 'body'
+        response = ""
+        callback_function_name = "callback_function"
+
+        nginx_run_server(config) do |conf|
+          EventMachine.run do
+            publish_message(channel, {}, body)
+            sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s + '?callback=' + callback_function_name).get :head => headers.merge({'If-Modified-Since' => Time.at(0).utc.strftime("%a, %d %b %Y %T %Z")})
+            sub_1.callback do
+              expect(sub_1.response).to eql("#{callback_function_name}([#{body}]);")
+              EventMachine.stop
+            end
+          end
+        end
+      end
+
+      it "should return old messages using function name specified in callback parameter grouping in one answer" do
+        channel = 'ch_test_return_old_messages_using_function_name_specified_in_callback_parameter_grouping_in_one_answer'
+        body = 'body'
+        response = ""
+        callback_function_name = "callback_function"
+
+        nginx_run_server(config) do |conf|
+          EventMachine.run do
+            publish_message(channel, {'Event-Id' => 'event_id'}, body)
+            publish_message(channel, {}, body + "1")
+
+            sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s + '.b2' + '?callback=' + callback_function_name).get :head => headers
+            sub_1.callback do
+              expect(sub_1.response).to eql("#{callback_function_name}([#{body},#{body + "1"}]);")
+
+              sub_2 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s + '?callback=' + callback_function_name).get :head => headers.merge({'Last-Event-Id' => 'event_id'})
+              sub_2.callback do
+                expect(sub_2.response).to eql("#{callback_function_name}([#{body + "1"}]);")
+
+                sub_3 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s + '?callback=' + callback_function_name).get :head => headers.merge({'If-Modified-Since' => Time.at(0).utc.strftime("%a, %d %b %Y %T %Z")})
+                sub_3.callback do
+                  expect(sub_3.response).to eql("#{callback_function_name}([#{body},#{body + "1"}]);")
+
+                  EventMachine.stop
+                end
+              end
+            end
+          end
+        end
+      end
+
+      it "should force content_type to be application/javascript when using function name specified in callback parameter" do
+        channel = 'test_force_content_type_to_be_application_javascript_when_using_function_name_specified_in_callback_parameter_when_polling'
+        body = 'body'
+        response = ""
+        callback_function_name = "callback_function"
+
+        nginx_run_server(config.merge({:content_type => "anything/value"})) do |conf|
+          EventMachine.run do
+            publish_message(channel, {}, body)
+            sent_headers = headers.merge({'accept' => 'otherknown/value'})
+            sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s + '?callback=' + callback_function_name).get :head => sent_headers
+            sub_1.callback do
+              expect(sub_1.response_header['CONTENT_TYPE']).to eql('application/javascript')
+              EventMachine.stop
+            end
+          end
+        end
+      end
+
+      it "should accept return content gzipped" do
+        channel = 'ch_test_get_content_gzipped'
+        body = 'body'
+        actual_response = ''
+
+        nginx_run_server(config.merge({:gzip => "on"})) do |conf|
+          EventMachine.run do
+            publish_message(channel, {}, body)
+
+            sent_headers = headers.merge({'accept-encoding' => 'gzip, compressed', 'If-Modified-Since' => Time.at(0).utc.strftime("%a, %d %b %Y %T %Z")})
+            sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => sent_headers, :decoding => false
+            sub_1.stream do |chunk|
+              actual_response << chunk
+            end
+            sub_1.callback do
+              expect(sub_1).to be_http_status(200)
+
+              expect(sub_1.response_header["ETAG"]).to match(/W\/\d+/)
+              expect(sub_1.response_header["CONTENT_ENCODING"]).to eql("gzip")
+              actual_response = Zlib::GzipReader.new(StringIO.new(actual_response)).read
+
+              expect(actual_response).to eql("#{body}")
+              EventMachine.stop
+            end
+          end
+        end
+      end
+    end
+
+    it "should not cache the response" do
+      channel = 'ch_test_not_cache_the_response'
+
+      nginx_run_server(config) do |conf|
+        EventMachine.run do
+          sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers
+          sub_1.callback do
+            expect(sub_1.response_header["EXPIRES"]).to eql("Thu, 01 Jan 1970 00:00:01 GMT")
+            expect(sub_1.response_header["CACHE_CONTROL"]).to eql("no-cache, no-store, must-revalidate")
+            EventMachine.stop
+          end
+        end
+      end
+    end
+  end
+
+  context "when using subscriber push mode config" do
+    let(:config) do
+      {
+        :ping_message_interval => nil,
+        :header_template => nil,
+        :footer_template => nil,
+        :message_template => nil,
+        :subscriber_mode => 'polling'
+      }
+    end
+
+    let(:headers) do
+      {'accept' => 'text/html'}
+    end
+
+    it_should_behave_like "polling location"
+  end
+
+  context "when using push mode header" do
+    let(:config) do
+      {
+        :ping_message_interval => nil,
+        :header_template => nil,
+        :footer_template => nil,
+        :message_template => nil,
+        :subscriber_mode => nil
+      }
+    end
+
+    let(:headers) do
+      {'accept' => 'text/html', 'X-Nginx-PushStream-Mode' => 'polling'}
+    end
+
+    it_should_behave_like "polling location"
+  end
+end
diff -Naur nginx-1.11.3/nginx-push-stream-module/misc/spec/subscriber/properties_spec.rb nginx-1.11.3-push/nginx-push-stream-module/misc/spec/subscriber/properties_spec.rb
--- nginx-1.11.3/nginx-push-stream-module/misc/spec/subscriber/properties_spec.rb	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/misc/spec/subscriber/properties_spec.rb	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,1041 @@
+require 'spec_helper'
+
+describe "Subscriber Properties" do
+  let(:config) do
+    {
+      :authorized_channels_only => "off",
+      :header_template => "HEADER\r\nTEMPLATE\r\n1234\r\n",
+      :content_type => "custom content type",
+      :subscriber_connection_ttl => "1s",
+      :ping_message_interval => "2s"
+    }
+  end
+
+  it "should not accept access without a channel path" do
+    nginx_run_server(config) do |conf|
+      EventMachine.run do
+        sub = EventMachine::HttpRequest.new(nginx_address + '/sub/').get :head => headers
+        sub.callback do
+          expect(sub).to be_http_status(400).without_body
+          expect(sub.response_header['X_NGINX_PUSHSTREAM_EXPLAIN']).to eql("No channel id provided.")
+          EventMachine.stop
+        end
+      end
+    end
+  end
+
+  it "should check accepted methods" do
+    nginx_run_server(config) do |conf|
+      # testing OPTIONS method, EventMachine::HttpRequest does not have support to it
+      socket = open_socket(nginx_host, nginx_port)
+      socket.print("OPTIONS /sub/ch_test_accepted_methods_0 HTTP/1.0\r\n\r\n")
+      headers, body = read_response_on_socket(socket)
+      expect(headers).to match_the_pattern(/HTTP\/1\.1 200 OK/)
+      expect(headers).to match_the_pattern(/Content-Length: 0/)
+      socket.close
+
+      EventMachine.run do
+        multi = EventMachine::MultiRequest.new
+
+        multi.add(:a, EventMachine::HttpRequest.new(nginx_address + '/sub/ch_test_accepted_methods_1').head)
+        multi.add(:b, EventMachine::HttpRequest.new(nginx_address + '/sub/ch_test_accepted_methods_2').put(:body => 'body'))
+        multi.add(:c, EventMachine::HttpRequest.new(nginx_address + '/sub/ch_test_accepted_methods_3').post)
+        multi.add(:d, EventMachine::HttpRequest.new(nginx_address + '/sub/ch_test_accepted_methods_4').delete)
+        multi.add(:e, EventMachine::HttpRequest.new(nginx_address + '/sub/ch_test_accepted_methods_5').get)
+
+        multi.callback do
+          expect(multi.responses[:callback].length).to eql(5)
+
+          expect(multi.responses[:callback][:a]).to be_http_status(405)
+          expect(multi.responses[:callback][:a].req.method).to eql("HEAD")
+          expect(multi.responses[:callback][:a].response_header['ALLOW']).to eql("GET")
+
+          expect(multi.responses[:callback][:b]).to be_http_status(405)
+          expect(multi.responses[:callback][:b].req.method).to eql("PUT")
+          expect(multi.responses[:callback][:b].response_header['ALLOW']).to eql("GET")
+
+          expect(multi.responses[:callback][:c]).to be_http_status(405)
+          expect(multi.responses[:callback][:c].req.method).to eql("POST")
+          expect(multi.responses[:callback][:c].response_header['ALLOW']).to eql("GET")
+
+          expect(multi.responses[:callback][:d]).to be_http_status(405)
+          expect(multi.responses[:callback][:d].req.method).to eql("DELETE")
+          expect(multi.responses[:callback][:d].response_header['ALLOW']).to eql("GET")
+
+          expect(multi.responses[:callback][:e]).not_to be_http_status(405)
+          expect(multi.responses[:callback][:e].req.method).to eql("GET")
+
+          EventMachine.stop
+        end
+      end
+    end
+  end
+
+  it "should not accept access to a channel with id 'ALL'" do
+    channel = 'ALL'
+
+    nginx_run_server(config) do |conf|
+      EventMachine.run do
+        sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers
+        sub_1.callback do
+          expect(sub_1).to be_http_status(403).without_body
+          expect(sub_1.response_header['X_NGINX_PUSHSTREAM_EXPLAIN']).to eql("Channel id not authorized for this method.")
+          EventMachine.stop
+        end
+      end
+    end
+  end
+
+  it "should not accept access to a channel with id containing wildcard" do
+    channel_1 = 'abcd*efgh'
+    channel_2 = '*abcdefgh'
+    channel_3 = 'abcdefgh*'
+
+    nginx_run_server(config) do |conf|
+      EventMachine.run do
+        multi = EventMachine::MultiRequest.new
+
+        multi.add(:a, EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel_1).get(:head => headers))
+        multi.add(:b, EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel_2).get(:head => headers))
+        multi.add(:c, EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel_3).get(:head => headers))
+        multi.callback do
+          expect(multi.responses[:callback].length).to eql(3)
+          multi.responses[:callback].each do |name, response|
+            expect(response).to be_http_status(403).without_body
+            expect(response.response_header['X_NGINX_PUSHSTREAM_EXPLAIN']).to eql("Channel id not authorized for this method.")
+          end
+
+          EventMachine.stop
+        end
+      end
+    end
+  end
+
+  it "should accept access to multiple channels" do
+    nginx_run_server(config) do |conf|
+      EventMachine.run do
+        multi = EventMachine::MultiRequest.new
+
+        multi.add(:a, EventMachine::HttpRequest.new(nginx_address + '/sub/ch_multi_channels_1').get)
+        multi.add(:b, EventMachine::HttpRequest.new(nginx_address + '/sub/ch_multi_channels_1.b10').get)
+        multi.add(:c, EventMachine::HttpRequest.new(nginx_address + '/sub/ch_multi_channels_2/ch_multi_channels_3').get)
+        multi.add(:d, EventMachine::HttpRequest.new(nginx_address + '/sub/ch_multi_channels_2.b2/ch_multi_channels_3').get)
+        multi.add(:e, EventMachine::HttpRequest.new(nginx_address + '/sub/ch_multi_channels_2/ch_multi_channels_3.b3').get)
+        multi.add(:f, EventMachine::HttpRequest.new(nginx_address + '/sub/ch_multi_channels_2.b2/ch_multi_channels_3.b3').get)
+        multi.add(:g, EventMachine::HttpRequest.new(nginx_address + '/sub/ch_multi_channels_4.b').get)
+
+        multi.callback do
+          expect(multi.responses[:callback].length).to eql(7)
+          multi.responses[:callback].each do |name, response|
+            expect(response).to be_http_status(200)
+          end
+
+          EventMachine.stop
+        end
+      end
+    end
+  end
+
+  it "should not accept access with a big channel id" do
+    channel = '123456'
+
+    nginx_run_server(config.merge(:max_channel_id_length => 5)) do |conf|
+      EventMachine.run do
+        sub = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s ).get :head => headers
+        sub.callback do
+          expect(sub).to be_http_status(400).without_body
+          expect(sub.response_header['X_NGINX_PUSHSTREAM_EXPLAIN']).to eql("Channel id is too large.")
+          EventMachine.stop
+        end
+      end
+    end
+  end
+
+  it "should not accept access to a wildcard channel without a normal channel" do
+    nginx_run_server(config.merge(:wildcard_channel_prefix => "bd_")) do |conf|
+      EventMachine.run do
+        multi = EventMachine::MultiRequest.new
+
+        multi.add(:a, EventMachine::HttpRequest.new(nginx_address + '/sub/bd_test_wildcard_channels_without_common_channel').get)
+        multi.add(:b, EventMachine::HttpRequest.new(nginx_address + '/sub/bd_').get)
+        multi.add(:c, EventMachine::HttpRequest.new(nginx_address + '/sub/bd1').get)
+        multi.add(:d, EventMachine::HttpRequest.new(nginx_address + '/sub/bd').get)
+
+        multi.callback do
+          expect(multi.responses[:callback].length).to eql(4)
+
+          expect(multi.responses[:callback][:a]).to be_http_status(403).without_body
+          expect(multi.responses[:callback][:a].response_header['X_NGINX_PUSHSTREAM_EXPLAIN']).to eql("Subscribed too much wildcard channels.")
+          expect(multi.responses[:callback][:a].req.uri.to_s).to eql(nginx_address + '/sub/bd_test_wildcard_channels_without_common_channel')
+
+          expect(multi.responses[:callback][:b]).to be_http_status(403).without_body
+          expect(multi.responses[:callback][:b].response_header['X_NGINX_PUSHSTREAM_EXPLAIN']).to eql("Subscribed too much wildcard channels.")
+          expect(multi.responses[:callback][:b].req.uri.to_s).to eql(nginx_address + '/sub/bd_')
+
+          expect(multi.responses[:callback][:c]).to be_http_status(200)
+          expect(multi.responses[:callback][:c].req.uri.to_s).to eql(nginx_address + '/sub/bd1')
+
+          expect(multi.responses[:callback][:d]).to be_http_status(200)
+          expect(multi.responses[:callback][:d].req.uri.to_s).to eql(nginx_address + '/sub/bd')
+
+          EventMachine.stop
+        end
+      end
+    end
+  end
+
+  it "should accept access to a wildcard channel with a normal channel" do
+    nginx_run_server(config.merge(:wildcard_channel_prefix => "bd_", :wildcard_channel_max_qtd => 2, :authorized_channels_only => "off")) do |conf|
+      EventMachine.run do
+        multi = EventMachine::MultiRequest.new
+
+        multi.add(:a, EventMachine::HttpRequest.new(nginx_address + '/sub/bd1/bd2/bd3/bd4/bd_1/bd_2/bd_3').get)
+        multi.add(:b, EventMachine::HttpRequest.new(nginx_address + '/sub/bd1/bd2/bd_1/bd_2').get)
+        multi.add(:c, EventMachine::HttpRequest.new(nginx_address + '/sub/bd1/bd_1').get)
+        multi.add(:d, EventMachine::HttpRequest.new(nginx_address + '/sub/bd1/bd2').get)
+
+        multi.callback do
+          expect(multi.responses[:callback].length).to eql(4)
+
+          expect(multi.responses[:callback][:a]).to be_http_status(403).without_body
+          expect(multi.responses[:callback][:a].response_header['X_NGINX_PUSHSTREAM_EXPLAIN']).to eql("Subscribed too much wildcard channels.")
+          expect(multi.responses[:callback][:a].req.uri.to_s).to eql(nginx_address + '/sub/bd1/bd2/bd3/bd4/bd_1/bd_2/bd_3')
+
+          expect(multi.responses[:callback][:b]).to be_http_status(200)
+          expect(multi.responses[:callback][:b].req.uri.to_s).to eql(nginx_address + '/sub/bd1/bd2/bd_1/bd_2')
+
+          expect(multi.responses[:callback][:c]).to be_http_status(200)
+          expect(multi.responses[:callback][:c].req.uri.to_s).to eql(nginx_address + '/sub/bd1/bd_1')
+
+          expect(multi.responses[:callback][:d]).to be_http_status(200)
+          expect(multi.responses[:callback][:d].req.uri.to_s).to eql(nginx_address + '/sub/bd1/bd2')
+
+          EventMachine.stop
+        end
+      end
+    end
+  end
+
+  it "should not accept access to an nonexistent channel with authorized only 'on'" do
+    channel = 'ch_test_subscribe_an_absent_channel_with_authorized_only_on'
+
+    nginx_run_server(config.merge(:authorized_channels_only => 'on')) do |conf|
+      EventMachine.run do
+        sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers
+        sub_1.callback do
+          expect(sub_1).to be_http_status(403).without_body
+          expect(sub_1.response_header['X_NGINX_PUSHSTREAM_EXPLAIN']).to eql("Subscriber could not create channels.")
+          EventMachine.stop
+        end
+      end
+    end
+  end
+
+  it "should accept access to an existent channel with authorized channel only 'on'" do
+    channel = 'ch_test_subscribe_an_existing_channel_with_authorized_only_on'
+    body = 'body'
+
+    nginx_run_server(config.merge(:authorized_channels_only => 'on')) do |conf|
+      #create channel
+      publish_message(channel, headers, body)
+
+      EventMachine.run do
+        sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers
+        sub_1.callback do
+          expect(sub_1).to be_http_status(200)
+          EventMachine.stop
+        end
+      end
+    end
+  end
+
+  it "should accept access to an existing channel and a nonexistent wildcard channel with authorized only 'on'" do
+    channel = 'ch_test_subscribe_an_existing_channel_and_absent_wildcard_channel_with_authorized_only_on'
+    wildcard_channel = 'bd_test_subscribe_an_existing_channel_and_absent_wildcard_channel_with_authorized_only_on'
+
+    body = 'body'
+
+    nginx_run_server(config.merge(:authorized_channels_only => 'on', :wildcard_channel_prefix => "bd_", :wildcard_channel_max_qtd => 1)) do |conf|
+      #create channel
+      publish_message(channel, headers, body)
+
+      EventMachine.run do
+        sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s + '/' + wildcard_channel.to_s).get :head => headers
+        sub_1.callback do
+          expect(sub_1).to be_http_status(200)
+          EventMachine.stop
+        end
+      end
+    end
+  end
+
+  it "should not accept access to an existing channel without messages with authorized only 'on'" do
+    channel = 'ch_test_subscribe_an_existing_channel_without_messages_and_with_authorized_only_on'
+
+    body = 'body'
+
+    nginx_run_server(config.merge(:authorized_channels_only => 'on', :message_ttl => "1s"), :timeout => 10) do |conf|
+      #create channel
+      publish_message(channel, headers, body)
+      sleep(5) #to ensure message was gone
+
+      EventMachine.run do
+        sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers
+        sub_1.callback do
+          expect(sub_1).to be_http_status(403).without_body
+          expect(sub_1.response_header['X_NGINX_PUSHSTREAM_EXPLAIN']).to eql("Subscriber could not create channels.")
+          EventMachine.stop
+        end
+      end
+    end
+  end
+
+  it "should not accept access to an existing channel without messages and an nonexistent wildcard channel with authorized only 'on'" do
+    channel = 'ch_test_subscribe_an_existing_channel_without_messages_and_absent_wildcard_channel_and_with_authorized_only_on_should_fail'
+    wildcard_channel = 'bd_test_subscribe_an_existing_channel_without_messages_and_absent_wildcard_channel_and_with_authorized_only_on_should_fail'
+
+    body = 'body'
+
+    nginx_run_server(config.merge(:authorized_channels_only => 'on', :message_ttl => "1s", :wildcard_channel_prefix => "bd_", :wildcard_channel_max_qtd => 1), :timeout => 10) do |conf|
+      #create channel
+      publish_message(channel, headers, body)
+      sleep(5) #to ensure message was gone
+
+      EventMachine.run do
+        sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s + '/' + wildcard_channel.to_s).get :head => headers
+        sub_1.callback do
+          expect(sub_1).to be_http_status(403).without_body
+          expect(sub_1.response_header['X_NGINX_PUSHSTREAM_EXPLAIN']).to eql("Subscriber could not create channels.")
+          EventMachine.stop
+        end
+      end
+    end
+  end
+
+  it "should receive new messages in a multi channel subscriber" do
+    channel_1 = 'test_retreive_new_messages_in_multichannel_subscribe_1'
+    channel_2 = 'test_retreive_new_messages_in_multich_subscribe_2'
+    channel_3 = 'test_retreive_new_messages_in_multchannel_subscribe_3'
+    channel_4 = 'test_retreive_new_msgs_in_multichannel_subscribe_4'
+    channel_5 = 'test_retreive_new_messages_in_multichannel_subs_5'
+    channel_6 = 'test_retreive_new_msgs_in_multichannel_subs_6'
+
+    body = 'body'
+
+    response = ""
+    nginx_run_server(config.merge(:header_template => nil, :message_template => '{\"channel\":\"~channel~\", \"id\":\"~id~\", \"message\":\"~text~\"}|')) do |conf|
+      EventMachine.run do
+        sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel_1.to_s + '/' + channel_2.to_s + '/' + channel_3.to_s + '/' + channel_4.to_s + '/' + channel_5.to_s + '/' + channel_6.to_s).get :head => headers
+        sub_1.stream do |chunk|
+          response += chunk
+          lines = response.split("|")
+
+          if lines.length >= 6
+            line = JSON.parse(lines[0])
+            expect(line['channel']).to eql(channel_1.to_s)
+            expect(line['message']).to eql('body' + channel_1.to_s)
+            expect(line['id'].to_i).to eql(1)
+
+            line = JSON.parse(lines[1])
+            expect(line['channel']).to eql(channel_2.to_s)
+            expect(line['message']).to eql('body' + channel_2.to_s)
+            expect(line['id'].to_i).to eql(1)
+
+            line = JSON.parse(lines[2])
+            expect(line['channel']).to eql(channel_3.to_s)
+            expect(line['message']).to eql('body' + channel_3.to_s)
+            expect(line['id'].to_i).to eql(1)
+
+            line = JSON.parse(lines[3])
+            expect(line['channel']).to eql(channel_4.to_s)
+            expect(line['message']).to eql('body' + channel_4.to_s)
+            expect(line['id'].to_i).to eql(1)
+
+            line = JSON.parse(lines[4])
+            expect(line['channel']).to eql(channel_5.to_s)
+            expect(line['message']).to eql('body' + channel_5.to_s)
+            expect(line['id'].to_i).to eql(1)
+
+            line = JSON.parse(lines[5])
+            expect(line['channel']).to eql(channel_6.to_s)
+            expect(line['message']).to eql('body' + channel_6.to_s)
+            expect(line['id'].to_i).to eql(1)
+
+            EventMachine.stop
+          end
+        end
+
+        EM.add_timer(0.5) do
+          publish_message(channel_1, headers, body + channel_1.to_s)
+          publish_message(channel_2, headers, body + channel_2.to_s)
+          publish_message(channel_3, headers, body + channel_3.to_s)
+          publish_message(channel_4, headers, body + channel_4.to_s)
+          publish_message(channel_5, headers, body + channel_5.to_s)
+          publish_message(channel_6, headers, body + channel_6.to_s)
+        end
+      end
+    end
+  end
+
+  it "should limit the number of channels" do
+    channel = 'ch_test_max_number_of_channels_'
+
+    nginx_run_server(config.merge(:max_number_of_channels => 1)) do |conf|
+      EventMachine.run do
+        sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s + 1.to_s).get :head => headers
+        sub_1.stream do
+          expect(sub_1).to be_http_status(200)
+
+          sub_2 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s + 2.to_s).get :head => headers
+          sub_2.callback do
+            expect(sub_2).to be_http_status(403).without_body
+            expect(sub_2.response_header['X_NGINX_PUSHSTREAM_EXPLAIN']).to eql("Number of channels were exceeded.")
+            EventMachine.stop
+          end
+        end
+      end
+    end
+  end
+
+  it "should limit the number of wildcard channels" do
+    channel = 'bd_test_max_number_of_wildcard_channels_'
+
+    nginx_run_server(config.merge(:max_number_of_wildcard_channels => 1, :wildcard_channel_prefix => 'bd_', :wildcard_channel_max_qtd => 1)) do |conf|
+      EventMachine.run do
+        sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/ch1/' + channel.to_s + 1.to_s).get :head => headers
+        sub_1.stream do
+          expect(sub_1).to be_http_status(200)
+
+          sub_2 = EventMachine::HttpRequest.new(nginx_address + '/sub/ch1/' + channel.to_s + 2.to_s).get :head => headers
+          sub_2.callback do
+            expect(sub_2).to be_http_status(403).without_body
+            expect(sub_2.response_header['X_NGINX_PUSHSTREAM_EXPLAIN']).to eql("Number of channels were exceeded.")
+            EventMachine.stop
+          end
+        end
+      end
+    end
+  end
+
+  it "should accept different message templates in each location" do
+    configuration = config.merge({
+      :message_template => '{\"text\":\"~text~\"}',
+      :header_template => nil,
+      :extra_location => %q{
+        location ~ /sub2/(.*)? {
+          # activate subscriber mode for this location
+          push_stream_subscriber;
+
+          # positional channel path
+          push_stream_channels_path               $1;
+          # message template
+          push_stream_message_template "{\"msg\":\"~text~\"}";
+        }
+
+      }
+    })
+
+    channel = 'ch_test_different_message_templates'
+    body = 'body'
+
+    nginx_run_server(configuration) do |conf|
+      EventMachine.run do
+        sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers
+        sub_1.stream do |chunk|
+          response = JSON.parse(chunk)
+          expect(response['msg']).to be_nil
+          expect(response['text']).to eql(body)
+          EventMachine.stop
+        end
+
+        sub_2 = EventMachine::HttpRequest.new(nginx_address + '/sub2/' + channel.to_s + '.b1').get :head => headers
+        sub_2.stream do |chunk|
+          response = JSON.parse(chunk)
+          expect(response['text']).to be_nil
+          expect(response['msg']).to eql(body)
+          EventMachine.stop
+        end
+
+        #publish a message
+        publish_message_inline(channel, headers, body)
+      end
+
+      EventMachine.run do
+        sub_3 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s + '.b1').get :head => headers
+        sub_3.stream do |chunk|
+          response = JSON.parse(chunk)
+          expect(response['msg']).to be_nil
+          expect(response['text']).to eql(body)
+          EventMachine.stop
+        end
+      end
+
+      EventMachine.run do
+        sub_4 = EventMachine::HttpRequest.new(nginx_address + '/sub2/' + channel.to_s + '.b1').get :head => headers
+        sub_4.stream do |chunk|
+          response = JSON.parse(chunk)
+          expect(response['text']).to be_nil
+          expect(response['msg']).to eql(body)
+          EventMachine.stop
+        end
+      end
+    end
+  end
+
+  it "should use default message template" do
+    channel = 'ch_test_default_message_template'
+    body = 'body'
+
+    nginx_run_server(config.merge(:message_template => nil, :header_template => nil)) do |conf|
+      EventMachine.run do
+        sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers
+        sub_1.stream do |chunk|
+          expect(chunk).to eql("#{body}")
+          EventMachine.stop
+        end
+
+        #publish a message
+        publish_message_inline(channel, headers, body)
+      end
+    end
+  end
+
+  it "should receive default ping message with default message template" do
+    channel = 'ch_test_default_ping_message_with_default_message_template'
+    body = 'body'
+
+    nginx_run_server(config.merge(:subscriber_connection_ttl => nil, :message_template => nil, :header_template => nil, :ping_message_interval => '1s', :ping_message_text => nil)) do |conf|
+      EventMachine.run do
+        sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers
+        sub_1.stream do |chunk|
+          expect(chunk).to eql(" ")
+          EventMachine.stop
+        end
+      end
+    end
+  end
+
+  it "should receive custom ping message with default message template" do
+    channel = 'ch_test_custom_ping_message_with_default_message_template'
+    body = 'body'
+
+    nginx_run_server(config.merge(:subscriber_connection_ttl => nil, :message_template => nil, :header_template => nil, :ping_message_interval => '1s', :ping_message_text => "pinging you!!!")) do |conf|
+      EventMachine.run do
+        sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers
+        sub_1.stream do |chunk|
+          expect(chunk).to eql(conf.ping_message_text)
+          EventMachine.stop
+        end
+      end
+    end
+  end
+
+  it "should receive default ping message with custom message template" do
+    channel = 'ch_test_default_ping_message_with_custom_message_template'
+    body = 'body'
+
+    nginx_run_server(config.merge(:subscriber_connection_ttl => nil, :message_template => "~id~:~text~", :header_template => nil, :ping_message_interval => '1s', :ping_message_text => nil)) do |conf|
+      EventMachine.run do
+        sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers
+        sub_1.stream do |chunk|
+          expect(chunk).to eql("-1: ")
+          EventMachine.stop
+        end
+      end
+    end
+  end
+
+  it "should receive custom ping message with custom message template" do
+    channel = 'ch_test_custom_ping_message_with_default_message_template'
+    body = 'body'
+
+    nginx_run_server(config.merge(:subscriber_connection_ttl => nil, :message_template => "~id~:~text~", :header_template => nil, :ping_message_interval => '1s', :ping_message_text => "pinging you!!!")) do |conf|
+      EventMachine.run do
+        sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers
+        sub_1.stream do |chunk|
+          expect(chunk).to eql("-1:#{conf.ping_message_text}")
+          EventMachine.stop
+        end
+      end
+    end
+  end
+
+  it "should receive transfer enconding as 'chunked'" do
+    channel = 'ch_test_transfer_encoding_chuncked'
+
+    nginx_run_server(config) do |conf|
+      EventMachine.run do
+        sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers
+        sub_1.stream do |chunk|
+          expect(sub_1.response_header['TRANSFER_ENCODING']).to eql("chunked")
+          EventMachine.stop
+        end
+      end
+    end
+  end
+
+  it "should limit the number of subscribers to one channel" do
+    channel = 'ch_test_cannot_add_more_subscriber_to_one_channel_than_allowed'
+    other_channel = 'ch_test_cannot_add_more_subscriber_to_one_channel_than_allowed_2'
+
+    nginx_run_server(config.merge(:max_subscribers_per_channel => 3, :subscriber_connection_ttl => "3s")) do |conf|
+      EventMachine.run do
+        EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get(:head => headers).stream do
+          EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get(:head => headers).stream do
+            EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get(:head => headers).stream do
+              sub_4 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers
+              sub_4.callback do
+                expect(sub_4).to be_http_status(403).without_body
+                expect(sub_4.response_header['X_NGINX_PUSHSTREAM_EXPLAIN']).to eql("Subscribers limit per channel has been exceeded.")
+
+                sub_5 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + other_channel.to_s).get :head => headers
+                sub_5.callback do
+                  expect(sub_5).to be_http_status(200)
+                  EventMachine.stop
+                end
+              end
+            end
+          end
+        end
+      end
+    end
+  end
+
+  it "should accept channels with '.b' in the name" do
+    channel = 'room.b18.beautiful'
+    response = ''
+
+    nginx_run_server(config.merge(:ping_message_interval => nil, :header_template => nil, :footer_template => nil, :message_template => nil)) do |conf|
+      EventMachine.run do
+        publish_message(channel, {'accept' => 'text/html'}, 'msg 1')
+        publish_message(channel, {'accept' => 'text/html'}, 'msg 2')
+        publish_message(channel, {'accept' => 'text/html'}, 'msg 3')
+        publish_message(channel, {'accept' => 'text/html'}, 'msg 4')
+
+        sub = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s + '.b3').get
+        sub.stream do |chunk|
+          response += chunk
+        end
+        sub.callback do
+          expect(response).to eql("msg 2msg 3msg 4")
+
+          response = ''
+          sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get
+          sub_1.stream do |chunk|
+            response += chunk
+          end
+          sub_1.callback do
+            expect(response).to eql("msg 5")
+
+            EventMachine.stop
+          end
+
+          publish_message_inline(channel, {'accept' => 'text/html'}, 'msg 5')
+        end
+      end
+    end
+  end
+
+  it "should not receive acess control allow headers by default" do
+    channel = 'test_access_control_allow_headers'
+
+    nginx_run_server(config) do |conf|
+      EventMachine.run do
+        sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers
+        sub_1.stream do |chunk|
+          expect(sub_1.response_header['ACCESS_CONTROL_ALLOW_ORIGIN']).to be_nil
+          expect(sub_1.response_header['ACCESS_CONTROL_ALLOW_METHODS']).to be_nil
+          expect(sub_1.response_header['ACCESS_CONTROL_ALLOW_HEADERS']).to be_nil
+
+          EventMachine.stop
+        end
+      end
+    end
+  end
+
+  context "when allow origin directive is set" do
+    it "should receive acess control allow headers" do
+      channel = 'test_access_control_allow_headers'
+
+      nginx_run_server(config.merge(:allowed_origins => "custom.domain.com")) do |conf|
+        EventMachine.run do
+          sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers
+          sub_1.stream do |chunk|
+            expect(sub_1.response_header['ACCESS_CONTROL_ALLOW_ORIGIN']).to eql("custom.domain.com")
+            expect(sub_1.response_header['ACCESS_CONTROL_ALLOW_METHODS']).to eql("GET")
+            expect(sub_1.response_header['ACCESS_CONTROL_ALLOW_HEADERS']).to eql("If-Modified-Since,If-None-Match,Etag,Event-Id,Event-Type,Last-Event-Id")
+
+            EventMachine.stop
+          end
+        end
+      end
+    end
+
+    it "should accept a complex value" do
+      channel = 'test_access_control_allow_origin_as_complex'
+
+      nginx_run_server(config.merge(:allowed_origins => "$arg_domain")) do |conf|
+        EventMachine.run do
+          sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s + '?domain=test.com').get :head => headers
+          sub_1.stream do |chunk|
+            expect(sub_1.response_header['ACCESS_CONTROL_ALLOW_ORIGIN']).to eql("test.com")
+            expect(sub_1.response_header['ACCESS_CONTROL_ALLOW_METHODS']).to eql("GET")
+            expect(sub_1.response_header['ACCESS_CONTROL_ALLOW_HEADERS']).to eql("If-Modified-Since,If-None-Match,Etag,Event-Id,Event-Type,Last-Event-Id")
+
+            EventMachine.stop
+          end
+        end
+      end
+    end
+  end
+
+  it "should receive the configured header template" do
+    channel = 'ch_test_header_template'
+
+    nginx_run_server(config) do |conf|
+      EventMachine.run do
+        sub = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers
+        sub.stream do |chunk|
+          expect(chunk).to eql("#{conf.header_template}")
+          EventMachine.stop
+        end
+      end
+    end
+  end
+
+  context "when header template file is set" do
+    before do
+      FileUtils.mkdir_p nginx_tests_tmp_dir
+      File.open(header_template_file, "w") {|f| f.write header_template_content }
+    end
+    after { File.delete(header_template_file) }
+
+    let(:header_template_file) { File.join(nginx_tests_tmp_dir, "header_template.txt") }
+    let(:header_template_content) { "Header\nTemplate\ninside a file" }
+
+    def assert_response_for(cfg, path, expected_response)
+      nginx_run_server(cfg) do |conf|
+        EventMachine.run do
+          sub = EventMachine::HttpRequest.new(nginx_address + path).get :head => headers
+          sub.stream do |chunk|
+            expect(chunk).to eql(expected_response)
+            EventMachine.stop
+          end
+        end
+      end
+    end
+
+    it "should receive the file content" do
+      channel = 'ch_test_header_template_file'
+      merged_config = config.merge({
+        header_template: nil,
+        header_template_file: header_template_file
+      })
+
+      assert_response_for(merged_config, '/sub/' + channel.to_s, header_template_content)
+    end
+
+    it "should not accept header_template and header_template_file on same level" do
+      merged_config = config.merge({
+        :header_template => nil,
+        :extra_location => %{
+          location /sub2 {
+            push_stream_subscriber;
+
+            push_stream_header_template 'inline header template\\r\\n\\r\\n';
+            push_stream_header_template_file #{header_template_file};
+          }
+        }
+      })
+
+      expect(nginx_test_configuration(merged_config)).to include(%{"push_stream_header_template_file" directive is duplicate or template set by 'push_stream_header_template'})
+    end
+
+    it "should not accept header_template_file and header_template on same level" do
+      merged_config = config.merge({
+        :header_template => nil,
+        :extra_location => %{
+          location /sub2 {
+            push_stream_subscriber;
+
+            push_stream_header_template_file #{header_template_file};
+            push_stream_header_template 'inline header template\\r\\n\\r\\n';
+          }
+        }
+      })
+
+      expect(nginx_test_configuration(merged_config)).to include(%{"push_stream_header_template" directive is duplicate})
+    end
+
+    it "should accept header_template_file and header_template on different levels" do
+      channel = 'ch_test_override_header_template_file'
+
+      merged_config = config.merge({
+        :header_template_file => header_template_file,
+        :header_template => nil,
+        :extra_location => %{
+          location ~ /sub2/(.*) {
+            push_stream_subscriber;
+            push_stream_channels_path $1;
+
+            push_stream_header_template 'inline header template';
+          }
+        }
+      })
+
+      assert_response_for(merged_config, '/sub/' + channel.to_s, header_template_content)
+      assert_response_for(merged_config, '/sub2/' + channel.to_s, 'inline header template')
+    end
+
+    it "should accept header_template and header_template_file on different levels" do
+      channel = 'ch_test_override_header_template_file'
+
+      merged_config = config.merge({
+        :header_template => 'inline header template',
+        :extra_location => %{
+          location ~ /sub2/(.*) {
+            push_stream_subscriber;
+            push_stream_channels_path $1;
+
+            push_stream_header_template_file #{header_template_file};
+          }
+        }
+      })
+
+      assert_response_for(merged_config, '/sub/' + channel.to_s, 'inline header template')
+      assert_response_for(merged_config, '/sub2/' + channel.to_s, header_template_content)
+    end
+
+    it "should return error when could not open the file" do
+      merged_config = config.merge({
+        :header_template => nil,
+        :header_template_file => "/unexistent/path"
+      })
+
+      expect(nginx_test_configuration(merged_config)).to include(%{push stream module: unable to open file "/unexistent/path" for header template})
+    end
+  end
+
+  it "should receive the configured content type" do
+    channel = 'ch_test_content_type'
+
+    nginx_run_server(config) do |conf|
+      EventMachine.run do
+        sub = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers
+        sub.stream do |chunk|
+          expect(sub.response_header['CONTENT_TYPE']).to eql(conf.content_type)
+          EventMachine.stop
+        end
+      end
+    end
+  end
+
+  it "should receive ping message on the configured ping message interval" do
+    channel = 'ch_test_ping_message_interval'
+
+    step1 = step2 = step3 = step4 = nil
+    chunks_received = 0
+
+    nginx_run_server(config.merge(:subscriber_connection_ttl => nil), :timeout => 10) do |conf|
+      EventMachine.run do
+        sub = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers
+        sub.stream do |chunk|
+          chunks_received += 1;
+          step1 = Time.now if chunks_received == 1
+          step2 = Time.now if chunks_received == 2
+          step3 = Time.now if chunks_received == 3
+          step4 = Time.now if chunks_received == 4
+          EventMachine.stop if chunks_received == 4
+        end
+        sub.callback do
+          expect(chunks_received).to eql(4)
+          expect(time_diff_sec(step2, step1).round).to eql(time_diff_sec(step4, step3).round)
+        end
+      end
+    end
+  end
+
+  it "should not cache the response" do
+    channel = 'ch_test_not_cache_the_response'
+
+    nginx_run_server(config.merge(:subscriber_connection_ttl => '1s')) do |conf|
+      EventMachine.run do
+        sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers
+        sub_1.callback do
+          expect(sub_1.response_header["EXPIRES"]).to eql("Thu, 01 Jan 1970 00:00:01 GMT")
+          expect(sub_1.response_header["CACHE_CONTROL"]).to eql("no-cache, no-store, must-revalidate")
+          EventMachine.stop
+        end
+      end
+    end
+  end
+
+  it "should accept channels path inside an if block" do
+    merged_config = config.merge({
+      :header_template => nil,
+      :footer_template => nil,
+      :subscriber_connection_ttl => '1s',
+      :extra_location => %{
+        location /sub2 {
+          push_stream_subscriber;
+
+          push_stream_channels_path            $arg_id;
+          if ($arg_test) {
+            push_stream_channels_path          test_$arg_id;
+          }
+        }
+      }
+    })
+
+    channel = 'channels_path_inside_if_block'
+    body = 'published message'
+    resp_1 = ""
+    resp_2 = ""
+
+    nginx_run_server(merged_config) do |conf|
+      EventMachine.run do
+        sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub2?id=' + channel.to_s).get :head => headers
+        sub_1.stream do |chunk|
+          resp_1 += chunk
+        end
+
+        sub_2 = EventMachine::HttpRequest.new(nginx_address + '/sub2?id=' + channel.to_s + '&test=1').get :head => headers
+        sub_2.stream do |chunk|
+          resp_2 += chunk
+        end
+        sub_2.callback do
+          expect(resp_1).to eql("<script>p(1,'channels_path_inside_if_block','published message');</script>")
+          expect(resp_2).to eql("<script>p(1,'test_channels_path_inside_if_block','published message');</script>")
+          EventMachine.stop
+        end
+
+        publish_message_inline(channel, {}, body)
+        publish_message_inline('test_' + channel, {}, body)
+      end
+    end
+  end
+
+  it "should accept return content gzipped" do
+    channel = 'ch_test_get_content_gzipped'
+    body = 'body'
+    actual_response = ''
+
+    nginx_run_server(config.merge({:gzip => "on", :subscriber_connection_ttl => '1s', :content_type => "text/html"})) do |conf|
+      EventMachine.run do
+        sent_headers = headers.merge({'accept-encoding' => 'gzip, compressed'})
+        sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => sent_headers, :decoding => false
+        sub_1.stream do |chunk|
+          actual_response << chunk
+        end
+        sub_1.callback do
+          expect(sub_1).to be_http_status(200)
+
+          expect(sub_1.response_header["CONTENT_ENCODING"]).to eql("gzip")
+          actual_response = Zlib::GzipReader.new(StringIO.new(actual_response)).read
+
+          expect(actual_response).to eql("HEADER\r\nTEMPLATE\r\n1234\r\n<script>p(1,'ch_test_get_content_gzipped','body');</script></body></html>")
+          EventMachine.stop
+        end
+        publish_message_inline(channel, {}, body)
+      end
+    end
+  end
+
+  it "should accept a configuration with more than one http block" do
+    extra_config = {
+      :subscriber_connection_ttl => '1s',
+      :content_type => "text/html",
+      :extra_configuration => %(
+        http {
+          server {
+            listen #{nginx_port.to_i + 1};
+            location / {
+              return 200 "extra server configuration";
+            }
+          }
+        }
+      )
+    }
+
+    channel = 'ch_test_extra_http'
+    body = 'body'
+    actual_response = ''
+
+    nginx_run_server(config.merge(extra_config)) do |conf|
+      EventMachine.run do
+        sub_1 = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s).get :head => headers
+        sub_1.stream do |chunk|
+          actual_response += chunk
+        end
+        sub_1.callback do
+          expect(sub_1).to be_http_status(200)
+
+          expect(actual_response).to eql("HEADER\r\nTEMPLATE\r\n1234\r\n<script>p(1,'ch_test_extra_http','body');</script></body></html>")
+
+          req = EventMachine::HttpRequest.new("http://#{nginx_host}:#{nginx_port.to_i + 1}/").get
+          req.callback do
+            expect(req.response).to eql("extra server configuration")
+            EventMachine.stop
+          end
+        end
+        publish_message_inline(channel, {}, body)
+      end
+    end
+  end
+
+  it "should accept a configuration with two shared memory zones without mix messages" do
+    extra_config = {
+      :subscriber_connection_ttl => '1s',
+      :content_type => "text/html",
+      :extra_configuration => %(
+        http {
+          push_stream_shared_memory_size         10m second;
+          push_stream_subscriber_connection_ttl         1s;
+          server {
+            listen #{nginx_port.to_i + 1};
+            location /pub {
+              push_stream_publisher;
+              push_stream_channels_path               $arg_id;
+            }
+
+            location ~ /sub/(.*) {
+              push_stream_subscriber;
+              push_stream_channels_path                   $1;
+            }
+          }
+        }
+      )
+    }
+
+    channel = 'ch_test_extra_http'
+    body = 'body'
+    actual_response_1 = ''
+    actual_response_2 = ''
+
+    nginx_run_server(config.merge(extra_config)) do |conf|
+      EventMachine.run do
+        sub_1 = EventMachine::HttpRequest.new("http://#{nginx_host}:#{nginx_port.to_i}/sub/" + channel.to_s).get
+        sub_1.stream do |chunk|
+          actual_response_1 += chunk
+        end
+        sub_2 = EventMachine::HttpRequest.new("http://#{nginx_host}:#{nginx_port.to_i + 1}/sub/" + channel.to_s).get
+        sub_2.stream do |chunk|
+          actual_response_2 += chunk
+        end
+        EM.add_timer(1.5) do
+          expect(sub_1).to be_http_status(200)
+          expect(sub_2).to be_http_status(200)
+
+          expect(actual_response_1).to eql("HEADER\r\nTEMPLATE\r\n1234\r\n<script>p(1,'ch_test_extra_http','body_1');</script></body></html>")
+          expect(actual_response_2).to eql("body_2")
+          EventMachine.stop
+        end
+
+        EM.add_timer(0.5) do
+          EventMachine::HttpRequest.new("http://#{nginx_host}:#{nginx_port.to_i}/pub/?id=" + channel.to_s).post :body => "#{body}_1"
+          EventMachine::HttpRequest.new("http://#{nginx_host}:#{nginx_port.to_i + 1}/pub/?id=" + channel.to_s).post :body => "#{body}_2"
+        end
+      end
+    end
+  end
+end
diff -Naur nginx-1.11.3/nginx-push-stream-module/misc/spec/subscriber/receive_old_message_spec.rb nginx-1.11.3-push/nginx-push-stream-module/misc/spec/subscriber/receive_old_message_spec.rb
--- nginx-1.11.3/nginx-push-stream-module/misc/spec/subscriber/receive_old_message_spec.rb	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/misc/spec/subscriber/receive_old_message_spec.rb	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,375 @@
+# encoding: ascii
+require 'spec_helper'
+
+describe "Receive old messages" do
+  let(:config) do
+    {
+      :header_template => nil,
+      :footer_template => nil,
+      :message_template => '{\"channel\":\"~channel~\", \"id\":\"~id~\", \"message\":\"~text~\"}\r\n',
+      :subscriber_mode => subscriber_mode,
+      :ping_message_interval => '1s'
+    }
+  end
+
+  let(:eol) { "\r\n" }
+
+  shared_examples_for "can receive old messages" do
+    it "should receive old messages in a multi channel subscriber using backtrack" do
+      channel_1 = 'ch_test_retreive_old_messages_in_multichannel_subscribe_1'
+      channel_2 = 'ch_test_retreive_old_messages_in_multichannel_subscribe_2'
+      channel_3 = 'ch_test_retreive_old_messages_in_multichannel_subscribe_3'
+
+      body = 'body'
+
+      nginx_run_server(config.merge(:header_template => 'HEADER\r\n')) do |conf|
+        #create channels with some messages
+        1.upto(3) do |i|
+          publish_message(channel_1, headers, body + i.to_s)
+          publish_message(channel_2, headers, body + i.to_s)
+          publish_message(channel_3, headers, body + i.to_s)
+        end
+
+        get_content(nginx_address + '/sub/' + channel_1.to_s + '/' + channel_2.to_s + '.b5' + '/' + channel_3.to_s + '.b2', 6, headers) do |response, response_headers|
+          if ["long-polling", "polling"].include?(conf.subscriber_mode)
+            expect(response_headers['LAST_MODIFIED'].to_s).not_to eql("")
+            expect(response_headers['ETAG'].to_s).not_to eql("")
+          end
+
+          lines = response.split(eol)
+          expect(lines[0]).to eql('HEADER')
+          line = JSON.parse(lines[1])
+          expect(line['channel']).to eql(channel_2.to_s)
+          expect(line['message']).to eql('body1')
+          expect(line['id'].to_i).to eql(1)
+
+          line = JSON.parse(lines[2])
+          expect(line['channel']).to eql(channel_2.to_s)
+          expect(line['message']).to eql('body2')
+          expect(line['id'].to_i).to eql(2)
+
+          line = JSON.parse(lines[3])
+          expect(line['channel']).to eql(channel_2.to_s)
+          expect(line['message']).to eql('body3')
+          expect(line['id'].to_i).to eql(3)
+
+          line = JSON.parse(lines[4])
+          expect(line['channel']).to eql(channel_3.to_s)
+          expect(line['message']).to eql('body2')
+          expect(line['id'].to_i).to eql(2)
+
+          line = JSON.parse(lines[5])
+          expect(line['channel']).to eql(channel_3.to_s)
+          expect(line['message']).to eql('body3')
+          expect(line['id'].to_i).to eql(3)
+        end
+      end
+    end
+
+    it "should receive old messages in a multi channel subscriber using 'if_modified_since' header" do
+      channel_1 = 'ch_test_retreive_old_messages_in_multichannel_subscribe_using_if_modified_since_header_1'
+      channel_2 = 'ch_test_retreive_old_messages_in_multichannel_subscribe_using_if_modified_since_header_2'
+      channel_3 = 'ch_test_retreive_old_messages_in_multichannel_subscribe_using_if_modified_since_header_3'
+
+      body = 'body'
+
+      nginx_run_server(config.merge(:header_template => 'HEADER\r\n'), :timeout => 45) do |conf|
+        #create channels with some messages with progressive interval (1,2,3,5,7,9,12,15,18 seconds)
+        1.upto(3) do |i|
+          sleep(i)
+          publish_message(channel_1, headers, body + i.to_s)
+          sleep(i)
+          publish_message(channel_2, headers, body + i.to_s)
+          sleep(i)
+          publish_message(channel_3, headers, body + i.to_s)
+        end
+
+        #get messages published less then 10 seconds ago
+        t = Time.now - 10
+
+        sent_headers = headers.merge({'If-Modified-Since' => t.utc.strftime("%a, %d %b %Y %T %Z")})
+
+        get_content(nginx_address + '/sub/' + channel_1.to_s + '/' + channel_2.to_s + '/' + channel_3.to_s, 5, sent_headers) do |response, response_headers|
+          if ["long-polling", "polling"].include?(conf.subscriber_mode)
+            expect(response_headers['LAST_MODIFIED'].to_s).not_to eql("")
+            expect(response_headers['ETAG'].to_s).not_to eql("")
+          end
+
+          lines = response.split(eol)
+          expect(lines[0]).to eql('HEADER')
+
+          line = JSON.parse(lines[1])
+          expect(line['channel']).to eql(channel_1.to_s)
+          expect(line['message']).to eql('body3')
+          expect(line['id'].to_i).to eql(3)
+
+          line = JSON.parse(lines[2])
+          expect(line['channel']).to eql(channel_2.to_s)
+          expect(line['message']).to eql('body3')
+          expect(line['id'].to_i).to eql(3)
+
+          line = JSON.parse(lines[3])
+          expect(line['channel']).to eql(channel_3.to_s)
+          expect(line['message']).to eql('body2')
+          expect(line['id'].to_i).to eql(2)
+
+          line = JSON.parse(lines[4])
+          expect(line['channel']).to eql(channel_3.to_s)
+          expect(line['message']).to eql('body3')
+          expect(line['id'].to_i).to eql(3)
+        end
+      end
+    end
+
+    it "should receive old messages in a multi channel subscriber using 'if_modified_since' header and backtrack mixed" do
+      channel_1 = 'ch_test_retreive_old_messages_in_multichannel_subscribe_using_if_modified_since_header_and_backtrack_mixed_1'
+      channel_2 = 'ch_test_retreive_old_messages_in_multichannel_subscribe_using_if_modified_since_header_and_backtrack_mixed_2'
+      channel_3 = 'ch_test_retreive_old_messages_in_multichannel_subscribe_using_if_modified_since_header_and_backtrack_mixed_3'
+
+      body = 'body'
+
+      nginx_run_server(config.merge(:header_template => 'HEADER\r\n'), :timeout => 45) do |conf|
+        #create channels with some messages with progressive interval (1,2,3,5,7,9,12,15,18 seconds)
+        1.upto(3) do |i|
+          sleep(i)
+          publish_message(channel_1, headers, body + i.to_s)
+          sleep(i)
+          publish_message(channel_2, headers, body + i.to_s)
+          sleep(i)
+          publish_message(channel_3, headers, body + i.to_s)
+        end
+
+        #get messages published less then 10 seconds ago
+        t = Time.now - 10
+
+        sent_headers = headers.merge({'If-Modified-Since' => t.utc.strftime("%a, %d %b %Y %T %Z")})
+
+        get_content(nginx_address + '/sub/' + channel_1.to_s + '/' + channel_2.to_s + '.b5' + '/' + channel_3.to_s, 7, sent_headers) do |response, response_headers|
+          if ["long-polling", "polling"].include?(conf.subscriber_mode)
+            expect(response_headers['LAST_MODIFIED'].to_s).not_to eql("")
+            expect(response_headers['ETAG'].to_s).not_to eql("")
+          end
+
+          lines = response.split(eol)
+          expect(lines[0]).to eql('HEADER')
+
+          line = JSON.parse(lines[1])
+          expect(line['channel']).to eql(channel_1.to_s)
+          expect(line['message']).to eql('body3')
+          expect(line['id'].to_i).to eql(3)
+
+          line = JSON.parse(lines[2])
+          expect(line['channel']).to eql(channel_2.to_s)
+          expect(line['message']).to eql('body1')
+          expect(line['id'].to_i).to eql(1)
+
+          line = JSON.parse(lines[3])
+          expect(line['channel']).to eql(channel_2.to_s)
+          expect(line['message']).to eql('body2')
+          expect(line['id'].to_i).to eql(2)
+
+          line = JSON.parse(lines[4])
+          expect(line['channel']).to eql(channel_2.to_s)
+          expect(line['message']).to eql('body3')
+          expect(line['id'].to_i).to eql(3)
+
+          line = JSON.parse(lines[5])
+          expect(line['channel']).to eql(channel_3.to_s)
+          expect(line['message']).to eql('body2')
+          expect(line['id'].to_i).to eql(2)
+
+          line = JSON.parse(lines[6])
+          expect(line['channel']).to eql(channel_3.to_s)
+          expect(line['message']).to eql('body3')
+          expect(line['id'].to_i).to eql(3)
+        end
+      end
+    end
+
+    it "should receive old messages by 'last_event_id'" do
+      channel = 'ch_test_disconnect_after_receive_old_messages_by_last_event_id_when_longpolling_is_on'
+
+      nginx_run_server(config.merge(:message_template => '~text~\r\n')) do |conf|
+        publish_message(channel, {'Event-Id' => 'event 1'}, 'msg 1')
+        publish_message(channel, {'Event-Id' => 'event 2'}, 'msg 2')
+        publish_message(channel, {}, 'msg 3')
+        publish_message(channel, {'Event-Id' => 'event 3'}, 'msg 4')
+
+        sent_headers = headers.merge({'Last-Event-Id' => 'event 2'})
+        get_content(nginx_address + '/sub/' + channel.to_s, 2, sent_headers) do |response, response_headers|
+          if ["long-polling", "polling"].include?(conf.subscriber_mode)
+            expect(response_headers['LAST_MODIFIED'].to_s).not_to eql("")
+            expect(response_headers['ETAG'].to_s).not_to eql("")
+          end
+
+          expect(response).to eql("msg 3\r\nmsg 4\r\n")
+        end
+      end
+    end
+
+    it "should receive old messages with equals 'if_modified_since' header untie them by the 'if_none_match' header" do
+      channel = 'ch_test_receiving_messages_untie_by_etag'
+      body_prefix = 'msg '
+      messages_to_publish = 10
+      now = nil
+
+      nginx_run_server(config.merge(:message_template => '~text~\r\n')) do |conf|
+        messages_to_publish.times do |i|
+          now = Time.now if i == 5
+          publish_message(channel.to_s, headers, body_prefix + i.to_s)
+        end
+
+        sent_headers = headers.merge({'If-Modified-Since' => now.utc.strftime("%a, %d %b %Y %T %Z"), 'If-None-Match' => '6'})
+        get_content(nginx_address + '/sub/' + channel.to_s, 4, sent_headers) do |response, response_headers|
+          if ["long-polling", "polling"].include?(conf.subscriber_mode)
+            expect(response_headers['LAST_MODIFIED'].to_s).not_to eql("")
+            expect(response_headers['ETAG'].to_s).to eql("W/10")
+          end
+
+          expect(response).to eql("msg 6\r\nmsg 7\r\nmsg 8\r\nmsg 9\r\n")
+        end
+      end
+    end
+
+    it "should receive message published on same second a subscriber connect" do
+      channel = 'ch_test_receiving_messages_untie_by_etag'
+      body = 'msg 1'
+
+      nginx_run_server(config.merge(:message_template => '~text~')) do |conf|
+        now = Time.now
+        publish_message(channel.to_s, headers, body)
+
+        sent_headers = headers.merge({'If-Modified-Since' => now.utc.strftime("%a, %d %b %Y %T %Z"), 'If-None-Match' => '0'})
+        get_content(nginx_address + '/sub/' + channel.to_s, 1, sent_headers) do |response, response_headers|
+          if ["long-polling", "polling"].include?(conf.subscriber_mode)
+            expect(response_headers['LAST_MODIFIED'].to_s).not_to eql("")
+            expect(response_headers['ETAG'].to_s).to eql("W/1")
+          end
+
+          expect(response).to eql("msg 1#{eol}")
+        end
+      end
+    end
+
+    it "should accept modified since and none match values not using headers" do
+      channel = 'ch_test_send_modified_since_and_none_match_values_not_using_headers'
+      body_prefix = 'msg '
+      messages_to_publish = 10
+      now = nil
+
+      nginx_run_server(config.merge(:last_received_message_time => "$arg_time", :last_received_message_tag => "$arg_tag", :message_template => '~text~\r\n')) do |conf|
+        messages_to_publish.times do |i|
+          now = Time.now if i == 5
+          publish_message(channel.to_s, headers, body_prefix + i.to_s)
+        end
+
+        params = "time=#{URI.encode(now.utc.strftime("%a, %d %b %Y %T %Z"))}&tag=6"
+        get_content(nginx_address + '/sub/' + channel.to_s + '?' + params, 4, headers) do |response, response_headers|
+          if ["long-polling", "polling"].include?(conf.subscriber_mode)
+            expect(response_headers['LAST_MODIFIED'].to_s).not_to eql("")
+            expect(response_headers['ETAG'].to_s).to eql("W/10")
+          end
+
+          expect(response).to eql("msg 6\r\nmsg 7\r\nmsg 8\r\nmsg 9\r\n")
+        end
+      end
+    end
+
+    it "should accept event id value not using headers" do
+      channel = 'ch_test_send_event_id_value_not_using_headers'
+      body_prefix = 'msg '
+      messages_to_publish = 10
+      now = nil
+
+      nginx_run_server(config.merge(:last_event_id => "$arg_event_id", :message_template => '~text~\r\n')) do |conf|
+        publish_message(channel, {'Event-Id' => 'event 1'}, 'msg 1')
+        publish_message(channel, {'Event-Id' => 'event 2'}, 'msg 2')
+        publish_message(channel, {}, 'msg 3')
+        publish_message(channel, {'Event-Id' => 'event 3'}, 'msg 4')
+
+        params = "event_id=#{URI.escape("event 2")}"
+        get_content(nginx_address + '/sub/' + channel.to_s + '?' + params, 2, headers) do |response, response_headers|
+          if ["long-polling", "polling"].include?(conf.subscriber_mode)
+            expect(response_headers['LAST_MODIFIED'].to_s).not_to eql("")
+            expect(response_headers['ETAG'].to_s).not_to eql("")
+          end
+
+          expect(response).to eql("msg 3\r\nmsg 4\r\n")
+        end
+      end
+    end
+  end
+
+  def get_content(url, number_expected_lines, request_headers, &block)
+    response = ''
+    EventMachine.run do
+      sub_1 = EventMachine::HttpRequest.new(url).get :head => request_headers
+      sub_1.stream do |chunk|
+        response += chunk
+        lines = response.split(eol).map {|line| line.gsub(/^: /, "").gsub(/^data: /, "").gsub(/^id: .*/, "") }.delete_if{|line| line.empty?}.compact
+
+        if lines.length >= number_expected_lines
+          EventMachine.stop
+          block.call("#{lines.join(eol)}#{eol}", sub_1.response_header) unless block.nil?
+        end
+      end
+    end
+  end
+
+  context "in stream mode" do
+    let(:subscriber_mode) { "streaming" }
+
+    it_should_behave_like "can receive old messages"
+  end
+
+  context "in pooling mode" do
+    let(:subscriber_mode) { "polling" }
+
+    it_should_behave_like "can receive old messages"
+  end
+
+  context "in long-pooling mode" do
+    let(:subscriber_mode) { "long-polling" }
+
+    it_should_behave_like "can receive old messages"
+  end
+
+  context "in event source mode" do
+    let(:subscriber_mode) { "eventsource" }
+    let(:eol) { "\n" }
+
+    it_should_behave_like "can receive old messages"
+  end
+
+  context "in websocket mode" do
+    let(:subscriber_mode) { "websocket" }
+
+    def get_content(url, number_expected_lines, request_headers, &block)
+      uri = URI.parse url
+
+      request_headers = request_headers.empty? ? "" : "#{request_headers.each_key.map{|k| "#{k}: #{request_headers[k]}"}.join("\r\n")}\r\n"
+      request = "GET #{uri.request_uri} HTTP/1.0\r\nConnection: Upgrade\r\nSec-WebSocket-Key: /mQoZf6pRiv8+6o72GncLQ==\r\nUpgrade: websocket\r\nSec-WebSocket-Version: 8\r\n#{request_headers}"
+
+      socket = open_socket(uri.host, uri.port)
+      socket.print("#{request}\r\n")
+      resp_headers, body = read_response_on_socket(socket, "\x89\x00")
+      socket.close
+
+      resp_headers = resp_headers.split("\r\n").inject({}) do |hash_headers, header|
+        parts = header.split(":")
+        hash_headers[parts[0]] = parts[1] if parts.count == 2
+        hash_headers
+      end
+
+      lines = body.gsub(/[^\w{:,}" ]/, "\n").gsub("f{", "{").split("\n").delete_if{|line| line.empty?}.compact
+
+      expect(lines.length).to be >= number_expected_lines
+
+      if lines.length >= number_expected_lines
+        block.call("#{lines.join("\r\n")}\r\n", resp_headers) unless block.nil?
+      end
+    end
+
+    it_should_behave_like "can receive old messages"
+  end
+end
diff -Naur nginx-1.11.3/nginx-push-stream-module/misc/spec/subscriber/websocket_spec.rb nginx-1.11.3-push/nginx-push-stream-module/misc/spec/subscriber/websocket_spec.rb
--- nginx-1.11.3/nginx-push-stream-module/misc/spec/subscriber/websocket_spec.rb	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/misc/spec/subscriber/websocket_spec.rb	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,888 @@
+# encoding: ascii
+require 'spec_helper'
+
+describe "Subscriber WebSocket" do
+  let(:config) do
+    {
+      :header_template => nil,
+      :message_template => nil,
+      :footer_template => nil,
+      :extra_location => %q{
+        location ~ /ws/(.*)? {
+            # activate websocket mode for this location
+            push_stream_subscriber websocket;
+
+            # positional channel path
+            push_stream_channels_path               $1;
+
+            # allow subscriber to publish
+            push_stream_websocket_allow_publish     on;
+            # store messages
+            push_stream_store_messages              on;
+        }
+      }
+    }
+  end
+
+  it "should check accepted methods" do
+    nginx_run_server(config) do |conf|
+      EventMachine.run do
+        multi = EventMachine::MultiRequest.new
+
+        multi.add(:a, EventMachine::HttpRequest.new(nginx_address + '/ws/ch_test_accepted_methods_1').head)
+        multi.add(:b, EventMachine::HttpRequest.new(nginx_address + '/ws/ch_test_accepted_methods_2').put(:body => 'body'))
+        multi.add(:c, EventMachine::HttpRequest.new(nginx_address + '/ws/ch_test_accepted_methods_3').post)
+        multi.add(:d, EventMachine::HttpRequest.new(nginx_address + '/ws/ch_test_accepted_methods_4').delete)
+        multi.add(:e, EventMachine::HttpRequest.new(nginx_address + '/ws/ch_test_accepted_methods_5').get)
+
+
+        multi.callback do
+          expect(multi.responses[:callback].length).to eql(5)
+
+          expect(multi.responses[:callback][:a]).to be_http_status(405)
+          expect(multi.responses[:callback][:a].req.method).to eql("HEAD")
+          expect(multi.responses[:callback][:a].response_header['ALLOW']).to eql("GET")
+
+          expect(multi.responses[:callback][:b]).to be_http_status(405)
+          expect(multi.responses[:callback][:b].req.method).to eql("PUT")
+          expect(multi.responses[:callback][:b].response_header['ALLOW']).to eql("GET")
+
+          expect(multi.responses[:callback][:c]).to be_http_status(405)
+          expect(multi.responses[:callback][:c].req.method).to eql("POST")
+          expect(multi.responses[:callback][:c].response_header['ALLOW']).to eql("GET")
+
+          expect(multi.responses[:callback][:d]).to be_http_status(405)
+          expect(multi.responses[:callback][:d].req.method).to eql("DELETE")
+          expect(multi.responses[:callback][:d].response_header['ALLOW']).to eql("GET")
+
+          expect(multi.responses[:callback][:e]).not_to be_http_status(405)
+          expect(multi.responses[:callback][:e].req.method).to eql("GET")
+
+          EventMachine.stop
+        end
+      end
+    end
+  end
+
+  it "should check mandatory headers" do
+    channel = 'ch_test_check_mandatory_headers'
+    request = "GET /ws/#{channel}.b1 HTTP/1.0\r\n"
+
+    nginx_run_server(config) do |conf|
+      socket = open_socket(nginx_host, nginx_port)
+      socket.print("#{request}\r\n")
+      headers, body = read_response_on_socket(socket)
+      expect(body).to eql("")
+      expect(headers).to match_the_pattern(/Don't have at least one of the mandatory headers: Connection, Upgrade, Sec-WebSocket-Key and Sec-WebSocket-Version/)
+      socket.close
+
+      request << "Connection: Upgrade\r\n"
+
+      socket = open_socket(nginx_host, nginx_port)
+      socket.print("#{request}\r\n")
+      headers, body = read_response_on_socket(socket)
+      expect(body).to eql("")
+      expect(headers).to match_the_pattern(/Don't have at least one of the mandatory headers: Connection, Upgrade, Sec-WebSocket-Key and Sec-WebSocket-Version/)
+      socket.close
+
+      request << "Sec-WebSocket-Key: /mQoZf6pRiv8+6o72GncLQ==\r\n"
+
+      socket = open_socket(nginx_host, nginx_port)
+      socket.print("#{request}\r\n")
+      headers, body = read_response_on_socket(socket)
+      expect(body).to eql("")
+      expect(headers).to match_the_pattern(/Don't have at least one of the mandatory headers: Connection, Upgrade, Sec-WebSocket-Key and Sec-WebSocket-Version/)
+      socket.close
+
+      request << "Upgrade: websocket\r\n"
+
+      socket = open_socket(nginx_host, nginx_port)
+      socket.print("#{request}\r\n")
+      headers, body = read_response_on_socket(socket)
+      expect(body).to eql("")
+      expect(headers).to match_the_pattern(/Don't have at least one of the mandatory headers: Connection, Upgrade, Sec-WebSocket-Key and Sec-WebSocket-Version/)
+      socket.close
+
+      request << "Sec-WebSocket-Version: 8\r\n"
+
+      socket = open_socket(nginx_host, nginx_port)
+      socket.print("#{request}\r\n")
+      headers, body = read_response_on_socket(socket)
+      expect(body).to eql("")
+      expect(headers).not_to match_the_pattern(/Don't have at least one of the mandatory headers: Connection, Upgrade, Sec-WebSocket-Key and Sec-WebSocket-Version/)
+      expect(headers).to match_the_pattern(/HTTP\/1\.1 101 Switching Protocols/)
+      socket.close
+    end
+  end
+
+  it "should check supported versions" do
+    channel = 'ch_test_supported_versions'
+    request = "GET /ws/#{channel}.b1 HTTP/1.0\r\nConnection: Upgrade\r\nSec-WebSocket-Key: /mQoZf6pRiv8+6o72GncLQ==\r\nUpgrade: websocket\r\n"
+
+    nginx_run_server(config) do |conf|
+      socket = open_socket(nginx_host, nginx_port)
+      socket.print("#{request}Sec-WebSocket-Version: 7\r\n\r\n")
+      headers, body = read_response_on_socket(socket)
+      expect(body).to eql("")
+      expect(headers).to match_the_pattern(/Sec-WebSocket-Version: 8, 13/)
+      expect(headers).to match_the_pattern(/X-Nginx-PushStream-Explain: Version not supported. Supported versions: 8, 13/)
+      socket.close
+
+      socket = open_socket(nginx_host, nginx_port)
+      socket.print("#{request}Sec-WebSocket-Version: 8\r\n\r\n")
+      headers, body = read_response_on_socket(socket)
+      expect(body).to eql("")
+      expect(headers).not_to match_the_pattern(/Sec-WebSocket-Version: 8, 13/)
+      expect(headers).not_to match_the_pattern(/X-Nginx-PushStream-Explain: Version not supported. Supported versions: 8, 13/)
+      socket.close
+
+      socket = open_socket(nginx_host, nginx_port)
+      socket.print("#{request}Sec-WebSocket-Version: 13\r\n\r\n")
+      headers, body = read_response_on_socket(socket)
+      expect(body).to eql("")
+      expect(headers).not_to match_the_pattern(/Sec-WebSocket-Version: 8, 13/)
+      expect(headers).not_to match_the_pattern(/X-Nginx-PushStream-Explain: Version not supported. Supported versions: 8, 13/)
+      socket.close
+    end
+  end
+
+  it "should check response headers" do
+    channel = 'ch_test_response_headers'
+    request = "GET /ws/#{channel}.b1 HTTP/1.0\r\nConnection: Upgrade\r\nSec-WebSocket-Key: /mQoZf6pRiv8+6o72GncLQ==\r\nUpgrade: websocket\r\nSec-WebSocket-Version: 8\r\n"
+
+    nginx_run_server(config) do |conf|
+      socket = open_socket(nginx_host, nginx_port)
+      socket.print("#{request}\r\n")
+      headers, body = read_response_on_socket(socket)
+      socket.close
+      expect(body).to eql("")
+      expect(headers).to match_the_pattern(/HTTP\/1\.1 101 Switching Protocols/)
+      expect(headers).to match_the_pattern(/Sec-WebSocket-Accept: RaIOIcQ6CBoc74B9EKdH0avYZnw=/)
+      expect(headers).to match_the_pattern(/Upgrade: WebSocket/)
+      expect(headers).to match_the_pattern(/Connection: Upgrade/)
+    end
+  end
+
+  it "should receive header template" do
+    channel = 'ch_test_receive_header_template'
+    request = "GET /ws/#{channel}.b1 HTTP/1.0\r\nConnection: Upgrade\r\nSec-WebSocket-Key: /mQoZf6pRiv8+6o72GncLQ==\r\nUpgrade: websocket\r\nSec-WebSocket-Version: 8\r\n"
+
+    nginx_run_server(config.merge(:header_template => "HEADER_TEMPLATE")) do |conf|
+      socket = open_socket(nginx_host, nginx_port)
+      socket.print("#{request}\r\n")
+      headers, body = read_response_on_socket(socket, 'TEMPLATE')
+      expect(body).to eql("\201\017HEADER_TEMPLATE")
+      socket.close
+    end
+  end
+
+  it "should send a ping frame to client" do
+    channel = 'ch_test_receive_ping_frame'
+    request = "GET /ws/#{channel}.b1 HTTP/1.0\r\nConnection: Upgrade\r\nSec-WebSocket-Key: /mQoZf6pRiv8+6o72GncLQ==\r\nUpgrade: websocket\r\nSec-WebSocket-Version: 8\r\n"
+
+    nginx_run_server(config.merge(:ping_message_interval => '1s')) do |conf|
+      socket = open_socket(nginx_host, nginx_port)
+      socket.print("#{request}\r\n")
+      headers, body = read_response_on_socket(socket)
+      body, dummy = read_response_on_socket(socket, "\211\000")
+      expect(body).to eql("\211\000")
+      socket.close
+    end
+  end
+
+  it "should send a close frame to client" do
+    channel = 'ch_test_receive_close_frame'
+    request = "GET /ws/#{channel}.b1 HTTP/1.0\r\nConnection: Upgrade\r\nSec-WebSocket-Key: /mQoZf6pRiv8+6o72GncLQ==\r\nUpgrade: websocket\r\nSec-WebSocket-Version: 8\r\n"
+
+    nginx_run_server(config.merge(:subscriber_connection_ttl => '1s')) do |conf|
+      socket = open_socket(nginx_host, nginx_port)
+      socket.print("#{request}\r\n")
+      headers, body = read_response_on_socket(socket)
+      body, dummy = read_response_on_socket(socket, "\210\000")
+      expect(body).to eql("\210\000")
+      socket.close
+    end
+  end
+
+  it "should send a explain message on close frame" do
+    channel = 'ch_test_receive_explain_message_close_frame'
+    request = "GET /ws/#{channel}.b1 HTTP/1.0\r\nConnection: Upgrade\r\nSec-WebSocket-Key: /mQoZf6pRiv8+6o72GncLQ==\r\nUpgrade: websocket\r\nSec-WebSocket-Version: 8\r\n"
+
+    nginx_run_server(config.merge(:authorized_channels_only => 'on')) do |conf|
+      socket = open_socket(nginx_host, nginx_port)
+      socket.print("#{request}\r\n")
+      headers, body = read_response_on_socket(socket, "\"}")
+      expect(body).to eql("\x88I\x03\xF0{\"http_status\": 403, \"explain\":\"Subscriber could not create channels.\"}")
+      socket.close
+    end
+  end
+
+  it "should receive footer template" do
+    channel = 'ch_test_receive_footer_template'
+    request = "GET /ws/#{channel}.b1 HTTP/1.0\r\nConnection: Upgrade\r\nSec-WebSocket-Key: /mQoZf6pRiv8+6o72GncLQ==\r\nUpgrade: websocket\r\nSec-WebSocket-Version: 8\r\n"
+
+    nginx_run_server(config.merge(:subscriber_connection_ttl => '1s', :footer_template => "FOOTER_TEMPLATE")) do |conf|
+      socket = open_socket(nginx_host, nginx_port)
+      socket.print("#{request}\r\n")
+      headers, body = read_response_on_socket(socket)
+      body, dummy = read_response_on_socket(socket, "\210\000")
+      expect(body).to eql("\201\017FOOTER_TEMPLATE\210\000")
+      socket.close
+    end
+  end
+
+  it "should check frames for messages with less than 125 bytes" do
+    channel = 'ch_test_receive_message_length_less_than_125'
+    request = "GET /ws/#{channel}.b1 HTTP/1.0\r\nConnection: Upgrade\r\nSec-WebSocket-Key: /mQoZf6pRiv8+6o72GncLQ==\r\nUpgrade: websocket\r\nSec-WebSocket-Version: 8\r\n"
+
+    nginx_run_server(config) do |conf|
+      socket = open_socket(nginx_host, nginx_port)
+      socket.print("#{request}\r\n")
+      headers, body = read_response_on_socket(socket)
+
+      publish_message(channel, {}, "Hello")
+
+      body, dummy = read_response_on_socket(socket, "Hello")
+      expect(body).to eql("\201\005Hello")
+      socket.close
+    end
+  end
+
+  it "should check frames for messages with more than 125 and less than 65535 bytes" do
+    message = ""
+    channel = 'ch_test_receive_message_length_more_than_125_less_then_65535'
+    request = "GET /ws/#{channel}.b1 HTTP/1.0\r\nConnection: Upgrade\r\nSec-WebSocket-Key: /mQoZf6pRiv8+6o72GncLQ==\r\nUpgrade: websocket\r\nSec-WebSocket-Version: 8\r\n"
+
+    65535.times { message << "a" }
+
+    nginx_run_server(config.merge(:client_max_body_size => '65k', :client_body_buffer_size => '65k')) do |conf|
+      publish_message(channel, {}, message)
+
+      socket = open_socket(nginx_host, nginx_port)
+      socket.print("#{request}\r\n")
+      headers, body = read_response_on_socket(socket, "aaa")
+      expect(body).to match_the_pattern(/^\201\176\377\377aaa/)
+      socket.close
+    end
+  end
+
+  it "should check frames for messages with more than 65535 bytes" do
+    message = ""
+    channel = 'ch_test_receive_message_length_more_than_65535'
+    request = "GET /ws/#{channel}.b1 HTTP/1.0\r\nConnection: Upgrade\r\nSec-WebSocket-Key: /mQoZf6pRiv8+6o72GncLQ==\r\nUpgrade: websocket\r\nSec-WebSocket-Version: 8\r\n"
+
+    65536.times { message << "a" }
+
+    nginx_run_server(config.merge(:client_max_body_size => '70k', :client_body_buffer_size => '70k')) do |conf|
+      publish_message(channel, {}, message)
+
+      socket = open_socket(nginx_host, nginx_port)
+      socket.print("#{request}\r\n")
+      headers, body = read_response_on_socket(socket, "aaa")
+      expect(body).to match_the_pattern(/^\201\177\000\000\000\000\000\001\000\000aaa/)
+      socket.close
+    end
+  end
+
+  it "should accept same message template in different locations" do
+    channel = 'ch_test_same_message_template_different_locations'
+    body = 'body'
+
+    nginx_run_server(config.merge(:message_template => '{\"text\":\"~text~\"}', :subscriber_connection_ttl => '1s')) do |conf|
+      publish_message(channel, {}, body)
+
+      request_1 = "GET /ws/#{channel}.b1 HTTP/1.0\r\nConnection: Upgrade\r\nSec-WebSocket-Key: /mQoZf6pRiv8+6o72GncLQ==\r\nUpgrade: websocket\r\nSec-WebSocket-Version: 8\r\n"
+      request_2 = "GET /sub/#{channel}.b1 HTTP/1.0\r\n"
+
+      socket_1 = open_socket(nginx_host, nginx_port)
+      socket_1.print("#{request_1}\r\n")
+      headers_1, body_1 = read_response_on_socket(socket_1, '}')
+      expect(body_1).to eql("\201\017{\"text\":\"#{body}\"}")
+
+      socket_2 = open_socket(nginx_host, nginx_port)
+      socket_2.print("#{request_2}\r\n")
+      headers_2, body_2 = read_response_on_socket(socket_2, '}')
+      expect(body_2).to eql("{\"text\":\"#{body}\"}")
+      socket_1.close
+      socket_2.close
+    end
+  end
+
+  it "should publish message to all subscribed channels using the same stream" do
+    frame = "%c%c%c%c%c%c%c%c%c%c%c" % [0x81, 0x85, 0xBD, 0xD0, 0xE5, 0x2A, 0xD5, 0xB5, 0x89, 0x46, 0xD2] #send 'hello' text
+
+    request = "GET /ws/ch2/ch1 HTTP/1.0\r\nConnection: Upgrade\r\nSec-WebSocket-Key: /mQoZf6pRiv8+6o72GncLQ==\r\nUpgrade: websocket\r\nSec-WebSocket-Version: 8\r\n"
+
+    nginx_run_server(config.merge({ message_template: '{\"channel\":\"~channel~\", \"id\":\"~id~\", \"message\":\"~text~\"}' })) do |conf|
+      socket = open_socket(nginx_host, nginx_port)
+      socket.print("#{request}\r\n")
+      headers, body = read_response_on_socket(socket)
+      socket.print(frame)
+
+      body, dummy = read_response_on_socket(socket, "ch1")
+      expect(body).to eql("\x81.{\"channel\":\"ch2\", \"id\":\"1\", \"message\":\"hello\"}\x81.{\"channel\":\"ch1\", \"id\":\"1\", \"message\":\"hello\"}")
+      socket.close
+
+      EventMachine.run do
+        pub = EventMachine::HttpRequest.new(nginx_address + '/channels-stats?id=ALL').get :timeout => 30
+        pub.callback do
+          expect(pub).to be_http_status(200).with_body
+          response = JSON.parse(pub.response)
+          expect(response["channels"].to_s).not_to be_empty
+          expect(response["channels"].to_i).to eql(2)
+          expect(response["infos"][0]["channel"]).to eql("ch2")
+          expect(response["infos"][0]["published_messages"]).to eql(1)
+          expect(response["infos"][0]["stored_messages"]).to eql(1)
+          expect(response["infos"][1]["channel"]).to eql("ch1")
+          expect(response["infos"][1]["published_messages"]).to eql(1)
+          expect(response["infos"][1]["stored_messages"]).to eql(1)
+          EventMachine.stop
+        end
+      end
+
+      EventMachine.run do
+        sub = EventMachine::HttpRequest.new(nginx_address + '/sub/ch1.b1').get :timeout => 30
+        sub.stream do |chunk|
+          line = JSON.parse(chunk.split("\r\n")[0])
+          expect(line['channel']).to eql("ch1")
+          expect(line['message']).to eql('hello')
+          expect(line['id'].to_i).to eql(1)
+          EventMachine.stop
+        end
+      end
+
+      EventMachine.run do
+        sub = EventMachine::HttpRequest.new(nginx_address + '/sub/ch2.b1').get :timeout => 30
+        sub.stream do |chunk|
+          line = JSON.parse(chunk.split("\r\n")[0])
+          expect(line['channel']).to eql("ch2")
+          expect(line['message']).to eql('hello')
+          expect(line['id'].to_i).to eql(1)
+          EventMachine.stop
+        end
+      end
+    end
+  end
+
+  it "should publish large message" do
+    channel = 'ch_test_publish_large_message'
+
+    small_message = "^|" + ("0123456789" * 1020) + "|$"
+    large_message = "^|" + ("0123456789" * 419430) + "|$"
+
+    received_messages = 0;
+    nginx_run_server(config.merge({ shared_memory_size: '15m', message_template: '{\"channel\":\"~channel~\", \"id\":\"~id~\", \"message\":\"~text~\"}' }), timeout: 10) do |conf|
+      EventMachine.run do
+        ws = WebSocket::EventMachine::Client.connect(:uri => "ws://#{nginx_host}:#{nginx_port}/ws/#{channel}")
+        ws.onmessage do |text, type|
+          received_messages += 1
+          msg = JSON.parse(text)
+          expect(msg['channel']).to eql(channel)
+          if received_messages == 1
+            expect(msg['message']).to eql(large_message)
+            expect(msg['message'].size).to eql(4194304) # 4mb
+            ws.send small_message
+          elsif received_messages == 2
+            expect(msg['message']).to eql(small_message)
+            expect(msg['message'].size).to eql(10204) # 10kb
+            EventMachine.stop
+          end
+        end
+
+        EM.add_timer(1) do
+          ws.send large_message
+        end
+      end
+    end
+  end
+
+  it "should publish message with a low bitrate" do
+    channel = 'ch_test_publish_message_low_bitrate'
+
+    configuration = config.merge({
+      shared_memory_size: '15m',
+      message_template: '{\"channel\":\"~channel~\", \"message\":\"~text~\"}',
+    })
+
+    count = 0
+    nginx_run_server(configuration, timeout: 60) do |conf|
+      EventMachine.run do
+        frame = "%c%c%c%c%c%c%c%c%c%c%c" % [0x81, 0x85, 0x37, 0xfa, 0x21, 0x3d, 0x7f, 0x9f, 0x4d, 0x51, 0x58] #send 'hello' frame
+
+        request = "GET /ws/#{channel} HTTP/1.0\r\nConnection: Upgrade\r\nSec-WebSocket-Key: /mQoZf6pRiv8+6o72GncLQ==\r\nUpgrade: websocket\r\nSec-WebSocket-Version: 8\r\n"
+
+        socket = open_socket(nginx_host, nginx_port)
+        socket.print("#{request}\r\n")
+        headers, body = read_response_on_socket(socket)
+
+        EM.add_periodic_timer(2) do
+          socket.print(frame[count])
+          count += 1
+        end
+
+        EM.add_timer(frame.size * 3) do
+          pub = EventMachine::HttpRequest.new(nginx_address + '/channels-stats?id=' + channel.to_s).get :timeout => 30
+          pub.callback do
+            body, dummy = read_response_on_socket(socket, "llo")
+            expect(body).to include(%[{"channel":"ch_test_publish_message_low_bitrate", "message":"Hello"}])
+            socket.close
+            expect(pub).to be_http_status(200).with_body
+            response = JSON.parse(pub.response)
+            expect(response["channel"].to_s).to eql(channel)
+            expect(response["published_messages"].to_i).to eql(1)
+            expect(response["stored_messages"].to_i).to eql(1)
+            expect(response["subscribers"].to_i).to eql(1)
+            EventMachine.stop
+          end
+        end
+      end
+    end
+  end
+
+  it "should accept ping message and return a pong frame" do
+    channel = 'ch_test_accept_ping_message'
+    frame = "%c%c%c%c%c%c%c" % [0x89, 0x05, 0x48, 0x65, 0x6c, 0x6c, 0x6f] #send 'ping' frame with message
+
+    request = "GET /ws/#{channel}.b1 HTTP/1.0\r\nConnection: Upgrade\r\nSec-WebSocket-Key: /mQoZf6pRiv8+6o72GncLQ==\r\nUpgrade: websocket\r\nSec-WebSocket-Version: 8\r\n"
+
+    nginx_run_server(config) do |conf|
+      socket = open_socket(nginx_host, nginx_port)
+      socket.print("#{request}\r\n")
+      headers, body = read_response_on_socket(socket)
+      socket.print(frame)
+      body, _ = read_response_on_socket(socket)
+      expect(body).to eql("\x8A\x00")
+
+      EventMachine.run do
+        pub = EventMachine::HttpRequest.new(nginx_address + '/channels-stats?id=' + channel.to_s).get :timeout => 30
+        pub.callback do
+          socket.close
+          expect(pub).to be_http_status(200).with_body
+          response = JSON.parse(pub.response)
+          expect(response["channel"].to_s).to eql(channel)
+          expect(response["published_messages"].to_i).to eql(0)
+          expect(response["stored_messages"].to_i).to eql(0)
+          expect(response["subscribers"].to_i).to eql(1)
+          EventMachine.stop
+        end
+      end
+    end
+  end
+
+  it "should accept pong message" do
+    channel = 'ch_test_accept_pong_message'
+    frame = "%c%c%c%c%c%c" % [0x8A, 0x80, 0xBD, 0xD0, 0xE5, 0x2A] #send 'pong' frame
+
+    request = "GET /ws/#{channel}.b1 HTTP/1.0\r\nConnection: Upgrade\r\nSec-WebSocket-Key: /mQoZf6pRiv8+6o72GncLQ==\r\nUpgrade: websocket\r\nSec-WebSocket-Version: 8\r\n"
+
+    nginx_run_server(config) do |conf|
+      socket = open_socket(nginx_host, nginx_port)
+      socket.print("#{request}\r\n")
+      headers, body = read_response_on_socket(socket)
+      socket.print(frame)
+
+      EventMachine.run do
+        pub = EventMachine::HttpRequest.new(nginx_address + '/channels-stats?id=' + channel.to_s).get :timeout => 30
+        pub.callback do
+          socket.close
+          expect(pub).to be_http_status(200).with_body
+          response = JSON.parse(pub.response)
+          expect(response["channel"].to_s).to eql(channel)
+          expect(response["published_messages"].to_i).to eql(0)
+          expect(response["stored_messages"].to_i).to eql(0)
+          expect(response["subscribers"].to_i).to eql(1)
+          EventMachine.stop
+        end
+      end
+    end
+  end
+
+  it "should accept close message" do
+    channel = 'ch_test_accept_close_message'
+    frame = "%c%c%c%c%c%c" % [0x88, 0x80, 0xBD, 0xD0, 0xE5, 0x2A] #send 'close' frame
+
+    request = "GET /ws/#{channel}.b1 HTTP/1.0\r\nConnection: Upgrade\r\nSec-WebSocket-Key: /mQoZf6pRiv8+6o72GncLQ==\r\nUpgrade: websocket\r\nSec-WebSocket-Version: 8\r\n"
+
+    nginx_run_server(config) do |conf|
+      socket = open_socket(nginx_host, nginx_port)
+      socket.print("#{request}\r\n")
+      headers, body = read_response_on_socket(socket)
+      socket.print(frame)
+      body, dummy = read_response_on_socket(socket, "\210\000")
+      expect(body).to eql("\210\000")
+
+      EventMachine.run do
+        pub = EventMachine::HttpRequest.new(nginx_address + '/channels-stats?id=' + channel.to_s).get :timeout => 30
+        pub.callback do
+          socket.close
+          expect(pub).to be_http_status(200).with_body
+          response = JSON.parse(pub.response)
+          expect(response["channel"].to_s).to eql(channel)
+          expect(response["published_messages"].to_i).to eql(0)
+          expect(response["stored_messages"].to_i).to eql(0)
+          expect(response["subscribers"].to_i).to eql(0)
+          EventMachine.stop
+        end
+      end
+    end
+  end
+
+  it "should accept messages with different bytes" do
+    nginx_run_server(config.merge(:client_max_body_size => '130k', :client_body_buffer_size => '130k', :message_template => "~text~|")) do |conf|
+      ranges = [0..255]
+      ranges.each do |range|
+        bytes = []
+        range.each do |i|
+          0.upto(255) do |j|
+            bytes << "%s%s" % [i.chr, j.chr]
+          end
+        end
+
+        channel = "ch_test_publish_messages_with_different_bytes_#{range}"
+
+        body = bytes.join('')
+        response = ''
+
+        request = "GET /ws/#{channel} HTTP/1.0\r\nConnection: Upgrade\r\nSec-WebSocket-Key: /mQoZf6pRiv8+6o72GncLQ==\r\nUpgrade: websocket\r\nSec-WebSocket-Version: 8\r\n"
+
+        socket = open_socket(nginx_host, nginx_port)
+        socket.print("#{request}\r\n")
+
+        EventMachine.run do
+          pub = EventMachine::HttpRequest.new(nginx_address + '/pub?id=' + channel.to_s ).post :head => headers, :body => body
+          pub.callback do
+            headers, resp = read_response_on_socket(socket, '|')
+            expect(resp.bytes.to_a).to eql("\x81\x7F\x00\x00\x00\x00\x00\x02\x00\x01#{body}|".bytes.to_a)
+            EventMachine.stop
+            socket.close
+          end
+        end
+      end
+    end
+  end
+
+  it "should not cache the response" do
+    channel = 'ch_test_not_cache_the_response'
+
+    request = "GET /ws/#{channel}.b1 HTTP/1.0\r\nConnection: Upgrade\r\nSec-WebSocket-Key: /mQoZf6pRiv8+6o72GncLQ==\r\nUpgrade: websocket\r\nSec-WebSocket-Version: 8\r\n"
+
+    nginx_run_server(config) do |conf|
+      socket = open_socket(nginx_host, nginx_port)
+      socket.print("#{request}\r\n")
+      headers, body = read_response_on_socket(socket)
+      socket.close
+
+      expect(headers).to include("Expires: Thu, 01 Jan 1970 00:00:01 GMT\r\n")
+      expect(headers).to include("Cache-Control: no-cache, no-store, must-revalidate\r\n")
+    end
+  end
+
+  it "should not try to parse the request line when receive a frame after send close frame" do
+    channel = 'ch_test_data_after_close_frame_parse_request_line'
+    pid = pid2 = 0
+
+    request = "GET /ws/#{channel}.b1 HTTP/1.1\r\nHost: localhost\r\nConnection: Upgrade\r\nSec-WebSocket-Key: /mQoZf6pRiv8+6o72GncLQ==\r\nUpgrade: websocket\r\nSec-WebSocket-Version: 8\r\n"
+
+    nginx_run_server(config.merge(:subscriber_connection_ttl => '1s')) do |conf|
+      File.open(conf.error_log, "a").truncate(0)
+
+      socket = open_socket(nginx_host, nginx_port)
+      socket.print("#{request}\r\n")
+      headers, body = read_response_on_socket(socket)
+
+      # wait for close frame
+      body, dummy = read_response_on_socket(socket, "\210\000")
+      expect(body).to eql("\210\000")
+
+      socket.print("WRITE SOMETHING UNKNOWN\r\n")
+
+      error_log = File.read(conf.error_log)
+      expect(error_log).not_to include("client sent invalid")
+      socket.close
+    end
+  end
+
+  it "should not try to parse the request line when doing a reload" do
+    channel = 'ch_test_reload_not_parse_request_line'
+    pid = pid2 = 0
+
+    request = "GET /ws/#{channel}.b1 HTTP/1.1\r\nHost: localhost\r\nConnection: Upgrade\r\nSec-WebSocket-Key: /mQoZf6pRiv8+6o72GncLQ==\r\nUpgrade: websocket\r\nSec-WebSocket-Version: 8\r\n"
+
+
+    nginx_run_server(config.merge(:ping_message_interval => "1s"), :timeout => 10) do |conf|
+      error_log_pre = File.readlines(conf.error_log)
+
+      EventMachine.run do
+        publish_message_inline(channel, {}, "body")
+
+        socket = open_socket(nginx_host, nginx_port)
+        socket.print("#{request}\r\n")
+        headers, body = read_response_on_socket(socket)
+
+        # check statistics
+        pub_1 = EventMachine::HttpRequest.new(nginx_address + '/channels-stats').get
+        pub_1.callback do
+          expect(pub_1).to be_http_status(200).with_body
+          resp_1 = JSON.parse(pub_1.response)
+          expect(resp_1.has_key?("channels")).to be_truthy
+          expect(resp_1["channels"].to_i).to eql(1)
+          expect(resp_1["subscribers"].to_i).to eql(1)
+
+          # send reload signal
+          `#{ nginx_executable } -c #{ conf.configuration_filename } -s reload > /dev/null 2>&1`
+
+          socket.print("WRITE SOMETHING UNKNOWN\r\n")
+
+          pub_2 = EventMachine::HttpRequest.new(nginx_address + '/channels-stats').get
+          pub_2.callback do
+            socket.close
+            expect(pub_2).to be_http_status(200).with_body
+            resp_2 = JSON.parse(pub_2.response)
+            expect(resp_2.has_key?("channels")).to be_truthy
+            expect(resp_2["channels"].to_i).to eql(1)
+            expect(resp_2["subscribers"].to_i).to eql(0)
+
+            error_log_pos = File.readlines(conf.error_log)
+            expect((error_log_pos - error_log_pre).join).not_to include("client sent invalid")
+
+            EventMachine.stop
+          end
+        end
+      end
+    end
+  end
+
+  it "should accept non latin characters" do
+    channel = 'ch_test_publish_non_latin'
+
+    nginx_run_server(config) do |conf|
+      EventMachine.run do
+        ws = WebSocket::EventMachine::Client.connect(:uri => "ws://#{nginx_host}:#{nginx_port}/ws/#{channel}")
+        ws.onmessage do |text, type|
+          expect(text).to eq("\xD8\xA3\xD9\x8E\xD8\xA8\xD9\x92\xD8\xAC\xD9\x8E\xD8\xAF\xD9\x90\xD9\x8A\xD9\x8E\xD9\x91\xD8\xA9 \xD8\xB9\xD9\x8E")
+          EventMachine.stop
+        end
+
+        EM.add_timer(1) do
+          ws.send "\xD8\xA3\xD9\x8E\xD8\xA8\xD9\x92\xD8\xAC\xD9\x8E\xD8\xAF\xD9\x90\xD9\x8A\xD9\x8E\xD9\x91\xD8\xA9 \xD8\xB9\xD9\x8E"
+        end
+      end
+    end
+  end
+
+  it "should reject an invalid utf8 sequence" do
+    channel = 'ch_test_publish_invalid_utf8'
+
+    nginx_run_server(config) do |conf|
+      EventMachine.run do
+        ws = WebSocket::EventMachine::Client.connect(:uri => "ws://#{nginx_host}:#{nginx_port}/ws/#{channel}")
+        ws.onmessage do |text, type|
+          fail("Should not have received the '#{text.force_encoding('UTF-8')}'")
+        end
+
+        ws.onclose do
+          EventMachine.stop
+        end
+
+        EM.add_timer(1) do
+          ws.send "\xA3\xD9\x8E\xD8\xA8\xD9\x92\xD8\xAC\xD9\x8E\xD8\xAF\xD9\x90\xD9\x8A\xD9\x8E\xD9\x91\xD8\xA9 \xD8\xB9\xD9\x8E"
+        end
+      end
+    end
+  end
+
+  it "should reject unsupported frames" do
+    channel = 'ch_test_reject_unsupported_frames'
+    frame = "%c%c%c%c%c%c%c%c%c%c%c" % [0x82, 0x85, 0xBD, 0xD0, 0xE5, 0x2A, 0xD5, 0xB5, 0x89, 0x46, 0xD2] #send binary frame
+
+    request = "GET /ws/#{channel}.b1 HTTP/1.0\r\nConnection: Upgrade\r\nSec-WebSocket-Key: /mQoZf6pRiv8+6o72GncLQ==\r\nUpgrade: websocket\r\nSec-WebSocket-Version: 8\r\n"
+
+    nginx_run_server(config) do |conf|
+      socket = open_socket(nginx_host, nginx_port)
+      socket.print("#{request}\r\n")
+      headers, body = read_response_on_socket(socket)
+      socket.print(frame)
+      body, dummy = read_response_on_socket(socket, "\210\000")
+      expect(body).to eql("\210\000")
+
+      EventMachine.run do
+        pub = EventMachine::HttpRequest.new(nginx_address + '/channels-stats?id=' + channel.to_s).get :timeout => 30
+        pub.callback do
+          socket.close
+          expect(pub).to be_http_status(200).with_body
+          response = JSON.parse(pub.response)
+          expect(response["channel"].to_s).to eql(channel)
+          expect(response["published_messages"].to_i).to eql(0)
+          expect(response["stored_messages"].to_i).to eql(0)
+          expect(response["subscribers"].to_i).to eql(0)
+          EventMachine.stop
+        end
+      end
+    end
+  end
+
+  it "should accept unmasked frames" do
+    channel = 'ch_test_publish_unmasked_frames'
+
+    configuration = config.merge({
+      shared_memory_size: '15m',
+      message_template: '{\"channel\":\"~channel~\", \"message\":\"~text~\"}',
+      subscriber_mode: 'long-polling',
+    })
+
+    nginx_run_server(configuration, timeout: 60) do |conf|
+      EventMachine.run do
+        frame = "%c%c%c%c%c%c%c" % [0x81, 0x05, 0x48, 0x65, 0x6c, 0x6c, 0x6f] #send 'hello' frame
+
+        request = "GET /ws/#{channel} HTTP/1.0\r\nConnection: Upgrade\r\nSec-WebSocket-Key: /mQoZf6pRiv8+6o72GncLQ==\r\nUpgrade: websocket\r\nSec-WebSocket-Version: 8\r\n"
+
+        socket = open_socket(nginx_host, nginx_port)
+        socket.print("#{request}\r\n")
+        headers, body = read_response_on_socket(socket)
+        socket.print(frame)
+        body, dummy = read_response_on_socket(socket, "llo")
+        expect(body).to include(%[{"channel":"ch_test_publish_unmasked_frames", "message":"Hello"}])
+        socket.close
+
+        sub = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s + '.b1').get :timeout => 30
+        sub.callback do
+          expect(sub).to be_http_status(200)
+          response = JSON.parse(sub.response)
+          expect(response["channel"].to_s).to eql(channel)
+          expect(response["message"]).to eql("Hello")
+          EventMachine.stop
+        end
+      end
+    end
+  end
+
+  it "should accept masked frames" do
+    channel = 'ch_test_publish_masked_frames'
+
+    configuration = config.merge({
+      shared_memory_size: '15m',
+      message_template: '{\"channel\":\"~channel~\", \"message\":\"~text~\"}',
+      subscriber_mode: 'long-polling',
+    })
+
+    nginx_run_server(configuration, timeout: 60) do |conf|
+      EventMachine.run do
+        frame = "%c%c%c%c%c%c%c%c%c%c%c" % [0x81, 0x85, 0x37, 0xfa, 0x21, 0x3d, 0x7f, 0x9f, 0x4d, 0x51, 0x58] #send 'hello' frame
+
+        request = "GET /ws/#{channel} HTTP/1.0\r\nConnection: Upgrade\r\nSec-WebSocket-Key: /mQoZf6pRiv8+6o72GncLQ==\r\nUpgrade: websocket\r\nSec-WebSocket-Version: 8\r\n"
+
+        socket = open_socket(nginx_host, nginx_port)
+        socket.print("#{request}\r\n")
+        headers, body = read_response_on_socket(socket)
+        socket.print(frame)
+        body, dummy = read_response_on_socket(socket, "llo")
+        expect(body).to include(%[{"channel":"ch_test_publish_masked_frames", "message":"Hello"}])
+        socket.close
+
+        sub = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s + '.b1').get :timeout => 30
+        sub.callback do
+          expect(sub).to be_http_status(200)
+          response = JSON.parse(sub.response)
+          expect(response["channel"].to_s).to eql(channel)
+          expect(response["message"]).to eql("Hello")
+          EventMachine.stop
+        end
+      end
+    end
+  end
+
+  it "should accept fragmented unmasked frames" do
+    channel = 'ch_test_publish_fragmented_unmasked_frames'
+
+    configuration = config.merge({
+      shared_memory_size: '15m',
+      message_template: '{\"channel\":\"~channel~\", \"message\":\"~text~\"}',
+      subscriber_mode: 'long-polling',
+    })
+
+    nginx_run_server(configuration, timeout: 60) do |conf|
+      EventMachine.run do
+        frame_part1 = "%c%c%c%c%c" % [0x01, 0x03, 0x48, 0x65, 0x6c] #send 'Hel' frame
+        frame_part2 = "%c%c%c%c" % [0x80, 0x02, 0x6c, 0x6f] #send 'lo' frame
+
+        request = "GET /ws/#{channel} HTTP/1.0\r\nConnection: Upgrade\r\nSec-WebSocket-Key: /mQoZf6pRiv8+6o72GncLQ==\r\nUpgrade: websocket\r\nSec-WebSocket-Version: 8\r\n"
+
+        socket = open_socket(nginx_host, nginx_port)
+        socket.print("#{request}\r\n")
+        headers, body = read_response_on_socket(socket)
+        socket.print(frame_part1)
+        socket.print(frame_part2)
+        body, dummy = read_response_on_socket(socket, "llo")
+        expect(body).to include(%[{"channel":"ch_test_publish_fragmented_unmasked_frames", "message":"Hello"}])
+        socket.close
+
+        sub = EventMachine::HttpRequest.new(nginx_address + '/sub/' + channel.to_s + '.b1').get :timeout => 30
+        sub.callback do
+          expect(sub).to be_http_status(200)
+          response = JSON.parse(sub.response)
+          expect(response["channel"].to_s).to eql(channel)
+          expect(response["message"]).to eql("Hello")
+          EventMachine.stop
+        end
+      end
+    end
+  end
+
+  it "should accept all kinds of frames mixed" do
+    channel = 'ch_test_publish_frames_mixed'
+
+    configuration = config.merge({
+      shared_memory_size: '15m',
+      message_template: '{\"channel\":\"~channel~\", \"message\":\"~text~\"}',
+    })
+
+    nginx_run_server(configuration, timeout: 60) do |conf|
+      frame_unmasked = "%c%c%c%c%c%c%c" % [0x81, 0x05, 0x48, 0x65, 0x6c, 0x6c, 0x6f] #send 'hello' frame
+      frame_masked = "%c%c%c%c%c%c%c%c%c%c%c" % [0x81, 0x85, 0x37, 0xfa, 0x21, 0x3d, 0x7f, 0x9f, 0x4d, 0x51, 0x58] #send 'hello' frame
+      frame_part1 = "%c%c%c%c%c" % [0x01, 0x03, 0x48, 0x65, 0x6c] #send 'Hel' frame
+      frame_part2 = "%c%c%c%c" % [0x80, 0x02, 0x6c, 0x6f] #send 'lo' frame
+
+      request = "GET /ws/#{channel} HTTP/1.0\r\nConnection: Upgrade\r\nSec-WebSocket-Key: /mQoZf6pRiv8+6o72GncLQ==\r\nUpgrade: websocket\r\nSec-WebSocket-Version: 8\r\n"
+
+      socket = open_socket(nginx_host, nginx_port)
+      socket.print("#{request}\r\n")
+      headers, body = read_response_on_socket(socket)
+
+      socket.print(frame_unmasked)
+      body, dummy = read_response_on_socket(socket, "llo")
+      expect(body).to include(%[{"channel":"ch_test_publish_frames_mixed", "message":"Hello"}])
+
+      socket.print(frame_masked)
+      body, dummy = read_response_on_socket(socket, "llo")
+      expect(body).to include(%[{"channel":"ch_test_publish_frames_mixed", "message":"Hello"}])
+
+      socket.print(frame_part1)
+      socket.print(frame_part2)
+      body, dummy = read_response_on_socket(socket, "llo")
+      expect(body).to include(%[{"channel":"ch_test_publish_frames_mixed", "message":"Hello"}])
+
+      socket.print(frame_masked)
+      body, dummy = read_response_on_socket(socket, "llo")
+      expect(body).to include(%[{"channel":"ch_test_publish_frames_mixed", "message":"Hello"}])
+
+      socket.print(frame_unmasked)
+      body, dummy = read_response_on_socket(socket, "llo")
+      expect(body).to include(%[{"channel":"ch_test_publish_frames_mixed", "message":"Hello"}])
+
+      socket.print(frame_part1)
+      socket.print(frame_part2)
+      body, dummy = read_response_on_socket(socket, "llo")
+      expect(body).to include(%[{"channel":"ch_test_publish_frames_mixed", "message":"Hello"}])
+
+      socket.print(frame_unmasked)
+      body, dummy = read_response_on_socket(socket, "llo")
+      expect(body).to include(%[{"channel":"ch_test_publish_frames_mixed", "message":"Hello"}])
+
+      socket.print(frame_masked)
+      body, dummy = read_response_on_socket(socket, "llo")
+      expect(body).to include(%[{"channel":"ch_test_publish_frames_mixed", "message":"Hello"}])
+
+      socket.close
+    end
+  end
+end
diff -Naur nginx-1.11.3/nginx-push-stream-module/misc/tools/Makefile nginx-1.11.3-push/nginx-push-stream-module/misc/tools/Makefile
--- nginx-1.11.3/nginx-push-stream-module/misc/tools/Makefile	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/misc/tools/Makefile	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,19 @@
+all: publisher subscriber 
+
+subscriber: subscriber.o util.o
+	gcc -g -Oo subscriber.o util.o -o subscriber -largtable2
+
+publisher: publisher.o util.o
+	gcc -g -Oo publisher.o util.o -o publisher -largtable2
+
+subscriber.o: subscriber.c
+	gcc -g -c subscriber.c
+
+publisher.o: publisher.c
+	gcc -g -c publisher.c
+
+util.o: util.c
+	gcc -g -c util.c
+
+clean:
+	rm -rf *o publisher subscriber
diff -Naur nginx-1.11.3/nginx-push-stream-module/misc/tools/publisher.c nginx-1.11.3-push/nginx-push-stream-module/misc/tools/publisher.c
--- nginx-1.11.3/nginx-push-stream-module/misc/tools/publisher.c	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/misc/tools/publisher.c	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,308 @@
+/*
+Copyright (C) 2011 Michael Costello, Wandenberg Peixoto <wandenberg@gmail.com>
+
+Usage './publisher --help' to see option
+*/
+#include <argtable2.h>
+#include "util.h"
+
+
+void write_message(Connection *connection, Statistics *stats);
+void read_response(Connection *connection, Statistics *stats, char *buffer, int buffer_len);
+
+int
+main_program(int num_messages, int num_channels, int num_connections, int loop_interval, const char *server_hostname, int server_port, int timeout)
+{
+    struct sockaddr_in server_address;
+    int main_sd = -1, num_events = 0, i, event_mask, channels_per_connection, num, start_time = 0, iters_to_next_summary = 0;
+    Connection *connections = NULL, *connection;
+    Statistics stats = {0,0,0,0,0};
+    int exitcode = EXIT_SUCCESS;
+    struct epoll_event events[MAX_EVENTS];
+    char buffer[BIG_BUFFER_SIZE];
+
+    info("Publisher starting up\n");
+    info("Publish: %d messages to %d channels on server: %s:%d\n", num_messages, num_channels, server_hostname, server_port);
+
+    if ((fill_server_address(server_hostname, server_port, &server_address)) != 0) {
+        error2("ERROR host name not found\n");
+    }
+
+    if ((main_sd = epoll_create(200 /* this size is not used on Linux kernel 2.6.8+ */)) < 0) {
+        error3("Failed %d creating main epoll socket\n", errno);
+    }
+
+    if ((connections = init_connections(num_connections, &server_address, main_sd)) == NULL) {
+        error2("Failed to create to connections\n");
+    }
+
+    stats.requested_connections = num_connections;
+
+    channels_per_connection = num_channels / num_connections;
+    for (i = 0; i < num_connections; i++) {
+        num = i * channels_per_connection;
+        connections[i].channel_start = num;
+        num += channels_per_connection - 1;
+        connections[i].channel_end = ((num > num_channels) || (i == (num_connections - 1))) ? num_channels - 1 : num;
+    }
+
+    // infinite loop
+    debug("Entering Infinite Loop\n");
+
+    iters_to_next_summary = ITERATIONS_TILL_SUMMARY_PER_TIMEOUT/timeout;
+
+    for(;;) {
+        if ((num_events = epoll_wait(main_sd, events, MAX_EVENTS, timeout)) < 0) {
+            error3("epoll_wait failed\n");
+        }
+
+        for (i = 0; i < num_events; i++) {
+            event_mask = events[i].events;
+            connection = (Connection *)(events[i].data.ptr);
+
+            if ((connection->message_count >= num_messages) && (connection->channel_id > connection->channel_end)) {
+                // remove write flag from event
+                if (change_connection(connection, EPOLLIN | EPOLLHUP) < 0) {
+                    error2("Failed creating socket for connection = %d\n", connection->index);
+                }
+
+                if (event_mask & EPOLLOUT) { // WRITE
+                    continue;
+                }
+            }
+
+            if (event_mask & EPOLLHUP) { // SERVER HUNG UP
+                debug("EPOLLHUP\n");
+                info("Server hung up on conncetion %d. Reconecting...\n", connection->index);
+                sleep(1);
+                reopen_connection(connection);
+
+                continue;
+            }
+
+            if (event_mask & EPOLLERR) {
+                debug("EPOLLERR\n");
+                info("Server returned an error on connection %d. Reconecting...\n", connection->index);
+                reopen_connection(connection);
+
+                continue;
+            }
+
+            if (event_mask & EPOLLIN) { // READ
+                debug("----------READ AVAILABLE-------\n");
+
+                if (connection->state == CONNECTED) {
+                    read_response(connection, &stats, buffer, BIG_BUFFER_SIZE);
+                }
+            }
+
+            if (event_mask & EPOLLOUT) { // WRITE
+                debug("----------WRITE AVAILABLE-------\n");
+
+                if (start_time == 0) {
+                    start_time = time(NULL);
+                }
+
+                if (connection->state == CONNECTING) {
+                    connection->state = CONNECTED;
+                    stats.connections++;
+                    debug("Connection opened for index=%d\n", connection->index);
+                }
+
+                write_message(connection, &stats);
+            }
+        }
+
+        if (iters_to_next_summary-- <= 0) {
+            iters_to_next_summary = ITERATIONS_TILL_SUMMARY_PER_TIMEOUT/timeout;
+            summary("Connections=%ld, Messages=%ld BytesWritten=%ld Msg/Sec=%0.2f\n", stats.connections, stats.messages, stats.bytes_written, calc_message_per_second(stats.messages, start_time));
+        }
+
+        if (stats.messages >= (num_channels * num_messages)) {
+            summary("Connections=%ld, Messages=%ld BytesWritten=%ld Msg/Sec=%0.2f\n", stats.connections, stats.messages, stats.bytes_written, calc_message_per_second(stats.messages, start_time));
+            if (loop_interval != 0) {
+                stats.messages = 0;
+                for (i = 0; i < num_connections; i++) {
+                    connections[i].message_count = 0;
+                    connections[i].channel_id = -1;
+
+                    if (change_connection(&connections[i], EPOLLIN | EPOLLHUP | EPOLLOUT) < 0) {
+                        error2("Failed creating socket for connection = %d\n", connection->index);
+                    }
+                }
+
+                sleep(loop_interval);
+
+            } else {
+                for (i = 0; i < num_connections; i++) {
+                    close_connection(&connections[i]);
+                    stats.connections--;
+                }
+                exitcode = EXIT_SUCCESS;
+                goto exit;
+            }
+        }
+    }
+
+
+exit:
+    if (connections != NULL) free(connections);
+
+    return exitcode;
+}
+
+
+void
+write_message(Connection *connection, Statistics *stats)
+{
+    char buffer[BUFFER_SIZE];
+    int len = 0, bytes_written = 0;
+
+    if ((connection->channel_id <= connection->channel_start) || (connection->channel_id > connection->channel_end)) {
+        connection->channel_id = connection->channel_start;
+        connection->message_count++;
+
+        // gives a message payload of 140 bytes
+        connection->content_length = sprintf(connection->content_buffer, "**MSG** msg=%06d 012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789012345678901234567890123456789", connection->message_count);
+        connection->content_buffer[connection->content_length] = '\0';
+    }
+
+    len = sprintf(buffer, "POST /pub?id=my_channel_%ld HTTP/1.1\r\nHost: loadtest\r\nContent-Length: %d\r\n\r\n%s", connection->channel_id, connection->content_length, connection->content_buffer);
+
+    if (write_connection(connection, stats, buffer, len) == EXIT_FAILURE) {
+        reopen_connection(connection);
+        return;
+    }
+
+    connection->channel_id++;
+}
+
+
+void
+read_response(Connection *connection, Statistics *stats, char *buffer, int buffer_len)
+{
+    int bytes_read = 0, bad_count = 0, ok_count = 0;
+
+    bytes_read = read(connection->sd, buffer, buffer_len - 1);
+
+    if (bytes_read < 0) {
+        error("Error reading from socket for connection %d\n", connection->index);
+        reopen_connection(connection);
+        return;
+    }
+
+    if (bytes_read == 0) { // server disconnected us
+        // reconnect
+        info("Server disconnected as requested %d.\n", connection->index);
+        close_connection(connection);
+        return;
+    }
+
+    stats->bytes_read += bytes_read;
+    buffer[bytes_read] = '\0';
+    debug("Read %d bytes\n", bytes_read);
+    trace("Read Message: %s\n", buffer);
+
+    bad_count = count_strinstr(buffer, "HTTP/1.1 4");
+    bad_count += count_strinstr(buffer, "HTTP/1.1 5");
+
+    if (bad_count > 0) {
+        info("Recevied error. Buffer is %s\n", buffer);
+        reopen_connection(connection);
+        return;
+    }
+
+    ok_count = count_strinstr(buffer, "HTTP/1.1 200 OK");
+    stats->messages += ok_count;
+}
+
+
+int
+main(int argc, char **argv)
+{
+    struct arg_int *messages    = arg_int0("m", "messages", "<n>", "define number of messages to publish in each channel (default is 1)");
+    struct arg_int *channels  = arg_int0("c", "channels", "<n>", "define number of channels (default is 1)");
+    struct arg_int *publishers  = arg_int0("p", "publishers", "<n>", "define number of publishers (default is 1)");
+
+    struct arg_int *loop_interval  = arg_int0("l", "loop_interval", "<n>", "define the interval between loops in seconds. each loop send the specified number of messages (default is 0, not loop)");
+
+    struct arg_str *server_name = arg_str0("S", "server", "<hostname>", "server hostname where messages will be published (default is \"127.0.0.1\")");
+    struct arg_int *server_port = arg_int0("P", "port", "<n>", "server port where messages will be published (default is 9080)");
+
+    struct arg_int *timeout = arg_int0(NULL, "timeout", "<n>", "timeout when waiting events on communication to the server (default is 1000)");
+    struct arg_int *verbose = arg_int0("v", "verbose", "<n>", "increase output messages detail (0 (default) - no messages, 1 - info messages, 2 - debug messages, 3 - trace messages");
+
+    struct arg_lit *help    = arg_lit0(NULL, "help", "print this help and exit");
+    struct arg_lit *version = arg_lit0(NULL, "version", "print version information and exit");
+    struct arg_end *end     = arg_end(20);
+
+    void* argtable[] = { messages, channels, publishers, loop_interval, server_name, server_port, timeout, verbose, help, version, end };
+
+    const char* progname = "publisher";
+    int nerrors;
+    int exitcode = EXIT_SUCCESS;
+
+    /* verify the argtable[] entries were allocated sucessfully */
+    if (arg_nullcheck(argtable) != 0) {
+        /* NULL entries were detected, some allocations must have failed */
+        printf("%s: insufficient memory\n", progname);
+        exitcode = EXIT_FAILURE;
+        goto exit;
+    }
+
+    /* set any command line default values prior to parsing */
+    messages->ival[0] = DEFAULT_NUM_MESSAGES;
+    publishers->ival[0] = DEFAULT_CONCURRENT_CONN;
+    channels->ival[0] = DEFAULT_NUM_CHANNELS;
+    loop_interval->ival[0] = 0;
+    server_name->sval[0] = DEFAULT_SERVER_HOSTNAME;
+    server_port->ival[0] = DEFAULT_SERVER_PORT;
+    timeout->ival[0] = DEFAULT_TIMEOUT;
+    verbose->ival[0] = 0;
+
+    /* Parse the command line as defined by argtable[] */
+    nerrors = arg_parse(argc, argv, argtable);
+
+    /* special case: '--help' takes precedence over error reporting */
+    if (help->count > 0) {
+        printf(DESCRIPTION_PUBLISHER, progname, VERSION, COPYRIGHT);
+        printf("Usage: %s", progname);
+        arg_print_syntax(stdout, argtable, "\n");
+        arg_print_glossary(stdout, argtable, "  %-25s %s\n");
+        exitcode = EXIT_SUCCESS;
+        goto exit;
+    }
+
+    /* special case: '--version' takes precedence error reporting */
+    if (version->count > 0) {
+        printf(DESCRIPTION_PUBLISHER, progname, VERSION, COPYRIGHT);
+        exitcode = EXIT_SUCCESS;
+        goto exit;
+    }
+
+    if (publishers->ival[0] > channels->ival[0]) {
+        printf("Publisher number (%d) can not be greater than Channel number (%d).\n", publishers->ival[0], channels->ival[0]);
+        exitcode = EXIT_FAILURE;
+        goto exit;
+    }
+
+    /* If the parser returned any errors then display them and exit */
+    if (nerrors > 0) {
+        /* Display the error details contained in the arg_end struct.*/
+        arg_print_errors(stdout, end, progname);
+        printf("Try '%s --help' for more information.\n", progname);
+        exitcode = EXIT_FAILURE;
+        goto exit;
+    }
+
+    verbose_messages = verbose->ival[0];
+
+    /* normal case: take the command line options at face value */
+    exitcode = main_program(messages->ival[0], channels->ival[0], publishers->ival[0], loop_interval->ival[0], server_name->sval[0], server_port->ival[0], timeout->ival[0]);
+
+exit:
+    /* deallocate each non-null entry in argtable[] */
+    arg_freetable(argtable, sizeof(argtable) / sizeof(argtable[0]));
+
+    return exitcode;
+}
diff -Naur nginx-1.11.3/nginx-push-stream-module/misc/tools/README nginx-1.11.3-push/nginx-push-stream-module/misc/tools/README
--- nginx-1.11.3/nginx-push-stream-module/misc/tools/README	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/misc/tools/README	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,78 @@
+Copyright (C) 2011 Michael Costello, Wandenberg Peixoto <wandenberg@gmail.com>
+
+These tools, publisher and subscriber, were developed only to do some load tests on push stream module.
+Their use is very restricted and is not intended to cover all possible configuration for the module.
+The first version was developed by Michael Costello and I made some improvements to distribute it.
+Feel free to help continuous improvement.
+
+Any feedbacks will be welcome.
+
+=============
+Requirements:
+=============
+
+lib argtable2
+GCC, make, the usual guys
+epoll event support
+
+================
+Developer Guide:
+================
+
+The basic configuration used on the load tests are listed bellow.
+To compile the tools only execute a make.
+
+To see all options use:
+  ./publisher --help
+  ./subscriber --help
+
+Pay attention on default values to run your tests.
+
+====================
+Basic Configuration:
+====================
+
+pid         logs/nginx.pid;
+error_log   logs/nginx-main_error.log debug;
+
+worker_rlimit_core  500M;
+working_directory /tmp/nginx;
+
+worker_processes    2;
+
+events {
+  worker_connections  1024;
+  use                 epoll;
+}
+
+http {
+  include         mime.types;
+  default_type    application/octet-stream;
+
+  access_log      logs/nginx-http_access.log;
+  error_log       logs/nginx-http_error.log debug;
+
+  push_stream_shared_memory_size               500M;
+
+  server {
+    listen           9080 default_server;
+    server_name     localhost;
+
+    location /channels-stats {
+      push_stream_channels_statistics;
+      push_stream_channels_path               $arg_id;
+    }
+
+    location /pub {
+      push_stream_publisher admin;
+      push_stream_channels_path               $arg_id;
+      push_stream_store_messages              off;
+    }
+
+    location ~ /sub/(.*) {
+      push_stream_subscriber;
+      push_stream_channels_path                   $1;
+      push_stream_message_template                "~text~:~id~:~channel~";
+    }
+  }
+}
diff -Naur nginx-1.11.3/nginx-push-stream-module/misc/tools/subscriber.c nginx-1.11.3-push/nginx-push-stream-module/misc/tools/subscriber.c
--- nginx-1.11.3/nginx-push-stream-module/misc/tools/subscriber.c	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/misc/tools/subscriber.c	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,288 @@
+/*
+Copyright (C) 2011 Michael Costello, Wandenberg Peixoto <wandenberg@gmail.com>
+
+Usage './subscriber --help' to see option
+*/
+#include <argtable2.h>
+#include "util.h"
+
+
+void subscribe_channels(Connection *connection, Statistics *stats);
+void read_response(Connection *connection, Statistics *stats, char *buffer, int buffer_len);
+
+int
+main_program(int num_channels, int num_connections, const char *server_hostname, int server_port, int timeout)
+{
+    struct sockaddr_in server_address;
+    int main_sd = -1, num_events = 0, i, j, event_mask, channels_per_connection, num, start_time = 0, iters_to_next_summary = 0;
+    Connection *connections = NULL, *connection;
+    Statistics stats = {0,0,0,0,0};
+    int exitcode = EXIT_SUCCESS;
+    struct epoll_event events[MAX_EVENTS];
+    char buffer[BIG_BUFFER_SIZE];
+
+    info("Subscriber starting up\n");
+    info("Subscriber: %d connections to %d channels on server: %s:%d\n", num_connections, num_channels, server_hostname, server_port);
+
+    if ((fill_server_address(server_hostname, server_port, &server_address)) != 0) {
+        error2("ERROR host name not found\n");
+    }
+
+    if ((main_sd = epoll_create(200 /* this size is not used on Linux kernel 2.6.8+ */)) < 0) {
+        error3("Failed %d creating main epoll socket\n", errno);
+    }
+
+    if ((connections = init_connections(num_connections, &server_address, main_sd)) == NULL) {
+        error2("Failed to create to connections\n");
+    }
+
+    stats.requested_connections = num_connections;
+
+    for (i = 0; i < num_connections; i++) {
+        connections[i].channel_start = 0;
+        connections[i].channel_end = num_channels - 1;
+    }
+
+    // infinite loop
+    debug("Entering Infinite Loop\n");
+
+    iters_to_next_summary = ITERATIONS_TILL_SUMMARY_PER_TIMEOUT/timeout;
+
+    for(;;) {
+        if ((num_events = epoll_wait(main_sd, events, MAX_EVENTS, timeout)) < 0) {
+            error3("epoll_wait failed\n");
+        }
+
+        for (i = 0; i < num_events; i++) {
+            event_mask = events[i].events;
+            connection = (Connection *)(events[i].data.ptr);
+
+            if (event_mask & EPOLLHUP) { // SERVER HUNG UP
+                debug("EPOLLHUP\n");
+                info("Server hung up on conncetion %d. Reconecting...\n", connection->index);
+                sleep(1);
+                stats.connections--;
+                reopen_connection(connection);
+
+                continue;
+            }
+
+            if (event_mask & EPOLLERR) {
+                debug("EPOLLERR\n");
+                info("Server returned an error on connection %d. Reconecting...\n", connection->index);
+                stats.connections--;
+                reopen_connection(connection);
+
+                continue;
+            }
+
+            if (event_mask & EPOLLIN) { // READ
+                debug("----------READ AVAILABLE-------\n");
+
+                if (connection->state == CONNECTED) {
+                    read_response(connection, &stats, buffer, BIG_BUFFER_SIZE);
+                }
+            }
+
+            if (event_mask & EPOLLOUT) { // WRITE
+                debug("----------WRITE AVAILABLE-------\n");
+
+                if (start_time == 0) {
+                    start_time = time(NULL);
+                }
+
+                if (connection->state == CONNECTING) {
+                    connection->state = CONNECTED;
+                    stats.connections++;
+                    debug("Connection opened for index=%d\n", connection->index);
+
+                    subscribe_channels(connection, &stats);
+
+                    // remove write flag from event
+                    if (change_connection(connection, EPOLLIN | EPOLLHUP) < 0) {
+                        error2("Failed creating socket for connection = %d\n", connection->index);
+                    }
+                }
+            }
+        }
+
+        if ((iters_to_next_summary-- <= 0)) {
+            iters_to_next_summary = ITERATIONS_TILL_SUMMARY_PER_TIMEOUT/timeout;
+            summary("Connections=%ld, Messages=%ld BytesRead=%ld Msg/Sec=%0.2f\n", stats.connections, stats.messages, stats.bytes_read, calc_message_per_second(stats.messages, start_time));
+        }
+
+        if (stats.connections == 0) {
+            num = 0;
+            for (j = 0; j < num_connections; j++) {
+                if (connections[i].state != CLOSED) {
+                    num++;
+                    break;
+                }
+            }
+
+            if (num == 0) {
+                exitcode = EXIT_SUCCESS;
+                goto exit;
+            }
+        }
+    }
+
+exit:
+    if (connections != NULL) free(connections);
+
+    return exitcode;
+}
+
+
+void
+subscribe_channels(Connection *connection, Statistics *stats)
+{
+    char buffer[BUFFER_SIZE];
+    int len = 0, bytes_written = 0;
+    long i = 0;
+
+    len = sprintf(buffer, "GET /sub");
+    for (i = connection->channel_start; i <= connection->channel_end; i++) {
+        len += sprintf(buffer + len, "/my_channel_%ld", i);
+    }
+
+    len += sprintf(buffer + len, "?conn=%d HTTP/1.1\r\nHost: loadtest\r\n\r\n", connection->index);
+
+    if (write_connection(connection, stats, buffer, len) == EXIT_FAILURE) {
+        stats->connections--;
+        reopen_connection(connection);
+        return;
+    }
+}
+
+
+void
+read_response(Connection *connection, Statistics *stats, char *buffer, int buffer_len)
+{
+    int bytes_read = 0, bad_count = 0, msg_count = 0, close_count = 0;
+
+    bytes_read = read(connection->sd, buffer, buffer_len - 1);
+
+    if (bytes_read < 0) {
+        error("Error reading from socket for connection %d\n", connection->index);
+        stats->connections--;
+        reopen_connection(connection);
+        return;
+    }
+
+    if (bytes_read == 0) { // server disconnected us
+        // reconnect
+        info("Server disconnected as requested %d.\n", connection->index);
+        stats->connections--;
+        reopen_connection(connection);
+        return;
+    }
+
+    stats->bytes_read += bytes_read;
+    buffer[bytes_read] = '\0';
+    debug("Read %d bytes\n", bytes_read);
+    trace("Read Message: %s\n", buffer);
+
+    bad_count = count_strinstr(buffer, "HTTP/1.1 4");
+    bad_count += count_strinstr(buffer, "HTTP/1.1 5");
+
+    if (bad_count > 0) {
+        info("Recevied error. Buffer is %s\n", buffer);
+        stats->connections--;
+        reopen_connection(connection);
+        return;
+    }
+
+    msg_count = count_strinstr(buffer, "**MSG**");
+    stats->messages += msg_count;
+
+    if ((close_count = count_strinstr(buffer, "**CLOSE**")) > 0) {
+        connection->channel_count += close_count;
+        info("%d Channel(s) has(have) been closed by server.\n", close_count);
+        if (connection->channel_count >= (connection->channel_end - connection->channel_start + 1)) {
+            info("Connection %d will be closed \n", connection->index);
+            close_connection(connection);
+            stats->connections--;
+        }
+    }
+}
+
+
+int
+main(int argc, char **argv)
+{
+    struct arg_int *channels  = arg_int0("c", "channels", "<n>", "define number of channels (default is 1)");
+    struct arg_int *subscribers  = arg_int0("s", "subscribers", "<n>", "define number of subscribers (default is 1)");
+
+    struct arg_str *server_name = arg_str0("S", "server", "<hostname>", "server hostname where messages will be published (default is \"127.0.0.1\")");
+    struct arg_int *server_port = arg_int0("P", "port", "<n>", "server port where messages will be published (default is 9080)");
+
+    struct arg_int *timeout = arg_int0(NULL, "timeout", "<n>", "timeout when waiting events on communication to the server (default is 1000)");
+    struct arg_int *verbose = arg_int0("v", "verbose", "<n>", "increase output messages detail (0 (default) - no messages, 1 - info messages, 2 - debug messages, 3 - trace messages");
+
+    struct arg_lit *help    = arg_lit0(NULL, "help", "print this help and exit");
+    struct arg_lit *version = arg_lit0(NULL, "version", "print version information and exit");
+    struct arg_end *end     = arg_end(20);
+
+    void* argtable[] = { channels, subscribers, server_name, server_port, timeout, verbose, help, version, end };
+
+    const char* progname = "subscriber";
+    int nerrors;
+    int exitcode = EXIT_SUCCESS;
+
+    /* verify the argtable[] entries were allocated sucessfully */
+    if (arg_nullcheck(argtable) != 0) {
+        /* NULL entries were detected, some allocations must have failed */
+        printf("%s: insufficient memory\n", progname);
+        exitcode = EXIT_FAILURE;
+        goto exit;
+    }
+
+    /* set any command line default values prior to parsing */
+    subscribers->ival[0] = DEFAULT_CONCURRENT_CONN;
+    channels->ival[0] = DEFAULT_NUM_CHANNELS;
+    server_name->sval[0] = DEFAULT_SERVER_HOSTNAME;
+    server_port->ival[0] = DEFAULT_SERVER_PORT;
+    timeout->ival[0] = DEFAULT_TIMEOUT;
+    verbose->ival[0] = 0;
+
+    /* Parse the command line as defined by argtable[] */
+    nerrors = arg_parse(argc, argv, argtable);
+
+    /* special case: '--help' takes precedence over error reporting */
+    if (help->count > 0) {
+        printf(DESCRIPTION_SUBSCRIBER, progname, VERSION, COPYRIGHT);
+        printf("Usage: %s", progname);
+        arg_print_syntax(stdout, argtable, "\n");
+        arg_print_glossary(stdout, argtable, "  %-25s %s\n");
+        exitcode = EXIT_SUCCESS;
+        goto exit;
+    }
+
+    /* special case: '--version' takes precedence error reporting */
+    if (version->count > 0) {
+        printf(DESCRIPTION_SUBSCRIBER, progname, VERSION, COPYRIGHT);
+        exitcode = EXIT_SUCCESS;
+        goto exit;
+    }
+
+    /* If the parser returned any errors then display them and exit */
+    if (nerrors > 0) {
+        /* Display the error details contained in the arg_end struct.*/
+        arg_print_errors(stdout, end, progname);
+        printf("Try '%s --help' for more information.\n", progname);
+        exitcode = EXIT_FAILURE;
+        goto exit;
+    }
+
+    verbose_messages = verbose->ival[0];
+
+    /* normal case: take the command line options at face value */
+    exitcode = main_program(channels->ival[0], subscribers->ival[0], server_name->sval[0], server_port->ival[0], timeout->ival[0]);
+
+exit:
+    /* deallocate each non-null entry in argtable[] */
+    arg_freetable(argtable, sizeof(argtable) / sizeof(argtable[0]));
+
+    return exitcode;
+}
diff -Naur nginx-1.11.3/nginx-push-stream-module/misc/tools/util.c nginx-1.11.3-push/nginx-push-stream-module/misc/tools/util.c
--- nginx-1.11.3/nginx-push-stream-module/misc/tools/util.c	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/misc/tools/util.c	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,172 @@
+#include "util.h"
+
+
+int
+fill_server_address(const char *server_hostname, int server_port, struct sockaddr_in *server_address)
+{
+    struct hostent *server = NULL;
+    if ((server = gethostbyname(server_hostname)) == NULL) {
+        return EXIT_FAILURE;
+    }
+
+    bzero((char *) server_address, sizeof(struct sockaddr_in));
+    server_address->sin_family = AF_INET;
+    memcpy((char *) &server_address->sin_addr.s_addr, (const char *) server->h_addr, server->h_length);
+    server_address->sin_port = htons(server_port);
+
+    return EXIT_SUCCESS;
+}
+
+
+Connection *
+init_connections(int num_connections, struct sockaddr_in *server_address, int main_sd)
+{
+    Connection *connections;
+    int         i;
+
+    if ((connections = (Connection *) malloc(sizeof(Connection) * num_connections)) == NULL) {
+        return NULL;
+    }
+
+    for (i = 0; i < num_connections; ++i) {
+        connections[i].index = i;
+        connections[i].server_address = server_address;
+        connections[i].main_sd = main_sd;
+        if (open_connection(&connections[i]) != 0) {
+            error("Opening connection %d\n", i);
+            return NULL;
+        }
+    }
+
+    info("Added %d connections.\n", num_connections);
+
+    return connections;
+}
+
+
+int
+open_connection(Connection *connection)
+{
+    struct epoll_event anEvent;
+    int exitcode = EXIT_SUCCESS;
+
+    connection->state = CONNECTING;
+    connection->channel_id = -1;
+    connection->content_length = 0;
+    connection->channel_count = 0;
+
+    if ((connection->sd = socket(AF_INET, SOCK_STREAM, 0)) < 0) {
+        error3("ERROR %d opening socket for connection %d\n", errno, connection->index);
+    }
+
+//    // set nonblocking
+//    int flags = fcntl(connection->sd, F_GETFL, 0);
+//    fcntl(connection->sd, F_SETFL, flags | O_NONBLOCK);
+//
+//    int rc = connect(connection->sd, (struct sockaddr *) connection->server_address, sizeof(struct sockaddr_in));
+//    if ((rc < 0) && (errno != EINPROGRESS))  {
+//        error3("ERROR connecting to server on connection %d\n", connection->index);
+//    }
+
+    if (connect(connection->sd, (struct sockaddr *) connection->server_address, sizeof(struct sockaddr_in)) < 0)  {
+        error3("ERROR connecting to server on connection %d\n", connection->index);
+    }
+
+    debug("Adding connection %d\n", connection->index);
+
+    anEvent.events = EPOLLIN | EPOLLOUT | EPOLLHUP;
+    anEvent.data.ptr = (void *) connection;
+    if (epoll_ctl(connection->main_sd, EPOLL_CTL_ADD, connection->sd, &anEvent) < 0)	{
+        error3("ERROR %d Failed creating socket for connection %d\n", errno, connection->index);
+    }
+
+    debug("Connection opening for index %d\n", connection->index);
+
+exit:
+    return exitcode;
+}
+
+
+void
+close_connection(Connection *connection)
+{
+    connection->state = CLOSED;
+    close(connection->sd);
+}
+
+
+
+int
+reopen_connection(Connection *connection)
+{
+    close_connection(connection);
+    return open_connection(connection);
+}
+
+
+int
+change_connection(Connection *connection, uint32_t events)
+{
+    struct epoll_event anEvent;
+    anEvent.events = events;
+    anEvent.data.ptr = (void *) connection;
+    return epoll_ctl(connection->main_sd, EPOLL_CTL_MOD, connection->sd, &anEvent);
+}
+
+
+int
+write_connection(Connection *connection, Statistics *stats, char *buffer, int buffer_len)
+{
+    int bytes_written = 0;
+
+    bytes_written = write(connection->sd, buffer, buffer_len);
+
+    if (bytes_written != buffer_len) {
+        error4("Error %d writing bytes (wrote=%d, wanted=%d) for connection %d\n", errno, bytes_written, buffer_len, connection->index);
+        return EXIT_FAILURE;
+    }
+    stats->bytes_written += bytes_written;
+    trace("Wrote %s\n", buffer);
+
+    return EXIT_SUCCESS;
+}
+
+
+float
+calc_message_per_second(int num_messages, int start_time)
+{
+    float ret_val = 0.0;
+    int now = time(NULL);
+    int diff = now - start_time;
+
+    if (diff == 0) {
+        diff = 1;
+    }
+
+    ret_val = (float) num_messages/diff;
+
+    info("CALC TIME.  Messages=%d, Time=%d Avg=%0.2f\n", num_messages, diff, ret_val);
+
+    return ret_val;
+}
+
+
+int
+count_strinstr(const char *big, const char *little)
+{
+    const char *p;
+    int count = 0;
+    size_t lil_len = strlen(little);
+
+    /* you decide what to do here */
+    if (lil_len == 0)
+        return -1;
+
+    p = strstr(big, little);
+    while (p) {
+    count++;
+    p = strstr(p + lil_len, little);
+    }
+    return count;
+}
+
diff -Naur nginx-1.11.3/nginx-push-stream-module/misc/tools/util.h nginx-1.11.3-push/nginx-push-stream-module/misc/tools/util.h
--- nginx-1.11.3/nginx-push-stream-module/misc/tools/util.h	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/misc/tools/util.h	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,83 @@
+#ifndef _UTIL_H_
+#define _UTIL_H_
+
+#include <stdlib.h>
+#include <stdio.h>
+#include <string.h>
+#include <sys/socket.h>
+#include <sys/epoll.h>
+#include <netdb.h>
+#include <errno.h>
+#include <fcntl.h>
+#include <unistd.h>
+
+#define error(...)  {fprintf(stderr, __VA_ARGS__);}
+#define error2(...) {error(__VA_ARGS__); exitcode = EXIT_FAILURE; goto exit;}
+#define error3(...) {perror("ERROR");error(__VA_ARGS__); exitcode = EXIT_FAILURE; goto exit;}
+#define error4(...) {perror("ERROR");error(__VA_ARGS__);}
+
+#define info(...) {if (verbose_messages >= 1) {fprintf(stdout, __VA_ARGS__);}}
+#define debug(...) {if (verbose_messages >= 2) {fprintf(stdout, __VA_ARGS__);}}
+#define trace(...) {if (verbose_messages >= 3) {fprintf(stdout, __VA_ARGS__);}}
+
+#define summary(...) fprintf(stdout, __VA_ARGS__)
+
+#define VERSION   "0.1"
+#define COPYRIGHT "Copyright (C) 2011 Michael Costello, Wandenberg Peixoto <wandenberg@gmail.com>"
+#define DESCRIPTION_PUBLISHER "'%s' v%s - program to publish messages to test Push Stream Module.\n%s\n"
+#define DESCRIPTION_SUBSCRIBER "'%s' v%s - program to subscribe channels to test Push Stream Module.\n%s\n"
+
+#define DEFAULT_NUM_MESSAGES    1
+#define DEFAULT_CONCURRENT_CONN 1
+#define DEFAULT_NUM_CHANNELS    1
+#define DEFAULT_SERVER_HOSTNAME "127.0.0.1"
+#define DEFAULT_SERVER_PORT     9080
+#define DEFAULT_TIMEOUT         1000
+
+#define MAX_EVENTS (60000 * 8)
+#define ITERATIONS_TILL_SUMMARY_PER_TIMEOUT 10000 //timeout: 1000 -> summary each 10 seconds
+#define BUFFER_SIZE 1024
+#define BIG_BUFFER_SIZE 640000
+
+typedef struct
+{
+    long requested_connections;
+    long connections;
+    long messages;
+    long bytes_written;
+    long bytes_read;
+} Statistics;
+
+enum State {INIT=0, CONNECTING, CONNECTED, CLOSED};
+
+// store per connection state here
+typedef struct
+{
+    int		   index;
+    int        main_sd;
+    int		   sd;
+    int		   message_count;
+    int		   num_messages;
+    int		   channel_count;
+    long	   channel_id;
+    long	   channel_start;
+    long	   channel_end;
+    char       content_buffer[BUFFER_SIZE];
+    int        content_length;
+    enum State state;
+    struct sockaddr_in *server_address;
+} Connection;
+
+static int verbose_messages = 0;
+
+int fill_server_address(const char *server_hostname, int server_port, struct sockaddr_in *server_address);
+Connection *init_connections(int count, struct sockaddr_in *server_address, int main_sd);
+int open_connection(Connection *connection);
+void close_connection(Connection *connection);
+int reopen_connection(Connection *connection);
+int write_connection(Connection *connection, Statistics *stats, char *buffer, int buffer_len);
+int change_connection(Connection *connection, uint32_t events);
+float calc_message_per_second(int num_messages, int start_time);
+
+
+#endif /* _UTIL_H_ */
diff -Naur nginx-1.11.3/nginx-push-stream-module/README.textile nginx-1.11.3-push/nginx-push-stream-module/README.textile
--- nginx-1.11.3/nginx-push-stream-module/README.textile	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/README.textile	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,288 @@
+h1(#nginx_push_stream_module). Nginx Push Stream Module
+
+A pure stream http push technology for your Nginx setup.
+
+"Comet":comet_ref made easy and *really scalable*.
+
+Supports "EventSource":eventsource_ref, "WebSocket":websocket_ref, Long Polling, and Forever Iframe. See "some examples":examples bellow.
+
+_This module is not distributed with the Nginx source. See "the installation instructions":installation._
+
+Available on github at "nginx_push_stream_module":repository
+
+h1(#changelog). Changelog
+
+Always take a look at "CHANGELOG.textile":changelog to see what's new.
+
+
+h1(#contribute). Contribute
+
+After you try this module and like it, feel free to "give something back":donate, and help in the maintenance of the project ;)
+!https://www.paypalobjects.com/WEBSCR-640-20110429-1/en_US/i/btn/btn_donate_LG.gif!:donate
+
+h1(#status). Status
+
+This module is considered production ready.
+
+h1(#basic-configuration). Basic Configuration
+
+<pre>
+    # add the push_stream_shared_memory_size to your http context
+    http {
+       push_stream_shared_memory_size 32M;
+
+        # define publisher and subscriber endpoints in your server context
+        server {
+           location /channels-stats {
+                # activate channels statistics mode for this location
+                push_stream_channels_statistics;
+
+                # query string based channel id
+                push_stream_channels_path               $arg_id;
+            }
+
+            location /pub {
+               # activate publisher (admin) mode for this location
+               push_stream_publisher admin;
+
+                # query string based channel id
+                push_stream_channels_path               $arg_id;
+            }
+
+            location ~ /sub/(.*) {
+                # activate subscriber (streaming) mode for this location
+                push_stream_subscriber;
+
+                # positional channel path
+                push_stream_channels_path                   $1;
+            }
+        }
+    }
+</pre>
+
+
+h1(#basic-usage). Basic Usage
+
+You can feel the flavor right now at the command line. Try using more than
+one terminal and start playing http pubsub:
+
+<pre>
+    # Subs
+    curl -s -v --no-buffer 'http://localhost/sub/my_channel_1'
+    curl -s -v --no-buffer 'http://localhost/sub/your_channel_1'
+    curl -s -v --no-buffer 'http://localhost/sub/your_channel_2'
+
+    # Pubs
+    curl -s -v -X POST 'http://localhost/pub?id=my_channel_1' -d 'Hello World!'
+    curl -s -v -X POST 'http://localhost/pub?id=your_channel_1' -d 'Hi everybody!'
+    curl -s -v -X POST 'http://localhost/pub?id=your_channel_2' -d 'Goodbye!'
+
+    # Channels Stats for publisher (json format)
+    curl -s -v 'http://localhost/pub?id=my_channel_1'
+
+    # All Channels Stats summarized (json format)
+    curl -s -v 'http://localhost/channels-stats'
+
+    # All Channels Stats detailed (json format)
+    curl -s -v 'http://localhost/channels-stats?id=ALL'
+
+    # Prefixed Channels Stats detailed (json format)
+    curl -s -v 'http://localhost/channels-stats?id=your_channel_*'
+
+    # Channels Stats (json format)
+    curl -s -v 'http://localhost/channels-stats?id=my_channel_1'
+
+    # Delete Channels
+    curl -s -v -X DELETE 'http://localhost/pub?id=my_channel_1'
+</pre>
+
+
+h1(#examples). Some Examples <a name="examples" href="#">&nbsp;</a>
+
+* "Curl examples":curl
+* "Forever (hidden) iFrame":forever_iframe
+* "Event Source":event_source
+* "WebSocket":websocket
+* "Long Polling":long_polling
+* "JSONP":jsonp
+* "M-JPEG":m-jpeg
+* "Other examples":wiki
+
+
+h1(#FAQ). FAQ <a names="faq" href="#">&nbsp;</a>
+
+Doubts?! Check the "FAQ":wiki.
+
+h1(#bug_report). Bug report <a name="bug_report" href="#">&nbsp;</a>
+
+To report a bug, please provide the following information when applicable
+
+# Which push stream module version is been used (commit sha1)?
+# Which nginx version is been used?
+# Nginx configuration in use
+# "nginx -V" command outuput
+# Core dump indicating a failure on the module code. Check "here":nginx_debugging how to produce one.
+# Step by step description to reproduce the error.
+
+h1(#who). Who is using the module? <a names="faq" href="#">&nbsp;</a>
+
+Do you use this module? Put your name on the "list":wiki.
+
+
+h1(#javascript_client). Javascript Client <a name="javascript_client" href="#">&nbsp;</a>
+
+There is a javascript client implementation "here":javascript_client, which is framework independent. Try and help improve it. ;)
+
+h1(#directives). Directives
+
+(1) Defining locations, (2) Main configuration, (3) Subscribers configuration, (4) Publishers configuration, (5) Channels Statistics configuration, (6) WebSocket configuration
+
+(head). | Directive | (1) | (2) | (3) | (4) | (5) | (6) |
+| "push_stream_channels_statistics":push_stream_channels_statistics | &nbsp;&nbsp;x | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;- |
+| "push_stream_publisher":push_stream_publisher | &nbsp;&nbsp;x | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;- |
+| "push_stream_subscriber":push_stream_subscriber | &nbsp;&nbsp;x | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;- |
+| "push_stream_shared_memory_size":push_stream_shared_memory_size | &nbsp;&nbsp;- | &nbsp;&nbsp;x | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;- |
+| "push_stream_channel_deleted_message_text":push_stream_channel_deleted_message_text | &nbsp;&nbsp;- | &nbsp;&nbsp;x | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;- |
+| "push_stream_channel_inactivity_time":push_stream_channel_inactivity_time | &nbsp;&nbsp;- | &nbsp;&nbsp;x | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;- |
+| "push_stream_ping_message_text":push_stream_ping_message_text | &nbsp;&nbsp;- | &nbsp;&nbsp;x | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;- |
+| "push_stream_timeout_with_body":push_stream_timeout_with_body | &nbsp;&nbsp;- | &nbsp;&nbsp;x | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;- |
+| "push_stream_message_ttl":push_stream_message_ttl | &nbsp;&nbsp;- | &nbsp;&nbsp;x | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;- |
+| "push_stream_max_subscribers_per_channel":push_stream_max_subscribers_per_channel | &nbsp;&nbsp;- | &nbsp;&nbsp;x | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;- |
+| "push_stream_max_messages_stored_per_channel":push_stream_max_messages_stored_per_channel | &nbsp;&nbsp;- | &nbsp;&nbsp;x | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;- |
+| "push_stream_max_channel_id_length":push_stream_max_channel_id_length | &nbsp;&nbsp;- | &nbsp;&nbsp;x | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;- |
+| "push_stream_max_number_of_channels":push_stream_max_number_of_channels | &nbsp;&nbsp;- | &nbsp;&nbsp;x | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;- |
+| "push_stream_max_number_of_wildcard_channels":push_stream_max_number_of_wildcard_channels | &nbsp;&nbsp;- | &nbsp;&nbsp;x | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;- |
+| "push_stream_wildcard_channel_prefix":push_stream_wildcard_channel_prefix | &nbsp;&nbsp;- | &nbsp;&nbsp;x | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;- |
+| "push_stream_events_channel_id":push_stream_events_channel_id | &nbsp;&nbsp;- | &nbsp;&nbsp;x | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;- |
+| "push_stream_channels_path":push_stream_channels_path | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;x | &nbsp;&nbsp;x | &nbsp;&nbsp;x | &nbsp;&nbsp;x |
+| "push_stream_store_messages":push_stream_store_messages | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;x | &nbsp;&nbsp;- | &nbsp;&nbsp;x |
+| "push_stream_channel_info_on_publish":push_stream_channel_info_on_publish | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;x | &nbsp;&nbsp;- | &nbsp;&nbsp;- |
+| "push_stream_authorized_channels_only":push_stream_authorized_channels_only | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;x | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;x |
+| "push_stream_header_template_file":push_stream_header_template_file | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;x | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;x |
+| "push_stream_header_template":push_stream_header_template | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;x | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;x |
+| "push_stream_message_template":push_stream_message_template | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;x | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;x |
+| "push_stream_footer_template":push_stream_footer_template | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;x | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;x |
+| "push_stream_wildcard_channel_max_qtd":push_stream_wildcard_channel_max_qtd | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;x | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;x |
+| "push_stream_ping_message_interval":push_stream_ping_message_interval | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;x | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;x |
+| "push_stream_subscriber_connection_ttl":push_stream_subscriber_connection_ttl | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;x | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;x |
+| "push_stream_longpolling_connection_ttl":push_stream_longpolling_connection_ttl | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;x | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;- |
+| "push_stream_websocket_allow_publish":push_stream_websocket_allow_publish | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;x |
+| "push_stream_last_received_message_time":push_stream_last_received_message_time | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;x | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;- |
+| "push_stream_last_received_message_tag":push_stream_last_received_message_tag | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;x | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;- |
+| "push_stream_last_event_id":push_stream_last_event_id | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;x | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;- |
+| "push_stream_user_agent":push_stream_user_agent | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;x | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;- |
+| "push_stream_padding_by_user_agent":push_stream_padding_by_user_agent | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;x | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;- |
+| "push_stream_allowed_origins":push_stream_allowed_origins | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;x | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;- |
+| "push_stream_allow_connections_to_events_channel":push_stream_allow_connections_to_events_channel | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;x | &nbsp;&nbsp;- | &nbsp;&nbsp;- | &nbsp;&nbsp;x |
+
+h1(#installation). Installation <a name="installation" href="#">&nbsp;</a>
+
+<pre>
+    # clone the project
+    git clone https://github.com/wandenberg/nginx-push-stream-module.git
+    NGINX_PUSH_STREAM_MODULE_PATH=$PWD/nginx-push-stream-module
+
+    # get desired nginx version (works with 1.2.0+)
+    wget http://nginx.org/download/nginx-1.2.0.tar.gz
+
+    # unpack, configure and build
+    tar xzvf nginx-1.2.0.tar.gz
+    cd nginx-1.2.0
+    ./configure --add-module=../nginx-push-stream-module
+    make
+
+    # install and finish
+    sudo make install
+
+    # check
+    sudo /usr/local/nginx/sbin/nginx -v
+        nginx version: nginx/1.2.0
+
+    # test configuration
+    sudo /usr/local/nginx/sbin/nginx -c $NGINX_PUSH_STREAM_MODULE_PATH/misc/nginx.conf -t
+        the configuration file $NGINX_PUSH_STREAM_MODULE_PATH/misc/nginx.conf syntax is ok
+        configuration file $NGINX_PUSH_STREAM_MODULE_PATH/misc/nginx.conf test is successful
+
+    # run
+    sudo /usr/local/nginx/sbin/nginx -c $NGINX_PUSH_STREAM_MODULE_PATH/misc/nginx.conf
+</pre>
+
+h1(#memory-usage). Memory usage
+
+Just as information is listed below the minimum amount of memory used for each object:
+
+* message on shared = 200 bytes
+* channel on shared = 270 bytes
+* subscriber
+  ** on shared = 160 bytes
+  ** on system = 6550 bytes
+
+h1(#tests). Tests
+
+The server tests for this module are written in Ruby, and are acceptance tests, click "here":tests for more details.
+
+h1(#discussion). Discussion
+
+Nginx Push Stream Module "Discussion Group":discussion
+
+h1(#contributors). Contributors
+
+"People":contributors
+
+[discussion]https://groups.google.com/group/nginxpushstream
+[donate]https://www.paypal.com/cgi-bin/webscr?cmd=_s-xclick&hosted_button_id=4LP6P9A7BC37S
+[eventsource_ref]http://dev.w3.org/html5/eventsource/
+[websocket_ref]http://dev.w3.org/html5/websockets/
+[comet_ref]http://en.wikipedia.org/wiki/Comet_%28programming%29
+[installation]#installation
+[examples]#examples
+[javascript_client]docs/javascript_client.textile#javascript_client
+[repository]https://github.com/wandenberg/nginx-push-stream-module
+[contributors]https://github.com/wandenberg/nginx-push-stream-module/contributors
+[changelog]CHANGELOG.textile
+[curl]docs/examples/curl.textile#curl
+[forever_iframe]docs/examples/forever_iframe.textile#forever_iframe
+[event_source]docs/examples/event_source.textile#event_source
+[websocket]docs/examples/websocket.textile#websocket
+[long_polling]docs/examples/long_polling.textile#long_polling
+[jsonp]docs/examples/long_polling.textile#jsonp
+[m-jpeg]docs/examples/m_jpeg.textile#m_jpeg
+[tests]docs/server_tests.textile
+[push_stream_channels_statistics]docs/directives/channels_statistics.textile#push_stream_channels_statistics
+[push_stream_publisher]docs/directives/publishers.textile#push_stream_publisher
+[push_stream_subscriber]docs/directives/subscribers.textile#push_stream_subscriber
+[push_stream_shared_memory_size]docs/directives/main.textile#push_stream_shared_memory_size
+[push_stream_channel_deleted_message_text]docs/directives/main.textile#push_stream_channel_deleted_message_text
+[push_stream_ping_message_text]docs/directives/main.textile#push_stream_ping_message_text
+[push_stream_channel_inactivity_time]docs/directives/main.textile#push_stream_channel_inactivity_time
+[push_stream_message_ttl]docs/directives/main.textile#push_stream_message_ttl
+[push_stream_max_subscribers_per_channel]docs/directives/main.textile#push_stream_max_subscribers_per_channel
+[push_stream_max_messages_stored_per_channel]docs/directives/main.textile#push_stream_max_messages_stored_per_channel
+[push_stream_max_channel_id_length]docs/directives/main.textile#push_stream_max_channel_id_length
+[push_stream_max_number_of_channels]docs/directives/main.textile#push_stream_max_number_of_channels
+[push_stream_max_number_of_wildcard_channels]docs/directives/main.textile#push_stream_max_number_of_wildcard_channels
+[push_stream_wildcard_channel_prefix]docs/directives/main.textile#push_stream_wildcard_channel_prefix
+[push_stream_events_channel_id]docs/directives/main.textile#push_stream_events_channel_id
+[push_stream_channels_path]docs/directives/subscribers.textile#push_stream_channels_path
+[push_stream_authorized_channels_only]docs/directives/subscribers.textile#push_stream_authorized_channels_only
+[push_stream_header_template_file]docs/directives/subscribers.textile#push_stream_header_template_file
+[push_stream_header_template]docs/directives/subscribers.textile#push_stream_header_template
+[push_stream_message_template]docs/directives/subscribers.textile#push_stream_message_template
+[push_stream_footer_template]docs/directives/subscribers.textile#push_stream_footer_template
+[push_stream_wildcard_channel_max_qtd]docs/directives/subscribers.textile#push_stream_wildcard_channel_max_qtd
+[push_stream_ping_message_interval]docs/directives/subscribers.textile#push_stream_ping_message_interval
+[push_stream_subscriber_connection_ttl]docs/directives/subscribers.textile#push_stream_subscriber_connection_ttl
+[push_stream_longpolling_connection_ttl]docs/directives/subscribers.textile#push_stream_longpolling_connection_ttl
+[push_stream_timeout_with_body]docs/directives/subscribers.textile#push_stream_timeout_with_body
+[push_stream_last_received_message_time]docs/directives/subscribers.textile#push_stream_last_received_message_time
+[push_stream_last_received_message_tag]docs/directives/subscribers.textile#push_stream_last_received_message_tag
+[push_stream_last_event_id]docs/directives/subscribers.textile#push_stream_last_event_id
+[push_stream_user_agent]docs/directives/subscribers.textile#push_stream_user_agent
+[push_stream_padding_by_user_agent]docs/directives/subscribers.textile#push_stream_padding_by_user_agent
+[push_stream_store_messages]docs/directives/publishers.textile#push_stream_store_messages
+[push_stream_channel_info_on_publish]docs/directives/publishers.textile#push_stream_channel_info_on_publish
+[push_stream_allowed_origins]docs/directives/subscribers.textile#push_stream_allowed_origins
+[push_stream_websocket_allow_publish]docs/directives/subscribers.textile#push_stream_websocket_allow_publish
+[push_stream_allow_connections_to_events_channel]docs/directives/subscribers.textile#push_stream_allow_connections_to_events_channel
+[wiki]https://github.com/wandenberg/nginx-push-stream-module/wiki/_pages
+[nginx_debugging]http://wiki.nginx.org/Debugging
diff -Naur nginx-1.11.3/nginx-push-stream-module/src/ngx_http_push_stream_module.c nginx-1.11.3-push/nginx-push-stream-module/src/ngx_http_push_stream_module.c
--- nginx-1.11.3/nginx-push-stream-module/src/ngx_http_push_stream_module.c	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/src/ngx_http_push_stream_module.c	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,415 @@
+/*
+ * Copyright (C) 2010-2015 Wandenberg Peixoto <wandenberg@gmail.com>, Rog√©rio Carvalho Schneider <stockrt@gmail.com>
+ *
+ * This file is part of Nginx Push Stream Module.
+ *
+ * Nginx Push Stream Module is free software: you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation, either version 3 of the License, or
+ * (at your option) any later version.
+ *
+ * Nginx Push Stream Module is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with Nginx Push Stream Module.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ *
+ * ngx_http_push_stream_module.c
+ *
+ * Created: Oct 26, 2010
+ * Authors: Wandenberg Peixoto <wandenberg@gmail.com>, Rog√©rio Carvalho Schneider <stockrt@gmail.com>
+ */
+
+#include <ngx_http_push_stream_module.h>
+#include <ngx_http_push_stream_module_setup.c>
+#include <ngx_http_push_stream_rbtree_util.c>
+#include <ngx_http_push_stream_module_utils.c>
+#include <ngx_http_push_stream_module_ipc.c>
+#include <ngx_http_push_stream_module_publisher.c>
+#include <ngx_http_push_stream_module_subscriber.c>
+#include <ngx_http_push_stream_module_websocket.c>
+
+static ngx_str_t *
+ngx_http_push_stream_channel_info_formatted(ngx_pool_t *pool, const ngx_str_t *format, ngx_str_t *id, ngx_uint_t published_messages, ngx_uint_t stored_messages, ngx_uint_t subscribers)
+{
+    ngx_str_t      *text;
+    ngx_uint_t      len;
+
+    if ((format == NULL) || (id == NULL)) {
+        return NULL;
+    }
+
+    len = 3*NGX_INT_T_LEN + format->len + id->len - 11;// minus 11 sprintf
+
+    if ((text = ngx_http_push_stream_create_str(pool, len)) == NULL) {
+        return NULL;
+    }
+
+    ngx_sprintf(text->data, (char *) format->data, id->data, published_messages, stored_messages, subscribers);
+    text->len = ngx_strlen(text->data);
+
+    return text;
+}
+
+
+static ngx_int_t
+ngx_http_push_stream_send_response_all_channels_info_summarized(ngx_http_request_t *r)
+{
+    ngx_uint_t                                   len;
+    ngx_str_t                                   *currenttime, *hostname, *format, *text;
+    u_char                                      *subscribers_by_workers, *start;
+    int                                          i, j, used_slots;
+    ngx_http_push_stream_main_conf_t            *mcf = ngx_http_get_module_main_conf(r, ngx_http_push_stream_module);
+    ngx_http_push_stream_shm_data_t             *data = mcf->shm_data;
+    ngx_http_push_stream_worker_data_t          *worker_data;
+    ngx_http_push_stream_content_subtype_t      *subtype;
+
+    subtype = ngx_http_push_stream_match_channel_info_format_and_content_type(r, 1);
+    currenttime = ngx_http_push_stream_get_formatted_current_time(r->pool);
+    hostname = ngx_http_push_stream_get_formatted_hostname(r->pool);
+
+    used_slots = 0;
+    for(i = 0; i < NGX_MAX_PROCESSES; i++) {
+        if (data->ipc[i].pid > 0) {
+            used_slots++;
+        }
+    }
+
+    len = (subtype->format_summarized_worker_item->len > subtype->format_summarized_worker_last_item->len) ? subtype->format_summarized_worker_item->len : subtype->format_summarized_worker_last_item->len;
+    len = used_slots * (3*NGX_INT_T_LEN + len - 8); //minus 8 sprintf
+    if ((subscribers_by_workers = ngx_pcalloc(r->pool, len)) == NULL) {
+        ngx_log_error(NGX_LOG_ERR, r->connection->log, 0, "Failed to allocate memory to write workers statistics.");
+        return NGX_HTTP_INTERNAL_SERVER_ERROR;
+    }
+    start = subscribers_by_workers;
+    for (i = 0, j = 0; (i < used_slots) && (j < NGX_MAX_PROCESSES); j++) {
+        worker_data = data->ipc + j;
+        if (worker_data->pid > 0) {
+            format = (i < used_slots - 1) ? subtype->format_summarized_worker_item : subtype->format_summarized_worker_last_item;
+            start = ngx_sprintf(start, (char *) format->data, worker_data->pid, worker_data->subscribers, ngx_time() - worker_data->startup);
+            i++;
+        }
+    }
+    *start = '\0';
+
+    len = 7*NGX_INT_T_LEN + subtype->format_summarized->len + hostname->len + currenttime->len + ngx_strlen(subscribers_by_workers) - 21;// minus 21 sprintf
+
+    if ((text = ngx_http_push_stream_create_str(r->pool, len)) == NULL) {
+        ngx_log_error(NGX_LOG_ERR, r->connection->log, 0, "Failed to allocate response buffer.");
+        return NGX_HTTP_INTERNAL_SERVER_ERROR;
+    }
+
+    ngx_sprintf(text->data, (char *) subtype->format_summarized->data, hostname->data, currenttime->data, data->channels, data->wildcard_channels, data->published_messages, data->stored_messages, data->messages_in_trash, data->channels_in_trash, data->subscribers, ngx_time() - data->startup, subscribers_by_workers);
+    text->len = ngx_strlen(text->data);
+
+    return ngx_http_push_stream_send_response(r, text, subtype->content_type, NGX_HTTP_OK);
+}
+
+
+static ngx_int_t
+ngx_http_push_stream_send_response_channels_info(ngx_http_request_t *r, ngx_queue_t *queue_channel_info) {
+    ngx_int_t                                 rc, content_len = 0;
+    ngx_chain_t                              *chain, *first = NULL, *last = NULL;
+    ngx_str_t                                *currenttime, *hostname, *text, *header_response;
+    ngx_queue_t                              *q;
+    ngx_http_push_stream_main_conf_t         *mcf = ngx_http_get_module_main_conf(r, ngx_http_push_stream_module);
+    ngx_http_push_stream_shm_data_t          *data = mcf->shm_data;
+    ngx_http_push_stream_content_subtype_t   *subtype = ngx_http_push_stream_match_channel_info_format_and_content_type(r, 1);
+
+    const ngx_str_t *format;
+    const ngx_str_t *head = subtype->format_group_head;
+    const ngx_str_t *tail = subtype->format_group_tail;
+
+    // format content body
+    for (q = ngx_queue_head(queue_channel_info); q != ngx_queue_sentinel(queue_channel_info); q = ngx_queue_next(q)) {
+        ngx_http_push_stream_channel_info_t *channel_info = ngx_queue_data(q, ngx_http_push_stream_channel_info_t, queue);
+        if ((chain = ngx_http_push_stream_get_buf(r)) == NULL) {
+            ngx_log_error(NGX_LOG_ERR, r->connection->log, 0, "push stream module: unable to allocate memory for response channels info");
+            return NGX_HTTP_INTERNAL_SERVER_ERROR;
+        }
+
+        format = (q != ngx_queue_last(queue_channel_info)) ? subtype->format_group_item : subtype->format_group_last_item;
+        if ((text = ngx_http_push_stream_channel_info_formatted(r->pool, format, &channel_info->id, channel_info->published_messages, channel_info->stored_messages, channel_info->subscribers)) == NULL) {
+            ngx_log_error(NGX_LOG_ERR, r->connection->log, 0, "push stream module: unable to allocate memory to format channel info");
+            return NGX_HTTP_INTERNAL_SERVER_ERROR;
+        }
+
+        chain->buf->last_buf = 0;
+        chain->buf->memory = 1;
+        chain->buf->temporary = 0;
+        chain->buf->pos = text->data;
+        chain->buf->last = text->data + text->len;
+        chain->buf->start = chain->buf->pos;
+        chain->buf->end = chain->buf->last;
+
+        content_len += text->len;
+
+        if (first == NULL) {
+            first = chain;
+        }
+
+        if (last != NULL) {
+            last->next = chain;
+        }
+
+        last = chain;
+    }
+
+    // get formatted current time
+    currenttime = ngx_http_push_stream_get_formatted_current_time(r->pool);
+
+    // get formatted hostname
+    hostname = ngx_http_push_stream_get_formatted_hostname(r->pool);
+
+    // format content header
+    if ((header_response = ngx_http_push_stream_create_str(r->pool, head->len + hostname->len + currenttime->len + NGX_INT_T_LEN)) == NULL) {
+        ngx_log_error(NGX_LOG_ERR, r->connection->log, 0, "push stream module: unable to allocate memory for response channels info");
+        return NGX_HTTP_INTERNAL_SERVER_ERROR;
+    }
+
+    ngx_sprintf(header_response->data, (char *) head->data, hostname->data, currenttime->data, data->channels, data->wildcard_channels, ngx_time() - data->startup);
+    header_response->len = ngx_strlen(header_response->data);
+
+    content_len += header_response->len + tail->len;
+
+    r->headers_out.content_type_len = subtype->content_type->len;
+    r->headers_out.content_type     = *subtype->content_type;
+    r->headers_out.content_length_n = content_len;
+    r->headers_out.status = NGX_HTTP_OK;
+
+    rc = ngx_http_send_header(r);
+    if (rc == NGX_ERROR || rc > NGX_OK || r->header_only) {
+        return rc;
+    }
+
+    // send content header
+    ngx_http_push_stream_send_response_text(r, header_response->data, header_response->len,0);
+    // send content body
+    if (first != NULL) {
+        ngx_http_push_stream_output_filter(r, first);
+    }
+    // send content footer
+    return ngx_http_push_stream_send_response_text(r, tail->data, tail->len, 1);
+}
+
+static ngx_int_t
+ngx_http_push_stream_send_response_all_channels_info_detailed(ngx_http_request_t *r, ngx_str_t *prefix)
+{
+    ngx_http_push_stream_main_conf_t         *mcf = ngx_http_get_module_main_conf(r, ngx_http_push_stream_module);
+    ngx_queue_t                               queue_channel_info;
+    ngx_http_push_stream_shm_data_t          *data = mcf->shm_data;
+    ngx_queue_t                              *q;
+    ngx_http_push_stream_channel_t           *channel;
+
+    ngx_queue_init(&queue_channel_info);
+
+    ngx_shmtx_lock(&data->channels_queue_mutex);
+    for (q = ngx_queue_head(&data->channels_queue); q != ngx_queue_sentinel(&data->channels_queue); q = ngx_queue_next(q)) {
+        channel = ngx_queue_data(q, ngx_http_push_stream_channel_t, queue);
+
+        ngx_http_push_stream_channel_info_t *channel_info;
+
+        if(!prefix || (ngx_strncmp(channel->id.data, prefix->data, prefix->len) == 0)) {
+
+            if ((channel_info = ngx_pcalloc(r->pool, sizeof(ngx_http_push_stream_channel_info_t))) != NULL) {
+                channel_info->id.data = channel->id.data;
+                channel_info->id.len = channel->id.len;
+                channel_info->published_messages = channel->last_message_id;
+                channel_info->stored_messages = channel->stored_messages;
+                channel_info->subscribers = channel->subscribers;
+
+                ngx_queue_insert_tail(&queue_channel_info, &channel_info->queue);
+            }
+
+        }
+    }
+    ngx_shmtx_unlock(&data->channels_queue_mutex);
+
+    return ngx_http_push_stream_send_response_channels_info(r, &queue_channel_info);
+}
+
+static ngx_int_t
+ngx_http_push_stream_send_response_channels_info_detailed(ngx_http_request_t *r, ngx_http_push_stream_requested_channel_t *requested_channels) {
+    ngx_str_t                                *text;
+    ngx_queue_t                               queue_channel_info;
+    ngx_http_push_stream_content_subtype_t   *subtype = ngx_http_push_stream_match_channel_info_format_and_content_type(r, 1);
+    ngx_http_push_stream_channel_info_t      *channel_info;
+    ngx_http_push_stream_requested_channel_t *requested_channel;
+    ngx_queue_t                              *q;
+    ngx_uint_t                                qtd_channels = 0;
+
+    ngx_queue_init(&queue_channel_info);
+
+    for (q = ngx_queue_head(&requested_channels->queue); q != ngx_queue_sentinel(&requested_channels->queue); q = ngx_queue_next(q)) {
+        requested_channel = ngx_queue_data(q, ngx_http_push_stream_requested_channel_t, queue);
+
+        if ((requested_channel->channel != NULL) && ((channel_info = ngx_pcalloc(r->pool, sizeof(ngx_http_push_stream_channel_info_t))) != NULL)) {
+            channel_info->id.data = requested_channel->channel->id.data;
+            channel_info->id.len = requested_channel->channel->id.len;
+            channel_info->published_messages = requested_channel->channel->last_message_id;
+            channel_info->stored_messages = requested_channel->channel->stored_messages;
+            channel_info->subscribers = requested_channel->channel->subscribers;
+
+            ngx_queue_insert_tail(&queue_channel_info, &channel_info->queue);
+            qtd_channels++;
+        }
+    }
+
+    if (qtd_channels == 0) {
+        return ngx_http_push_stream_send_only_header_response(r, NGX_HTTP_NOT_FOUND, NULL);
+    }
+
+    if (qtd_channels == 1) {
+        channel_info = ngx_queue_data(ngx_queue_head(&queue_channel_info), ngx_http_push_stream_channel_info_t, queue);
+        text = ngx_http_push_stream_channel_info_formatted(r->pool, subtype->format_item, &channel_info->id, channel_info->published_messages, channel_info->stored_messages, channel_info->subscribers);
+        if (text == NULL) {
+            ngx_log_error(NGX_LOG_ERR, r->connection->log, 0, "Failed to allocate response buffer.");
+            return NGX_HTTP_INTERNAL_SERVER_ERROR;
+        }
+
+        return ngx_http_push_stream_send_response(r, text, subtype->content_type, NGX_HTTP_OK);
+    }
+
+    return ngx_http_push_stream_send_response_channels_info(r, &queue_channel_info);
+}
+
+static ngx_int_t
+ngx_http_push_stream_check_and_parse_template_pattern(ngx_conf_t *cf, ngx_http_push_stream_template_t *template, u_char *last, u_char *start, const ngx_str_t *token, ngx_http_push_stream_template_part_type part_type)
+{
+    ngx_http_push_stream_template_parts_t *part;
+
+    if (ngx_strncasecmp(start, token->data, token->len) == 0) {
+        if ((start - last) > 0) {
+            part = ngx_pcalloc(cf->pool, sizeof(ngx_http_push_stream_template_parts_t));
+            if (part == NULL) {
+                ngx_log_error(NGX_LOG_ERR, cf->log, 0, "push stream module: unable to allocate memory for add template part");
+                return NGX_ERROR;
+            }
+            part->kind = PUSH_STREAM_TEMPLATE_PART_TYPE_LITERAL;
+            part->text.data = last;
+            part->text.len = start - last;
+            template->literal_len += part->text.len;
+            ngx_queue_insert_tail(&template->parts, &part->queue);
+        }
+
+        part = ngx_pcalloc(cf->pool, sizeof(ngx_http_push_stream_template_parts_t));
+        if (part == NULL) {
+            ngx_log_error(NGX_LOG_ERR, cf->log, 0, "push stream module: unable to allocate memory for add template part");
+            return NGX_ERROR;
+        }
+        part->kind = part_type;
+        ngx_queue_insert_tail(&template->parts, &part->queue);
+
+        return NGX_OK;
+    }
+
+    return NGX_DECLINED;
+}
+
+static ngx_int_t
+ngx_http_push_stream_find_or_add_template(ngx_conf_t *cf, ngx_str_t template, ngx_flag_t eventsource, ngx_flag_t websocket)
+{
+    ngx_http_push_stream_main_conf_t      *mcf = ngx_http_conf_get_module_main_conf(cf, ngx_http_push_stream_module);
+    ngx_queue_t                           *q;
+    ngx_http_push_stream_template_t       *cur;
+    ngx_str_t                             *aux = NULL;
+    u_char                                *start = NULL, *last = NULL;
+    size_t                                 len = 0;
+    ngx_http_push_stream_template_parts_t *part;
+    ngx_int_t                              rc;
+
+    for (q = ngx_queue_head(&mcf->msg_templates); q != ngx_queue_sentinel(&mcf->msg_templates); q = ngx_queue_next(q)) {
+        cur = ngx_queue_data(q, ngx_http_push_stream_template_t, queue);
+        if ((ngx_memn2cmp(cur->template->data, template.data, cur->template->len, template.len) == 0) &&
+            (cur->eventsource == eventsource) && (cur->websocket == websocket)) {
+            return cur->index;
+        }
+    }
+
+    mcf->qtd_templates++;
+
+    cur = ngx_pcalloc(cf->pool, sizeof(ngx_http_push_stream_template_t));
+    aux = ngx_http_push_stream_create_str(cf->pool, template.len);
+    if ((cur == NULL) || (aux == NULL)) {
+        ngx_log_error(NGX_LOG_ERR, cf->log, 0, "push stream module: unable to allocate memory for add template to main configuration");
+        return -1;
+    }
+    cur->template = aux;
+    cur->eventsource = eventsource;
+    cur->websocket = websocket;
+    cur->index = mcf->qtd_templates;
+    cur->qtd_message_id = 0;
+    cur->qtd_event_id = 0;
+    cur->qtd_event_type = 0;
+    cur->qtd_channel = 0;
+    cur->qtd_text = 0;
+    cur->qtd_tag = 0;
+    cur->qtd_time = 0;
+    cur->qtd_size = 0;
+    cur->literal_len = 0;
+    ngx_queue_init(&cur->parts);
+    ngx_memcpy(cur->template->data, template.data, template.len);
+    ngx_queue_insert_tail(&mcf->msg_templates, &cur->queue);
+
+    len = cur->template->len;
+    last = start = cur->template->data;
+    while ((start = ngx_strnstr(start, "~", len)) != NULL) {
+        if ((rc = ngx_http_push_stream_check_and_parse_template_pattern(cf, cur, last, start, &NGX_HTTP_PUSH_STREAM_TOKEN_MESSAGE_ID, PUSH_STREAM_TEMPLATE_PART_TYPE_ID)) == NGX_OK) {
+            start += NGX_HTTP_PUSH_STREAM_TOKEN_MESSAGE_ID.len;
+            last = start;
+            cur->qtd_message_id++;
+        } else if ((rc == NGX_DECLINED) && ((rc = ngx_http_push_stream_check_and_parse_template_pattern(cf, cur, last, start, &NGX_HTTP_PUSH_STREAM_TOKEN_MESSAGE_EVENT_ID, PUSH_STREAM_TEMPLATE_PART_TYPE_EVENT_ID)) == NGX_OK)) {
+            start += NGX_HTTP_PUSH_STREAM_TOKEN_MESSAGE_EVENT_ID.len;
+            last = start;
+            cur->qtd_event_id++;
+        } else if ((rc == NGX_DECLINED) && ((rc = ngx_http_push_stream_check_and_parse_template_pattern(cf, cur, last, start, &NGX_HTTP_PUSH_STREAM_TOKEN_MESSAGE_EVENT_TYPE, PUSH_STREAM_TEMPLATE_PART_TYPE_EVENT_TYPE)) == NGX_OK)) {
+            start += NGX_HTTP_PUSH_STREAM_TOKEN_MESSAGE_EVENT_TYPE.len;
+            last = start;
+            cur->qtd_event_type++;
+        } else if ((rc == NGX_DECLINED) && ((rc = ngx_http_push_stream_check_and_parse_template_pattern(cf, cur, last, start, &NGX_HTTP_PUSH_STREAM_TOKEN_MESSAGE_CHANNEL, PUSH_STREAM_TEMPLATE_PART_TYPE_CHANNEL)) == NGX_OK)) {
+            start += NGX_HTTP_PUSH_STREAM_TOKEN_MESSAGE_CHANNEL.len;
+            last = start;
+            cur->qtd_channel++;
+        } else if ((rc == NGX_DECLINED) && ((rc = ngx_http_push_stream_check_and_parse_template_pattern(cf, cur, last, start, &NGX_HTTP_PUSH_STREAM_TOKEN_MESSAGE_TEXT, PUSH_STREAM_TEMPLATE_PART_TYPE_TEXT)) == NGX_OK)) {
+            start += NGX_HTTP_PUSH_STREAM_TOKEN_MESSAGE_TEXT.len;
+            last = start;
+            cur->qtd_text++;
+        } else if ((rc == NGX_DECLINED) && ((rc = ngx_http_push_stream_check_and_parse_template_pattern(cf, cur, last, start, &NGX_HTTP_PUSH_STREAM_TOKEN_MESSAGE_TAG, PUSH_STREAM_TEMPLATE_PART_TYPE_TAG)) == NGX_OK)) {
+            start += NGX_HTTP_PUSH_STREAM_TOKEN_MESSAGE_TAG.len;
+            last = start;
+            cur->qtd_tag++;
+        } else if ((rc == NGX_DECLINED) && ((rc = ngx_http_push_stream_check_and_parse_template_pattern(cf, cur, last, start, &NGX_HTTP_PUSH_STREAM_TOKEN_MESSAGE_TIME, PUSH_STREAM_TEMPLATE_PART_TYPE_TIME)) == NGX_OK)) {
+            start += NGX_HTTP_PUSH_STREAM_TOKEN_MESSAGE_TIME.len;
+            last = start;
+            cur->qtd_time++;
+        } else if ((rc == NGX_DECLINED) && ((rc = ngx_http_push_stream_check_and_parse_template_pattern(cf, cur, last, start, &NGX_HTTP_PUSH_STREAM_TOKEN_MESSAGE_SIZE, PUSH_STREAM_TEMPLATE_PART_TYPE_SIZE)) == NGX_OK)) {
+            start += NGX_HTTP_PUSH_STREAM_TOKEN_MESSAGE_SIZE.len;
+            last = start;
+            cur->qtd_size++;
+        } else {
+            start += 1;
+        }
+
+        if (rc == NGX_ERROR) {
+            return -1;
+        }
+    }
+
+    if (last < (cur->template->data + cur->template->len)) {
+        part = ngx_pcalloc(cf->pool, sizeof(ngx_http_push_stream_template_parts_t));
+        if (part == NULL) {
+            ngx_log_error(NGX_LOG_ERR, cf->log, 0, "push stream module: unable to allocate memory for add template part");
+            return -1;
+        }
+        part->kind = PUSH_STREAM_TEMPLATE_PART_TYPE_LITERAL;
+        part->text.data = last;
+        part->text.len = (cur->template->data + cur->template->len) - last;
+        cur->literal_len += part->text.len;
+        ngx_queue_insert_tail(&cur->parts, &part->queue);
+    }
+
+    return cur->index;
+}
diff -Naur nginx-1.11.3/nginx-push-stream-module/src/ngx_http_push_stream_module_ipc.c nginx-1.11.3-push/nginx-push-stream-module/src/ngx_http_push_stream_module_ipc.c
--- nginx-1.11.3/nginx-push-stream-module/src/ngx_http_push_stream_module_ipc.c	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/src/ngx_http_push_stream_module_ipc.c	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,530 @@
+/*
+ * This file is distributed under the MIT License.
+ *
+ * Copyright (c) 2009 Leo Ponomarev
+ *
+ * Permission is hereby granted, free of charge, to any person
+ * obtaining a copy of this software and associated documentation
+ * files (the "Software"), to deal in the Software without
+ * restriction, including without limitation the rights to use,
+ * copy, modify, merge, publish, distribute, sublicense, and/or sell
+ * copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following
+ * conditions:
+ *
+ * The above copyright notice and this permission notice shall be
+ * included in all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES
+ * OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
+ * HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,
+ * WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
+ * OTHER DEALINGS IN THE SOFTWARE.
+ *
+ *
+ * ngx_http_push_stream_module_ipc.c
+ *
+ * Modified: Oct 26, 2010
+ * Modifications by: Wandenberg Peixoto <wandenberg@gmail.com>, Rog√©rio Carvalho Schneider <stockrt@gmail.com>
+ */
+
+#include <ngx_http_push_stream_module_ipc.h>
+
+void ngx_http_push_stream_ipc_init_worker_data(ngx_http_push_stream_shm_data_t *data);
+static ngx_inline void ngx_http_push_stream_census_worker_subscribers_data(ngx_http_push_stream_shm_data_t *data);
+static ngx_inline void ngx_http_push_stream_process_worker_message_data(ngx_http_push_stream_shm_data_t *data);
+
+
+static ngx_int_t
+ngx_http_push_stream_init_ipc(ngx_cycle_t *cycle, ngx_int_t workers)
+{
+    int         i, s = 0, on = 1;
+    ngx_int_t   last_expected_process = ngx_last_process;
+
+
+    /*
+     * here's the deal: we have no control over fork()ing, nginx's internal
+     * socketpairs are unusable for our purposes (as of nginx 0.8 -- check the
+     * code to see why), and the module initialization callbacks occur before
+     * any workers are spawned. Rather than futzing around with existing
+     * socketpairs, we populate our own socketpairs array.
+     * Trouble is, ngx_spawn_process() creates them one-by-one, and we need to
+     * do it all at once. So we must guess all the workers' ngx_process_slots in
+     * advance. Meaning the spawning logic must be copied to the T.
+     */
+
+    for(i=0; i<workers; i++) {
+        while (s < last_expected_process && ngx_processes[s].pid != NGX_INVALID_FILE) {
+            // find empty existing slot
+            s++;
+        }
+
+        // copypaste from os/unix/ngx_process.c (ngx_spawn_process)
+        ngx_socket_t    *socks = ngx_http_push_stream_socketpairs[s];
+        if (socketpair(AF_UNIX, SOCK_STREAM, 0, socks) == -1) {
+            ngx_log_error(NGX_LOG_ALERT, cycle->log, ngx_errno, "socketpair() failed on socketpair while initializing push stream module");
+            return NGX_ERROR;
+        }
+        if (ngx_nonblocking(socks[0]) == -1) {
+            ngx_log_error(NGX_LOG_ALERT, cycle->log, ngx_errno, ngx_nonblocking_n " failed on socketpair while initializing push stream module");
+            ngx_close_channel(socks, cycle->log);
+            return NGX_ERROR;
+        }
+        if (ngx_nonblocking(socks[1]) == -1) {
+            ngx_log_error(NGX_LOG_ALERT, cycle->log, ngx_errno, ngx_nonblocking_n " failed on socketpair while initializing push stream module");
+            ngx_close_channel(socks, cycle->log);
+            return NGX_ERROR;
+        }
+        if (ioctl(socks[0], FIOASYNC, &on) == -1) {
+            ngx_log_error(NGX_LOG_ALERT, cycle->log, ngx_errno, "ioctl(FIOASYNC) failed on socketpair while initializing push stream module");
+            ngx_close_channel(socks, cycle->log);
+            return NGX_ERROR;
+        }
+        if (fcntl(socks[0], F_SETOWN, ngx_pid) == -1) {
+            ngx_log_error(NGX_LOG_ALERT, cycle->log, ngx_errno, "fcntl(F_SETOWN) failed on socketpair while initializing push stream module");
+            ngx_close_channel(socks, cycle->log);
+            return NGX_ERROR;
+        }
+        if (fcntl(socks[0], F_SETFD, FD_CLOEXEC) == -1) {
+            ngx_log_error(NGX_LOG_ALERT, cycle->log, ngx_errno, "fcntl(FD_CLOEXEC) failed on socketpair while initializing push stream module");
+            ngx_close_channel(socks, cycle->log);
+            return NGX_ERROR;
+        }
+        if (fcntl(socks[1], F_SETFD, FD_CLOEXEC) == -1) {
+            ngx_log_error(NGX_LOG_ALERT, cycle->log, ngx_errno, "fcntl(FD_CLOEXEC) failed while initializing push stream module");
+            ngx_close_channel(socks, cycle->log);
+            return NGX_ERROR;
+        }
+
+        s++; // NEXT!!
+    }
+
+    return NGX_OK;
+}
+
+
+static void
+ngx_http_push_stream_ipc_exit_worker(ngx_cycle_t *cycle)
+{
+    ngx_close_channel((ngx_socket_t *) ngx_http_push_stream_socketpairs[ngx_process_slot], cycle->log);
+}
+
+
+// will be called many times
+static ngx_int_t
+ngx_http_push_stream_ipc_init_worker(void)
+{
+    ngx_slab_pool_t                        *global_shpool = (ngx_slab_pool_t *) ngx_http_push_stream_global_shm_zone->shm.addr;
+    ngx_http_push_stream_global_shm_data_t *global_data = (ngx_http_push_stream_global_shm_data_t *) ngx_http_push_stream_global_shm_zone->data;
+    ngx_queue_t                            *q;
+    int                                     i;
+
+    ngx_shmtx_lock(&global_shpool->mutex);
+    global_data->pid[ngx_process_slot] = ngx_pid;
+    for (q = ngx_queue_head(&global_data->shm_datas_queue); q != ngx_queue_sentinel(&global_data->shm_datas_queue); q = ngx_queue_next(q)) {
+        ngx_http_push_stream_shm_data_t *data = ngx_queue_data(q, ngx_http_push_stream_shm_data_t, shm_data_queue);
+        ngx_http_push_stream_ipc_init_worker_data(data);
+    }
+    ngx_shmtx_unlock(&global_shpool->mutex);
+
+    for(i = 0; i < NGX_MAX_PROCESSES; i++) {
+        if (global_data->pid[i] > 0) {
+            ngx_http_push_stream_alert_worker_census_subscribers(global_data->pid[i], i, ngx_cycle->log);
+        }
+    }
+
+    return NGX_OK;
+}
+
+
+void
+ngx_http_push_stream_ipc_init_worker_data(ngx_http_push_stream_shm_data_t *data)
+{
+    ngx_slab_pool_t                        *shpool = data->shpool;
+    int                                     i;
+
+    // cleanning old content if worker die and another one is set on same slot
+    ngx_http_push_stream_clean_worker_data(data);
+
+    ngx_shmtx_lock(&shpool->mutex);
+
+    data->ipc[ngx_process_slot].pid = ngx_pid;
+    data->ipc[ngx_process_slot].startup = ngx_time();
+
+    data->slots_for_census = 0;
+    for(i = 0; i < NGX_MAX_PROCESSES; i++) {
+        if (data->ipc[i].pid > 0) {
+            data->slots_for_census++;
+        }
+    }
+
+    ngx_shmtx_unlock(&shpool->mutex);
+}
+
+
+static void
+ngx_http_push_stream_alert_shutting_down_workers(void)
+{
+    ngx_http_push_stream_global_shm_data_t *global_data = (ngx_http_push_stream_global_shm_data_t *) ngx_http_push_stream_global_shm_zone->data;
+    int                                     i;
+
+    for(i = 0; i < NGX_MAX_PROCESSES; i++) {
+        if (global_data->pid[i] > 0) {
+            ngx_http_push_stream_alert_worker_shutting_down_cleanup(global_data->pid[i], i, ngx_cycle->log);
+            ngx_close_channel((ngx_socket_t *) ngx_http_push_stream_socketpairs[i], ngx_cycle->log);
+            ngx_http_push_stream_socketpairs[i][0] = NGX_INVALID_FILE;
+            ngx_http_push_stream_socketpairs[i][1] = NGX_INVALID_FILE;
+        }
+    }
+}
+
+
+static ngx_int_t
+ngx_http_push_stream_unsubscribe_worker(ngx_http_push_stream_channel_t *channel, ngx_slab_pool_t *shpool)
+{
+    ngx_http_push_stream_pid_queue_t        *worker;
+    ngx_queue_t                             *q;
+
+    ngx_shmtx_lock(channel->mutex);
+    for (q = ngx_queue_head(&channel->workers_with_subscribers); q != ngx_queue_sentinel(&channel->workers_with_subscribers); q = ngx_queue_next(q)) {
+        worker = ngx_queue_data(q, ngx_http_push_stream_pid_queue_t, queue);
+        if ((worker->pid == ngx_pid) || (worker->slot == ngx_process_slot)) {
+            ngx_queue_remove(&worker->queue);
+            ngx_slab_free(shpool, worker);
+            break;
+        }
+    }
+    ngx_shmtx_unlock(channel->mutex);
+
+    return NGX_OK;
+}
+
+
+static void
+ngx_http_push_stream_clean_worker_data(ngx_http_push_stream_shm_data_t *data)
+{
+    ngx_slab_pool_t                        *shpool = data->shpool;
+    ngx_queue_t                            *cur, *q;
+    ngx_http_push_stream_channel_t         *channel;
+    ngx_http_push_stream_worker_msg_t      *worker_msg;
+
+    while (!ngx_queue_empty(&data->ipc[ngx_process_slot].messages_queue)) {
+        cur = ngx_queue_head(&data->ipc[ngx_process_slot].messages_queue);
+        worker_msg = ngx_queue_data(cur, ngx_http_push_stream_worker_msg_t, queue);
+        ngx_http_push_stream_free_worker_message_memory(shpool, worker_msg);
+    }
+
+    ngx_queue_init(&data->ipc[ngx_process_slot].subscribers_queue);
+
+    ngx_shmtx_lock(&data->channels_queue_mutex);
+    for (q = ngx_queue_head(&data->channels_queue); q != ngx_queue_sentinel(&data->channels_queue); q = ngx_queue_next(q)) {
+        channel = ngx_queue_data(q, ngx_http_push_stream_channel_t, queue);
+        ngx_http_push_stream_unsubscribe_worker(channel, shpool);
+    }
+    ngx_shmtx_unlock(&data->channels_queue_mutex);
+
+    data->ipc[ngx_process_slot].pid = NGX_INVALID_FILE;
+    data->ipc[ngx_process_slot].subscribers = 0;
+}
+
+
+static ngx_int_t
+ngx_http_push_stream_register_worker_message_handler(ngx_cycle_t *cycle)
+{
+    if (ngx_add_channel_event(cycle, ngx_http_push_stream_socketpairs[ngx_process_slot][1], NGX_READ_EVENT, ngx_http_push_stream_channel_handler) == NGX_ERROR) {
+        ngx_log_error(NGX_LOG_ALERT, cycle->log, ngx_errno, "failed to register channel handler while initializing push stream module worker");
+        return NGX_ERROR;
+    }
+
+    return NGX_OK;
+}
+
+
+static void
+ngx_http_push_stream_channel_handler(ngx_event_t *ev)
+{
+    // copypaste from os/unix/ngx_process_cycle.c (ngx_channel_handler)
+    ngx_int_t           n;
+    ngx_channel_t       ch;
+    ngx_connection_t   *c;
+
+
+    if (ev->timedout) {
+        ev->timedout = 0;
+        return;
+    }
+    c = ev->data;
+
+    while (1) {
+        n = ngx_read_channel(c->fd, &ch, sizeof(ch), ev->log);
+        if (n == NGX_ERROR) {
+            if (ngx_event_flags & NGX_USE_EPOLL_EVENT) {
+                ngx_del_conn(c, 0);
+            }
+            ngx_close_connection(c);
+            return;
+        }
+
+        if ((ngx_event_flags & NGX_USE_EVENTPORT_EVENT) && (ngx_add_event(ev, NGX_READ_EVENT, 0) == NGX_ERROR)) {
+            return;
+        }
+
+        if (n == NGX_AGAIN) {
+            return;
+        }
+
+        if (ch.command == NGX_CMD_HTTP_PUSH_STREAM_CHECK_MESSAGES.command) {
+            ngx_http_push_stream_process_worker_message();
+        } else if (ch.command == NGX_CMD_HTTP_PUSH_STREAM_CENSUS_SUBSCRIBERS.command) {
+            ngx_http_push_stream_census_worker_subscribers();
+        } else if (ch.command == NGX_CMD_HTTP_PUSH_STREAM_DELETE_CHANNEL.command) {
+            ngx_http_push_stream_delete_worker_channel();
+        } else if (ch.command == NGX_CMD_HTTP_PUSH_STREAM_CLEANUP_SHUTTING_DOWN.command) {
+            ngx_http_push_stream_cleanup_shutting_down_worker();
+        }
+    }
+}
+
+
+static ngx_int_t
+ngx_http_push_stream_alert_worker(ngx_pid_t pid, ngx_int_t slot, ngx_log_t *log, ngx_channel_t command)
+{
+    if (ngx_http_push_stream_socketpairs[slot][0] != NGX_INVALID_FILE) {
+        return ngx_write_channel(ngx_http_push_stream_socketpairs[slot][0], &command, sizeof(ngx_channel_t), log);
+    }
+    return NGX_OK;
+}
+
+
+static ngx_inline void
+ngx_http_push_stream_census_worker_subscribers(void)
+{
+    ngx_slab_pool_t                        *global_shpool = (ngx_slab_pool_t *) ngx_http_push_stream_global_shm_zone->shm.addr;
+    ngx_http_push_stream_global_shm_data_t *global_data = (ngx_http_push_stream_global_shm_data_t *) ngx_http_push_stream_global_shm_zone->data;
+    ngx_queue_t                            *q;
+
+    ngx_shmtx_lock(&global_shpool->mutex);
+    for (q = ngx_queue_head(&global_data->shm_datas_queue); q != ngx_queue_sentinel(&global_data->shm_datas_queue); q = ngx_queue_next(q)) {
+        ngx_http_push_stream_shm_data_t *data = ngx_queue_data(q, ngx_http_push_stream_shm_data_t, shm_data_queue);
+        ngx_http_push_stream_census_worker_subscribers_data(data);
+    }
+    ngx_shmtx_unlock(&global_shpool->mutex);
+}
+
+static ngx_inline void
+ngx_http_push_stream_census_worker_subscribers_data(ngx_http_push_stream_shm_data_t *data)
+{
+    ngx_slab_pool_t                             *shpool = data->shpool;
+    ngx_http_push_stream_worker_data_t          *thisworker_data = &data->ipc[ngx_process_slot];
+    ngx_queue_t                                 *q, *cur, *cur_worker;
+    int                                          i;
+
+
+    thisworker_data->subscribers = 0;
+
+    ngx_shmtx_lock(&data->channels_queue_mutex);
+    for (q = ngx_queue_head(&data->channels_queue); q != ngx_queue_sentinel(&data->channels_queue); q = ngx_queue_next(q)) {
+        ngx_http_push_stream_channel_t *channel = ngx_queue_data(q, ngx_http_push_stream_channel_t, queue);
+        ngx_shmtx_lock(channel->mutex);
+        for (cur_worker = ngx_queue_head(&channel->workers_with_subscribers); cur_worker != ngx_queue_sentinel(&channel->workers_with_subscribers); cur_worker = ngx_queue_next(cur_worker)) {
+            ngx_http_push_stream_pid_queue_t *worker = ngx_queue_data(cur_worker, ngx_http_push_stream_pid_queue_t, queue);
+            if (worker->pid == ngx_pid) {
+                worker->subscribers = 0;
+            }
+        }
+        ngx_shmtx_unlock(channel->mutex);
+    }
+    ngx_shmtx_unlock(&data->channels_queue_mutex);
+
+    for (q = ngx_queue_head(&thisworker_data->subscribers_queue); q != ngx_queue_sentinel(&thisworker_data->subscribers_queue); q = ngx_queue_next(q)) {
+        ngx_http_push_stream_subscriber_t *subscriber = ngx_queue_data(q, ngx_http_push_stream_subscriber_t, worker_queue);
+
+        for (cur = ngx_queue_head(&subscriber->subscriptions); cur != ngx_queue_sentinel(&subscriber->subscriptions); cur = ngx_queue_next(cur)) {
+            ngx_http_push_stream_subscription_t *subscription = ngx_queue_data(cur, ngx_http_push_stream_subscription_t, queue);
+            subscription->channel_worker_sentinel->subscribers++;
+        }
+        thisworker_data->subscribers++;
+    }
+
+    ngx_shmtx_lock(&shpool->mutex);
+    data->slots_for_census--;
+    ngx_shmtx_unlock(&shpool->mutex);
+
+    if (data->slots_for_census == 0) {
+        ngx_shmtx_lock(&shpool->mutex);
+        data->subscribers = 0;
+        for (i = 0; i < NGX_MAX_PROCESSES; i++) {
+            if (data->ipc[i].pid > 0) {
+                data->subscribers += data->ipc[i].subscribers;
+            }
+        }
+        ngx_shmtx_unlock(&shpool->mutex);
+
+        ngx_shmtx_lock(&data->channels_queue_mutex);
+        for (q = ngx_queue_head(&data->channels_queue); q != ngx_queue_sentinel(&data->channels_queue); q = ngx_queue_next(q)) {
+            ngx_http_push_stream_channel_t *channel = ngx_queue_data(q, ngx_http_push_stream_channel_t, queue);
+            ngx_shmtx_lock(channel->mutex);
+            channel->subscribers = 0;
+            for (cur_worker = ngx_queue_head(&channel->workers_with_subscribers); cur_worker != ngx_queue_sentinel(&channel->workers_with_subscribers); cur_worker = ngx_queue_next(cur_worker)) {
+                ngx_http_push_stream_pid_queue_t *worker = ngx_queue_data(cur_worker, ngx_http_push_stream_pid_queue_t, queue);
+                channel->subscribers += worker->subscribers;
+            }
+            ngx_shmtx_unlock(channel->mutex);
+        }
+        ngx_shmtx_unlock(&data->channels_queue_mutex);
+    }
+
+
+}
+
+
+static ngx_inline void
+ngx_http_push_stream_process_worker_message(void)
+{
+    ngx_http_push_stream_global_shm_data_t *global_data = (ngx_http_push_stream_global_shm_data_t *) ngx_http_push_stream_global_shm_zone->data;
+    ngx_queue_t                            *q;
+
+    for (q = ngx_queue_head(&global_data->shm_datas_queue); q != ngx_queue_sentinel(&global_data->shm_datas_queue); q = ngx_queue_next(q)) {
+        ngx_http_push_stream_shm_data_t *data = ngx_queue_data(q, ngx_http_push_stream_shm_data_t, shm_data_queue);
+        ngx_http_push_stream_process_worker_message_data(data);
+    }
+}
+
+
+static ngx_inline void
+ngx_http_push_stream_process_worker_message_data(ngx_http_push_stream_shm_data_t *data)
+{
+    ngx_http_push_stream_worker_msg_t      *worker_msg;
+    ngx_queue_t                            *cur, *q;
+    ngx_slab_pool_t                        *shpool = data->shpool;
+    ngx_http_push_stream_worker_data_t     *thisworker_data = data->ipc + ngx_process_slot;
+
+
+    while (!ngx_queue_empty(&thisworker_data->messages_queue)) {
+        cur = ngx_queue_head(&thisworker_data->messages_queue);
+        worker_msg = ngx_queue_data(cur, ngx_http_push_stream_worker_msg_t, queue);
+        if (worker_msg->pid == ngx_pid) {
+            // everything is okay
+            ngx_http_push_stream_respond_to_subscribers(worker_msg->channel, worker_msg->subscriptions_sentinel, worker_msg->msg);
+        } else {
+            // that's quite bad you see. a previous worker died with an undelivered message.
+            // but all its subscribers' connections presumably got canned, too. so it's not so bad after all.
+
+            ngx_log_error(NGX_LOG_ERR, ngx_cycle->log, 0, "push stream module: worker %i intercepted a message intended for another worker process (%i) that probably died and will remove the reference to the old worker", ngx_pid, worker_msg->pid);
+
+            // delete that invalid sucker
+            ngx_shmtx_lock(worker_msg->channel->mutex);
+            for (q = ngx_queue_head(&worker_msg->channel->workers_with_subscribers); q != ngx_queue_sentinel(&worker_msg->channel->workers_with_subscribers); q = ngx_queue_next(q)) {
+                ngx_http_push_stream_pid_queue_t *worker = ngx_queue_data(q, ngx_http_push_stream_pid_queue_t, queue);
+                if (worker->pid == worker_msg->pid) {
+                    ngx_queue_remove(&worker->queue);
+                    ngx_slab_free(shpool, worker);
+                    break;
+                }
+            }
+            ngx_shmtx_unlock(worker_msg->channel->mutex);
+        }
+
+        // free worker_msg already sent
+        ngx_http_push_stream_free_worker_message_memory(shpool, worker_msg);
+    }
+}
+
+
+static ngx_int_t
+ngx_http_push_stream_send_worker_message(ngx_http_push_stream_channel_t *channel, ngx_queue_t *subscriptions_sentinel, ngx_pid_t pid, ngx_int_t worker_slot, ngx_http_push_stream_msg_t *msg, ngx_flag_t *queue_was_empty, ngx_log_t *log, ngx_http_push_stream_main_conf_t *mcf)
+{
+    ngx_slab_pool_t                         *shpool = mcf->shpool;
+    ngx_http_push_stream_worker_data_t      *thisworker_data = mcf->shm_data->ipc + worker_slot;
+    ngx_http_push_stream_worker_msg_t       *newmessage;
+
+    ngx_shmtx_lock(&shpool->mutex);
+    if ((newmessage = ngx_slab_alloc_locked(shpool, sizeof(ngx_http_push_stream_worker_msg_t))) == NULL) {
+        ngx_shmtx_unlock(&shpool->mutex);
+        ngx_log_error(NGX_LOG_ERR, log, 0, "push stream module: unable to allocate worker message, pid: %P, slot: %d", pid, worker_slot);
+        return NGX_ERROR;
+    }
+
+    msg->workers_ref_count++;
+    newmessage->msg = msg;
+    newmessage->pid = pid;
+    newmessage->subscriptions_sentinel = subscriptions_sentinel;
+    newmessage->channel = channel;
+    newmessage->mcf = mcf;
+    *queue_was_empty = ngx_queue_empty(&thisworker_data->messages_queue);
+    ngx_queue_insert_tail(&thisworker_data->messages_queue, &newmessage->queue);
+    ngx_shmtx_unlock(&shpool->mutex);
+
+    return NGX_OK;
+}
+
+
+static void
+ngx_http_push_stream_broadcast(ngx_http_push_stream_channel_t *channel, ngx_http_push_stream_msg_t *msg, ngx_log_t *log, ngx_http_push_stream_main_conf_t *mcf)
+{
+    // subscribers are queued up in a local pool. Queue heads, however, are located
+    // in shared memory, identified by pid.
+    ngx_http_push_stream_pid_queue_t        *worker;
+    ngx_queue_t                             *q;
+    ngx_flag_t                               queue_was_empty[NGX_MAX_PROCESSES];
+
+    ngx_shmtx_lock(channel->mutex);
+    for (q = ngx_queue_head(&channel->workers_with_subscribers); q != ngx_queue_sentinel(&channel->workers_with_subscribers); q = ngx_queue_next(q)) {
+        worker = ngx_queue_data(q, ngx_http_push_stream_pid_queue_t, queue);
+        ngx_http_push_stream_send_worker_message(channel, &worker->subscriptions, worker->pid, worker->slot, msg, &queue_was_empty[worker->slot], log, mcf);
+    }
+    ngx_shmtx_unlock(channel->mutex);
+
+    for (q = ngx_queue_head(&channel->workers_with_subscribers); q != ngx_queue_sentinel(&channel->workers_with_subscribers); q = ngx_queue_next(q)) {
+        worker = ngx_queue_data(q, ngx_http_push_stream_pid_queue_t, queue);
+        // interprocess communication breakdown
+        if (queue_was_empty[worker->slot] && (ngx_http_push_stream_alert_worker_check_messages(worker->pid, worker->slot, log) != NGX_OK)) {
+            ngx_log_error(NGX_LOG_ERR, log, 0, "push stream module: error communicating with worker process, pid: %P, slot: %d", worker->pid, worker->slot);
+        }
+    }
+
+    if (ngx_queue_empty(&msg->queue)) {
+        ngx_http_push_stream_throw_the_message_away(msg, mcf->shm_data);
+    }
+}
+
+static ngx_int_t
+ngx_http_push_stream_respond_to_subscribers(ngx_http_push_stream_channel_t *channel, ngx_queue_t *subscriptions, ngx_http_push_stream_msg_t *msg)
+{
+    ngx_queue_t      *q;
+
+    if (subscriptions == NULL) {
+        return NGX_ERROR;
+    }
+
+    if (msg != NULL) {
+
+        // now let's respond to some requests!
+        for (q = ngx_queue_head(subscriptions); q != ngx_queue_sentinel(subscriptions);) {
+            ngx_http_push_stream_subscription_t *subscription = ngx_queue_data(q, ngx_http_push_stream_subscription_t, channel_worker_queue);
+            q = ngx_queue_next(q);
+            ngx_http_push_stream_subscriber_t *subscriber = subscription->subscriber;
+            if (subscriber->longpolling) {
+                ngx_http_push_stream_add_polling_headers(subscriber->request, msg->time, msg->tag, subscriber->request->pool);
+                ngx_http_send_header(subscriber->request);
+
+                ngx_http_push_stream_send_response_content_header(subscriber->request, ngx_http_get_module_loc_conf(subscriber->request, ngx_http_push_stream_module));
+                ngx_http_push_stream_send_response_message(subscriber->request, channel, msg, 1, 0);
+                ngx_http_push_stream_send_response_finalize(subscriber->request);
+            } else {
+                if (ngx_http_push_stream_send_response_message(subscriber->request, channel, msg, 0, 0) != NGX_OK) {
+                    ngx_http_push_stream_send_response_finalize(subscriber->request);
+                } else {
+                    ngx_http_push_stream_module_ctx_t     *ctx = ngx_http_get_module_ctx(subscriber->request, ngx_http_push_stream_module);
+                    ngx_http_push_stream_loc_conf_t       *pslcf = ngx_http_get_module_loc_conf(subscriber->request, ngx_http_push_stream_module);
+                    ngx_http_push_stream_timer_reset(pslcf->ping_message_interval, ctx->ping_timer);
+                }
+            }
+        }
+    }
+
+    return NGX_OK;
+}
diff -Naur nginx-1.11.3/nginx-push-stream-module/src/ngx_http_push_stream_module_publisher.c nginx-1.11.3-push/nginx-push-stream-module/src/ngx_http_push_stream_module_publisher.c
--- nginx-1.11.3/nginx-push-stream-module/src/ngx_http_push_stream_module_publisher.c	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/src/ngx_http_push_stream_module_publisher.c	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,343 @@
+/*
+ * Copyright (C) 2010-2015 Wandenberg Peixoto <wandenberg@gmail.com>, Rog√©rio Carvalho Schneider <stockrt@gmail.com>
+ *
+ * This file is part of Nginx Push Stream Module.
+ *
+ * Nginx Push Stream Module is free software: you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation, either version 3 of the License, or
+ * (at your option) any later version.
+ *
+ * Nginx Push Stream Module is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with Nginx Push Stream Module.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ *
+ * ngx_http_push_stream_module_publisher.c
+ *
+ * Created: Oct 26, 2010
+ * Authors: Wandenberg Peixoto <wandenberg@gmail.com>, Rog√©rio Carvalho Schneider <stockrt@gmail.com>
+ */
+
+#include <ngx_http_push_stream_module_publisher.h>
+#include <ngx_http_push_stream_module_version.h>
+
+static ngx_int_t    ngx_http_push_stream_publisher_handle_after_read_body(ngx_http_request_t *r, ngx_http_client_body_handler_pt post_handler);
+
+static ngx_int_t
+ngx_http_push_stream_publisher_handler(ngx_http_request_t *r)
+{
+    ngx_http_push_stream_main_conf_t   *mcf = ngx_http_get_module_main_conf(r, ngx_http_push_stream_module);
+    ngx_http_push_stream_loc_conf_t    *cf = ngx_http_get_module_loc_conf(r, ngx_http_push_stream_module);
+    ngx_http_push_stream_module_ctx_t  *ctx;
+
+    ngx_http_push_stream_requested_channel_t       *requested_channels, *requested_channel;
+    ngx_str_t                                       vv_allowed_origins = ngx_null_string;
+    ngx_queue_t                                     *q;
+
+    ngx_http_push_stream_set_expires(r, NGX_HTTP_PUSH_STREAM_EXPIRES_EPOCH, 0);
+
+
+    if (cf->allowed_origins != NULL) {
+        ngx_http_push_stream_complex_value(r, cf->allowed_origins, &vv_allowed_origins);
+    }
+
+    if (vv_allowed_origins.len > 0) {
+        ngx_http_push_stream_add_response_header(r, &NGX_HTTP_PUSH_STREAM_HEADER_ACCESS_CONTROL_ALLOW_ORIGIN, &vv_allowed_origins);
+        const ngx_str_t *header_value = (cf->location_type == NGX_HTTP_PUSH_STREAM_PUBLISHER_MODE_ADMIN) ? &NGX_HTTP_PUSH_STREAM_ALLOW_GET_POST_PUT_DELETE_METHODS : &NGX_HTTP_PUSH_STREAM_ALLOW_GET_POST_PUT_METHODS;
+        ngx_http_push_stream_add_response_header(r, &NGX_HTTP_PUSH_STREAM_HEADER_ACCESS_CONTROL_ALLOW_METHODS, header_value);
+        ngx_http_push_stream_add_response_header(r, &NGX_HTTP_PUSH_STREAM_HEADER_ACCESS_CONTROL_ALLOW_HEADERS, &NGX_HTTP_PUSH_STREAM_ALLOWED_HEADERS);
+    }
+
+    if (r->method & NGX_HTTP_OPTIONS) {
+        return ngx_http_push_stream_send_only_header_response(r, NGX_HTTP_OK, NULL);
+    }
+
+    // only accept GET, POST, PUT and DELETE methods if enable publisher administration
+    if ((cf->location_type == NGX_HTTP_PUSH_STREAM_PUBLISHER_MODE_ADMIN) && !(r->method & (NGX_HTTP_GET|NGX_HTTP_POST|NGX_HTTP_PUT|NGX_HTTP_DELETE))) {
+        ngx_http_push_stream_add_response_header(r, &NGX_HTTP_PUSH_STREAM_HEADER_ALLOW, &NGX_HTTP_PUSH_STREAM_ALLOW_GET_POST_PUT_DELETE_METHODS);
+        return ngx_http_push_stream_send_only_header_response(r, NGX_HTTP_NOT_ALLOWED, NULL);
+    }
+
+    // only accept GET, POST and PUT methods if NOT enable publisher administration
+    if ((cf->location_type != NGX_HTTP_PUSH_STREAM_PUBLISHER_MODE_ADMIN) && !(r->method & (NGX_HTTP_GET|NGX_HTTP_POST|NGX_HTTP_PUT))) {
+        ngx_http_push_stream_add_response_header(r, &NGX_HTTP_PUSH_STREAM_HEADER_ALLOW, &NGX_HTTP_PUSH_STREAM_ALLOW_GET_POST_PUT_METHODS);
+        return ngx_http_push_stream_send_only_header_response(r, NGX_HTTP_NOT_ALLOWED, NULL);
+    }
+
+    if ((ctx = ngx_http_push_stream_add_request_context(r)) == NULL) {
+        ngx_log_error(NGX_LOG_ERR, r->connection->log, 0, "push stream module: unable to create request context");
+        return ngx_http_push_stream_send_only_header_response(r, NGX_HTTP_INTERNAL_SERVER_ERROR, NULL);
+    }
+
+    //get channels ids
+    requested_channels = ngx_http_push_stream_parse_channels_ids_from_path(r, r->pool);
+    if ((requested_channels == NULL) || ngx_queue_empty(&requested_channels->queue)) {
+        ngx_log_error(NGX_LOG_WARN, r->connection->log, 0, "push stream module: the push_stream_channels_path is required but is not set");
+        return ngx_http_push_stream_send_only_header_response(r, NGX_HTTP_BAD_REQUEST, &NGX_HTTP_PUSH_STREAM_NO_CHANNEL_ID_MESSAGE);
+    }
+
+    for (q = ngx_queue_head(&requested_channels->queue); q != ngx_queue_sentinel(&requested_channels->queue); q = ngx_queue_next(q)) {
+        requested_channel = ngx_queue_data(q, ngx_http_push_stream_requested_channel_t, queue);
+
+        // check if channel id isn't equals to ALL or contain wildcard
+        if ((ngx_memn2cmp(requested_channel->id->data, NGX_HTTP_PUSH_STREAM_ALL_CHANNELS_INFO_ID.data, requested_channel->id->len, NGX_HTTP_PUSH_STREAM_ALL_CHANNELS_INFO_ID.len) == 0) || (ngx_strchr(requested_channel->id->data, '*') != NULL)) {
+            return ngx_http_push_stream_send_only_header_response(r, NGX_HTTP_FORBIDDEN, &NGX_HTTP_PUSH_STREAM_CHANNEL_ID_NOT_AUTHORIZED_MESSAGE);
+        }
+
+        // could not have a large size
+        if ((mcf->max_channel_id_length != NGX_CONF_UNSET_UINT) && (requested_channel->id->len > mcf->max_channel_id_length)) {
+            ngx_log_error(NGX_LOG_WARN, r->connection->log, 0, "push stream module: channel id is larger than allowed %d", requested_channel->id->len);
+            return ngx_http_push_stream_send_only_header_response(r, NGX_HTTP_BAD_REQUEST, &NGX_HTTP_PUSH_STREAM_TOO_LARGE_CHANNEL_ID_MESSAGE);
+        }
+
+        if (r->method & (NGX_HTTP_POST|NGX_HTTP_PUT)) {
+            // create the channel if doesn't exist
+            requested_channel->channel = ngx_http_push_stream_get_channel(requested_channel->id, r->connection->log, mcf);
+            if (requested_channel->channel == NULL) {
+                return ngx_http_push_stream_send_only_header_response(r, NGX_HTTP_INTERNAL_SERVER_ERROR, NULL);
+            }
+
+            if (requested_channel->channel == NGX_HTTP_PUSH_STREAM_NUMBER_OF_CHANNELS_EXCEEDED) {
+                ngx_log_error(NGX_LOG_ERR, r->connection->log, 0, "push stream module: number of channels were exceeded");
+                return ngx_http_push_stream_send_only_header_response(r, NGX_HTTP_FORBIDDEN, &NGX_HTTP_PUSH_STREAM_NUMBER_OF_CHANNELS_EXCEEDED_MESSAGE);
+            }
+        } else {
+            requested_channel->channel = ngx_http_push_stream_find_channel(requested_channel->id, r->connection->log, mcf);
+        }
+
+        if ((r->method != NGX_HTTP_GET) && (requested_channel->channel != NULL) && requested_channel->channel->for_events) {
+            ngx_log_error(NGX_LOG_ERR, r->connection->log, 0, "push stream module: only internal routines can change events channel");
+            return ngx_http_push_stream_send_only_header_response(r, NGX_HTTP_FORBIDDEN, &NGX_HTTP_PUSH_STREAM_INTERNAL_ONLY_EVENTS_CHANNEL_MESSAGE);
+        }
+    }
+
+    ctx->requested_channels = requested_channels;
+
+    if (r->method & (NGX_HTTP_POST|NGX_HTTP_PUT)) {
+        return ngx_http_push_stream_publisher_handle_after_read_body(r, ngx_http_push_stream_publisher_body_handler);
+    }
+
+    if ((cf->location_type == NGX_HTTP_PUSH_STREAM_PUBLISHER_MODE_ADMIN) && (r->method == NGX_HTTP_DELETE)) {
+        return ngx_http_push_stream_publisher_handle_after_read_body(r, ngx_http_push_stream_publisher_delete_handler);
+    }
+
+    return ngx_http_push_stream_send_response_channels_info_detailed(r, requested_channels);
+}
+
+static ngx_int_t
+ngx_http_push_stream_publisher_handle_after_read_body(ngx_http_request_t *r, ngx_http_client_body_handler_pt post_handler)
+{
+    ngx_int_t                           rc;
+
+    /*
+     * Instruct ngx_http_read_subscriber_request_body to store the request
+     * body entirely in a memory buffer or in a file.
+     */
+    r->request_body_in_single_buf = 0;
+    r->request_body_in_persistent_file = 1;
+    r->request_body_in_clean_file = 0;
+    r->request_body_file_log_level = 0;
+
+    // parse the body message and return
+    rc = ngx_http_read_client_request_body(r, post_handler);
+    if (rc >= NGX_HTTP_SPECIAL_RESPONSE) {
+        return rc;
+    }
+
+    return NGX_DONE;
+}
+
+static ngx_buf_t *
+ngx_http_push_stream_read_request_body_to_buffer(ngx_http_request_t *r)
+{
+    ngx_buf_t                              *buf = NULL;
+    ngx_chain_t                            *chain;
+    ssize_t                                 n;
+    off_t                                   len;
+
+    buf = ngx_create_temp_buf(r->pool, r->headers_in.content_length_n + 1);
+    if (buf != NULL) {
+        buf->memory = 1;
+        buf->temporary = 0;
+        ngx_memset(buf->start, '\0', r->headers_in.content_length_n + 1);
+
+        chain = r->request_body->bufs;
+        while ((chain != NULL) && (chain->buf != NULL)) {
+            len = ngx_buf_size(chain->buf);
+            // if buffer is equal to content length all the content is in this buffer
+            if (len >= r->headers_in.content_length_n) {
+                buf->start = buf->pos;
+                buf->last = buf->pos;
+                len = r->headers_in.content_length_n;
+            }
+
+            if (chain->buf->in_file) {
+                n = ngx_read_file(chain->buf->file, buf->start, len, 0);
+                if (n == NGX_FILE_ERROR) {
+                    ngx_log_error(NGX_LOG_ERR, r->connection->log, 0, "push stream module: cannot read file with request body");
+                    return NULL;
+                }
+                buf->last = buf->last + len;
+                ngx_delete_file(chain->buf->file->name.data);
+                chain->buf->file->fd = NGX_INVALID_FILE;
+            } else {
+                buf->last = ngx_copy(buf->start, chain->buf->pos, len);
+            }
+
+            chain = chain->next;
+            buf->start = buf->last;
+        }
+    }
+    return buf;
+}
+
+static void
+ngx_http_push_stream_publisher_delete_handler(ngx_http_request_t *r)
+{
+    ngx_http_push_stream_main_conf_t       *mcf = ngx_http_get_module_main_conf(r, ngx_http_push_stream_module);
+    ngx_http_push_stream_module_ctx_t      *ctx = ngx_http_get_module_ctx(r, ngx_http_push_stream_module);
+    ngx_buf_t                              *buf = NULL;
+    u_char                                 *text = mcf->channel_deleted_message_text.data;
+    size_t                                  len = mcf->channel_deleted_message_text.len;
+    ngx_uint_t                              qtd_channels = 0;
+
+    ngx_http_push_stream_requested_channel_t       *requested_channel;
+    ngx_queue_t                                    *q;
+
+    if (r->headers_in.content_length_n > 0) {
+
+        // get and check if has access to request body
+        NGX_HTTP_PUSH_STREAM_CHECK_AND_FINALIZE_REQUEST_ON_ERROR(r->request_body->bufs, NULL, r, "push stream module: unexpected publisher message request body buffer location. please report this to the push stream module developers.");
+
+        buf = ngx_http_push_stream_read_request_body_to_buffer(r);
+        NGX_HTTP_PUSH_STREAM_CHECK_AND_FINALIZE_REQUEST_ON_ERROR(buf, NULL, r, "push stream module: cannot allocate memory for read the message");
+
+        text = buf->pos;
+        len = ngx_buf_size(buf);
+    }
+
+    for (q = ngx_queue_head(&ctx->requested_channels->queue); q != ngx_queue_sentinel(&ctx->requested_channels->queue); q = ngx_queue_next(q)) {
+        requested_channel = ngx_queue_data(q, ngx_http_push_stream_requested_channel_t, queue);
+        if (ngx_http_push_stream_delete_channel(mcf, requested_channel->channel, text, len, r->pool)) {
+            qtd_channels++;
+        }
+    }
+
+    if (qtd_channels == 0) {
+        ngx_http_push_stream_send_only_header_response_and_finalize(r, NGX_HTTP_NOT_FOUND, NULL);
+    } else {
+        ngx_http_push_stream_send_only_header_response_and_finalize(r, NGX_HTTP_OK, &NGX_HTTP_PUSH_STREAM_CHANNEL_DELETED);
+    }
+}
+
+static void
+ngx_http_push_stream_publisher_body_handler(ngx_http_request_t *r)
+{
+    ngx_str_t                              *event_id, *event_type;
+    ngx_http_push_stream_module_ctx_t      *ctx = ngx_http_get_module_ctx(r, ngx_http_push_stream_module);
+    ngx_http_push_stream_main_conf_t       *mcf = ngx_http_get_module_main_conf(r, ngx_http_push_stream_module);
+    ngx_http_push_stream_loc_conf_t        *cf = ngx_http_get_module_loc_conf(r, ngx_http_push_stream_module);
+    ngx_buf_t                              *buf = NULL;
+
+    ngx_http_push_stream_requested_channel_t       *requested_channel;
+    ngx_queue_t                                    *q;
+
+    // check if body message wasn't empty
+    if (r->headers_in.content_length_n <= 0) {
+        ngx_log_error(NGX_LOG_ERR, r->connection->log, 0, "push stream module: Post request was sent with no message");
+        ngx_http_push_stream_send_only_header_response_and_finalize(r, NGX_HTTP_BAD_REQUEST, &NGX_HTTP_PUSH_STREAM_EMPTY_POST_REQUEST_MESSAGE);
+        return;
+    }
+
+    // get and check if has access to request body
+    NGX_HTTP_PUSH_STREAM_CHECK_AND_FINALIZE_REQUEST_ON_ERROR(r->request_body->bufs, NULL, r, "push stream module: unexpected publisher message request body buffer location. please report this to the push stream module developers.");
+
+
+    // copy request body to a memory buffer
+    buf = ngx_http_push_stream_read_request_body_to_buffer(r);
+    NGX_HTTP_PUSH_STREAM_CHECK_AND_FINALIZE_REQUEST_ON_ERROR(buf, NULL, r, "push stream module: cannot allocate memory for read the message");
+
+    event_id = ngx_http_push_stream_get_header(r, &NGX_HTTP_PUSH_STREAM_HEADER_EVENT_ID);
+    event_type = ngx_http_push_stream_get_header(r, &NGX_HTTP_PUSH_STREAM_HEADER_EVENT_TYPE);
+
+    for (q = ngx_queue_head(&ctx->requested_channels->queue); q != ngx_queue_sentinel(&ctx->requested_channels->queue); q = ngx_queue_next(q)) {
+        requested_channel = ngx_queue_data(q, ngx_http_push_stream_requested_channel_t, queue);
+
+        if (ngx_http_push_stream_add_msg_to_channel(mcf, r->connection->log, requested_channel->channel, buf->pos, ngx_buf_size(buf), event_id, event_type, cf->store_messages, r->pool) != NGX_OK) {
+            ngx_http_finalize_request(r, NGX_HTTP_INTERNAL_SERVER_ERROR);
+            return;
+        }
+    }
+
+    if (cf->channel_info_on_publish) {
+        ngx_http_push_stream_send_response_channels_info_detailed(r, ctx->requested_channels);
+        ngx_http_finalize_request(r, NGX_OK);
+    } else {
+        ngx_http_push_stream_send_only_header_response_and_finalize(r, NGX_HTTP_OK, NULL);
+    }
+}
+
+static ngx_int_t
+ngx_http_push_stream_channels_statistics_handler(ngx_http_request_t *r)
+{
+    ngx_http_push_stream_main_conf_t   *mcf = ngx_http_get_module_main_conf(r, ngx_http_push_stream_module);
+    char                               *pos = NULL;
+
+    ngx_http_push_stream_requested_channel_t       *requested_channels, *requested_channel;
+    ngx_queue_t                                     *q;
+
+
+    ngx_http_push_stream_set_expires(r, NGX_HTTP_PUSH_STREAM_EXPIRES_EPOCH, 0);
+
+    // only accept GET method
+    if (!(r->method & NGX_HTTP_GET)) {
+        ngx_http_push_stream_add_response_header(r, &NGX_HTTP_PUSH_STREAM_HEADER_ALLOW, &NGX_HTTP_PUSH_STREAM_ALLOW_GET);
+        return ngx_http_push_stream_send_only_header_response(r, NGX_HTTP_NOT_ALLOWED, NULL);
+    }
+
+    ngx_http_push_stream_add_response_header(r, &NGX_HTTP_PUSH_STREAM_HEADER_TAG, &NGX_HTTP_PUSH_STREAM_TAG);
+    ngx_http_push_stream_add_response_header(r, &NGX_HTTP_PUSH_STREAM_HEADER_COMMIT, &NGX_HTTP_PUSH_STREAM_COMMIT);
+
+    //get channels ids
+    requested_channels = ngx_http_push_stream_parse_channels_ids_from_path(r, r->pool);
+
+    // if not specify a channel id, get info about all channels in a resumed way
+    if ((requested_channels == NULL) || ngx_queue_empty(&requested_channels->queue)) {
+        return ngx_http_push_stream_send_response_all_channels_info_summarized(r);
+    }
+
+    for (q = ngx_queue_head(&requested_channels->queue); q != ngx_queue_sentinel(&requested_channels->queue); q = ngx_queue_next(q)) {
+        requested_channel = ngx_queue_data(q, ngx_http_push_stream_requested_channel_t, queue);
+
+        // could not have a large size
+        if ((mcf->max_channel_id_length != NGX_CONF_UNSET_UINT) && (requested_channel->id->len > mcf->max_channel_id_length)) {
+            ngx_log_error(NGX_LOG_WARN, r->connection->log, 0, "push stream module: channel id is larger than allowed %d", requested_channel->id->len);
+            return ngx_http_push_stream_send_only_header_response(r, NGX_HTTP_BAD_REQUEST, &NGX_HTTP_PUSH_STREAM_TOO_LARGE_CHANNEL_ID_MESSAGE);
+        }
+
+        if ((pos = ngx_strchr(requested_channel->id->data, '*')) != NULL) {
+            ngx_str_t *aux = NULL;
+            if (pos != (char *) requested_channel->id->data) {
+                *pos = '\0';
+                requested_channel->id->len  = ngx_strlen(requested_channel->id->data);
+                aux = requested_channel->id;
+            }
+            return ngx_http_push_stream_send_response_all_channels_info_detailed(r, aux);
+        }
+
+        // if specify a channel id equals to ALL, get info about all channels in a detailed way
+        if (ngx_memn2cmp(requested_channel->id->data, NGX_HTTP_PUSH_STREAM_ALL_CHANNELS_INFO_ID.data, requested_channel->id->len, NGX_HTTP_PUSH_STREAM_ALL_CHANNELS_INFO_ID.len) == 0) {
+            return ngx_http_push_stream_send_response_all_channels_info_detailed(r, NULL);
+        }
+
+        requested_channel->channel = ngx_http_push_stream_find_channel(requested_channel->id, r->connection->log, mcf);
+    }
+
+    // if specify a channels ids != ALL, get info about specified channels if they exists
+    return ngx_http_push_stream_send_response_channels_info_detailed(r, requested_channels);
+}
diff -Naur nginx-1.11.3/nginx-push-stream-module/src/ngx_http_push_stream_module_setup.c nginx-1.11.3-push/nginx-push-stream-module/src/ngx_http_push_stream_module_setup.c
--- nginx-1.11.3/nginx-push-stream-module/src/ngx_http_push_stream_module_setup.c	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/src/ngx_http_push_stream_module_setup.c	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,1146 @@
+/*
+ * Copyright (C) 2010-2015 Wandenberg Peixoto <wandenberg@gmail.com>, Rog√©rio Carvalho Schneider <stockrt@gmail.com>
+ *
+ * This file is part of Nginx Push Stream Module.
+ *
+ * Nginx Push Stream Module is free software: you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation, either version 3 of the License, or
+ * (at your option) any later version.
+ *
+ * Nginx Push Stream Module is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with Nginx Push Stream Module.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ *
+ * ngx_http_push_stream_module_setup.c
+ *
+ * Created: Oct 26, 2010
+ * Authors: Wandenberg Peixoto <wandenberg@gmail.com>, Rog√©rio Carvalho Schneider <stockrt@gmail.com>
+ */
+
+#include <ngx_http_push_stream_module_setup.h>
+
+ngx_uint_t ngx_http_push_stream_padding_max_len = 0;
+ngx_flag_t ngx_http_push_stream_enabled = 0;
+
+static ngx_command_t    ngx_http_push_stream_commands[] = {
+    { ngx_string("push_stream_channels_statistics"),
+        NGX_HTTP_LOC_CONF|NGX_CONF_NOARGS,
+        ngx_http_push_stream_channels_statistics,
+        NGX_HTTP_LOC_CONF_OFFSET,
+        0,
+        NULL },
+    { ngx_string("push_stream_publisher"),
+        NGX_HTTP_LOC_CONF|NGX_CONF_NOARGS|NGX_CONF_TAKE1,
+        ngx_http_push_stream_publisher,
+        NGX_HTTP_LOC_CONF_OFFSET,
+        offsetof(ngx_http_push_stream_loc_conf_t, location_type),
+        NULL },
+    { ngx_string("push_stream_subscriber"),
+        NGX_HTTP_LOC_CONF|NGX_CONF_NOARGS|NGX_CONF_TAKE1,
+        ngx_http_push_stream_subscriber,
+        NGX_HTTP_LOC_CONF_OFFSET,
+        offsetof(ngx_http_push_stream_loc_conf_t, location_type),
+        NULL },
+
+    /* Main directives*/
+    { ngx_string("push_stream_shared_memory_size"),
+        NGX_HTTP_MAIN_CONF|NGX_CONF_TAKE12,
+        ngx_http_push_stream_set_shm_size_slot,
+        NGX_HTTP_MAIN_CONF_OFFSET,
+        0,
+        NULL },
+    { ngx_string("push_stream_channel_deleted_message_text"),
+        NGX_HTTP_MAIN_CONF|NGX_CONF_TAKE1,
+        ngx_conf_set_str_slot,
+        NGX_HTTP_MAIN_CONF_OFFSET,
+        offsetof(ngx_http_push_stream_main_conf_t, channel_deleted_message_text),
+        NULL },
+    { ngx_string("push_stream_channel_inactivity_time"),
+        NGX_HTTP_MAIN_CONF|NGX_CONF_TAKE1,
+        ngx_conf_set_sec_slot,
+        NGX_HTTP_MAIN_CONF_OFFSET,
+        offsetof(ngx_http_push_stream_main_conf_t, channel_inactivity_time),
+        NULL },
+    { ngx_string("push_stream_ping_message_text"),
+        NGX_HTTP_MAIN_CONF|NGX_CONF_TAKE1,
+        ngx_conf_set_str_slot,
+        NGX_HTTP_MAIN_CONF_OFFSET,
+        offsetof(ngx_http_push_stream_main_conf_t, ping_message_text),
+        NULL },
+    { ngx_string("push_stream_timeout_with_body"),
+        NGX_HTTP_MAIN_CONF|NGX_CONF_TAKE1,
+        ngx_conf_set_flag_slot,
+        NGX_HTTP_MAIN_CONF_OFFSET,
+        offsetof(ngx_http_push_stream_main_conf_t, timeout_with_body),
+        NULL },
+    { ngx_string("push_stream_message_ttl"),
+        NGX_HTTP_MAIN_CONF|NGX_CONF_TAKE1,
+        ngx_conf_set_sec_slot,
+        NGX_HTTP_MAIN_CONF_OFFSET,
+        offsetof(ngx_http_push_stream_main_conf_t, message_ttl),
+        NULL },
+    { ngx_string("push_stream_max_subscribers_per_channel"),
+        NGX_HTTP_MAIN_CONF|NGX_CONF_TAKE1,
+        ngx_conf_set_num_slot,
+        NGX_HTTP_MAIN_CONF_OFFSET,
+        offsetof(ngx_http_push_stream_main_conf_t, max_subscribers_per_channel),
+        NULL },
+    { ngx_string("push_stream_max_messages_stored_per_channel"),
+        NGX_HTTP_MAIN_CONF|NGX_CONF_TAKE1,
+        ngx_conf_set_num_slot,
+        NGX_HTTP_MAIN_CONF_OFFSET,
+        offsetof(ngx_http_push_stream_main_conf_t, max_messages_stored_per_channel),
+        NULL },
+    { ngx_string("push_stream_max_channel_id_length"),
+        NGX_HTTP_MAIN_CONF|NGX_CONF_TAKE1,
+        ngx_conf_set_num_slot,
+        NGX_HTTP_MAIN_CONF_OFFSET,
+        offsetof(ngx_http_push_stream_main_conf_t, max_channel_id_length),
+        NULL },
+    { ngx_string("push_stream_max_number_of_channels"),
+        NGX_HTTP_MAIN_CONF|NGX_CONF_TAKE1,
+        ngx_conf_set_num_slot,
+        NGX_HTTP_MAIN_CONF_OFFSET,
+        offsetof(ngx_http_push_stream_main_conf_t, max_number_of_channels),
+        NULL },
+    { ngx_string("push_stream_max_number_of_wildcard_channels"),
+        NGX_HTTP_MAIN_CONF|NGX_CONF_TAKE1,
+        ngx_conf_set_num_slot,
+        NGX_HTTP_MAIN_CONF_OFFSET,
+        offsetof(ngx_http_push_stream_main_conf_t, max_number_of_wildcard_channels),
+        NULL },
+    { ngx_string("push_stream_wildcard_channel_prefix"),
+        NGX_HTTP_MAIN_CONF|NGX_CONF_TAKE1,
+        ngx_conf_set_str_slot,
+        NGX_HTTP_MAIN_CONF_OFFSET,
+        offsetof(ngx_http_push_stream_main_conf_t, wildcard_channel_prefix),
+        NULL },
+    { ngx_string("push_stream_events_channel_id"),
+        NGX_HTTP_MAIN_CONF|NGX_CONF_TAKE1,
+        ngx_conf_set_str_slot,
+        NGX_HTTP_MAIN_CONF_OFFSET,
+        offsetof(ngx_http_push_stream_main_conf_t, events_channel_id),
+        NULL },
+
+    /* Location directives */
+    { ngx_string("push_stream_channels_path"),
+        NGX_HTTP_MAIN_CONF|NGX_HTTP_SRV_CONF|NGX_HTTP_LOC_CONF|NGX_HTTP_LIF_CONF|NGX_CONF_TAKE1,
+        ngx_http_set_complex_value_slot,
+        NGX_HTTP_LOC_CONF_OFFSET,
+        offsetof(ngx_http_push_stream_loc_conf_t, channels_path),
+        NULL },
+    { ngx_string("push_stream_store_messages"),
+        NGX_HTTP_MAIN_CONF|NGX_HTTP_SRV_CONF|NGX_HTTP_LOC_CONF|NGX_HTTP_LIF_CONF|NGX_CONF_TAKE1,
+        ngx_conf_set_flag_slot,
+        NGX_HTTP_LOC_CONF_OFFSET,
+        offsetof(ngx_http_push_stream_loc_conf_t, store_messages),
+        NULL },
+    { ngx_string("push_stream_channel_info_on_publish"),
+        NGX_HTTP_MAIN_CONF|NGX_HTTP_SRV_CONF|NGX_HTTP_LOC_CONF|NGX_CONF_TAKE1,
+        ngx_conf_set_flag_slot,
+        NGX_HTTP_LOC_CONF_OFFSET,
+        offsetof(ngx_http_push_stream_loc_conf_t, channel_info_on_publish),
+        NULL },
+    { ngx_string("push_stream_authorized_channels_only"),
+        NGX_HTTP_MAIN_CONF|NGX_HTTP_SRV_CONF|NGX_HTTP_LOC_CONF|NGX_CONF_TAKE1,
+        ngx_conf_set_flag_slot,
+        NGX_HTTP_LOC_CONF_OFFSET,
+        offsetof(ngx_http_push_stream_loc_conf_t, authorized_channels_only),
+        NULL },
+    { ngx_string("push_stream_header_template_file"),
+        NGX_HTTP_MAIN_CONF|NGX_HTTP_SRV_CONF|NGX_HTTP_LOC_CONF|NGX_CONF_TAKE1,
+        ngx_http_push_stream_set_header_template_from_file,
+        NGX_HTTP_LOC_CONF_OFFSET,
+        offsetof(ngx_http_push_stream_loc_conf_t, header_template),
+        NULL },
+    { ngx_string("push_stream_header_template"),
+        NGX_HTTP_MAIN_CONF|NGX_HTTP_SRV_CONF|NGX_HTTP_LOC_CONF|NGX_CONF_TAKE1,
+        ngx_conf_set_str_slot,
+        NGX_HTTP_LOC_CONF_OFFSET,
+        offsetof(ngx_http_push_stream_loc_conf_t, header_template),
+        NULL },
+    { ngx_string("push_stream_message_template"),
+        NGX_HTTP_MAIN_CONF|NGX_HTTP_SRV_CONF|NGX_HTTP_LOC_CONF|NGX_CONF_TAKE1,
+        ngx_conf_set_str_slot,
+        NGX_HTTP_LOC_CONF_OFFSET,
+        offsetof(ngx_http_push_stream_loc_conf_t, message_template),
+        NULL },
+    { ngx_string("push_stream_footer_template"),
+        NGX_HTTP_MAIN_CONF|NGX_HTTP_SRV_CONF|NGX_HTTP_LOC_CONF|NGX_CONF_TAKE1,
+        ngx_conf_set_str_slot,
+        NGX_HTTP_LOC_CONF_OFFSET,
+        offsetof(ngx_http_push_stream_loc_conf_t, footer_template),
+        NULL },
+    { ngx_string("push_stream_wildcard_channel_max_qtd"),
+        NGX_HTTP_MAIN_CONF|NGX_HTTP_SRV_CONF|NGX_HTTP_LOC_CONF|NGX_CONF_TAKE1,
+        ngx_conf_set_num_slot,
+        NGX_HTTP_LOC_CONF_OFFSET,
+        offsetof(ngx_http_push_stream_loc_conf_t, wildcard_channel_max_qtd),
+        NULL },
+    { ngx_string("push_stream_ping_message_interval"),
+        NGX_HTTP_MAIN_CONF|NGX_HTTP_SRV_CONF|NGX_HTTP_LOC_CONF|NGX_CONF_TAKE1,
+        ngx_conf_set_msec_slot,
+        NGX_HTTP_LOC_CONF_OFFSET,
+        offsetof(ngx_http_push_stream_loc_conf_t, ping_message_interval),
+        NULL },
+    { ngx_string("push_stream_subscriber_connection_ttl"),
+        NGX_HTTP_MAIN_CONF|NGX_HTTP_SRV_CONF|NGX_HTTP_LOC_CONF|NGX_CONF_TAKE1,
+        ngx_conf_set_msec_slot,
+        NGX_HTTP_LOC_CONF_OFFSET,
+        offsetof(ngx_http_push_stream_loc_conf_t, subscriber_connection_ttl),
+        NULL },
+    { ngx_string("push_stream_longpolling_connection_ttl"),
+        NGX_HTTP_MAIN_CONF|NGX_HTTP_SRV_CONF|NGX_HTTP_LOC_CONF|NGX_CONF_TAKE1,
+        ngx_conf_set_msec_slot,
+        NGX_HTTP_LOC_CONF_OFFSET,
+        offsetof(ngx_http_push_stream_loc_conf_t, longpolling_connection_ttl),
+        NULL },
+    { ngx_string("push_stream_websocket_allow_publish"),
+        NGX_HTTP_MAIN_CONF|NGX_HTTP_SRV_CONF|NGX_HTTP_LOC_CONF|NGX_CONF_TAKE1,
+        ngx_conf_set_flag_slot,
+        NGX_HTTP_LOC_CONF_OFFSET,
+        offsetof(ngx_http_push_stream_loc_conf_t, websocket_allow_publish),
+        NULL },
+    { ngx_string("push_stream_last_received_message_time"),
+        NGX_HTTP_MAIN_CONF|NGX_HTTP_SRV_CONF|NGX_HTTP_LOC_CONF|NGX_HTTP_LIF_CONF|NGX_CONF_TAKE1,
+        ngx_http_set_complex_value_slot,
+        NGX_HTTP_LOC_CONF_OFFSET,
+        offsetof(ngx_http_push_stream_loc_conf_t, last_received_message_time),
+        NULL },
+    { ngx_string("push_stream_last_received_message_tag"),
+        NGX_HTTP_MAIN_CONF|NGX_HTTP_SRV_CONF|NGX_HTTP_LOC_CONF|NGX_HTTP_LIF_CONF|NGX_CONF_TAKE1,
+        ngx_http_set_complex_value_slot,
+        NGX_HTTP_LOC_CONF_OFFSET,
+        offsetof(ngx_http_push_stream_loc_conf_t, last_received_message_tag),
+        NULL },
+    { ngx_string("push_stream_last_event_id"),
+        NGX_HTTP_MAIN_CONF|NGX_HTTP_SRV_CONF|NGX_HTTP_LOC_CONF|NGX_HTTP_LIF_CONF|NGX_CONF_TAKE1,
+        ngx_http_set_complex_value_slot,
+        NGX_HTTP_LOC_CONF_OFFSET,
+        offsetof(ngx_http_push_stream_loc_conf_t, last_event_id),
+        NULL },
+    { ngx_string("push_stream_user_agent"),
+        NGX_HTTP_MAIN_CONF|NGX_HTTP_SRV_CONF|NGX_HTTP_LOC_CONF|NGX_CONF_TAKE1,
+        ngx_http_set_complex_value_slot,
+        NGX_HTTP_LOC_CONF_OFFSET,
+        offsetof(ngx_http_push_stream_loc_conf_t, user_agent),
+        NULL },
+    { ngx_string("push_stream_padding_by_user_agent"),
+        NGX_HTTP_MAIN_CONF|NGX_HTTP_SRV_CONF|NGX_HTTP_LOC_CONF|NGX_CONF_TAKE1,
+        ngx_conf_set_str_slot,
+        NGX_HTTP_LOC_CONF_OFFSET,
+        offsetof(ngx_http_push_stream_loc_conf_t, padding_by_user_agent),
+        NULL },
+    { ngx_string("push_stream_allowed_origins"),
+        NGX_HTTP_MAIN_CONF|NGX_HTTP_SRV_CONF|NGX_HTTP_LOC_CONF|NGX_CONF_TAKE1,
+        ngx_http_set_complex_value_slot,
+        NGX_HTTP_LOC_CONF_OFFSET,
+        offsetof(ngx_http_push_stream_loc_conf_t, allowed_origins),
+        NULL },
+    { ngx_string("push_stream_allow_connections_to_events_channel"),
+        NGX_HTTP_MAIN_CONF|NGX_HTTP_SRV_CONF|NGX_HTTP_LOC_CONF|NGX_HTTP_LIF_CONF|NGX_CONF_TAKE1,
+        ngx_conf_set_flag_slot,
+        NGX_HTTP_LOC_CONF_OFFSET,
+        offsetof(ngx_http_push_stream_loc_conf_t, allow_connections_to_events_channel),
+        NULL },
+
+    ngx_null_command
+};
+
+
+static ngx_http_module_t    ngx_http_push_stream_module_ctx = {
+    ngx_http_push_stream_preconfig,             /* preconfiguration */
+    ngx_http_push_stream_postconfig,            /* postconfiguration */
+    ngx_http_push_stream_create_main_conf,      /* create main configuration */
+    ngx_http_push_stream_init_main_conf,        /* init main configuration */
+    NULL,                                       /* create server configuration */
+    NULL,                                       /* merge server configuration */
+    ngx_http_push_stream_create_loc_conf,       /* create location configuration */
+    ngx_http_push_stream_merge_loc_conf,        /* merge location configuration */
+};
+
+
+ngx_module_t    ngx_http_push_stream_module = {
+    NGX_MODULE_V1,
+    &ngx_http_push_stream_module_ctx,           /* module context */
+    ngx_http_push_stream_commands,              /* module directives */
+    NGX_HTTP_MODULE,                            /* module type */
+    NULL,                                       /* init master */
+    ngx_http_push_stream_init_module,           /* init module */
+    ngx_http_push_stream_init_worker,           /* init process */
+    NULL,                                       /* init thread */
+    NULL,                                       /* exit thread */
+    ngx_http_push_stream_exit_worker,           /* exit process */
+    ngx_http_push_stream_exit_master,           /* exit master */
+    NGX_MODULE_V1_PADDING
+};
+
+
+static ngx_int_t
+ngx_http_push_stream_init_module(ngx_cycle_t *cycle)
+{
+    ngx_core_conf_t                         *ccf = (ngx_core_conf_t *) ngx_get_conf(cycle->conf_ctx, ngx_core_module);
+
+    if (!ngx_http_push_stream_enabled) {
+        ngx_log_error(NGX_LOG_NOTICE, cycle->log, 0, "ngx_http_push_stream_module will not be used with this configuration.");
+        return NGX_OK;
+    }
+
+    // initialize our little IPC
+    ngx_int_t rc;
+    if ((rc = ngx_http_push_stream_init_ipc(cycle, ccf->worker_processes)) == NGX_OK) {
+        ngx_http_push_stream_alert_shutting_down_workers();
+    }
+    return rc;
+}
+
+
+static ngx_int_t
+ngx_http_push_stream_init_worker(ngx_cycle_t *cycle)
+{
+    if (!ngx_http_push_stream_enabled) {
+        return NGX_OK;
+    }
+
+    if ((ngx_process != NGX_PROCESS_SINGLE) && (ngx_process != NGX_PROCESS_WORKER)) {
+        return NGX_OK;
+    }
+
+    if ((ngx_http_push_stream_ipc_init_worker()) != NGX_OK) {
+        return NGX_ERROR;
+    }
+
+    // turn on timer to cleanup memory of old messages and channels
+    ngx_http_push_stream_memory_cleanup_timer_set();
+
+    return ngx_http_push_stream_register_worker_message_handler(cycle);
+}
+
+
+static void
+ngx_http_push_stream_exit_master(ngx_cycle_t *cycle)
+{
+    if (!ngx_http_push_stream_enabled) {
+        return;
+    }
+
+    // destroy channel tree in shared memory
+    ngx_http_push_stream_collect_expired_messages_and_empty_channels(1);
+    ngx_http_push_stream_free_memory_of_expired_messages_and_channels(1);
+}
+
+
+static void
+ngx_http_push_stream_exit_worker(ngx_cycle_t *cycle)
+{
+    if (!ngx_http_push_stream_enabled) {
+        return;
+    }
+
+    if ((ngx_process != NGX_PROCESS_SINGLE) && (ngx_process != NGX_PROCESS_WORKER)) {
+        return;
+    }
+
+    ngx_http_push_stream_cleanup_shutting_down_worker();
+
+    ngx_http_push_stream_ipc_exit_worker(cycle);
+}
+
+
+static ngx_int_t
+ngx_http_push_stream_preconfig(ngx_conf_t *cf)
+{
+    size_t size = ngx_align(2 * sizeof(ngx_http_push_stream_global_shm_data_t), ngx_pagesize);
+    ngx_shm_zone_t     *shm_zone = ngx_shared_memory_add(cf, &ngx_http_push_stream_global_shm_name, size, &ngx_http_push_stream_module);
+
+    if (shm_zone == NULL) {
+        return NGX_ERROR;
+    }
+
+    shm_zone->init = ngx_http_push_stream_init_global_shm_zone;
+    shm_zone->data = (void *) 1;
+
+    return NGX_OK;
+}
+
+
+static ngx_int_t
+ngx_http_push_stream_postconfig(ngx_conf_t *cf)
+{
+    if ((ngx_http_push_stream_padding_max_len > 0) && (ngx_http_push_stream_module_paddings_chunks == NULL)) {
+        ngx_uint_t steps = ngx_http_push_stream_padding_max_len / 100;
+        if ((ngx_http_push_stream_module_paddings_chunks = ngx_pcalloc(cf->pool, sizeof(ngx_str_t) * (steps + 1))) == NULL) {
+            ngx_conf_log_error(NGX_LOG_ERR, cf, 0, "push stream module: unable to allocate memory to create padding messages");
+            return NGX_ERROR;
+        }
+
+        u_int padding_max_len = ngx_http_push_stream_padding_max_len + ((ngx_http_push_stream_padding_max_len % 2) ? 1 : 0);
+        ngx_str_t *aux = ngx_http_push_stream_create_str(cf->pool, padding_max_len);
+        if (aux == NULL) {
+            ngx_conf_log_error(NGX_LOG_ERR, cf, 0, "push stream module: unable to allocate memory to create padding messages value");
+            return NGX_ERROR;
+        }
+
+        while (padding_max_len > 0) {
+            padding_max_len -= 2;
+            ngx_memcpy(aux->data + padding_max_len, CRLF, 2);
+        }
+
+        ngx_int_t i, len = ngx_http_push_stream_padding_max_len;
+        for (i = steps; i >= 0; i--) {
+            ngx_str_t *padding = ngx_pcalloc(cf->pool, sizeof(ngx_str_t));
+            if ((*(ngx_http_push_stream_module_paddings_chunks + i) = padding) == NULL) {
+                ngx_conf_log_error(NGX_LOG_ERR, cf, 0, "push stream module: unable to allocate memory to create padding messages");
+                return NGX_ERROR;
+            }
+            padding->data = &aux->data[aux->len - len];
+            padding->len = len;
+            len = i * 100;
+        }
+    }
+
+    if ((ngx_http_push_stream_padding_max_len > 0) && (ngx_http_push_stream_module_paddings_chunks_for_eventsource == NULL)) {
+        ngx_uint_t steps = ngx_http_push_stream_padding_max_len / 100;
+        if ((ngx_http_push_stream_module_paddings_chunks_for_eventsource = ngx_pcalloc(cf->pool, sizeof(ngx_str_t) * (steps + 1))) == NULL) {
+            ngx_conf_log_error(NGX_LOG_ERR, cf, 0, "push stream module: unable to allocate memory to create padding messages for eventsource");
+            return NGX_ERROR;
+        }
+
+        u_int padding_max_len = ngx_http_push_stream_padding_max_len + ((ngx_http_push_stream_padding_max_len % 2) ? 1 : 0);
+        ngx_str_t *aux = ngx_http_push_stream_create_str(cf->pool, padding_max_len);
+        if (aux == NULL) {
+            ngx_conf_log_error(NGX_LOG_ERR, cf, 0, "push stream module: unable to allocate memory to create padding messages value");
+            return NGX_ERROR;
+        }
+
+        ngx_memset(aux->data, ':', padding_max_len);
+        padding_max_len -= 1;
+        ngx_memcpy(aux->data + padding_max_len, "\n", 1);
+
+        ngx_int_t i, len = ngx_http_push_stream_padding_max_len;
+        for (i = steps; i >= 0; i--) {
+            ngx_str_t *padding = ngx_pcalloc(cf->pool, sizeof(ngx_str_t));
+            if ((*(ngx_http_push_stream_module_paddings_chunks_for_eventsource + i) = padding) == NULL) {
+                ngx_conf_log_error(NGX_LOG_ERR, cf, 0, "push stream module: unable to allocate memory to create padding messages");
+                return NGX_ERROR;
+            }
+            padding->data = &aux->data[aux->len - len];
+            padding->len = len;
+            len = i * 100;
+        }
+    }
+
+    return NGX_OK;
+}
+
+
+// main config
+static void *
+ngx_http_push_stream_create_main_conf(ngx_conf_t *cf)
+{
+    ngx_http_push_stream_main_conf_t    *mcf = ngx_pcalloc(cf->pool, sizeof(ngx_http_push_stream_main_conf_t));
+
+    if (mcf == NULL) {
+        return NGX_CONF_ERROR;
+    }
+
+    mcf->enabled = 0;
+    ngx_str_null(&mcf->channel_deleted_message_text);
+    mcf->channel_inactivity_time = NGX_CONF_UNSET;
+    ngx_str_null(&mcf->ping_message_text);
+    ngx_str_null(&mcf->wildcard_channel_prefix);
+    mcf->max_number_of_channels = NGX_CONF_UNSET_UINT;
+    mcf->max_number_of_wildcard_channels = NGX_CONF_UNSET_UINT;
+    mcf->message_ttl = NGX_CONF_UNSET;
+    mcf->max_channel_id_length = NGX_CONF_UNSET_UINT;
+    mcf->max_subscribers_per_channel = NGX_CONF_UNSET;
+    mcf->max_messages_stored_per_channel = NGX_CONF_UNSET_UINT;
+    mcf->qtd_templates = 0;
+    mcf->timeout_with_body = NGX_CONF_UNSET;
+    ngx_str_null(&mcf->events_channel_id);
+    mcf->events_channel = NULL;
+    mcf->ping_msg = NULL;
+    mcf->longpooling_timeout_msg = NULL;
+    ngx_queue_init(&mcf->msg_templates);
+
+    return mcf;
+}
+
+
+static char *
+ngx_http_push_stream_init_main_conf(ngx_conf_t *cf, void *parent)
+{
+    ngx_http_push_stream_main_conf_t     *conf = parent;
+
+    if (!conf->enabled) {
+        return NGX_CONF_OK;
+    }
+
+    ngx_conf_init_value(conf->message_ttl, NGX_HTTP_PUSH_STREAM_DEFAULT_MESSAGE_TTL);
+    ngx_conf_init_value(conf->channel_inactivity_time, NGX_HTTP_PUSH_STREAM_DEFAULT_CHANNEL_INACTIVITY_TIME);
+    ngx_conf_merge_str_value(conf->channel_deleted_message_text, conf->channel_deleted_message_text, NGX_HTTP_PUSH_STREAM_CHANNEL_DELETED_MESSAGE_TEXT);
+    ngx_conf_merge_str_value(conf->ping_message_text, conf->ping_message_text, NGX_HTTP_PUSH_STREAM_PING_MESSAGE_TEXT);
+    ngx_conf_merge_str_value(conf->wildcard_channel_prefix, conf->wildcard_channel_prefix, NGX_HTTP_PUSH_STREAM_DEFAULT_WILDCARD_CHANNEL_PREFIX);
+    ngx_conf_merge_str_value(conf->events_channel_id, conf->events_channel_id, NGX_HTTP_PUSH_STREAM_DEFAULT_EVENTS_CHANNEL_ID);
+    ngx_conf_init_value(conf->timeout_with_body, 0);
+
+    // sanity checks
+    // shm size should be set
+    if (conf->shm_zone == NULL) {
+        ngx_conf_log_error(NGX_LOG_ERR, cf, 0, "push stream module: push_stream_shared_memory_size must be set.");
+        return NGX_CONF_ERROR;
+    }
+
+    // max number of channels cannot be zero
+    if ((conf->max_number_of_channels != NGX_CONF_UNSET_UINT) && (conf->max_number_of_channels == 0)) {
+        ngx_conf_log_error(NGX_LOG_ERR, cf, 0, "push stream module: push_stream_max_number_of_channels cannot be zero.");
+        return NGX_CONF_ERROR;
+    }
+
+    // max number of wildcard channels cannot be zero
+    if ((conf->max_number_of_wildcard_channels != NGX_CONF_UNSET_UINT) && (conf->max_number_of_wildcard_channels == 0)) {
+        ngx_conf_log_error(NGX_LOG_ERR, cf, 0, "push stream module: push_stream_max_number_of_wildcard_channels cannot be zero.");
+        return NGX_CONF_ERROR;
+    }
+
+    // message ttl cannot be zero
+    if ((conf->message_ttl != NGX_CONF_UNSET) && (conf->message_ttl == 0)) {
+        ngx_conf_log_error(NGX_LOG_ERR, cf, 0, "push stream module: push_stream_message_ttl cannot be zero.");
+        return NGX_CONF_ERROR;
+    }
+
+    // max subscriber per channel cannot be zero
+    if ((conf->max_subscribers_per_channel != NGX_CONF_UNSET_UINT) && (conf->max_subscribers_per_channel == 0)) {
+        ngx_conf_log_error(NGX_LOG_ERR, cf, 0, "push stream module: push_stream_max_subscribers_per_channel cannot be zero.");
+        return NGX_CONF_ERROR;
+    }
+
+    // max messages stored per channel cannot be zero
+    if ((conf->max_messages_stored_per_channel != NGX_CONF_UNSET_UINT) && (conf->max_messages_stored_per_channel == 0)) {
+        ngx_conf_log_error(NGX_LOG_ERR, cf, 0, "push stream module: push_stream_max_messages_stored_per_channel cannot be zero.");
+        return NGX_CONF_ERROR;
+    }
+
+    // max channel id length cannot be zero
+    if ((conf->max_channel_id_length != NGX_CONF_UNSET_UINT) && (conf->max_channel_id_length == 0)) {
+        ngx_conf_log_error(NGX_LOG_ERR, cf, 0, "push stream module: push_stream_max_channel_id_length cannot be zero.");
+        return NGX_CONF_ERROR;
+    }
+
+    ngx_regex_compile_t *backtrack_parser = NULL;
+    u_char               errstr[NGX_MAX_CONF_ERRSTR];
+
+    if ((backtrack_parser = ngx_pcalloc(cf->pool, sizeof(ngx_regex_compile_t))) == NULL) {
+        ngx_conf_log_error(NGX_LOG_ERR, cf, 0, "push stream module: push stream module: unable to allocate memory to compile backtrack parser");
+        return NGX_CONF_ERROR;
+    }
+
+    backtrack_parser->pattern = NGX_HTTP_PUSH_STREAM_BACKTRACK_PATTERN;
+    backtrack_parser->pool = cf->pool;
+    backtrack_parser->err.len = NGX_MAX_CONF_ERRSTR;
+    backtrack_parser->err.data = errstr;
+
+    if (ngx_regex_compile(backtrack_parser) != NGX_OK) {
+        ngx_conf_log_error(NGX_LOG_ERR, cf, 0, "push stream module: unable to compile backtrack parser pattern %V", &NGX_HTTP_PUSH_STREAM_BACKTRACK_PATTERN);
+        return NGX_CONF_ERROR;
+    }
+
+    conf->backtrack_parser_regex = backtrack_parser->regex;
+
+    return NGX_CONF_OK;
+}
+
+
+// location config stuff
+static void *
+ngx_http_push_stream_create_loc_conf(ngx_conf_t *cf)
+{
+    ngx_http_push_stream_loc_conf_t     *lcf = ngx_pcalloc(cf->pool, sizeof(ngx_http_push_stream_loc_conf_t));
+
+    if (lcf == NULL) {
+        return NGX_CONF_ERROR;
+    }
+
+    lcf->channels_path = NULL;
+    lcf->authorized_channels_only = NGX_CONF_UNSET_UINT;
+    lcf->store_messages = NGX_CONF_UNSET_UINT;
+    lcf->message_template_index = -1;
+    ngx_str_null(&lcf->message_template);
+    ngx_str_null(&lcf->header_template);
+    ngx_str_null(&lcf->footer_template);
+    lcf->wildcard_channel_max_qtd = NGX_CONF_UNSET_UINT;
+    lcf->location_type = NGX_CONF_UNSET_UINT;
+    lcf->ping_message_interval = NGX_CONF_UNSET_MSEC;
+    lcf->subscriber_connection_ttl = NGX_CONF_UNSET_MSEC;
+    lcf->longpolling_connection_ttl = NGX_CONF_UNSET_MSEC;
+    lcf->websocket_allow_publish = NGX_CONF_UNSET_UINT;
+    lcf->channel_info_on_publish = NGX_CONF_UNSET_UINT;
+    lcf->allow_connections_to_events_channel = NGX_CONF_UNSET_UINT;
+    lcf->last_received_message_time = NULL;
+    lcf->last_received_message_tag = NULL;
+    lcf->last_event_id = NULL;
+    lcf->user_agent = NULL;
+    ngx_str_null(&lcf->padding_by_user_agent);
+    lcf->paddings = NULL;
+    lcf->allowed_origins = NULL;
+
+    return lcf;
+}
+
+
+static char *
+ngx_http_push_stream_merge_loc_conf(ngx_conf_t *cf, void *parent, void *child)
+{
+    ngx_http_push_stream_main_conf_t    *mcf = ngx_http_conf_get_module_main_conf(cf, ngx_http_push_stream_module);
+    ngx_http_push_stream_loc_conf_t     *prev = parent, *conf = child;
+
+    ngx_conf_merge_uint_value(conf->authorized_channels_only, prev->authorized_channels_only, 0);
+    ngx_conf_merge_value(conf->store_messages, prev->store_messages, 0);
+    ngx_conf_merge_str_value(conf->header_template, prev->header_template, NGX_HTTP_PUSH_STREAM_DEFAULT_HEADER_TEMPLATE);
+    ngx_conf_merge_str_value(conf->message_template, prev->message_template, NGX_HTTP_PUSH_STREAM_DEFAULT_MESSAGE_TEMPLATE);
+    ngx_conf_merge_str_value(conf->footer_template, prev->footer_template, NGX_HTTP_PUSH_STREAM_DEFAULT_FOOTER_TEMPLATE);
+    ngx_conf_merge_uint_value(conf->wildcard_channel_max_qtd, prev->wildcard_channel_max_qtd, mcf->max_number_of_wildcard_channels);
+    ngx_conf_merge_msec_value(conf->ping_message_interval, prev->ping_message_interval, NGX_CONF_UNSET_MSEC);
+    ngx_conf_merge_msec_value(conf->subscriber_connection_ttl, prev->subscriber_connection_ttl, NGX_CONF_UNSET_MSEC);
+    ngx_conf_merge_msec_value(conf->longpolling_connection_ttl, prev->longpolling_connection_ttl, conf->subscriber_connection_ttl);
+    ngx_conf_merge_value(conf->websocket_allow_publish, prev->websocket_allow_publish, 0);
+    ngx_conf_merge_value(conf->channel_info_on_publish, prev->channel_info_on_publish, 1);
+    ngx_conf_merge_value(conf->allow_connections_to_events_channel, prev->allow_connections_to_events_channel, 0);
+    ngx_conf_merge_str_value(conf->padding_by_user_agent, prev->padding_by_user_agent, NGX_HTTP_PUSH_STREAM_DEFAULT_PADDING_BY_USER_AGENT);
+    ngx_conf_merge_uint_value(conf->location_type, prev->location_type, NGX_CONF_UNSET_UINT);
+
+    if (conf->channels_path == NULL) {
+        conf->channels_path = prev->channels_path;
+    }
+
+    if (conf->last_received_message_time == NULL) {
+        conf->last_received_message_time = prev->last_received_message_time;
+    }
+
+    if (conf->last_received_message_tag == NULL) {
+        conf->last_received_message_tag = prev->last_received_message_tag;
+    }
+
+    if (conf->last_event_id == NULL) {
+        conf->last_event_id = prev->last_event_id;
+    }
+
+    if (conf->user_agent == NULL) {
+        conf->user_agent = prev->user_agent;
+    }
+
+    if (conf->allowed_origins == NULL) {
+        conf->allowed_origins = prev->allowed_origins ;
+    }
+
+    if (conf->location_type == NGX_CONF_UNSET_UINT) {
+        return NGX_CONF_OK;
+    }
+
+    if (conf->channels_path == NULL) {
+        ngx_conf_log_error(NGX_LOG_ERR, cf, 0, "push stream module: push_stream_channels_path must be set.");
+        return NGX_CONF_ERROR;
+    }
+
+    // changing properties for event source support
+    if (conf->location_type == NGX_HTTP_PUSH_STREAM_SUBSCRIBER_MODE_EVENTSOURCE) {
+        // formatting header template
+        if (ngx_strncmp(conf->header_template.data, NGX_HTTP_PUSH_STREAM_EVENTSOURCE_COMMENT_PREFIX.data, NGX_HTTP_PUSH_STREAM_EVENTSOURCE_COMMENT_PREFIX.len) != 0) {
+            if (conf->header_template.len > 0) {
+                ngx_str_t *aux = ngx_http_push_stream_apply_template_to_each_line(&conf->header_template, &NGX_HTTP_PUSH_STREAM_EVENTSOURCE_COMMENT_TEMPLATE, cf->pool);
+                if (aux == NULL) {
+                    ngx_conf_log_error(NGX_LOG_ERR, cf, 0, "push stream module: push_stream_message_module failed to apply template to header message.");
+                    return NGX_CONF_ERROR;
+                }
+                conf->header_template.data = aux->data;
+                conf->header_template.len = aux->len;
+            } else {
+                conf->header_template.data = NGX_HTTP_PUSH_STREAM_EVENTSOURCE_DEFAULT_HEADER_TEMPLATE.data;
+                conf->header_template.len = NGX_HTTP_PUSH_STREAM_EVENTSOURCE_DEFAULT_HEADER_TEMPLATE.len;
+            }
+        }
+
+        // formatting message template
+        if (ngx_strncmp(conf->message_template.data, NGX_HTTP_PUSH_STREAM_EVENTSOURCE_MESSAGE_PREFIX.data, NGX_HTTP_PUSH_STREAM_EVENTSOURCE_MESSAGE_PREFIX.len) != 0) {
+            ngx_str_t *aux = (conf->message_template.len > 0) ? &conf->message_template : (ngx_str_t *) &NGX_HTTP_PUSH_STREAM_TOKEN_MESSAGE_TEXT;
+            ngx_str_t *template = ngx_http_push_stream_create_str(cf->pool, NGX_HTTP_PUSH_STREAM_EVENTSOURCE_MESSAGE_PREFIX.len + aux->len + 1);
+            if (template == NULL) {
+                ngx_conf_log_error(NGX_LOG_ERR, cf, 0, "push stream module: unable to allocate memory to append message prefix to message template");
+                return NGX_CONF_ERROR;
+            }
+            u_char *last = ngx_copy(template->data, NGX_HTTP_PUSH_STREAM_EVENTSOURCE_MESSAGE_PREFIX.data, NGX_HTTP_PUSH_STREAM_EVENTSOURCE_MESSAGE_PREFIX.len);
+            last = ngx_copy(last, aux->data, aux->len);
+            ngx_memcpy(last, "\n", 1);
+
+            conf->message_template.data = template->data;
+            conf->message_template.len = template->len;
+        }
+
+        // formatting footer template
+        if (ngx_strncmp(conf->footer_template.data, NGX_HTTP_PUSH_STREAM_EVENTSOURCE_COMMENT_PREFIX.data, NGX_HTTP_PUSH_STREAM_EVENTSOURCE_COMMENT_PREFIX.len) != 0) {
+            if (conf->footer_template.len > 0) {
+                ngx_str_t *aux = ngx_http_push_stream_apply_template_to_each_line(&conf->footer_template, &NGX_HTTP_PUSH_STREAM_EVENTSOURCE_COMMENT_TEMPLATE, cf->pool);
+                if (aux == NULL) {
+                    ngx_conf_log_error(NGX_LOG_ERR, cf, 0, "push stream module: push_stream_message_module failed to apply template to footer message.");
+                    return NGX_CONF_ERROR;
+                }
+
+                conf->footer_template.data = aux->data;
+                conf->footer_template.len = aux->len;
+            }
+        }
+    } else if (conf->location_type == NGX_HTTP_PUSH_STREAM_SUBSCRIBER_MODE_WEBSOCKET) {
+        // formatting header and footer template for chunk transfer
+        if (conf->header_template.len > 0) {
+            ngx_str_t *aux = ngx_http_push_stream_get_formatted_websocket_frame(&NGX_HTTP_PUSH_STREAM_WEBSOCKET_TEXT_LAST_FRAME_BYTE, sizeof(NGX_HTTP_PUSH_STREAM_WEBSOCKET_TEXT_LAST_FRAME_BYTE), conf->header_template.data, conf->header_template.len, cf->pool);
+            if (aux == NULL) {
+                ngx_conf_log_error(NGX_LOG_ERR, cf, 0, "push stream module: unable to allocate memory to format header template");
+                return NGX_CONF_ERROR;
+            }
+            conf->header_template.data = aux->data;
+            conf->header_template.len = aux->len;
+        }
+
+        if (conf->footer_template.len > 0) {
+            ngx_str_t *aux = ngx_http_push_stream_get_formatted_websocket_frame(&NGX_HTTP_PUSH_STREAM_WEBSOCKET_TEXT_LAST_FRAME_BYTE, sizeof(NGX_HTTP_PUSH_STREAM_WEBSOCKET_TEXT_LAST_FRAME_BYTE), conf->footer_template.data, conf->footer_template.len, cf->pool);
+            if (aux == NULL) {
+                ngx_conf_log_error(NGX_LOG_ERR, cf, 0, "push stream module: unable to allocate memory to format footer template");
+                return NGX_CONF_ERROR;
+            }
+            conf->footer_template.data = aux->data;
+            conf->footer_template.len = aux->len;
+        }
+    }
+
+    // sanity checks
+    // ping message interval cannot be zero
+    if ((conf->ping_message_interval != NGX_CONF_UNSET_MSEC) && (conf->ping_message_interval == 0)) {
+        ngx_conf_log_error(NGX_LOG_ERR, cf, 0, "push stream module: push_stream_ping_message_interval cannot be zero.");
+        return NGX_CONF_ERROR;
+    }
+
+    // subscriber connection ttl cannot be zero
+    if ((conf->subscriber_connection_ttl != NGX_CONF_UNSET_MSEC) && (conf->subscriber_connection_ttl == 0)) {
+        ngx_conf_log_error(NGX_LOG_ERR, cf, 0, "push stream module: push_stream_subscriber_connection_ttl cannot be zero.");
+        return NGX_CONF_ERROR;
+    }
+
+    // long polling connection ttl cannot be zero
+    if ((conf->longpolling_connection_ttl != NGX_CONF_UNSET_MSEC) && (conf->longpolling_connection_ttl == 0)) {
+        ngx_conf_log_error(NGX_LOG_ERR, cf, 0, "push stream module: push_stream_longpolling_connection_ttl cannot be zero.");
+        return NGX_CONF_ERROR;
+    }
+
+    // message template cannot be blank
+    if (conf->message_template.len == 0) {
+        ngx_conf_log_error(NGX_LOG_ERR, cf, 0, "push stream module: push_stream_message_template cannot be blank.");
+        return NGX_CONF_ERROR;
+    }
+
+    // wildcard channel max qtd cannot be zero
+    if ((conf->wildcard_channel_max_qtd != NGX_CONF_UNSET_UINT) && (conf->wildcard_channel_max_qtd == 0)) {
+        ngx_conf_log_error(NGX_LOG_ERR, cf, 0, "push stream module: push_stream_wildcard_channel_max_qtd cannot be zero.");
+        return NGX_CONF_ERROR;
+    }
+
+    // wildcard channel max qtd cannot be set without a channel prefix
+    if ((conf->wildcard_channel_max_qtd != NGX_CONF_UNSET_UINT) && (conf->wildcard_channel_max_qtd > 0) && (mcf->wildcard_channel_prefix.len == 0)) {
+        ngx_conf_log_error(NGX_LOG_ERR, cf, 0, "push stream module: cannot set wildcard channel max qtd if push_stream_wildcard_channel_prefix is not set or blank.");
+        return NGX_CONF_ERROR;
+    }
+
+    // max number of wildcard channels cannot be smaller than value in wildcard channel max qtd
+    if ((mcf->max_number_of_wildcard_channels != NGX_CONF_UNSET_UINT) && (conf->wildcard_channel_max_qtd != NGX_CONF_UNSET_UINT) &&  (mcf->max_number_of_wildcard_channels < conf->wildcard_channel_max_qtd)) {
+        ngx_conf_log_error(NGX_LOG_ERR, cf, 0, "push stream module: max number of wildcard channels cannot be smaller than value in push_stream_wildcard_channel_max_qtd.");
+        return NGX_CONF_ERROR;
+    }
+
+    if ((conf->location_type == NGX_HTTP_PUSH_STREAM_SUBSCRIBER_MODE_LONGPOLLING) ||
+        (conf->location_type == NGX_HTTP_PUSH_STREAM_SUBSCRIBER_MODE_POLLING) ||
+        (conf->location_type == NGX_HTTP_PUSH_STREAM_SUBSCRIBER_MODE_STREAMING) ||
+        (conf->location_type == NGX_HTTP_PUSH_STREAM_SUBSCRIBER_MODE_EVENTSOURCE) ||
+        (conf->location_type == NGX_HTTP_PUSH_STREAM_SUBSCRIBER_MODE_WEBSOCKET)) {
+        if ((conf->message_template_index = ngx_http_push_stream_find_or_add_template(cf, conf->message_template, (conf->location_type == NGX_HTTP_PUSH_STREAM_SUBSCRIBER_MODE_EVENTSOURCE), (conf->location_type == NGX_HTTP_PUSH_STREAM_SUBSCRIBER_MODE_WEBSOCKET))) < 0) {
+            ngx_conf_log_error(NGX_LOG_ERR, cf, 0, "push stream module: push stream module: unable to parse message template: %V", &conf->message_template);
+            return NGX_CONF_ERROR;
+        }
+
+
+        if (conf->padding_by_user_agent.len > 0) {
+            if ((conf->paddings = ngx_http_push_stream_parse_paddings(cf, &conf->padding_by_user_agent)) == NULL) {
+                ngx_conf_log_error(NGX_LOG_ERR, cf, 0, "push stream module: push stream module: unable to parse paddings by user agent");
+                return NGX_CONF_ERROR;
+            }
+
+            ngx_queue_t *q;
+            for (q = ngx_queue_head(conf->paddings); q != ngx_queue_sentinel(conf->paddings); q = ngx_queue_next(q)) {
+                ngx_http_push_stream_padding_t *padding = ngx_queue_data(q, ngx_http_push_stream_padding_t, queue);
+                ngx_http_push_stream_padding_max_len = ngx_max(ngx_http_push_stream_padding_max_len, padding->header_min_len);
+                ngx_http_push_stream_padding_max_len = ngx_max(ngx_http_push_stream_padding_max_len, padding->message_min_len);
+            }
+        }
+    }
+
+    return NGX_CONF_OK;
+}
+
+
+static char *
+ngx_http_push_stream_setup_handler(ngx_conf_t *cf, void *conf, ngx_int_t (*handler) (ngx_http_request_t *))
+{
+    ngx_http_core_loc_conf_t            *clcf = ngx_http_conf_get_module_loc_conf(cf, ngx_http_core_module);
+    ngx_http_push_stream_main_conf_t    *mcf = ngx_http_conf_get_module_main_conf(cf, ngx_http_push_stream_module);
+
+    ngx_http_push_stream_enabled = 1;
+    mcf->enabled = 1;
+    clcf->handler = handler;
+    clcf->if_modified_since = NGX_HTTP_IMS_OFF;
+
+    return NGX_CONF_OK;
+}
+
+
+static char *
+ngx_http_push_stream_channels_statistics(ngx_conf_t *cf, ngx_command_t *cmd, void *conf)
+{
+    char *rc = ngx_http_push_stream_setup_handler(cf, conf, &ngx_http_push_stream_channels_statistics_handler);
+
+    if (rc == NGX_CONF_OK) {
+        ngx_http_push_stream_loc_conf_t     *pslcf = conf;
+        pslcf->location_type = NGX_HTTP_PUSH_STREAM_STATISTICS_MODE;
+    }
+
+    return rc;
+}
+
+
+static char *
+ngx_http_push_stream_publisher(ngx_conf_t *cf, ngx_command_t *cmd, void *conf)
+{
+    ngx_int_t                      *field = (ngx_int_t *) ((char *) conf + cmd->offset);
+    if (*field != NGX_CONF_UNSET) {
+        return "is duplicate";
+    }
+
+    *field = NGX_HTTP_PUSH_STREAM_PUBLISHER_MODE_NORMAL; //default
+    if(cf->args->nelts > 1) {
+        ngx_str_t                   value = (((ngx_str_t *) cf->args->elts)[1]);
+        if ((value.len == NGX_HTTP_PUSH_STREAM_MODE_NORMAL.len) && (ngx_strncasecmp(value.data, NGX_HTTP_PUSH_STREAM_MODE_NORMAL.data, NGX_HTTP_PUSH_STREAM_MODE_NORMAL.len) == 0)) {
+            *field = NGX_HTTP_PUSH_STREAM_PUBLISHER_MODE_NORMAL;
+        } else if ((value.len == NGX_HTTP_PUSH_STREAM_MODE_ADMIN.len) && (ngx_strncasecmp(value.data, NGX_HTTP_PUSH_STREAM_MODE_ADMIN.data, NGX_HTTP_PUSH_STREAM_MODE_ADMIN.len) == 0)) {
+            *field = NGX_HTTP_PUSH_STREAM_PUBLISHER_MODE_ADMIN;
+        } else {
+            ngx_conf_log_error(NGX_LOG_ERR, cf, 0, "push stream module: invalid push_stream_publisher mode value: %V, accepted values (%s, %s)", &value, NGX_HTTP_PUSH_STREAM_MODE_NORMAL.data, NGX_HTTP_PUSH_STREAM_MODE_ADMIN.data);
+            return NGX_CONF_ERROR;
+        }
+    }
+
+    return ngx_http_push_stream_setup_handler(cf, conf, &ngx_http_push_stream_publisher_handler);
+}
+
+
+static char *
+ngx_http_push_stream_subscriber(ngx_conf_t *cf, ngx_command_t *cmd, void *conf)
+{
+    ngx_int_t                      *field = (ngx_int_t *) ((char *) conf + cmd->offset);
+    if (*field != NGX_CONF_UNSET) {
+        return "is duplicate";
+    }
+
+    *field = NGX_HTTP_PUSH_STREAM_SUBSCRIBER_MODE_STREAMING; //default
+    if(cf->args->nelts > 1) {
+        ngx_str_t                   value = (((ngx_str_t *) cf->args->elts)[1]);
+        if ((value.len == NGX_HTTP_PUSH_STREAM_MODE_STREAMING.len) && (ngx_strncasecmp(value.data, NGX_HTTP_PUSH_STREAM_MODE_STREAMING.data, NGX_HTTP_PUSH_STREAM_MODE_STREAMING.len) == 0)) {
+            *field = NGX_HTTP_PUSH_STREAM_SUBSCRIBER_MODE_STREAMING;
+        } else if ((value.len == NGX_HTTP_PUSH_STREAM_MODE_POLLING.len) && (ngx_strncasecmp(value.data, NGX_HTTP_PUSH_STREAM_MODE_POLLING.data, NGX_HTTP_PUSH_STREAM_MODE_POLLING.len) == 0)) {
+            *field = NGX_HTTP_PUSH_STREAM_SUBSCRIBER_MODE_POLLING;
+        } else if ((value.len == NGX_HTTP_PUSH_STREAM_MODE_LONGPOLLING.len) && (ngx_strncasecmp(value.data, NGX_HTTP_PUSH_STREAM_MODE_LONGPOLLING.data, NGX_HTTP_PUSH_STREAM_MODE_LONGPOLLING.len) == 0)) {
+            *field = NGX_HTTP_PUSH_STREAM_SUBSCRIBER_MODE_LONGPOLLING;
+        } else if ((value.len == NGX_HTTP_PUSH_STREAM_MODE_EVENTSOURCE.len) && (ngx_strncasecmp(value.data, NGX_HTTP_PUSH_STREAM_MODE_EVENTSOURCE.data, NGX_HTTP_PUSH_STREAM_MODE_EVENTSOURCE.len) == 0)) {
+            *field = NGX_HTTP_PUSH_STREAM_SUBSCRIBER_MODE_EVENTSOURCE;
+        } else if ((value.len == NGX_HTTP_PUSH_STREAM_MODE_WEBSOCKET.len) && (ngx_strncasecmp(value.data, NGX_HTTP_PUSH_STREAM_MODE_WEBSOCKET.data, NGX_HTTP_PUSH_STREAM_MODE_WEBSOCKET.len) == 0)) {
+            *field = NGX_HTTP_PUSH_STREAM_SUBSCRIBER_MODE_WEBSOCKET;
+        } else {
+            ngx_conf_log_error(NGX_LOG_ERR, cf, 0, "push stream module: invalid push_stream_subscriber mode value: %V, accepted values (%V, %V, %V, %V, %V)", &value, &NGX_HTTP_PUSH_STREAM_MODE_STREAMING, &NGX_HTTP_PUSH_STREAM_MODE_POLLING, &NGX_HTTP_PUSH_STREAM_MODE_LONGPOLLING, &NGX_HTTP_PUSH_STREAM_MODE_EVENTSOURCE, &NGX_HTTP_PUSH_STREAM_MODE_WEBSOCKET);
+            return NGX_CONF_ERROR;
+        }
+    }
+
+    if (*field == NGX_HTTP_PUSH_STREAM_SUBSCRIBER_MODE_WEBSOCKET) {
+        char *rc = ngx_http_push_stream_setup_handler(cf, conf, &ngx_http_push_stream_websocket_handler);
+#if (NGX_HAVE_SHA1)
+        if (rc == NGX_CONF_OK) {
+            ngx_http_push_stream_loc_conf_t     *pslcf = conf;
+            pslcf->location_type = NGX_HTTP_PUSH_STREAM_SUBSCRIBER_MODE_WEBSOCKET;
+        }
+#else
+        rc = NGX_CONF_ERROR;
+        ngx_conf_log_error(NGX_LOG_ERR, cf, 0, "push stream module: push stream module: sha1 support is needed to use WebSocket");
+#endif
+        return rc;
+    }
+    return ngx_http_push_stream_setup_handler(cf, conf, &ngx_http_push_stream_subscriber_handler);
+}
+
+
+// shared memory
+char *
+ngx_http_push_stream_set_shm_size_slot(ngx_conf_t *cf, ngx_command_t *cmd, void *conf)
+{
+    ngx_http_push_stream_main_conf_t    *mcf = ngx_http_conf_get_module_main_conf(cf, ngx_http_push_stream_module);
+    size_t                               shm_size;
+    size_t                               shm_size_limit = 32 * ngx_pagesize;
+    ngx_str_t                           *value;
+    ngx_str_t                           *name;
+
+    value = cf->args->elts;
+
+    shm_size = ngx_align(ngx_parse_size(&value[1]), ngx_pagesize);
+    if (shm_size < shm_size_limit) {
+        ngx_conf_log_error(NGX_LOG_WARN, cf, 0, "The push_stream_shared_memory_size value must be at least %ulKiB", shm_size_limit >> 10);
+        return NGX_CONF_ERROR;
+    }
+
+    name = (cf->args->nelts > 2) ? &value[2] : &ngx_http_push_stream_shm_name;
+    if ((ngx_http_push_stream_global_shm_zone != NULL) && (ngx_http_push_stream_global_shm_zone->data != NULL)) {
+        ngx_http_push_stream_global_shm_data_t *global_data = (ngx_http_push_stream_global_shm_data_t *) ngx_http_push_stream_global_shm_zone->data;
+        ngx_queue_t                            *q;
+
+        for (q = ngx_queue_head(&global_data->shm_datas_queue); q != ngx_queue_sentinel(&global_data->shm_datas_queue); q = ngx_queue_next(q)) {
+            ngx_http_push_stream_shm_data_t *data = ngx_queue_data(q, ngx_http_push_stream_shm_data_t, shm_data_queue);
+            if ((name->len == data->shm_zone->shm.name.len) &&
+                (ngx_strncmp(name->data, data->shm_zone->shm.name.data, name->len) == 0) &&
+                (data->shm_zone->shm.size != shm_size)) {
+                shm_size = data->shm_zone->shm.size;
+                ngx_conf_log_error(NGX_LOG_WARN, cf, 0, "Cannot change memory area size without restart, ignoring change on zone: %V", name);
+            }
+        }
+    }
+    ngx_conf_log_error(NGX_LOG_INFO, cf, 0, "Using %udKiB of shared memory for push stream module on zone: %V", shm_size >> 10, name);
+
+    mcf->shm_zone = ngx_shared_memory_add(cf, name, shm_size, &ngx_http_push_stream_module);
+
+    if (mcf->shm_zone == NULL) {
+        return NGX_CONF_ERROR;
+    }
+
+    if (mcf->shm_zone->data) {
+        ngx_conf_log_error(NGX_LOG_EMERG, cf, 0, "duplicate zone \"%V\"", name);
+        return NGX_CONF_ERROR;
+    }
+
+    mcf->shm_zone->init = ngx_http_push_stream_init_shm_zone;
+    mcf->shm_zone->data = mcf;
+
+    return NGX_CONF_OK;
+}
+
+
+char *
+ngx_http_push_stream_set_header_template_from_file(ngx_conf_t *cf, ngx_command_t *cmd, void *conf)
+{
+    ngx_str_t                      *field = (ngx_str_t *) ((char *) conf + cmd->offset);
+
+    if (field->data != NULL) {
+        return "is duplicate or template set by 'push_stream_header_template'";
+    }
+
+    ngx_str_t                      *value = &(((ngx_str_t *) cf->args->elts)[1]);
+    ngx_file_t                      file;
+    ngx_file_info_t                 fi;
+    ssize_t                         n;
+
+    ngx_memzero(&file, sizeof(ngx_file_t));
+    file.name = *value;
+    file.log = cf->log;
+
+    file.fd = ngx_open_file(value->data, NGX_FILE_RDONLY, NGX_FILE_OPEN, 0);
+    if (file.fd == NGX_INVALID_FILE) {
+        ngx_conf_log_error(NGX_LOG_ERR, cf, 0, "push stream module: unable to open file \"%V\" for header template", value);
+        return NGX_CONF_ERROR;
+    }
+
+    if (ngx_fd_info(file.fd, &fi) == NGX_FILE_ERROR) {
+        ngx_conf_log_error(NGX_LOG_ERR, cf, 0, "push stream module: unable to stat file \"%V\" for header template", value);
+        ngx_close_file(file.fd);
+        return NGX_CONF_ERROR;
+    }
+
+    field->len = (size_t) ngx_file_size(&fi);
+
+    field->data = ngx_pcalloc(cf->pool, field->len);
+    if (field->data == NULL) {
+        ngx_conf_log_error(NGX_LOG_ERR, cf, 0, "push stream module: unable to allocate memory to read header template file", value);
+        ngx_close_file(file.fd);
+        return NGX_CONF_ERROR;
+    }
+
+    n = ngx_read_file(&file, field->data, field->len, 0);
+    if (n == NGX_ERROR) {
+        ngx_conf_log_error(NGX_LOG_ERR, cf, 0, "push stream module: unable to read data from file \"%V\" for header template", value);
+        ngx_close_file(file.fd);
+        return NGX_CONF_ERROR;
+    }
+
+    if ((size_t) n != field->len) {
+        ngx_conf_log_error(NGX_LOG_ERR, cf, 0,  "push stream module: returned only %z bytes instead of %z from file \"%V\"", n, field->len, value);
+        ngx_close_file(file.fd);
+        return NGX_CONF_ERROR;
+    }
+
+    if (ngx_close_file(file.fd) == NGX_FILE_ERROR) {
+        ngx_conf_log_error(NGX_LOG_ERR, cf, 0, "push stream module: unable to close file \"%V\" for header template", value);
+        return NGX_CONF_ERROR;
+    }
+
+    return NGX_CONF_OK;
+}
+
+
+// shared memory zone initializer
+ngx_int_t
+ngx_http_push_stream_init_global_shm_zone(ngx_shm_zone_t *shm_zone, void *data)
+{
+    ngx_slab_pool_t                            *shpool = (ngx_slab_pool_t *) shm_zone->shm.addr;
+    ngx_http_push_stream_global_shm_data_t     *d;
+    int i;
+
+    if (data) { /* zone already initialized */
+        shm_zone->data = data;
+        ngx_queue_init(&((ngx_http_push_stream_global_shm_data_t *) data)->shm_datas_queue);
+        ngx_http_push_stream_global_shm_zone = shm_zone;
+        return NGX_OK;
+    }
+
+    if ((d = (ngx_http_push_stream_global_shm_data_t *) ngx_slab_alloc(shpool, sizeof(*d))) == NULL) { //shm_data plus an array.
+        return NGX_ERROR;
+    }
+    shm_zone->data = d;
+    for (i = 0; i < NGX_MAX_PROCESSES; i++) {
+        d->pid[i] = -1;
+    }
+
+    ngx_queue_init(&d->shm_datas_queue);
+
+    ngx_http_push_stream_global_shm_zone = shm_zone;
+
+    return NGX_OK;
+}
+
+
+ngx_int_t
+ngx_http_push_stream_init_shm_zone(ngx_shm_zone_t *shm_zone, void *data)
+{
+    ngx_http_push_stream_global_shm_data_t *global_shm_data = (ngx_http_push_stream_global_shm_data_t *) ngx_http_push_stream_global_shm_zone->data;
+    ngx_http_push_stream_main_conf_t       *mcf = shm_zone->data;
+    ngx_http_push_stream_shm_data_t        *d;
+    int i;
+
+    mcf->shm_zone = shm_zone;
+    mcf->shpool = (ngx_slab_pool_t *) shm_zone->shm.addr;
+
+    if (data) { /* zone already initialized */
+        shm_zone->data = data;
+        d = (ngx_http_push_stream_shm_data_t *) data;
+        d->mcf = mcf;
+        d->shm_zone = shm_zone;
+        d->shpool = mcf->shpool;
+        mcf->shm_data = data;
+        ngx_queue_insert_tail(&global_shm_data->shm_datas_queue, &d->shm_data_queue);
+        return NGX_OK;
+    }
+
+    ngx_rbtree_node_t                   *sentinel;
+
+    if ((d = (ngx_http_push_stream_shm_data_t *) ngx_slab_alloc(mcf->shpool, sizeof(*d))) == NULL) { //shm_data plus an array.
+        return NGX_ERROR;
+    }
+    d->mcf = mcf;
+    mcf->shm_data = d;
+    shm_zone->data = d;
+    for (i = 0; i < NGX_MAX_PROCESSES; i++) {
+        d->ipc[i].pid = -1;
+        d->ipc[i].startup = 0;
+        d->ipc[i].subscribers = 0;
+        ngx_queue_init(&d->ipc[i].messages_queue);
+        ngx_queue_init(&d->ipc[i].subscribers_queue);
+    }
+
+    d->channels = 0;
+    d->wildcard_channels = 0;
+    d->published_messages = 0;
+    d->stored_messages = 0;
+    d->subscribers = 0;
+    d->channels_in_trash = 0;
+    d->messages_in_trash = 0;
+    d->startup = ngx_time();
+    d->last_message_time = 0;
+    d->last_message_tag = 0;
+    d->shm_zone = shm_zone;
+    d->shpool = mcf->shpool;
+    d->slots_for_census = 0;
+
+    // initialize rbtree
+    if ((sentinel = ngx_slab_alloc(mcf->shpool, sizeof(*sentinel))) == NULL) {
+        return NGX_ERROR;
+    }
+    ngx_rbtree_init(&d->tree, sentinel, ngx_http_push_stream_rbtree_insert);
+
+    ngx_queue_init(&d->messages_trash);
+    ngx_queue_init(&d->channels_queue);
+    ngx_queue_init(&d->channels_to_delete);
+    ngx_queue_init(&d->channels_trash);
+
+    ngx_queue_insert_tail(&global_shm_data->shm_datas_queue, &d->shm_data_queue);
+
+    if (ngx_http_push_stream_create_shmtx(&d->messages_trash_mutex, &d->messages_trash_lock, (u_char *) "push_stream_messages_trash") != NGX_OK) {
+        return NGX_ERROR;
+    }
+
+    if (ngx_http_push_stream_create_shmtx(&d->channels_queue_mutex, &d->channels_queue_lock, (u_char *) "push_stream_channels_queue") != NGX_OK) {
+        return NGX_ERROR;
+    }
+
+    if (ngx_http_push_stream_create_shmtx(&d->channels_to_delete_mutex, &d->channels_to_delete_lock, (u_char *) "push_stream_channels_to_delete") != NGX_OK) {
+        return NGX_ERROR;
+    }
+
+    if (ngx_http_push_stream_create_shmtx(&d->channels_trash_mutex, &d->channels_trash_lock, (u_char *) "push_stream_channels_trash") != NGX_OK) {
+        return NGX_ERROR;
+    }
+
+    if (ngx_http_push_stream_create_shmtx(&d->cleanup_mutex, &d->cleanup_lock, (u_char *) "push_stream_cleanup") != NGX_OK) {
+        return NGX_ERROR;
+    }
+
+    u_char lock_name[25];
+    for (i = 0; i < 10; i++) {
+        ngx_sprintf(lock_name, "push_stream_channels_%d", i);
+        if (ngx_http_push_stream_create_shmtx(&d->channels_mutex[i], &d->channels_lock[i], lock_name) != NGX_OK) {
+            return NGX_ERROR;
+        }
+    }
+
+    d->mutex_round_robin = 0;
+
+    if (mcf->events_channel_id.len > 0) {
+        if ((mcf->events_channel = ngx_http_push_stream_get_channel(&mcf->events_channel_id, ngx_cycle->log, mcf)) == NULL) {
+            ngx_log_error(NGX_LOG_ERR, ngx_cycle->log, 0, "push stream module: unable to create events channel");
+            return NGX_ERROR;
+        }
+
+        if (ngx_http_push_stream_create_shmtx(&d->events_channel_mutex, &d->events_channel_lock, (u_char *) "push_stream_events_channel") != NGX_OK) {
+            return NGX_ERROR;
+        }
+
+        mcf->events_channel->mutex = &d->events_channel_mutex;
+    }
+
+    return NGX_OK;
+}
diff -Naur nginx-1.11.3/nginx-push-stream-module/src/ngx_http_push_stream_module_subscriber.c nginx-1.11.3-push/nginx-push-stream-module/src/ngx_http_push_stream_module_subscriber.c
--- nginx-1.11.3/nginx-push-stream-module/src/ngx_http_push_stream_module_subscriber.c	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/src/ngx_http_push_stream_module_subscriber.c	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,669 @@
+/*
+ * Copyright (C) 2010-2015 Wandenberg Peixoto <wandenberg@gmail.com>, Rog√©rio Carvalho Schneider <stockrt@gmail.com>
+ *
+ * This file is part of Nginx Push Stream Module.
+ *
+ * Nginx Push Stream Module is free software: you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation, either version 3 of the License, or
+ * (at your option) any later version.
+ *
+ * Nginx Push Stream Module is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with Nginx Push Stream Module.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ *
+ * ngx_http_push_stream_module_subscriber.c
+ *
+ * Created: Oct 26, 2010
+ * Authors: Wandenberg Peixoto <wandenberg@gmail.com>, Rog√©rio Carvalho Schneider <stockrt@gmail.com>
+ */
+
+#include <ngx_http_push_stream_module_subscriber.h>
+
+static ngx_int_t                                 ngx_http_push_stream_subscriber_assign_channel(ngx_http_push_stream_main_conf_t *mcf, ngx_http_push_stream_loc_conf_t *cf, ngx_http_request_t *r, ngx_http_push_stream_requested_channel_t *requested_channel, time_t if_modified_since, ngx_int_t tag, ngx_str_t *last_event_id, ngx_http_push_stream_subscriber_t *subscriber, ngx_pool_t *temp_pool);
+static ngx_http_push_stream_subscriber_t        *ngx_http_push_stream_subscriber_prepare_request_to_keep_connected(ngx_http_request_t *r);
+static ngx_int_t                                 ngx_http_push_stream_registry_subscriber(ngx_http_request_t *r, ngx_http_push_stream_subscriber_t *worker_subscriber);
+static ngx_flag_t                                ngx_http_push_stream_has_old_messages_to_send(ngx_http_push_stream_channel_t *channel, ngx_uint_t backtrack, time_t if_modified_since, ngx_int_t tag, time_t greater_message_time, ngx_int_t greater_message_tag, ngx_str_t *last_event_id);
+static void                                      ngx_http_push_stream_send_old_messages(ngx_http_request_t *r, ngx_http_push_stream_channel_t *channel, ngx_uint_t backtrack, time_t if_modified_since, ngx_int_t tag, time_t greater_message_time, ngx_int_t greater_message_tag, ngx_str_t *last_event_id);
+static ngx_http_push_stream_pid_queue_t         *ngx_http_push_stream_get_worker_subscriber_channel_sentinel_locked(ngx_slab_pool_t *shpool, ngx_http_push_stream_channel_t *channel, ngx_log_t *log);
+static ngx_http_push_stream_subscription_t      *ngx_http_push_stream_create_channel_subscription(ngx_http_request_t *r, ngx_http_push_stream_channel_t *channel, ngx_http_push_stream_subscriber_t *subscriber);
+static ngx_int_t                                 ngx_http_push_stream_assing_subscription_to_channel(ngx_slab_pool_t *shpool, ngx_http_push_stream_channel_t *channel, ngx_http_push_stream_subscription_t *subscription, ngx_queue_t *subscriptions, ngx_log_t *log);
+static ngx_int_t                                 ngx_http_push_stream_subscriber_polling_handler(ngx_http_request_t *r, ngx_http_push_stream_requested_channel_t *channels_ids, time_t if_modified_since, ngx_int_t tag, ngx_str_t *last_event_id, ngx_flag_t longpolling, ngx_pool_t *temp_pool);
+static ngx_http_push_stream_padding_t           *ngx_http_push_stream_get_padding_by_user_agent(ngx_http_request_t *r);
+void                                             ngx_http_push_stream_websocket_reading(ngx_http_request_t *r);
+
+static ngx_int_t
+ngx_http_push_stream_subscriber_handler(ngx_http_request_t *r)
+{
+    ngx_http_push_stream_main_conf_t               *mcf = ngx_http_get_module_main_conf(r, ngx_http_push_stream_module);
+    ngx_http_push_stream_loc_conf_t                *cf = ngx_http_get_module_loc_conf(r, ngx_http_push_stream_module);
+    ngx_http_push_stream_subscriber_t              *worker_subscriber;
+    ngx_http_push_stream_requested_channel_t       *requested_channels, *requested_channel;
+    ngx_queue_t                                    *q;
+    ngx_http_push_stream_module_ctx_t              *ctx;
+    ngx_int_t                                       tag;
+    time_t                                          if_modified_since;
+    ngx_str_t                                      *last_event_id = NULL;
+    ngx_str_t                                      *push_mode;
+    ngx_flag_t                                      polling, longpolling;
+    ngx_int_t                                       status_code;
+    ngx_str_t                                      *explain_error_message;
+    ngx_str_t                                       vv_allowed_origins = ngx_null_string;
+
+    // add headers to support cross domain requests
+    if (cf->allowed_origins != NULL) {
+        ngx_http_push_stream_complex_value(r, cf->allowed_origins, &vv_allowed_origins);
+    }
+
+    if (vv_allowed_origins.len > 0) {
+        ngx_http_push_stream_add_response_header(r, &NGX_HTTP_PUSH_STREAM_HEADER_ACCESS_CONTROL_ALLOW_ORIGIN, &vv_allowed_origins);
+        ngx_http_push_stream_add_response_header(r, &NGX_HTTP_PUSH_STREAM_HEADER_ACCESS_CONTROL_ALLOW_METHODS, &NGX_HTTP_PUSH_STREAM_ALLOW_GET);
+        ngx_http_push_stream_add_response_header(r, &NGX_HTTP_PUSH_STREAM_HEADER_ACCESS_CONTROL_ALLOW_HEADERS, &NGX_HTTP_PUSH_STREAM_ALLOWED_HEADERS);
+    }
+
+    if (r->method & NGX_HTTP_OPTIONS) {
+        return ngx_http_push_stream_send_only_header_response(r, NGX_HTTP_OK, NULL);
+    }
+
+    ngx_http_push_stream_set_expires(r, NGX_HTTP_PUSH_STREAM_EXPIRES_EPOCH, 0);
+
+    // only accept GET method
+    if (!(r->method & NGX_HTTP_GET)) {
+        ngx_http_push_stream_add_response_header(r, &NGX_HTTP_PUSH_STREAM_HEADER_ALLOW, &NGX_HTTP_PUSH_STREAM_ALLOW_GET);
+        return ngx_http_push_stream_send_only_header_response(r, NGX_HTTP_NOT_ALLOWED, NULL);
+    }
+
+    if ((ctx = ngx_http_push_stream_add_request_context(r)) == NULL) {
+        ngx_log_error(NGX_LOG_ERR, r->connection->log, 0, "push stream module: unable to create request context");
+        return NGX_HTTP_INTERNAL_SERVER_ERROR;
+    }
+
+    //get channels ids and backtracks from path
+    requested_channels = ngx_http_push_stream_parse_channels_ids_from_path(r, r->pool);
+    if ((requested_channels == NULL) || ngx_queue_empty(&requested_channels->queue)) {
+        ngx_log_error(NGX_LOG_WARN, r->connection->log, 0, "push stream module: the push_stream_channels_path is required but is not set");
+        return ngx_http_push_stream_send_only_header_response(r, NGX_HTTP_BAD_REQUEST, &NGX_HTTP_PUSH_STREAM_NO_CHANNEL_ID_MESSAGE);
+    }
+
+    //validate channels: name, length and quantity. check if channel exists when authorized_channels_only is on. check if channel is full of subscribers
+    if (ngx_http_push_stream_validate_channels(r, requested_channels, &status_code, &explain_error_message) == NGX_ERROR) {
+        return ngx_http_push_stream_send_only_header_response(r, status_code, explain_error_message);
+    }
+
+    // get control values
+    ngx_http_push_stream_get_last_received_message_values(r, &if_modified_since, &tag, &last_event_id);
+
+    push_mode = ngx_http_push_stream_get_header(r, &NGX_HTTP_PUSH_STREAM_HEADER_MODE);
+    polling = ((cf->location_type == NGX_HTTP_PUSH_STREAM_SUBSCRIBER_MODE_POLLING) || ((push_mode != NULL) && (push_mode->len == NGX_HTTP_PUSH_STREAM_MODE_POLLING.len) && (ngx_strncasecmp(push_mode->data, NGX_HTTP_PUSH_STREAM_MODE_POLLING.data, NGX_HTTP_PUSH_STREAM_MODE_POLLING.len) == 0)));
+    longpolling = ((cf->location_type == NGX_HTTP_PUSH_STREAM_SUBSCRIBER_MODE_LONGPOLLING) || ((push_mode != NULL) && (push_mode->len == NGX_HTTP_PUSH_STREAM_MODE_LONGPOLLING.len) && (ngx_strncasecmp(push_mode->data, NGX_HTTP_PUSH_STREAM_MODE_LONGPOLLING.data, NGX_HTTP_PUSH_STREAM_MODE_LONGPOLLING.len) == 0)));
+
+    if (polling || longpolling) {
+        ngx_int_t result = ngx_http_push_stream_subscriber_polling_handler(r, requested_channels, if_modified_since, tag, last_event_id, longpolling, ctx->temp_pool);
+        if (ctx->temp_pool != NULL) {
+            ngx_destroy_pool(ctx->temp_pool);
+            ctx->temp_pool = NULL;
+        }
+        return result;
+    }
+
+    ctx->padding = ngx_http_push_stream_get_padding_by_user_agent(r);
+
+    // stream access
+    if ((worker_subscriber = ngx_http_push_stream_subscriber_prepare_request_to_keep_connected(r)) == NULL) {
+        return NGX_HTTP_INTERNAL_SERVER_ERROR;
+    }
+
+    ngx_http_send_header(r);
+
+    // sending response content header
+    if (ngx_http_push_stream_send_response_content_header(r, cf) == NGX_ERROR) {
+        ngx_log_error(NGX_LOG_ERR, r->connection->log, 0, "push stream module: could not send content header to subscriber");
+        return NGX_HTTP_INTERNAL_SERVER_ERROR;
+    }
+
+    if (ngx_http_push_stream_registry_subscriber(r, worker_subscriber) == NGX_ERROR) {
+        return NGX_HTTP_INTERNAL_SERVER_ERROR;
+    }
+
+    // adding subscriber to channel(s) and send old messages
+    for (q = ngx_queue_head(&requested_channels->queue); q != ngx_queue_sentinel(&requested_channels->queue); q = ngx_queue_next(q)) {
+        requested_channel = ngx_queue_data(q, ngx_http_push_stream_requested_channel_t, queue);
+
+        if (ngx_http_push_stream_subscriber_assign_channel(mcf, cf, r, requested_channel, if_modified_since, tag, last_event_id, worker_subscriber, ctx->temp_pool) != NGX_OK) {
+            return NGX_HTTP_INTERNAL_SERVER_ERROR;
+        }
+    }
+
+    if (ctx->temp_pool != NULL) {
+        ngx_destroy_pool(ctx->temp_pool);
+        ctx->temp_pool = NULL;
+    }
+    return NGX_DONE;
+}
+
+static ngx_int_t
+ngx_http_push_stream_subscriber_polling_handler(ngx_http_request_t *r, ngx_http_push_stream_requested_channel_t *requested_channels, time_t if_modified_since, ngx_int_t tag, ngx_str_t *last_event_id, ngx_flag_t longpolling, ngx_pool_t *temp_pool)
+{
+    ngx_http_push_stream_main_conf_t               *mcf = ngx_http_get_module_main_conf(r, ngx_http_push_stream_module);
+    ngx_http_push_stream_loc_conf_t                *cf = ngx_http_get_module_loc_conf(r, ngx_http_push_stream_module);
+    ngx_slab_pool_t                                *shpool = mcf->shpool;
+    ngx_http_push_stream_module_ctx_t              *ctx = ngx_http_get_module_ctx(r, ngx_http_push_stream_module);
+    ngx_http_push_stream_requested_channel_t       *requested_channel;
+    ngx_queue_t                                    *q;
+    ngx_http_push_stream_subscriber_t              *worker_subscriber;
+    ngx_http_push_stream_subscription_t            *subscription;
+    time_t                                          greater_message_time;
+    ngx_int_t                                       greater_message_tag;
+    ngx_flag_t                                      has_message_to_send = 0;
+    ngx_str_t                                       callback_function_name;
+
+    if (ngx_http_arg(r, NGX_HTTP_PUSH_STREAM_CALLBACK.data, NGX_HTTP_PUSH_STREAM_CALLBACK.len, &callback_function_name) == NGX_OK) {
+        ngx_http_push_stream_unescape_uri(&callback_function_name);
+        if ((ctx->callback = ngx_pcalloc(r->pool, sizeof(ngx_str_t))) == NULL) {
+            ngx_log_error(NGX_LOG_ERR, r->connection->log, 0, "push stream module: unable to allocate memory for callback function name");
+            return NGX_HTTP_INTERNAL_SERVER_ERROR;
+        }
+        ctx->callback->data = callback_function_name.data;
+        ctx->callback->len = callback_function_name.len;
+    }
+
+    greater_message_tag = tag;
+    greater_message_time = (if_modified_since < 0) ? 0 : if_modified_since;
+
+    // check if has any message to send
+    for (q = ngx_queue_head(&requested_channels->queue); q != ngx_queue_sentinel(&requested_channels->queue); q = ngx_queue_next(q)) {
+        requested_channel = ngx_queue_data(q, ngx_http_push_stream_requested_channel_t, queue);
+
+        if (ngx_http_push_stream_has_old_messages_to_send(requested_channel->channel, requested_channel->backtrack_messages, if_modified_since, tag, greater_message_time, greater_message_tag, last_event_id)) {
+            has_message_to_send = 1;
+            if (requested_channel->channel->last_message_time > greater_message_time) {
+                greater_message_time = requested_channel->channel->last_message_time;
+                greater_message_tag = requested_channel->channel->last_message_tag;
+            } else {
+                if ((requested_channel->channel->last_message_time == greater_message_time) && (requested_channel->channel->last_message_tag > greater_message_tag) ) {
+                    greater_message_tag = requested_channel->channel->last_message_tag;
+                }
+            }
+        }
+    }
+
+
+    if (longpolling && !has_message_to_send) {
+        // long polling mode without messages
+        if ((worker_subscriber = ngx_http_push_stream_subscriber_prepare_request_to_keep_connected(r)) == NULL) {
+            return NGX_HTTP_INTERNAL_SERVER_ERROR;
+        }
+        worker_subscriber->longpolling = 1;
+
+        if (ngx_http_push_stream_registry_subscriber(r, worker_subscriber) == NGX_ERROR) {
+            return NGX_HTTP_INTERNAL_SERVER_ERROR;
+        }
+
+        // adding subscriber to channel(s)
+        for (q = ngx_queue_head(&requested_channels->queue); q != ngx_queue_sentinel(&requested_channels->queue); q = ngx_queue_next(q)) {
+            requested_channel = ngx_queue_data(q, ngx_http_push_stream_requested_channel_t, queue);
+
+            if ((subscription = ngx_http_push_stream_create_channel_subscription(r, requested_channel->channel, worker_subscriber)) == NULL) {
+                return NGX_HTTP_INTERNAL_SERVER_ERROR;
+            }
+
+            ngx_http_push_stream_assing_subscription_to_channel(shpool, requested_channel->channel, subscription, &worker_subscriber->subscriptions, r->connection->log);
+        }
+
+        return NGX_DONE;
+    }
+
+    // polling or long polling with messages to send
+
+    ngx_http_push_stream_add_polling_headers(r, greater_message_time, greater_message_tag, temp_pool);
+
+    if (!has_message_to_send) {
+        // polling subscriber requests get a 304 with their entity tags preserved if don't have new messages.
+        return ngx_http_push_stream_send_only_header_response(r, NGX_HTTP_NOT_MODIFIED, NULL);
+    }
+
+    // polling with messages or long polling without messages to send
+    r->headers_out.status = NGX_HTTP_OK;
+    r->headers_out.content_length_n = -1;
+
+    ngx_http_send_header(r);
+
+    // sending response content header
+    if (ngx_http_push_stream_send_response_content_header(r, cf) == NGX_ERROR) {
+        ngx_log_error(NGX_LOG_ERR, r->connection->log, 0, "push stream module: could not send content header to subscriber");
+        return NGX_HTTP_INTERNAL_SERVER_ERROR;
+    }
+
+    if (ctx->callback != NULL) {
+        ngx_http_push_stream_send_response_text(r, ctx->callback->data, ctx->callback->len, 0);
+        ngx_http_push_stream_send_response_text(r, NGX_HTTP_PUSH_STREAM_CALLBACK_INIT_CHUNK.data, NGX_HTTP_PUSH_STREAM_CALLBACK_INIT_CHUNK.len, 0);
+    }
+
+    for (q = ngx_queue_head(&requested_channels->queue); q != ngx_queue_sentinel(&requested_channels->queue); q = ngx_queue_next(q)) {
+        requested_channel = ngx_queue_data(q, ngx_http_push_stream_requested_channel_t, queue);
+        ngx_http_push_stream_send_old_messages(r, requested_channel->channel, requested_channel->backtrack_messages, if_modified_since, tag, greater_message_time, greater_message_tag, last_event_id);
+    }
+
+    if (ctx->callback != NULL) {
+        ngx_http_push_stream_send_response_text(r, NGX_HTTP_PUSH_STREAM_CALLBACK_END_CHUNK.data, NGX_HTTP_PUSH_STREAM_CALLBACK_END_CHUNK.len, 0);
+    }
+
+    if (cf->footer_template.len > 0) {
+        ngx_http_push_stream_send_response_text(r, cf->footer_template.data, cf->footer_template.len, 0);
+    }
+
+    ngx_http_send_special(r, NGX_HTTP_LAST | NGX_HTTP_FLUSH);
+
+    return NGX_OK;
+}
+
+static ngx_int_t
+ngx_http_push_stream_subscriber_assign_channel(ngx_http_push_stream_main_conf_t *mcf, ngx_http_push_stream_loc_conf_t *cf, ngx_http_request_t *r, ngx_http_push_stream_requested_channel_t *requested_channel, time_t if_modified_since, ngx_int_t tag, ngx_str_t *last_event_id, ngx_http_push_stream_subscriber_t *subscriber, ngx_pool_t *temp_pool)
+{
+    ngx_http_push_stream_subscription_t        *subscription;
+    ngx_slab_pool_t                            *shpool = mcf->shpool;
+
+    if ((subscription = ngx_http_push_stream_create_channel_subscription(r, requested_channel->channel, subscriber)) == NULL) {
+        return NGX_ERROR;
+    }
+
+    // send old messages to new subscriber
+    ngx_http_push_stream_send_old_messages(r, requested_channel->channel, requested_channel->backtrack_messages, if_modified_since, tag, 0, -1, last_event_id);
+
+    return ngx_http_push_stream_assing_subscription_to_channel(shpool, requested_channel->channel, subscription, &subscriber->subscriptions, r->connection->log);
+}
+
+
+static ngx_int_t
+ngx_http_push_stream_validate_channels(ngx_http_request_t *r, ngx_http_push_stream_requested_channel_t *requested_channels, ngx_int_t *status_code, ngx_str_t **explain_error_message)
+{
+    ngx_http_push_stream_main_conf_t               *mcf = ngx_http_get_module_main_conf(r, ngx_http_push_stream_module);
+    ngx_http_push_stream_loc_conf_t                *cf = ngx_http_get_module_loc_conf(r, ngx_http_push_stream_module);
+    ngx_http_push_stream_requested_channel_t       *requested_channel;
+    ngx_queue_t                                    *q;
+    ngx_uint_t                                      subscribed_channels_qtd = 0;
+    ngx_uint_t                                      subscribed_wildcard_channels_qtd = 0;
+    ngx_flag_t                                      is_wildcard_channel;
+
+    for (q = ngx_queue_head(&requested_channels->queue); q != ngx_queue_sentinel(&requested_channels->queue); q = ngx_queue_next(q)) {
+        requested_channel = ngx_queue_data(q, ngx_http_push_stream_requested_channel_t, queue);
+        // could not be ALL channel or contain wildcard
+        if ((ngx_memn2cmp(requested_channel->id->data, NGX_HTTP_PUSH_STREAM_ALL_CHANNELS_INFO_ID.data, requested_channel->id->len, NGX_HTTP_PUSH_STREAM_ALL_CHANNELS_INFO_ID.len) == 0) || (ngx_strchr(requested_channel->id->data, '*') != NULL)) {
+            *status_code = NGX_HTTP_FORBIDDEN;
+            *explain_error_message = (ngx_str_t *) &NGX_HTTP_PUSH_STREAM_CHANNEL_ID_NOT_AUTHORIZED_MESSAGE;
+            return NGX_ERROR;
+        }
+
+        // could not have a large size
+        if ((mcf->max_channel_id_length != NGX_CONF_UNSET_UINT) && (requested_channel->id->len > mcf->max_channel_id_length)) {
+            ngx_log_error(NGX_LOG_WARN, r->connection->log, 0, "push stream module: channel id is larger than allowed %d", requested_channel->id->len);
+            *status_code = NGX_HTTP_BAD_REQUEST;
+            *explain_error_message = (ngx_str_t *) &NGX_HTTP_PUSH_STREAM_TOO_LARGE_CHANNEL_ID_MESSAGE;
+            return NGX_ERROR;
+        }
+
+        // count subscribed normal and wildcard channels
+        subscribed_channels_qtd++;
+        is_wildcard_channel = 0;
+        if ((mcf->wildcard_channel_prefix.len > 0) && (ngx_strncmp(requested_channel->id->data, mcf->wildcard_channel_prefix.data, mcf->wildcard_channel_prefix.len) == 0)) {
+            is_wildcard_channel = 1;
+            subscribed_wildcard_channels_qtd++;
+        }
+
+        requested_channel->channel = ngx_http_push_stream_find_channel(requested_channel->id, r->connection->log, mcf);
+
+        // check if channel exists when authorized_channels_only is on
+        if (cf->authorized_channels_only && !is_wildcard_channel && ((requested_channel->channel == NULL) || (requested_channel->channel->stored_messages == 0))) {
+            *status_code = NGX_HTTP_FORBIDDEN;
+            *explain_error_message = (ngx_str_t *) &NGX_HTTP_PUSH_STREAM_CANNOT_CREATE_CHANNELS;
+            return NGX_ERROR;
+        }
+
+        // check if channel is full of subscribers
+        if ((mcf->max_subscribers_per_channel != NGX_CONF_UNSET_UINT) && ((requested_channel->channel != NULL) && (requested_channel->channel->subscribers >= mcf->max_subscribers_per_channel))) {
+            *status_code = NGX_HTTP_FORBIDDEN;
+            *explain_error_message = (ngx_str_t *) &NGX_HTTP_PUSH_STREAM_TOO_SUBSCRIBERS_PER_CHANNEL;
+            return NGX_ERROR;
+        }
+
+        // check if is allowed to connect to events channel
+        if (!cf->allow_connections_to_events_channel && (requested_channel->channel != NULL) && requested_channel->channel->for_events) {
+            ngx_log_error(NGX_LOG_ERR, r->connection->log, 0, "push stream module: subscription to events channel is not allowed");
+            *status_code = NGX_HTTP_FORBIDDEN;
+            *explain_error_message = (ngx_str_t *) &NGX_HTTP_PUSH_STREAM_SUBSCRIPTION_EVENTS_CHANNEL_FORBIDDEN_MESSAGE;
+            return NGX_ERROR;
+        }
+    }
+
+    // check if number of subscribed wildcard channels is acceptable
+    if ((cf->wildcard_channel_max_qtd != NGX_CONF_UNSET_UINT) && (subscribed_wildcard_channels_qtd > 0) && ((subscribed_wildcard_channels_qtd > cf->wildcard_channel_max_qtd) || (subscribed_wildcard_channels_qtd == subscribed_channels_qtd))) {
+        ngx_log_error(NGX_LOG_ERR, r->connection->log, 0, "push stream module: max subscribed wildcard channels exceeded");
+        *status_code = NGX_HTTP_FORBIDDEN;
+        *explain_error_message = (ngx_str_t *) &NGX_HTTP_PUSH_STREAM_TOO_MUCH_WILDCARD_CHANNELS;
+        return NGX_ERROR;
+    }
+
+    // create the channels in advance, if doesn't exist, to ensure max number of channels in the server
+    for (q = ngx_queue_head(&requested_channels->queue); q != ngx_queue_sentinel(&requested_channels->queue); q = ngx_queue_next(q)) {
+        requested_channel = ngx_queue_data(q, ngx_http_push_stream_requested_channel_t, queue);
+        if (requested_channel->channel != NULL) {
+            continue;
+        }
+
+        requested_channel->channel = ngx_http_push_stream_get_channel(requested_channel->id, r->connection->log, mcf);
+        if (requested_channel->channel == NULL) {
+            ngx_log_error(NGX_LOG_ERR, r->connection->log, 0, "push stream module: unable to allocate memory for new channel");
+            *status_code = NGX_HTTP_INTERNAL_SERVER_ERROR;
+            *explain_error_message = (ngx_str_t *) &NGX_HTTP_PUSH_STREAM_EMPTY;
+            return NGX_ERROR;
+        }
+
+        if (requested_channel->channel == NGX_HTTP_PUSH_STREAM_NUMBER_OF_CHANNELS_EXCEEDED) {
+            ngx_log_error(NGX_LOG_ERR, r->connection->log, 0, "push stream module: number of channels were exceeded");
+            *status_code = NGX_HTTP_FORBIDDEN;
+            *explain_error_message = (ngx_str_t *) &NGX_HTTP_PUSH_STREAM_NUMBER_OF_CHANNELS_EXCEEDED_MESSAGE;
+            return NGX_ERROR;
+        }
+    }
+
+    return NGX_OK;
+}
+
+
+static ngx_http_push_stream_subscriber_t *
+ngx_http_push_stream_subscriber_prepare_request_to_keep_connected(ngx_http_request_t *r)
+{
+    ngx_http_push_stream_loc_conf_t                *cf = ngx_http_get_module_loc_conf(r, ngx_http_push_stream_module);
+    ngx_http_push_stream_module_ctx_t              *ctx = ngx_http_get_module_ctx(r, ngx_http_push_stream_module);
+    ngx_http_push_stream_subscriber_t              *worker_subscriber;
+
+    if ((worker_subscriber = ngx_pcalloc(r->pool, sizeof(ngx_http_push_stream_subscriber_t))) == NULL) {
+        ngx_log_error(NGX_LOG_ERR, r->connection->log, 0, "push stream module: unable to allocate worker subscriber");
+        return NULL;
+    }
+
+    worker_subscriber->longpolling = 0;
+    worker_subscriber->request = r;
+    worker_subscriber->worker_subscribed_pid = ngx_pid;
+    ngx_queue_init(&worker_subscriber->worker_queue);
+    ngx_queue_init(&worker_subscriber->subscriptions);
+    ctx->subscriber = worker_subscriber;
+
+    // increment request reference count to keep connection open
+    r->main->count++;
+
+    // responding subscriber
+    r->read_event_handler = (cf->location_type == NGX_HTTP_PUSH_STREAM_SUBSCRIBER_MODE_WEBSOCKET) ? ngx_http_push_stream_websocket_reading : ngx_http_test_reading;
+    r->write_event_handler = ngx_http_request_empty_handler;
+
+    if (cf->location_type == NGX_HTTP_PUSH_STREAM_SUBSCRIBER_MODE_EVENTSOURCE) {
+        r->headers_out.content_type_len = NGX_HTTP_PUSH_STREAM_EVENTSOURCE_CONTENT_TYPE.len;
+        r->headers_out.content_type = NGX_HTTP_PUSH_STREAM_EVENTSOURCE_CONTENT_TYPE;
+    } else {
+        ngx_http_set_content_type(r);
+    }
+
+    r->headers_out.status = NGX_HTTP_OK;
+    r->headers_out.content_length_n = -1;
+
+    return worker_subscriber;
+}
+
+static ngx_int_t
+ngx_http_push_stream_registry_subscriber(ngx_http_request_t *r, ngx_http_push_stream_subscriber_t *worker_subscriber)
+{
+    ngx_http_push_stream_main_conf_t               *mcf = ngx_http_get_module_main_conf(r, ngx_http_push_stream_module);
+    ngx_http_push_stream_loc_conf_t                *cf = ngx_http_get_module_loc_conf(r, ngx_http_push_stream_module);
+    ngx_http_push_stream_shm_data_t                *data = mcf->shm_data;
+    ngx_http_push_stream_worker_data_t             *thisworker_data = &data->ipc[ngx_process_slot];
+    ngx_msec_t                                      connection_ttl = worker_subscriber->longpolling ? cf->longpolling_connection_ttl : cf->subscriber_connection_ttl;
+    ngx_http_push_stream_module_ctx_t              *ctx = ngx_http_get_module_ctx(r, ngx_http_push_stream_module);
+    ngx_slab_pool_t                                *shpool = mcf->shpool;
+
+    // adding subscriber to worker list of subscribers
+    ngx_queue_insert_tail(&thisworker_data->subscribers_queue, &worker_subscriber->worker_queue);
+
+    ctx->longpolling = worker_subscriber->longpolling;
+    ctx->subscriber = worker_subscriber;
+
+    if ((connection_ttl != NGX_CONF_UNSET_MSEC) || (cf->ping_message_interval != NGX_CONF_UNSET_MSEC)) {
+
+        if (connection_ttl != NGX_CONF_UNSET_MSEC) {
+            if ((ctx->disconnect_timer = ngx_pcalloc(worker_subscriber->request->pool, sizeof(ngx_event_t))) == NULL) {
+                return NGX_ERROR;
+            }
+        }
+
+        if ((!ctx->longpolling) && (cf->ping_message_interval != NGX_CONF_UNSET_MSEC)) {
+            if ((ctx->ping_timer = ngx_pcalloc(worker_subscriber->request->pool, sizeof(ngx_event_t))) == NULL) {
+                return NGX_ERROR;
+            }
+        }
+
+        if (ctx->disconnect_timer != NULL) {
+            ctx->disconnect_timer->handler = ngx_http_push_stream_disconnect_timer_wake_handler;
+            ctx->disconnect_timer->data = worker_subscriber->request;
+            ctx->disconnect_timer->log = worker_subscriber->request->connection->log;
+            ngx_http_push_stream_timer_reset(connection_ttl, ctx->disconnect_timer);
+        }
+
+        if (ctx->ping_timer != NULL) {
+            ctx->ping_timer->handler = ngx_http_push_stream_ping_timer_wake_handler;
+            ctx->ping_timer->data = worker_subscriber->request;
+            ctx->ping_timer->log = worker_subscriber->request->connection->log;
+            ngx_http_push_stream_timer_reset(cf->ping_message_interval, ctx->ping_timer);
+        }
+    }
+
+    // increment global subscribers count
+    ngx_shmtx_lock(&shpool->mutex);
+    data->subscribers++;
+    ngx_shmtx_unlock(&shpool->mutex);
+    thisworker_data->subscribers++;
+
+    return NGX_OK;
+}
+
+static ngx_flag_t
+ngx_http_push_stream_has_old_messages_to_send(ngx_http_push_stream_channel_t *channel, ngx_uint_t backtrack, time_t if_modified_since, ngx_int_t tag, time_t greater_message_time, ngx_int_t greater_message_tag, ngx_str_t *last_event_id)
+{
+    ngx_flag_t old_messages = 0;
+    ngx_http_push_stream_msg_t *message;
+    ngx_queue_t                *q;
+
+    if (channel->stored_messages > 0) {
+
+        if (backtrack > 0) {
+            old_messages = 1;
+        } else if ((last_event_id != NULL) || (if_modified_since >= 0)) {
+            ngx_flag_t found = 0;
+            ngx_shmtx_lock(channel->mutex);
+            for (q = ngx_queue_head(&channel->message_queue); q != ngx_queue_sentinel(&channel->message_queue); q = ngx_queue_next(q)) {
+                message = ngx_queue_data(q, ngx_http_push_stream_msg_t, queue);
+                if (message->deleted) {
+                    break;
+                }
+
+                if ((!found) && (last_event_id != NULL) && (message->event_id != NULL) && (ngx_memn2cmp(message->event_id->data, last_event_id->data, message->event_id->len, last_event_id->len) == 0)) {
+                    found = 1;
+                    continue;
+                }
+
+                if ((!found) && (if_modified_since >= 0) && ((message->time > if_modified_since) || ((message->time == if_modified_since) && (tag >= 0) && (message->tag >= tag)))) {
+                    found = 1;
+                    if ((message->time == if_modified_since) && (message->tag == tag)) {
+                        continue;
+                    }
+                }
+
+                if (found) {
+                    old_messages = 1;
+                    break;
+                }
+            }
+            ngx_shmtx_unlock(channel->mutex);
+        }
+    }
+    return old_messages;
+}
+
+static void
+ngx_http_push_stream_send_old_messages(ngx_http_request_t *r, ngx_http_push_stream_channel_t *channel, ngx_uint_t backtrack, time_t if_modified_since, ngx_int_t tag, time_t greater_message_time, ngx_int_t greater_message_tag, ngx_str_t *last_event_id)
+{
+    ngx_http_push_stream_module_ctx_t     *ctx = ngx_http_get_module_ctx(r, ngx_http_push_stream_module);
+    ngx_http_push_stream_msg_t            *message;
+    ngx_queue_t                           *q;
+
+    if (ngx_http_push_stream_has_old_messages_to_send(channel, backtrack, if_modified_since, tag, greater_message_time, greater_message_tag, last_event_id)) {
+        if (backtrack > 0) {
+            ngx_uint_t qtd = (backtrack > channel->stored_messages) ? channel->stored_messages : backtrack;
+            ngx_uint_t start = channel->stored_messages - qtd;
+            ngx_shmtx_lock(channel->mutex);
+            // positioning at first message, and send the others
+            for (q = ngx_queue_head(&channel->message_queue); (qtd > 0) && q != ngx_queue_sentinel(&channel->message_queue); q = ngx_queue_next(q)) {
+                message = ngx_queue_data(q, ngx_http_push_stream_msg_t, queue);
+                if (message->deleted) {
+                    break;
+                }
+
+                if (start == 0) {
+                    qtd--;
+                    ngx_http_push_stream_send_response_message(r, channel, message, 0, ctx->message_sent);
+                } else {
+                    start--;
+                }
+            }
+            ngx_shmtx_unlock(channel->mutex);
+        } else if ((last_event_id != NULL) || (if_modified_since >= 0)) {
+            ngx_flag_t found = 0;
+            ngx_shmtx_lock(channel->mutex);
+            for (q = ngx_queue_head(&channel->message_queue); q != ngx_queue_sentinel(&channel->message_queue); q = ngx_queue_next(q)) {
+                message = ngx_queue_data(q, ngx_http_push_stream_msg_t, queue);
+                if (message->deleted) {
+                    break;
+                }
+
+                if ((!found) && (last_event_id != NULL) && (message->event_id != NULL) && (ngx_memn2cmp(message->event_id->data, last_event_id->data, message->event_id->len, last_event_id->len) == 0)) {
+                    found = 1;
+                    continue;
+                }
+
+                if ((!found) && (if_modified_since >= 0) && ((message->time > if_modified_since) || ((message->time == if_modified_since) && (tag >= 0) && (message->tag >= tag)))) {
+                    found = 1;
+                    if ((message->time == if_modified_since) && (message->tag == tag)) {
+                        continue;
+                    }
+                }
+
+                if (found && (((greater_message_time == 0) && (greater_message_tag == -1)) || (greater_message_time > message->time) || ((greater_message_time == message->time) && (greater_message_tag >= message->tag)))) {
+                    ngx_http_push_stream_send_response_message(r, channel, message, 0, ctx->message_sent);
+                }
+            }
+            ngx_shmtx_unlock(channel->mutex);
+        }
+    }
+}
+
+static ngx_http_push_stream_pid_queue_t *
+ngx_http_push_stream_get_worker_subscriber_channel_sentinel_locked(ngx_slab_pool_t *shpool, ngx_http_push_stream_channel_t *channel, ngx_log_t *log)
+{
+    ngx_http_push_stream_pid_queue_t     *worker_sentinel;
+    ngx_queue_t                          *q;
+
+    for (q = ngx_queue_head(&channel->workers_with_subscribers); q != ngx_queue_sentinel(&channel->workers_with_subscribers); q = ngx_queue_next(q)) {
+        worker_sentinel = ngx_queue_data(q, ngx_http_push_stream_pid_queue_t, queue);
+        if (worker_sentinel->pid == ngx_pid) {
+            return worker_sentinel;
+        }
+    }
+
+    if ((worker_sentinel = ngx_slab_alloc(shpool, sizeof(ngx_http_push_stream_pid_queue_t))) == NULL) {
+        ngx_log_error(NGX_LOG_ERR, log, 0, "push stream module: unable to allocate worker subscriber queue marker in shared memory");
+        return NULL;
+    }
+
+    // initialize
+    ngx_queue_insert_tail(&channel->workers_with_subscribers, &worker_sentinel->queue);
+
+    worker_sentinel->subscribers = 0;
+    worker_sentinel->pid = ngx_pid;
+    worker_sentinel->slot = ngx_process_slot;
+    ngx_queue_init(&worker_sentinel->subscriptions);
+
+    return worker_sentinel;
+}
+
+static ngx_http_push_stream_subscription_t *
+ngx_http_push_stream_create_channel_subscription(ngx_http_request_t *r, ngx_http_push_stream_channel_t *channel, ngx_http_push_stream_subscriber_t *subscriber)
+{
+    ngx_http_push_stream_subscription_t        *subscription;
+
+    if ((subscription = ngx_pcalloc(r->pool, sizeof(ngx_http_push_stream_subscription_t))) == NULL) {
+        ngx_log_error(NGX_LOG_ERR, r->connection->log, 0, "push stream module: unable to allocate subscribed channel reference");
+        return NULL;
+    }
+
+    subscription->channel_worker_sentinel = NULL;
+    subscription->channel = channel;
+    subscription->subscriber = subscriber;
+    ngx_queue_init(&subscription->queue);
+    ngx_queue_init(&subscription->channel_worker_queue);
+
+    return subscription;
+}
+
+static ngx_int_t
+ngx_http_push_stream_assing_subscription_to_channel(ngx_slab_pool_t *shpool, ngx_http_push_stream_channel_t *channel, ngx_http_push_stream_subscription_t *subscription, ngx_queue_t *subscriptions, ngx_log_t *log)
+{
+    ngx_http_push_stream_main_conf_t           *mcf = ngx_http_get_module_main_conf(subscription->subscriber->request, ngx_http_push_stream_module);
+    ngx_http_push_stream_pid_queue_t           *worker_subscribers_sentinel;
+
+    ngx_shmtx_lock(channel->mutex);
+    if ((worker_subscribers_sentinel = ngx_http_push_stream_get_worker_subscriber_channel_sentinel_locked(shpool, channel, log)) == NULL) {
+        ngx_shmtx_unlock(channel->mutex);
+        return NGX_ERROR;
+    }
+
+    channel->subscribers++; // do this only when we know everything went okay
+    worker_subscribers_sentinel->subscribers++;
+    channel->expires = ngx_time() + mcf->channel_inactivity_time;
+    ngx_queue_insert_tail(subscriptions, &subscription->queue);
+    ngx_queue_insert_tail(&worker_subscribers_sentinel->subscriptions, &subscription->channel_worker_queue);
+    subscription->channel_worker_sentinel = worker_subscribers_sentinel;
+    ngx_shmtx_unlock(channel->mutex);
+
+    ngx_http_push_stream_send_event(mcf, log, channel, &NGX_HTTP_PUSH_STREAM_EVENT_TYPE_CLIENT_SUBSCRIBED, NULL);
+
+    return NGX_OK;
+}
+
+
+static ngx_http_push_stream_padding_t *
+ngx_http_push_stream_get_padding_by_user_agent(ngx_http_request_t *r)
+{
+    ngx_http_push_stream_loc_conf_t                *cf = ngx_http_get_module_loc_conf(r, ngx_http_push_stream_module);
+    ngx_queue_t                                    *q;
+    ngx_str_t                                       vv_user_agent = ngx_null_string;
+
+    if (cf->user_agent != NULL) {
+        ngx_http_push_stream_complex_value(r, cf->user_agent, &vv_user_agent);
+    } else if (r->headers_in.user_agent != NULL) {
+        vv_user_agent = r->headers_in.user_agent->value;
+    }
+
+    if ((cf->paddings != NULL) && (vv_user_agent.len > 0)) {
+        for (q = ngx_queue_head(cf->paddings); q != ngx_queue_sentinel(cf->paddings); q = ngx_queue_next(q)) {
+            ngx_http_push_stream_padding_t *padding = ngx_queue_data(q, ngx_http_push_stream_padding_t, queue);
+            if (ngx_regex_exec(padding->agent, &vv_user_agent, NULL, 0) >= 0) {
+                return padding;
+            }
+        }
+    }
+
+    return NULL;
+}
diff -Naur nginx-1.11.3/nginx-push-stream-module/src/ngx_http_push_stream_module_utils.c nginx-1.11.3-push/nginx-push-stream-module/src/ngx_http_push_stream_module_utils.c
--- nginx-1.11.3/nginx-push-stream-module/src/ngx_http_push_stream_module_utils.c	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/src/ngx_http_push_stream_module_utils.c	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,2348 @@
+/*
+ * Copyright (C) 2010-2015 Wandenberg Peixoto <wandenberg@gmail.com>, Rog√©rio Carvalho Schneider <stockrt@gmail.com>
+ *
+ * This file is part of Nginx Push Stream Module.
+ *
+ * Nginx Push Stream Module is free software: you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation, either version 3 of the License, or
+ * (at your option) any later version.
+ *
+ * Nginx Push Stream Module is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with Nginx Push Stream Module.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ *
+ * ngx_http_push_stream_module_utils.c
+ *
+ * Created: Oct 26, 2010
+ * Authors: Wandenberg Peixoto <wandenberg@gmail.com>, Rog√©rio Carvalho Schneider <stockrt@gmail.com>
+ */
+
+#include <ngx_http_push_stream_module_utils.h>
+
+static void            nxg_http_push_stream_free_channel_memory(ngx_slab_pool_t *shpool, ngx_http_push_stream_channel_t *channel);
+static void            ngx_http_push_stream_run_cleanup_pool_handler(ngx_pool_t *p, ngx_pool_cleanup_pt handler);
+static void            ngx_http_push_stream_cleanup_request_context(ngx_http_request_t *r);
+static ngx_int_t       ngx_http_push_stream_send_response_padding(ngx_http_request_t *r, size_t len, ngx_flag_t sending_header);
+void                   ngx_http_push_stream_delete_channels_data(ngx_http_push_stream_shm_data_t *data);
+void                   ngx_http_push_stream_collect_expired_messages_and_empty_channels_data(ngx_http_push_stream_shm_data_t *data, ngx_flag_t force);
+void                   ngx_http_push_stream_free_memory_of_expired_messages_and_channels_data(ngx_http_push_stream_shm_data_t *data, ngx_flag_t force);
+static ngx_inline void ngx_http_push_stream_cleanup_shutting_down_worker_data(ngx_http_push_stream_shm_data_t *data);
+static void            ngx_http_push_stream_flush_pending_output(ngx_http_request_t *r);
+
+
+ngx_uint_t
+ngx_http_push_stream_ensure_qtd_of_messages(ngx_http_push_stream_shm_data_t *data, ngx_http_push_stream_channel_t *channel, ngx_uint_t max_messages, ngx_flag_t expired)
+{
+    ngx_http_push_stream_msg_t             *msg;
+    ngx_queue_t                            *q;
+    ngx_uint_t                              qtd_removed = 0;
+
+    if (max_messages == NGX_CONF_UNSET_UINT) {
+        return qtd_removed;
+    }
+
+    ngx_shmtx_lock(channel->mutex);
+    while (!ngx_queue_empty(&channel->message_queue) && ((channel->stored_messages > max_messages) || expired)) {
+        q = ngx_queue_head(&channel->message_queue);
+        msg = ngx_queue_data(q, ngx_http_push_stream_msg_t, queue);
+
+        if (expired && (msg->deleted || (msg->expires == 0) || (msg->expires > ngx_time()) || (msg->workers_ref_count > 0))) {
+            break;
+        }
+
+        qtd_removed++;
+        NGX_HTTP_PUSH_STREAM_DECREMENT_COUNTER(channel->stored_messages);
+        ngx_queue_remove(&msg->queue);
+        ngx_http_push_stream_throw_the_message_away(msg, data);
+    }
+    ngx_shmtx_unlock(channel->mutex);
+
+    return qtd_removed;
+}
+
+
+static void
+ngx_http_push_stream_delete_channels(void)
+{
+    ngx_http_push_stream_global_shm_data_t *global_data = (ngx_http_push_stream_global_shm_data_t *) ngx_http_push_stream_global_shm_zone->data;
+    ngx_queue_t                            *q;
+
+    for (q = ngx_queue_head(&global_data->shm_datas_queue); q != ngx_queue_sentinel(&global_data->shm_datas_queue); q = ngx_queue_next(q)) {
+        ngx_http_push_stream_shm_data_t *data = ngx_queue_data(q, ngx_http_push_stream_shm_data_t, shm_data_queue);
+        ngx_http_push_stream_delete_channels_data(data);
+    }
+}
+
+void
+ngx_http_push_stream_delete_channels_data(ngx_http_push_stream_shm_data_t *data)
+{
+    ngx_http_push_stream_main_conf_t            *mcf = data->mcf;
+    ngx_http_push_stream_channel_t              *channel;
+    ngx_http_push_stream_pid_queue_t            *worker;
+    ngx_queue_t                                 *cur_worker, *cur;
+
+    ngx_queue_t                                 *q;
+
+    ngx_shmtx_lock(&data->channels_to_delete_mutex);
+    for (q = ngx_queue_head(&data->channels_to_delete); q != ngx_queue_sentinel(&data->channels_to_delete); q = ngx_queue_next(q)) {
+        channel = ngx_queue_data(q, ngx_http_push_stream_channel_t, queue);
+
+        ngx_shmtx_lock(channel->mutex);
+        // remove subscribers if any
+        if (channel->subscribers > 0) {
+            // find the current worker
+            for (cur_worker = ngx_queue_head(&channel->workers_with_subscribers); cur_worker != ngx_queue_sentinel(&channel->workers_with_subscribers); cur_worker = ngx_queue_next(cur_worker)) {
+                worker = ngx_queue_data(cur_worker, ngx_http_push_stream_pid_queue_t, queue);
+                if (worker->pid == ngx_pid) {
+
+                    // to each subscription of this channel in this worker
+                    while (!ngx_queue_empty(&worker->subscriptions)) {
+                        cur = ngx_queue_head(&worker->subscriptions);
+                        ngx_http_push_stream_subscription_t *subscription = ngx_queue_data(cur, ngx_http_push_stream_subscription_t, channel_worker_queue);
+                        ngx_http_push_stream_subscriber_t *subscriber = subscription->subscriber;
+
+                        NGX_HTTP_PUSH_STREAM_DECREMENT_COUNTER(channel->subscribers);
+                        NGX_HTTP_PUSH_STREAM_DECREMENT_COUNTER(worker->subscribers);
+                        // remove the subscription for the channel from subscriber
+                        ngx_queue_remove(&subscription->queue);
+                        // remove the subscription for the channel from worker
+                        ngx_queue_remove(&subscription->channel_worker_queue);
+
+                        ngx_http_push_stream_send_event(mcf, ngx_cycle->log, subscription->channel, &NGX_HTTP_PUSH_STREAM_EVENT_TYPE_CLIENT_UNSUBSCRIBED, subscriber->request->pool);
+
+                        if (subscriber->longpolling) {
+                            ngx_http_push_stream_add_polling_headers(subscriber->request, ngx_time(), 0, subscriber->request->pool);
+                            ngx_http_send_header(subscriber->request);
+
+                            ngx_http_push_stream_send_response_content_header(subscriber->request, ngx_http_get_module_loc_conf(subscriber->request, ngx_http_push_stream_module));
+                        }
+
+                        ngx_http_push_stream_send_response_message(subscriber->request, channel, channel->channel_deleted_message, 1, 0);
+
+
+                        // subscriber does not have any other subscription, the connection may be closed
+                        if (subscriber->longpolling || ngx_queue_empty(&subscriber->subscriptions)) {
+                            ngx_http_push_stream_send_response_finalize(subscriber->request);
+                        }
+                    }
+                }
+            }
+        }
+        ngx_shmtx_unlock(channel->mutex);
+    }
+    ngx_shmtx_unlock(&data->channels_to_delete_mutex);
+}
+
+void
+ngx_http_push_stream_collect_deleted_channels_data(ngx_http_push_stream_shm_data_t *data)
+{
+    ngx_http_push_stream_main_conf_t            *mcf = data->mcf;
+    ngx_http_push_stream_channel_t              *channel;
+    ngx_queue_t                                 *q;
+    ngx_uint_t                                   qtd_removed;
+    ngx_pool_t                                  *temp_pool = NULL;
+
+    if (mcf->events_channel_id.len > 0) {
+        temp_pool = ngx_create_pool(4096, ngx_cycle->log);
+    }
+
+    ngx_shmtx_lock(&data->channels_to_delete_mutex);
+    for (q = ngx_queue_head(&data->channels_to_delete); q != ngx_queue_sentinel(&data->channels_to_delete);) {
+        channel = ngx_queue_data(q, ngx_http_push_stream_channel_t, queue);
+        q = ngx_queue_next(q);
+
+        // remove all messages
+        qtd_removed = ngx_http_push_stream_ensure_qtd_of_messages(data, channel, 0, 0);
+        if (qtd_removed > 0) {
+            ngx_shmtx_lock(&data->channels_queue_mutex);
+            NGX_HTTP_PUSH_STREAM_DECREMENT_COUNTER_BY(data->stored_messages, qtd_removed);
+            ngx_shmtx_unlock(&data->channels_queue_mutex);
+        }
+
+        // channel has no subscribers and can be released
+        if (channel->subscribers == 0) {
+            channel->expires = ngx_time() + NGX_HTTP_PUSH_STREAM_DEFAULT_SHM_MEMORY_CLEANUP_OBJECTS_TTL;
+
+            // move the channel to trash queue
+            ngx_queue_remove(&channel->queue);
+            ngx_shmtx_lock(&data->channels_trash_mutex);
+            ngx_queue_insert_tail(&data->channels_trash, &channel->queue);
+            data->channels_in_trash++;
+            ngx_shmtx_unlock(&data->channels_trash_mutex);
+
+            ngx_http_push_stream_send_event(mcf, ngx_cycle->log, channel, &NGX_HTTP_PUSH_STREAM_EVENT_TYPE_CHANNEL_DESTROYED, temp_pool);
+        }
+    }
+    ngx_shmtx_unlock(&data->channels_to_delete_mutex);
+
+    if (temp_pool != NULL) {
+        ngx_destroy_pool(temp_pool);
+    }
+}
+
+
+static ngx_inline void
+ngx_http_push_stream_delete_worker_channel(void)
+{
+    ngx_http_push_stream_delete_channels();
+}
+
+
+static ngx_inline void
+ngx_http_push_stream_cleanup_shutting_down_worker(void)
+{
+    ngx_http_push_stream_global_shm_data_t *global_data = (ngx_http_push_stream_global_shm_data_t *) ngx_http_push_stream_global_shm_zone->data;
+    ngx_queue_t                            *q;
+
+    for (q = ngx_queue_head(&global_data->shm_datas_queue); q != ngx_queue_sentinel(&global_data->shm_datas_queue); q = ngx_queue_next(q)) {
+        ngx_http_push_stream_shm_data_t *data = ngx_queue_data(q, ngx_http_push_stream_shm_data_t, shm_data_queue);
+        ngx_http_push_stream_cleanup_shutting_down_worker_data(data);
+    }
+    global_data->pid[ngx_process_slot] = -1;
+}
+
+
+static ngx_inline void
+ngx_http_push_stream_cleanup_shutting_down_worker_data(ngx_http_push_stream_shm_data_t *data)
+{
+    ngx_http_push_stream_worker_data_t          *thisworker_data = data->ipc + ngx_process_slot;
+    ngx_queue_t                                 *q;
+
+    while (!ngx_queue_empty(&thisworker_data->subscribers_queue)) {
+        q = ngx_queue_head(&thisworker_data->subscribers_queue);
+        ngx_http_push_stream_subscriber_t *subscriber = ngx_queue_data(q, ngx_http_push_stream_subscriber_t, worker_queue);
+        if (subscriber->longpolling) {
+            ngx_http_push_stream_send_response_finalize_for_longpolling_by_timeout(subscriber->request);
+        } else {
+            ngx_http_push_stream_send_response_finalize(subscriber->request);
+        }
+    }
+
+    if (ngx_http_push_stream_memory_cleanup_event.timer_set) {
+        ngx_del_timer(&ngx_http_push_stream_memory_cleanup_event);
+    }
+
+    if (ngx_http_push_stream_buffer_cleanup_event.timer_set) {
+        ngx_del_timer(&ngx_http_push_stream_buffer_cleanup_event);
+    }
+
+    ngx_http_push_stream_clean_worker_data(data);
+}
+
+ngx_uint_t
+ngx_http_push_stream_apply_text_template(ngx_str_t **dst_value, ngx_str_t **dst_message, ngx_str_t *text, const ngx_str_t *template, const ngx_str_t *token, ngx_slab_pool_t *shpool, ngx_pool_t *temp_pool)
+{
+    if (text != NULL) {
+        if ((*dst_value = ngx_slab_alloc(shpool, sizeof(ngx_str_t) + text->len + 1)) == NULL) {
+            return NGX_ERROR;
+        }
+
+        (*dst_value)->len = text->len;
+        (*dst_value)->data = (u_char *) ((*dst_value) + 1);
+        ngx_memcpy((*dst_value)->data, text->data, text->len);
+        (*dst_value)->data[(*dst_value)->len] = '\0';
+
+        ngx_str_t *aux = ngx_http_push_stream_str_replace(template, token, text, 0, temp_pool);
+        if (aux == NULL) {
+            return NGX_ERROR;
+        }
+
+        if (((*dst_message) = ngx_slab_alloc(shpool, sizeof(ngx_str_t) + aux->len)) == NULL) {
+            return NGX_ERROR;
+        }
+
+        (*dst_message)->len = aux->len;
+        (*dst_message)->data = (u_char *) ((*dst_message) + 1);
+        ngx_memcpy((*dst_message)->data, aux->data, (*dst_message)->len);
+    }
+
+    return NGX_OK;
+}
+
+ngx_http_push_stream_msg_t *
+ngx_http_push_stream_convert_char_to_msg_on_shared(ngx_http_push_stream_main_conf_t *mcf, u_char *data, size_t len, ngx_http_push_stream_channel_t *channel, ngx_int_t id, ngx_str_t *event_id, ngx_str_t *event_type, ngx_pool_t *temp_pool)
+{
+    ngx_slab_pool_t                           *shpool = mcf->shpool;
+    ngx_http_push_stream_shm_data_t           *shm_data = mcf->shm_data;
+    ngx_queue_t                               *q;
+    ngx_http_push_stream_msg_t                *msg;
+    int                                        i = 0;
+
+    if ((msg = ngx_slab_alloc(shpool, sizeof(ngx_http_push_stream_msg_t))) == NULL) {
+        return NULL;
+    }
+
+    msg->event_id = NULL;
+    msg->event_type = NULL;
+    msg->event_id_message = NULL;
+    msg->event_type_message = NULL;
+    msg->formatted_messages = NULL;
+    msg->deleted = 0;
+    msg->expires = 0;
+    msg->id = id;
+    msg->workers_ref_count = 0;
+    msg->time = (id < 0) ? 0 : ngx_time();
+    msg->tag = (id < 0) ? 0 : ((msg->time == shm_data->last_message_time) ? (shm_data->last_message_tag + 1) : 1);
+    msg->qtd_templates = mcf->qtd_templates;
+    ngx_queue_init(&msg->queue);
+
+    if ((msg->raw.data = ngx_slab_alloc(shpool, len + 1)) == NULL) {
+        ngx_http_push_stream_free_message_memory(shpool, msg);
+        return NULL;
+    }
+
+    msg->raw.len = len;
+    // copy the message to shared memory
+    ngx_memcpy(msg->raw.data, data, len);
+    msg->raw.data[msg->raw.len] = '\0';
+
+
+    if (ngx_http_push_stream_apply_text_template(&msg->event_id, &msg->event_id_message, event_id, &NGX_HTTP_PUSH_STREAM_EVENTSOURCE_ID_TEMPLATE, &NGX_HTTP_PUSH_STREAM_TOKEN_MESSAGE_EVENT_ID, shpool, temp_pool) != NGX_OK) {
+        ngx_http_push_stream_free_message_memory(shpool, msg);
+        return NULL;
+    }
+
+    if (ngx_http_push_stream_apply_text_template(&msg->event_type, &msg->event_type_message, event_type, &NGX_HTTP_PUSH_STREAM_EVENTSOURCE_EVENT_TEMPLATE, &NGX_HTTP_PUSH_STREAM_TOKEN_MESSAGE_EVENT_TYPE, shpool, temp_pool) != NGX_OK) {
+        ngx_http_push_stream_free_message_memory(shpool, msg);
+        return NULL;
+    }
+
+    if ((msg->formatted_messages = ngx_slab_alloc(shpool, sizeof(ngx_str_t) * msg->qtd_templates)) == NULL) {
+        ngx_http_push_stream_free_message_memory(shpool, msg);
+        return NULL;
+    }
+    ngx_memzero(msg->formatted_messages, sizeof(ngx_str_t) * msg->qtd_templates);
+
+    for (q = ngx_queue_head(&mcf->msg_templates); q != ngx_queue_sentinel(&mcf->msg_templates); q = ngx_queue_next(q)) {
+        ngx_http_push_stream_template_t *cur = ngx_queue_data(q, ngx_http_push_stream_template_t, queue);
+        ngx_str_t *aux = NULL;
+        if (cur->eventsource) {
+            ngx_http_push_stream_line_t     *cur_line;
+            ngx_queue_t                     *lines, *q_line;
+
+            if ((lines = ngx_http_push_stream_split_by_crlf(&msg->raw, temp_pool)) == NULL) {
+                ngx_http_push_stream_free_message_memory(shpool, msg);
+                return NULL;
+            }
+
+            for (q_line = ngx_queue_head(lines); q_line != ngx_queue_sentinel(lines); q_line = ngx_queue_next(q_line )) {
+                cur_line = ngx_queue_data(q_line , ngx_http_push_stream_line_t, queue);
+                if ((cur_line->line = ngx_http_push_stream_format_message(channel, msg, cur_line->line, cur, temp_pool)) == NULL) {
+                    break;
+                }
+            }
+
+            ngx_str_t *tmp = ngx_http_push_stream_join_with_crlf(lines, temp_pool);
+            if ((aux = ngx_http_push_stream_create_str(temp_pool, tmp->len + 1)) != NULL) {
+                ngx_sprintf(aux->data, "%V\n", tmp);
+            }
+        } else {
+            aux = ngx_http_push_stream_format_message(channel, msg, &msg->raw, cur, temp_pool);
+        }
+
+        if (aux == NULL) {
+            ngx_http_push_stream_free_message_memory(shpool, msg);
+            return NULL;
+        }
+
+        ngx_str_t *text = aux;
+        if (cur->websocket) {
+            text = ngx_http_push_stream_get_formatted_websocket_frame(&NGX_HTTP_PUSH_STREAM_WEBSOCKET_TEXT_LAST_FRAME_BYTE, sizeof(NGX_HTTP_PUSH_STREAM_WEBSOCKET_TEXT_LAST_FRAME_BYTE), aux->data, aux->len, temp_pool);
+        }
+
+        ngx_str_t *formmated = (msg->formatted_messages + i);
+        if ((text == NULL) || ((formmated->data = ngx_slab_alloc(shpool, text->len)) == NULL)) {
+            ngx_http_push_stream_free_message_memory(shpool, msg);
+            return NULL;
+        }
+
+        formmated->len = text->len;
+        ngx_memcpy(formmated->data, text->data, formmated->len);
+
+        i++;
+    }
+
+    return msg;
+}
+
+
+ngx_int_t
+ngx_http_push_stream_add_msg_to_channel(ngx_http_push_stream_main_conf_t *mcf, ngx_log_t *log, ngx_http_push_stream_channel_t *channel, u_char *text, size_t len, ngx_str_t *event_id, ngx_str_t *event_type, ngx_flag_t store_messages, ngx_pool_t *temp_pool)
+{
+    ngx_http_push_stream_shm_data_t        *data = mcf->shm_data;
+    ngx_http_push_stream_msg_t             *msg;
+    ngx_uint_t                              qtd_removed;
+
+    // create a buffer copy in shared mem
+    msg = ngx_http_push_stream_convert_char_to_msg_on_shared(mcf, text, len, channel, channel->last_message_id + 1, event_id, event_type, temp_pool);
+    if (msg == NULL) {
+        ngx_log_error(NGX_LOG_ERR, log, 0, "push stream module: unable to allocate message in shared memory");
+        return NGX_ERROR;
+    }
+
+    ngx_shmtx_lock(channel->mutex);
+    channel->last_message_id++;
+
+    // tag message with time stamp and a sequence tag
+    channel->last_message_time = msg->time;
+    channel->last_message_tag = msg->tag;
+    // set message expiration time
+    msg->expires = msg->time + mcf->message_ttl;
+    channel->expires = ngx_time() + mcf->channel_inactivity_time;
+
+    // put messages on the queue
+    if (store_messages) {
+        ngx_queue_insert_tail(&channel->message_queue, &msg->queue);
+        channel->stored_messages++;
+    }
+    ngx_shmtx_unlock(channel->mutex);
+
+    // now see if the queue is too big
+    qtd_removed = ngx_http_push_stream_ensure_qtd_of_messages(data, channel, mcf->max_messages_stored_per_channel, 0);
+
+    if (!channel->for_events) {
+        ngx_shmtx_lock(&data->channels_queue_mutex);
+        data->published_messages++;
+
+        if (msg->time >= data->last_message_time) {
+            data->last_message_time = msg->time;
+            data->last_message_tag = msg->tag;
+        }
+
+        NGX_HTTP_PUSH_STREAM_DECREMENT_COUNTER_BY(data->stored_messages, qtd_removed);
+
+        if (store_messages) {
+            data->stored_messages++;
+        }
+        ngx_shmtx_unlock(&data->channels_queue_mutex);
+    }
+
+    // send an alert to workers
+    ngx_http_push_stream_broadcast(channel, msg, log, mcf);
+
+    // turn on timer to cleanup buffer of old messages
+    ngx_http_push_stream_buffer_cleanup_timer_set();
+
+    return NGX_OK;
+}
+
+
+ngx_int_t
+ngx_http_push_stream_send_event(ngx_http_push_stream_main_conf_t *mcf, ngx_log_t *log, ngx_http_push_stream_channel_t *channel, ngx_str_t *event_type, ngx_pool_t *received_temp_pool)
+{
+    ngx_pool_t *temp_pool = received_temp_pool;
+
+    if ((temp_pool == NULL) && ((temp_pool = ngx_create_pool(4096, log)) == NULL)) {
+        return NGX_ERROR;
+    }
+
+    if ((mcf->events_channel_id.len > 0) && !channel->for_events) {
+        size_t len = ngx_strlen(NGX_HTTP_PUSH_STREAM_EVENT_TEMPLATE) + event_type->len + channel->id.len;
+        ngx_str_t *event = ngx_http_push_stream_create_str(temp_pool, len);
+        if (event != NULL) {
+            ngx_sprintf(event->data, NGX_HTTP_PUSH_STREAM_EVENT_TEMPLATE, event_type, &channel->id);
+            ngx_http_push_stream_add_msg_to_channel(mcf, log, mcf->events_channel, event->data, ngx_strlen(event->data), NULL, event_type, 1, temp_pool);
+        }
+    }
+
+    if ((received_temp_pool == NULL) && (temp_pool != NULL)) {
+        ngx_destroy_pool(temp_pool);
+    }
+
+    return NGX_OK;
+}
+
+
+static ngx_int_t
+ngx_http_push_stream_send_only_header_response(ngx_http_request_t *r, ngx_int_t status_code, const ngx_str_t *explain_error_message)
+{
+    ngx_int_t rc;
+
+    r->header_only = 1;
+    r->headers_out.content_length_n = 0;
+    r->headers_out.status = status_code;
+    if (explain_error_message != NULL) {
+        ngx_http_push_stream_add_response_header(r, &NGX_HTTP_PUSH_STREAM_HEADER_EXPLAIN, explain_error_message);
+    }
+
+    rc = ngx_http_send_header(r);
+
+    if (rc > NGX_HTTP_SPECIAL_RESPONSE) {
+        return NGX_HTTP_INTERNAL_SERVER_ERROR;
+    }
+
+    return rc;
+}
+
+
+static ngx_int_t
+ngx_http_push_stream_send_only_header_response_and_finalize(ngx_http_request_t *r, ngx_int_t status_code, const ngx_str_t *explain_error_message)
+{
+    ngx_int_t rc;
+    rc = ngx_http_push_stream_send_only_header_response(r, status_code, explain_error_message);
+    ngx_http_finalize_request(r, (rc == NGX_ERROR) ? NGX_DONE : NGX_OK);
+    return NGX_DONE;
+}
+
+
+static ngx_table_elt_t *
+ngx_http_push_stream_add_response_header(ngx_http_request_t *r, const ngx_str_t *header_name, const ngx_str_t *header_value)
+{
+    ngx_table_elt_t     *h = ngx_list_push(&r->headers_out.headers);
+
+    if (h == NULL) {
+        return NULL;
+    }
+    h->hash = 1;
+    h->key.len = header_name->len;
+    h->key.data = header_name->data;
+    h->value.len = header_value->len;
+    h->value.data = header_value->data;
+
+    return h;
+}
+
+static ngx_str_t *
+ngx_http_push_stream_get_header(ngx_http_request_t *r, const ngx_str_t *header_name)
+{
+    ngx_table_elt_t             *h;
+    ngx_list_part_t             *part;
+    ngx_uint_t                   i;
+    ngx_str_t                   *aux = NULL;
+
+    part = &r->headers_in.headers.part;
+    h = part->elts;
+
+    for (i = 0; /* void */; i++) {
+
+        if (i >= part->nelts) {
+            if (part->next == NULL) {
+                break;
+            }
+
+            part = part->next;
+            h = part->elts;
+            i = 0;
+        }
+
+        if ((h[i].key.len == header_name->len) && (ngx_strncasecmp(h[i].key.data, header_name->data, header_name->len) == 0)) {
+            aux = ngx_http_push_stream_create_str(r->pool, h[i].value.len);
+            if (aux != NULL) {
+                ngx_memcpy(aux->data, h[i].value.data, h[i].value.len);
+            }
+            break;
+        }
+    }
+
+    return aux;
+}
+
+static ngx_int_t
+ngx_http_push_stream_send_response_content_header(ngx_http_request_t *r, ngx_http_push_stream_loc_conf_t *pslcf)
+{
+    ngx_int_t rc = NGX_OK;
+
+    if (pslcf->header_template.len > 0) {
+        rc = ngx_http_push_stream_send_response_text(r, pslcf->header_template.data, pslcf->header_template.len, 0);
+        if (rc == NGX_OK) {
+            rc = ngx_http_push_stream_send_response_padding(r, pslcf->header_template.len, 1);
+        }
+    }
+
+    return rc;
+}
+
+static ngx_int_t
+ngx_http_push_stream_send_response_message(ngx_http_request_t *r, ngx_http_push_stream_channel_t *channel, ngx_http_push_stream_msg_t *msg, ngx_flag_t send_callback, ngx_flag_t send_separator)
+{
+    ngx_http_push_stream_loc_conf_t       *pslcf = ngx_http_get_module_loc_conf(r, ngx_http_push_stream_module);
+    ngx_http_push_stream_module_ctx_t     *ctx = ngx_http_get_module_ctx(r, ngx_http_push_stream_module);
+    ngx_flag_t                             use_jsonp = (ctx != NULL) && (ctx->callback != NULL);
+    ngx_int_t rc = NGX_OK;
+
+    if (pslcf->location_type == NGX_HTTP_PUSH_STREAM_SUBSCRIBER_MODE_EVENTSOURCE) {
+        if (msg->event_id_message != NULL) {
+            rc = ngx_http_push_stream_send_response_text(r, msg->event_id_message->data, msg->event_id_message->len, 0);
+        }
+
+        if ((rc == NGX_OK) && (msg->event_type_message != NULL)) {
+            rc = ngx_http_push_stream_send_response_text(r, msg->event_type_message->data, msg->event_type_message->len, 0);
+        }
+    }
+
+    if (rc == NGX_OK) {
+        ngx_str_t *str = ngx_http_push_stream_get_formatted_message(r, channel, msg);
+        if (str != NULL) {
+            if ((rc == NGX_OK) && use_jsonp && send_callback) {
+                rc = ngx_http_push_stream_send_response_text(r, ctx->callback->data, ctx->callback->len, 0);
+                if (rc == NGX_OK) {
+                    rc = ngx_http_push_stream_send_response_text(r, NGX_HTTP_PUSH_STREAM_CALLBACK_INIT_CHUNK.data, NGX_HTTP_PUSH_STREAM_CALLBACK_INIT_CHUNK.len, 0);
+                }
+            }
+
+            if ((rc == NGX_OK) && use_jsonp && send_separator) {
+                rc = ngx_http_push_stream_send_response_text(r, NGX_HTTP_PUSH_STREAM_CALLBACK_MID_CHUNK.data, NGX_HTTP_PUSH_STREAM_CALLBACK_MID_CHUNK.len, 0);
+            }
+
+            if (rc == NGX_OK) {
+                rc = ngx_http_push_stream_send_response_text(r, str->data, str->len, 0);
+                if (rc == NGX_OK) {
+                    ctx->message_sent = 1;
+                }
+            }
+
+            if ((rc == NGX_OK) && use_jsonp && send_callback) {
+                rc = ngx_http_push_stream_send_response_text(r, NGX_HTTP_PUSH_STREAM_CALLBACK_END_CHUNK.data, NGX_HTTP_PUSH_STREAM_CALLBACK_END_CHUNK.len, 0);
+            }
+
+            if (rc == NGX_OK) {
+                rc = ngx_http_push_stream_send_response_padding(r, str->len, 0);
+            }
+        }
+    }
+
+    return rc;
+}
+
+
+ngx_chain_t *
+ngx_http_push_stream_get_buf(ngx_http_request_t *r)
+{
+    ngx_http_push_stream_module_ctx_t      *ctx = NULL;
+    ngx_chain_t                            *out = NULL;
+
+    if ((ctx = ngx_http_get_module_ctx(r, ngx_http_push_stream_module)) != NULL) {
+        out = ngx_chain_get_free_buf(r->pool, &ctx->free);
+        if (out != NULL) {
+            out->buf->tag = (ngx_buf_tag_t) &ngx_http_push_stream_module;
+        }
+    } else {
+        out = (ngx_chain_t *) ngx_pcalloc(r->pool, sizeof(ngx_chain_t));
+        if (out == NULL) {
+            return NULL;
+        }
+
+        out->buf = ngx_calloc_buf(r->pool);
+        if (out->buf == NULL) {
+            return NULL;
+        }
+    }
+
+    return out;
+}
+
+
+ngx_int_t
+ngx_http_push_stream_output_filter(ngx_http_request_t *r, ngx_chain_t *in)
+{
+    ngx_http_core_loc_conf_t               *clcf;
+    ngx_http_push_stream_module_ctx_t      *ctx = NULL;
+    ngx_int_t                               rc;
+    ngx_event_t                            *wev;
+    ngx_connection_t                       *c;
+
+    c = r->connection;
+    wev = c->write;
+
+    rc = ngx_http_output_filter(r, in);
+
+    if ((rc == NGX_OK) && (ctx = ngx_http_get_module_ctx(r, ngx_http_push_stream_module)) != NULL) {
+        ngx_chain_update_chains(r->pool, &ctx->free, &ctx->busy, &in, (ngx_buf_tag_t) &ngx_http_push_stream_module);
+    }
+
+    if (c->buffered & NGX_HTTP_LOWLEVEL_BUFFERED) {
+
+        clcf = ngx_http_get_module_loc_conf(r->main, ngx_http_core_module);
+
+        r->write_event_handler = ngx_http_push_stream_flush_pending_output;
+
+        if (!wev->delayed) {
+            ngx_add_timer(wev, clcf->send_timeout);
+        }
+
+        if (ngx_handle_write_event(wev, clcf->send_lowat) != NGX_OK) {
+            return NGX_ERROR;
+        }
+
+        return NGX_OK;
+
+    } else {
+        if (wev->timer_set) {
+            ngx_del_timer(wev);
+        }
+    }
+
+    return rc;
+}
+
+
+static void
+ngx_http_push_stream_flush_pending_output(ngx_http_request_t *r)
+{
+    int                        rc;
+    ngx_event_t               *wev;
+    ngx_connection_t          *c;
+    ngx_http_core_loc_conf_t  *clcf;
+
+    c = r->connection;
+    wev = c->write;
+
+    ngx_log_debug2(NGX_LOG_DEBUG_HTTP, wev->log, 0, "push stream module http writer handler: \"%V?%V\"", &r->uri, &r->args);
+
+    clcf = ngx_http_get_module_loc_conf(r->main, ngx_http_core_module);
+
+    if (wev->timedout) {
+        if (!wev->delayed) {
+            ngx_log_error(NGX_LOG_INFO, c->log, NGX_ETIMEDOUT, "push stream module: client timed out");
+            c->timedout = 1;
+
+            ngx_http_finalize_request(r, NGX_HTTP_REQUEST_TIME_OUT);
+            return;
+        }
+
+        wev->timedout = 0;
+        wev->delayed = 0;
+
+        if (!wev->ready) {
+            ngx_add_timer(wev, clcf->send_timeout);
+
+            if (ngx_handle_write_event(wev, clcf->send_lowat) != NGX_OK) {
+                ngx_http_finalize_request(r, 0);
+            }
+
+            return;
+        }
+
+    }
+
+    if (wev->delayed || r->aio) {
+        ngx_log_debug0(NGX_LOG_DEBUG_HTTP, wev->log, 0, "push stream module http writer delayed");
+
+        if (ngx_handle_write_event(wev, clcf->send_lowat) != NGX_OK) {
+            ngx_http_finalize_request(r, 0);
+        }
+
+        return;
+    }
+
+    rc = ngx_http_push_stream_output_filter(r, NULL);
+
+    ngx_log_debug3(NGX_LOG_DEBUG_HTTP, c->log, 0, "push stream module http writer output filter: %d, \"%V?%V\"", rc, &r->uri, &r->args);
+
+    if (rc == NGX_ERROR) {
+        ngx_http_finalize_request(r, rc);
+        return;
+    }
+
+    if (r->buffered || r->postponed || (r == r->main && c->buffered)) {
+
+        if (!wev->delayed) {
+            ngx_add_timer(wev, clcf->send_timeout);
+        }
+
+        if (ngx_handle_write_event(wev, clcf->send_lowat) != NGX_OK) {
+            ngx_http_finalize_request(r, 0);
+        }
+
+        return;
+    }
+
+    ngx_log_debug2(NGX_LOG_DEBUG_HTTP, wev->log, 0, "push stream module http writer done: \"%V?%V\"", &r->uri, &r->args);
+
+    r->write_event_handler = ngx_http_request_empty_handler;
+}
+
+
+static ngx_int_t
+ngx_http_push_stream_send_response(ngx_http_request_t *r, ngx_str_t *text, const ngx_str_t *content_type, ngx_int_t status_code)
+{
+    ngx_int_t                rc;
+
+    if ((r == NULL) || (text == NULL) || (content_type == NULL)) {
+        return NGX_HTTP_INTERNAL_SERVER_ERROR;
+    }
+
+    r->headers_out.content_type_len = content_type->len;
+    r->headers_out.content_type = *content_type;
+    r->headers_out.content_length_n = text->len;
+
+    r->headers_out.status = status_code;
+
+    rc = ngx_http_send_header(r);
+
+    if (rc == NGX_ERROR || rc > NGX_OK || r->header_only) {
+        return rc;
+    }
+
+    return ngx_http_push_stream_send_response_text(r, text->data, text->len, 1);
+}
+
+static ngx_int_t
+ngx_http_push_stream_send_response_text(ngx_http_request_t *r, const u_char *text, uint len, ngx_flag_t last_buffer)
+{
+    ngx_buf_t     *b;
+    ngx_chain_t   *out;
+
+    if ((text == NULL) || (r->connection->error)) {
+        return NGX_ERROR;
+    }
+
+    out = ngx_http_push_stream_get_buf(r);
+    if (out == NULL) {
+        return NGX_ERROR;
+    }
+
+    b = out->buf;
+
+    b->last_buf = last_buffer;
+    b->last_in_chain = 1;
+    b->flush = 1;
+    b->memory = 1;
+    b->temporary = 0;
+    b->pos = (u_char *) text;
+    b->start = b->pos;
+    b->end = b->pos + len;
+    b->last = b->end;
+
+    out->next = NULL;
+
+    return ngx_http_push_stream_output_filter(r, out);
+}
+
+
+static ngx_int_t
+ngx_http_push_stream_send_response_padding(ngx_http_request_t *r, size_t len, ngx_flag_t sending_header)
+{
+    ngx_http_push_stream_module_ctx_t *ctx = ngx_http_get_module_ctx(r, ngx_http_push_stream_module);
+    ngx_http_push_stream_loc_conf_t   *pslcf = ngx_http_get_module_loc_conf(r, ngx_http_push_stream_module);
+    ngx_flag_t eventsource = (pslcf->location_type == NGX_HTTP_PUSH_STREAM_SUBSCRIBER_MODE_EVENTSOURCE);
+
+    if (ctx->padding != NULL) {
+        ngx_int_t diff = ((sending_header) ? ctx->padding->header_min_len : ctx->padding->message_min_len) - len;
+        if (diff > 0) {
+            ngx_int_t padding_index = diff / 100;
+            ngx_str_t *padding = eventsource ? ngx_http_push_stream_module_paddings_chunks_for_eventsource[padding_index] : ngx_http_push_stream_module_paddings_chunks[padding_index];
+            ngx_http_push_stream_send_response_text(r, padding->data, padding->len, 0);
+        }
+    }
+
+    return NGX_OK;
+}
+
+
+
+static void
+ngx_http_push_stream_run_cleanup_pool_handler(ngx_pool_t *p, ngx_pool_cleanup_pt handler)
+{
+    ngx_pool_cleanup_t       *c;
+
+    if (p == NULL) {
+        return;
+    }
+
+    for (c = p->cleanup; c; c = c->next) {
+        if ((c->handler == handler) && (c->data != NULL)) {
+            c->handler(c->data);
+            return;
+        }
+    }
+}
+
+/**
+ * Should never be called inside a locked block
+ * */
+static void
+ngx_http_push_stream_send_response_finalize(ngx_http_request_t *r)
+{
+    ngx_http_push_stream_loc_conf_t *pslcf = ngx_http_get_module_loc_conf(r, ngx_http_push_stream_module);
+    ngx_int_t                        rc = NGX_OK;
+
+    ngx_http_push_stream_run_cleanup_pool_handler(r->pool, (ngx_pool_cleanup_pt) ngx_http_push_stream_cleanup_request_context);
+
+    if (pslcf->footer_template.len > 0) {
+        rc = ngx_http_push_stream_send_response_text(r, pslcf->footer_template.data, pslcf->footer_template.len, 0);
+    }
+
+    if (rc == NGX_OK) {
+        if (pslcf->location_type == NGX_HTTP_PUSH_STREAM_SUBSCRIBER_MODE_WEBSOCKET) {
+            rc = ngx_http_push_stream_send_response_text(r, NGX_HTTP_PUSH_STREAM_WEBSOCKET_CLOSE_LAST_FRAME_BYTE, sizeof(NGX_HTTP_PUSH_STREAM_WEBSOCKET_CLOSE_LAST_FRAME_BYTE), 1);
+        } else {
+            rc = ngx_http_send_special(r, NGX_HTTP_LAST | NGX_HTTP_FLUSH);
+        }
+    }
+
+    ngx_http_finalize_request(r, (rc == NGX_ERROR) ? NGX_DONE : NGX_OK);
+}
+
+static void
+ngx_http_push_stream_send_response_finalize_for_longpolling_by_timeout(ngx_http_request_t *r)
+{
+    ngx_http_push_stream_main_conf_t   *mcf = ngx_http_get_module_main_conf(r, ngx_http_push_stream_module);
+
+    ngx_http_push_stream_run_cleanup_pool_handler(r->pool, (ngx_pool_cleanup_pt) ngx_http_push_stream_cleanup_request_context);
+
+    ngx_http_push_stream_add_polling_headers(r, ngx_time(), 0, r->pool);
+
+    if (mcf->timeout_with_body && (mcf->longpooling_timeout_msg == NULL)) {
+        // create longpooling timeout message
+        if ((mcf->longpooling_timeout_msg == NULL) && (mcf->longpooling_timeout_msg = ngx_http_push_stream_convert_char_to_msg_on_shared(mcf, (u_char *) NGX_HTTP_PUSH_STREAM_LONGPOOLING_TIMEOUT_MESSAGE_TEXT, ngx_strlen(NGX_HTTP_PUSH_STREAM_LONGPOOLING_TIMEOUT_MESSAGE_TEXT), NULL, NGX_HTTP_PUSH_STREAM_LONGPOOLING_TIMEOUT_MESSAGE_ID, NULL, NULL, r->pool)) == NULL) {
+            ngx_log_error(NGX_LOG_ERR, r->connection->log, 0, "push stream module: unable to allocate long pooling timeout message in shared memory");
+        }
+    }
+
+    if (mcf->timeout_with_body && (mcf->longpooling_timeout_msg != NULL)) {
+        ngx_http_send_header(r);
+
+        ngx_http_push_stream_send_response_content_header(r, ngx_http_get_module_loc_conf(r, ngx_http_push_stream_module));
+        ngx_http_push_stream_send_response_message(r, NULL, mcf->longpooling_timeout_msg, 1, 0);
+        ngx_http_push_stream_send_response_finalize(r);
+    } else {
+        ngx_http_push_stream_send_only_header_response_and_finalize(r, NGX_HTTP_NOT_MODIFIED, NULL);
+    }
+}
+
+static ngx_int_t
+ngx_http_push_stream_send_websocket_close_frame(ngx_http_request_t *r, ngx_uint_t http_status, const ngx_str_t *reason)
+{
+    ngx_int_t rc;
+    ngx_str_t *text = ngx_http_push_stream_create_str(r->pool, reason->len + NGX_INT_T_LEN + NGX_HTTP_PUSH_STREAM_WEBSOCKET_CLOSE_REASON.len);
+    if (text == NULL) {
+        rc = ngx_http_push_stream_send_response_text(r, NGX_HTTP_PUSH_STREAM_WEBSOCKET_CLOSE_LAST_FRAME_BYTE, sizeof(NGX_HTTP_PUSH_STREAM_WEBSOCKET_CLOSE_LAST_FRAME_BYTE), 1);
+    } else {
+        u_char *last = ngx_sprintf(text->data, (char *) NGX_HTTP_PUSH_STREAM_WEBSOCKET_CLOSE_REASON.data, http_status, reason);
+        text->len = last - text->data;
+        ngx_str_t *frame = ngx_http_push_stream_get_formatted_websocket_frame(NGX_HTTP_PUSH_STREAM_WEBSOCKET_CLOSE_LAST_FRAME_BYTE, 1, text->data, text->len, r->pool);
+        rc = ngx_http_push_stream_send_response_text(r, (const u_char *) frame->data, frame->len, 1);
+    }
+    return (rc == NGX_ERROR) ? NGX_DONE : NGX_OK;
+}
+
+static ngx_flag_t
+ngx_http_push_stream_delete_channel(ngx_http_push_stream_main_conf_t *mcf, ngx_http_push_stream_channel_t *channel, u_char *text, size_t len, ngx_pool_t *temp_pool)
+{
+    ngx_http_push_stream_shm_data_t        *data = mcf->shm_data;
+    ngx_http_push_stream_pid_queue_t       *worker;
+    ngx_queue_t                            *q;
+    ngx_flag_t                              deleted = 0;
+
+    ngx_shmtx_lock(&data->channels_queue_mutex);
+    if ((channel != NULL) && !channel->deleted) {
+        deleted = 1;
+        channel->deleted = 1;
+        (channel->wildcard) ? NGX_HTTP_PUSH_STREAM_DECREMENT_COUNTER(data->wildcard_channels) : NGX_HTTP_PUSH_STREAM_DECREMENT_COUNTER(data->channels);
+
+        // remove channel from tree
+        ngx_rbtree_delete(&data->tree, &channel->node);
+        // move the channel to unrecoverable queue
+        ngx_queue_remove(&channel->queue);
+
+        ngx_shmtx_lock(&data->channels_to_delete_mutex);
+        ngx_queue_insert_tail(&data->channels_to_delete, &channel->queue);
+        ngx_shmtx_unlock(&data->channels_to_delete_mutex);
+
+        // apply channel deleted message text to message template
+        if ((channel->channel_deleted_message = ngx_http_push_stream_convert_char_to_msg_on_shared(mcf, text, len, channel, NGX_HTTP_PUSH_STREAM_CHANNEL_DELETED_MESSAGE_ID, NULL, NULL, temp_pool)) == NULL) {
+            ngx_shmtx_unlock(&data->channels_queue_mutex);
+            ngx_log_error(NGX_LOG_ERR, temp_pool->log, 0, "push stream module: unable to allocate memory to channel deleted message");
+            return 0;
+        }
+
+        // send signal to each worker with subscriber to this channel
+        if (ngx_queue_empty(&channel->workers_with_subscribers)) {
+            ngx_http_push_stream_alert_worker_delete_channel(ngx_pid, ngx_process_slot, ngx_cycle->log);
+        } else {
+            for (q = ngx_queue_head(&channel->workers_with_subscribers); q != ngx_queue_sentinel(&channel->workers_with_subscribers); q = ngx_queue_next(q)) {
+                worker = ngx_queue_data(q, ngx_http_push_stream_pid_queue_t, queue);
+                ngx_http_push_stream_alert_worker_delete_channel(worker->pid, worker->slot, ngx_cycle->log);
+            }
+        }
+    }
+
+    ngx_shmtx_unlock(&data->channels_queue_mutex);
+    return deleted;
+}
+
+
+static void
+ngx_http_push_stream_collect_expired_messages_and_empty_channels(ngx_flag_t force)
+{
+    ngx_http_push_stream_global_shm_data_t *global_data = (ngx_http_push_stream_global_shm_data_t *) ngx_http_push_stream_global_shm_zone->data;
+    ngx_queue_t                            *q;
+
+    for (q = ngx_queue_head(&global_data->shm_datas_queue); q != ngx_queue_sentinel(&global_data->shm_datas_queue); q = ngx_queue_next(q)) {
+        ngx_http_push_stream_shm_data_t *data = ngx_queue_data(q, ngx_http_push_stream_shm_data_t, shm_data_queue);
+        ngx_http_push_stream_collect_expired_messages_and_empty_channels_data(data, force);
+    }
+}
+
+
+void
+ngx_http_push_stream_collect_expired_messages_and_empty_channels_data(ngx_http_push_stream_shm_data_t *data, ngx_flag_t force)
+{
+    ngx_http_push_stream_main_conf_t   *mcf = data->mcf;
+    ngx_http_push_stream_channel_t     *channel;
+    ngx_queue_t                        *q;
+    ngx_pool_t                         *temp_pool = NULL;
+
+    if (mcf->events_channel_id.len > 0) {
+        if ((temp_pool = ngx_create_pool(4096, ngx_cycle->log)) == NULL) {
+            ngx_log_error(NGX_LOG_ERR, ngx_cycle->log, 0, "push stream module: unable to allocate memory to temporary pool");
+            return;
+        }
+    }
+
+    ngx_http_push_stream_collect_expired_messages_data(data, force);
+
+    ngx_shmtx_lock(&data->channels_queue_mutex);
+    for (q = ngx_queue_head(&data->channels_queue); q != ngx_queue_sentinel(&data->channels_queue);) {
+        channel = ngx_queue_data(q, ngx_http_push_stream_channel_t, queue);
+        q = ngx_queue_next(q);
+
+        if ((channel->stored_messages == 0) && (channel->subscribers == 0) && (channel->expires < ngx_time()) && !channel->for_events) {
+            channel->deleted = 1;
+            channel->expires = ngx_time() + NGX_HTTP_PUSH_STREAM_DEFAULT_SHM_MEMORY_CLEANUP_OBJECTS_TTL;
+            (channel->wildcard) ? NGX_HTTP_PUSH_STREAM_DECREMENT_COUNTER(data->wildcard_channels) : NGX_HTTP_PUSH_STREAM_DECREMENT_COUNTER(data->channels);
+
+            // move the channel to trash queue
+            ngx_rbtree_delete(&data->tree, &channel->node);
+            ngx_queue_remove(&channel->queue);
+            ngx_shmtx_lock(&data->channels_trash_mutex);
+            ngx_queue_insert_tail(&data->channels_trash, &channel->queue);
+            data->channels_in_trash++;
+            ngx_shmtx_unlock(&data->channels_trash_mutex);
+
+            ngx_http_push_stream_send_event(mcf, ngx_cycle->log, channel, &NGX_HTTP_PUSH_STREAM_EVENT_TYPE_CHANNEL_DESTROYED, temp_pool);
+        }
+    }
+    ngx_shmtx_unlock(&data->channels_queue_mutex);
+
+    if (temp_pool != NULL) {
+        ngx_destroy_pool(temp_pool);
+    }
+}
+
+
+static void
+ngx_http_push_stream_collect_expired_messages_data(ngx_http_push_stream_shm_data_t *data, ngx_flag_t force)
+{
+    ngx_http_push_stream_channel_t         *channel;
+    ngx_queue_t                            *q;
+    ngx_uint_t                              qtd_removed;
+
+    ngx_shmtx_lock(&data->channels_queue_mutex);
+
+    for (q = ngx_queue_head(&data->channels_queue); q != ngx_queue_sentinel(&data->channels_queue); q = ngx_queue_next(q)) {
+        channel = ngx_queue_data(q, ngx_http_push_stream_channel_t, queue);
+
+        qtd_removed = ngx_http_push_stream_ensure_qtd_of_messages(data, channel, (force) ? 0 : channel->stored_messages, 1);
+        NGX_HTTP_PUSH_STREAM_DECREMENT_COUNTER_BY(data->stored_messages, qtd_removed);
+    }
+
+    ngx_shmtx_unlock(&data->channels_queue_mutex);
+}
+
+
+static void
+ngx_http_push_stream_free_memory_of_expired_channels(ngx_http_push_stream_shm_data_t *data, ngx_slab_pool_t *shpool, ngx_flag_t force)
+{
+    ngx_http_push_stream_channel_t         *channel;
+    ngx_queue_t                            *cur;
+
+    ngx_shmtx_lock(&data->channels_trash_mutex);
+    while (!ngx_queue_empty(&data->channels_trash)) {
+        cur = ngx_queue_head(&data->channels_trash);
+        channel = ngx_queue_data(cur, ngx_http_push_stream_channel_t, queue);
+
+        if ((ngx_time() > channel->expires) || force) {
+            ngx_queue_remove(&channel->queue);
+            nxg_http_push_stream_free_channel_memory(shpool, channel);
+            NGX_HTTP_PUSH_STREAM_DECREMENT_COUNTER(data->channels_in_trash);
+        } else {
+            break;
+        }
+    }
+    ngx_shmtx_unlock(&data->channels_trash_mutex);
+}
+
+
+static void
+nxg_http_push_stream_free_channel_memory(ngx_slab_pool_t *shpool, ngx_http_push_stream_channel_t *channel)
+{
+    // delete the worker-subscriber queue
+    ngx_http_push_stream_pid_queue_t     *worker;
+    ngx_queue_t                          *cur;
+    ngx_shmtx_t                          *mutex = channel->mutex;
+
+    if (channel->channel_deleted_message != NULL) ngx_http_push_stream_free_message_memory(shpool, channel->channel_deleted_message);
+    ngx_shmtx_lock(mutex);
+    while (!ngx_queue_empty(&channel->workers_with_subscribers)) {
+        cur = ngx_queue_head(&channel->workers_with_subscribers);
+        worker = ngx_queue_data(cur, ngx_http_push_stream_pid_queue_t, queue);
+        ngx_queue_remove(&worker->queue);
+        ngx_slab_free(shpool, worker);
+    }
+
+    ngx_slab_free(shpool, channel->id.data);
+    ngx_slab_free(shpool, channel);
+    ngx_shmtx_unlock(mutex);
+}
+
+
+static ngx_int_t
+ngx_http_push_stream_memory_cleanup(void)
+{
+    ngx_http_push_stream_global_shm_data_t *global_data = (ngx_http_push_stream_global_shm_data_t *) ngx_http_push_stream_global_shm_zone->data;
+    ngx_queue_t                            *q;
+
+    for (q = ngx_queue_head(&global_data->shm_datas_queue); q != ngx_queue_sentinel(&global_data->shm_datas_queue); q = ngx_queue_next(q)) {
+        ngx_http_push_stream_shm_data_t *data = ngx_queue_data(q, ngx_http_push_stream_shm_data_t, shm_data_queue);
+        ngx_http_push_stream_delete_channels_data(data);
+        if (ngx_shmtx_trylock(&data->cleanup_mutex)) {
+            ngx_http_push_stream_collect_deleted_channels_data(data);
+            ngx_http_push_stream_collect_expired_messages_and_empty_channels_data(data, 0);
+            ngx_http_push_stream_free_memory_of_expired_messages_and_channels_data(data, 0);
+            ngx_shmtx_unlock(&data->cleanup_mutex);
+        }
+    }
+
+    return NGX_OK;
+}
+
+
+static ngx_int_t
+ngx_http_push_stream_buffer_cleanup(void)
+{
+    ngx_http_push_stream_global_shm_data_t *global_data = (ngx_http_push_stream_global_shm_data_t *) ngx_http_push_stream_global_shm_zone->data;
+    ngx_queue_t                            *q;
+
+
+    for (q = ngx_queue_head(&global_data->shm_datas_queue); q != ngx_queue_sentinel(&global_data->shm_datas_queue); q = ngx_queue_next(q)) {
+        ngx_http_push_stream_shm_data_t *data = ngx_queue_data(q, ngx_http_push_stream_shm_data_t, shm_data_queue);
+        if (ngx_shmtx_trylock(&data->cleanup_mutex)) {
+            ngx_http_push_stream_collect_expired_messages_data(data, 0);
+            ngx_shmtx_unlock(&data->cleanup_mutex);
+        }
+    }
+
+    return NGX_OK;
+}
+
+
+static ngx_int_t
+ngx_http_push_stream_free_memory_of_expired_messages_and_channels(ngx_flag_t force)
+{
+    ngx_http_push_stream_global_shm_data_t *global_data = (ngx_http_push_stream_global_shm_data_t *) ngx_http_push_stream_global_shm_zone->data;
+    ngx_queue_t                            *q;
+
+    for (q = ngx_queue_head(&global_data->shm_datas_queue); q != ngx_queue_sentinel(&global_data->shm_datas_queue); q = ngx_queue_next(q)) {
+        ngx_http_push_stream_shm_data_t *data = ngx_queue_data(q, ngx_http_push_stream_shm_data_t, shm_data_queue);
+        ngx_http_push_stream_free_memory_of_expired_messages_and_channels_data(data, 0);
+    }
+
+    return NGX_OK;
+}
+
+
+void
+ngx_http_push_stream_free_memory_of_expired_messages_and_channels_data(ngx_http_push_stream_shm_data_t *data, ngx_flag_t force)
+{
+    ngx_slab_pool_t                        *shpool = data->shpool;
+    ngx_http_push_stream_msg_t             *message;
+    ngx_queue_t                            *cur;
+
+    ngx_shmtx_lock(&data->messages_trash_mutex);
+    while (!ngx_queue_empty(&data->messages_trash)) {
+        cur = ngx_queue_head(&data->messages_trash);
+        message = ngx_queue_data(cur, ngx_http_push_stream_msg_t, queue);
+
+        if (force || ((message->workers_ref_count <= 0) && (ngx_time() > message->expires))) {
+            ngx_queue_remove(&message->queue);
+            ngx_http_push_stream_free_message_memory(shpool, message);
+            NGX_HTTP_PUSH_STREAM_DECREMENT_COUNTER(data->messages_in_trash);
+        } else {
+            break;
+        }
+    }
+    ngx_shmtx_unlock(&data->messages_trash_mutex);
+    ngx_http_push_stream_free_memory_of_expired_channels(data, shpool, force);
+}
+
+
+static void
+ngx_http_push_stream_free_message_memory(ngx_slab_pool_t *shpool, ngx_http_push_stream_msg_t *msg)
+{
+    u_int i;
+
+    if (msg == NULL) {
+        return;
+    }
+
+    ngx_shmtx_lock(&shpool->mutex);
+    if (msg->formatted_messages != NULL) {
+        for (i = 0; i < msg->qtd_templates; i++) {
+            ngx_str_t *formmated = (msg->formatted_messages + i);
+            if ((formmated != NULL) && (formmated->data != NULL)) {
+                ngx_slab_free_locked(shpool, formmated->data);
+            }
+        }
+
+        ngx_slab_free_locked(shpool, msg->formatted_messages);
+    }
+
+    if (msg->raw.data != NULL) ngx_slab_free_locked(shpool, msg->raw.data);
+    if (msg->event_id != NULL) ngx_slab_free_locked(shpool, msg->event_id);
+    if (msg->event_type != NULL) ngx_slab_free_locked(shpool, msg->event_type);
+    if (msg->event_id_message != NULL) ngx_slab_free_locked(shpool, msg->event_id_message);
+    if (msg->event_type_message != NULL) ngx_slab_free_locked(shpool, msg->event_type_message);
+    ngx_slab_free_locked(shpool, msg);
+    ngx_shmtx_unlock(&shpool->mutex);
+}
+
+
+static void
+ngx_http_push_stream_free_worker_message_memory(ngx_slab_pool_t *shpool, ngx_http_push_stream_worker_msg_t *worker_msg)
+{
+    ngx_shmtx_lock(&shpool->mutex);
+    worker_msg->msg->workers_ref_count--;
+    if ((worker_msg->msg->workers_ref_count <= 0) && worker_msg->msg->deleted) {
+        worker_msg->msg->expires = ngx_time() + NGX_HTTP_PUSH_STREAM_DEFAULT_SHM_MEMORY_CLEANUP_OBJECTS_TTL;
+    }
+    ngx_queue_remove(&worker_msg->queue);
+    ngx_slab_free_locked(shpool, worker_msg);
+    ngx_shmtx_unlock(&shpool->mutex);
+}
+
+
+static void
+ngx_http_push_stream_throw_the_message_away(ngx_http_push_stream_msg_t *msg, ngx_http_push_stream_shm_data_t *data)
+{
+    ngx_shmtx_lock(&data->channels_trash_mutex);
+    msg->deleted = 1;
+    msg->expires = ngx_time() + NGX_HTTP_PUSH_STREAM_DEFAULT_SHM_MEMORY_CLEANUP_OBJECTS_TTL;
+    ngx_queue_insert_tail(&data->messages_trash, &msg->queue);
+    data->messages_in_trash++;
+    ngx_shmtx_unlock(&data->channels_trash_mutex);
+}
+
+
+static void
+ngx_http_push_stream_timer_set(ngx_msec_t timer_interval, ngx_event_t *event, ngx_event_handler_pt event_handler, ngx_flag_t start_timer)
+{
+    if ((timer_interval != NGX_CONF_UNSET_MSEC) && start_timer) {
+        if (event->handler == NULL) {
+            event->handler = event_handler;
+            event->data = event; //set event as data to avoid error when running on debug mode (on log event)
+            event->log = ngx_cycle->log;
+            ngx_http_push_stream_timer_reset(timer_interval, event);
+        }
+    }
+}
+
+
+static void
+ngx_http_push_stream_timer_reset(ngx_msec_t timer_interval, ngx_event_t *timer_event)
+{
+    if (!ngx_exiting && (timer_interval != NGX_CONF_UNSET_MSEC) && (timer_event != NULL)) {
+        if (timer_event->timedout) {
+            ngx_time_update();
+        }
+        ngx_add_timer(timer_event, timer_interval);
+    }
+}
+
+
+static void
+ngx_http_push_stream_ping_timer_wake_handler(ngx_event_t *ev)
+{
+    ngx_http_request_t                 *r = (ngx_http_request_t *) ev->data;
+    ngx_http_push_stream_main_conf_t   *mcf = ngx_http_get_module_main_conf(r, ngx_http_push_stream_module);
+    ngx_http_push_stream_loc_conf_t    *pslcf = ngx_http_get_module_loc_conf(r, ngx_http_push_stream_module);
+    ngx_http_push_stream_module_ctx_t  *ctx = ngx_http_get_module_ctx(r, ngx_http_push_stream_module);
+    ngx_int_t                           rc = NGX_OK;
+
+    if ((ctx == NULL) || (ctx->ping_timer == NULL)) {
+        return;
+    }
+
+    if (pslcf->location_type == NGX_HTTP_PUSH_STREAM_SUBSCRIBER_MODE_EVENTSOURCE) {
+        rc = ngx_http_push_stream_send_response_text(r, NGX_HTTP_PUSH_STREAM_EVENTSOURCE_PING_MESSAGE_CHUNK.data, NGX_HTTP_PUSH_STREAM_EVENTSOURCE_PING_MESSAGE_CHUNK.len, 0);
+    } else if (pslcf->location_type == NGX_HTTP_PUSH_STREAM_SUBSCRIBER_MODE_WEBSOCKET) {
+        rc = ngx_http_push_stream_send_response_text(r, NGX_HTTP_PUSH_STREAM_WEBSOCKET_PING_LAST_FRAME_BYTE, sizeof(NGX_HTTP_PUSH_STREAM_WEBSOCKET_PING_LAST_FRAME_BYTE), 0);
+    } else {
+        if (mcf->ping_msg == NULL) {
+            // create ping message
+            if ((mcf->ping_msg == NULL) && (mcf->ping_msg = ngx_http_push_stream_convert_char_to_msg_on_shared(mcf, mcf->ping_message_text.data, mcf->ping_message_text.len, NULL, NGX_HTTP_PUSH_STREAM_PING_MESSAGE_ID, NULL, NULL, r->pool)) == NULL) {
+                ngx_log_error(NGX_LOG_ERR, r->connection->log, 0, "push stream module: unable to allocate ping message in shared memory");
+            }
+        }
+
+        if (mcf->ping_msg != NULL) {
+            rc = ngx_http_push_stream_send_response_message(r, NULL, mcf->ping_msg, 1, 0);
+        }
+    }
+
+    if (rc != NGX_OK) {
+        ngx_http_push_stream_send_response_finalize(r);
+    } else {
+        ngx_http_push_stream_timer_reset(pslcf->ping_message_interval, ctx->ping_timer);
+    }
+}
+
+static void
+ngx_http_push_stream_disconnect_timer_wake_handler(ngx_event_t *ev)
+{
+    ngx_http_request_t                    *r = (ngx_http_request_t *) ev->data;
+    ngx_http_push_stream_module_ctx_t     *ctx = ngx_http_get_module_ctx(r, ngx_http_push_stream_module);
+
+    if (ctx->longpolling) {
+        ngx_http_push_stream_send_response_finalize_for_longpolling_by_timeout(r);
+    } else {
+        ngx_http_push_stream_send_response_finalize(r);
+    }
+}
+
+static void
+ngx_http_push_stream_memory_cleanup_timer_wake_handler(ngx_event_t *ev)
+{
+    ngx_http_push_stream_memory_cleanup();
+    ngx_http_push_stream_timer_reset(NGX_HTTP_PUSH_STREAM_DEFAULT_SHM_MEMORY_CLEANUP_INTERVAL, &ngx_http_push_stream_memory_cleanup_event);
+}
+
+static void
+ngx_http_push_stream_buffer_timer_wake_handler(ngx_event_t *ev)
+{
+    ngx_http_push_stream_buffer_cleanup();
+    ngx_http_push_stream_timer_reset(NGX_HTTP_PUSH_STREAM_MESSAGE_BUFFER_CLEANUP_INTERVAL, &ngx_http_push_stream_buffer_cleanup_event);
+}
+
+static ngx_str_t *
+ngx_http_push_stream_str_replace(const ngx_str_t *org, const ngx_str_t *find, const ngx_str_t *replace, off_t offset, ngx_pool_t *pool)
+{
+    if (org == NULL) {
+        return NULL;
+    }
+
+    ngx_str_t *result = (ngx_str_t *) org;
+
+    if (find->len > 0) {
+        u_char *ret = (u_char *) ngx_strnstr(org->data + offset, (char *) find->data, org->len - offset);
+        if (ret != NULL) {
+            ngx_str_t *tmp = ngx_http_push_stream_create_str(pool, org->len + replace->len - find->len);
+            if (tmp == NULL) {
+                ngx_log_error(NGX_LOG_ERR, pool->log, 0, "push stream module: unable to allocate memory to apply text replace");
+                return NULL;
+            }
+
+            off_t offset_found = ret - org->data;
+            ngx_memcpy(tmp->data, org->data, offset_found);
+            ngx_memcpy(tmp->data + offset_found, replace->data, replace->len);
+            ngx_memcpy(tmp->data + offset_found + replace->len, org->data + offset_found + find->len, org->len - offset_found - find->len);
+
+            result = ngx_http_push_stream_str_replace(tmp, find, replace, offset_found + replace->len, pool);
+        }
+    }
+
+    return result;
+}
+
+
+static ngx_str_t *
+ngx_http_push_stream_get_formatted_message(ngx_http_request_t *r, ngx_http_push_stream_channel_t *channel, ngx_http_push_stream_msg_t *message)
+{
+    ngx_http_push_stream_loc_conf_t        *pslcf = ngx_http_get_module_loc_conf(r, ngx_http_push_stream_module);
+    if (pslcf->message_template_index > 0) {
+        return message->formatted_messages + pslcf->message_template_index - 1;
+    }
+    return &message->raw;
+}
+
+
+static ngx_str_t *
+ngx_http_push_stream_format_message(ngx_http_push_stream_channel_t *channel, ngx_http_push_stream_msg_t *message, ngx_str_t *text, ngx_http_push_stream_template_t *template, ngx_pool_t *temp_pool)
+{
+    u_char                    *last;
+    ngx_str_t                 *txt = NULL;
+    size_t                     len = 0;
+    ngx_queue_t               *q;
+    u_char                     id[NGX_INT_T_LEN + 1];
+    u_char                     tag[NGX_INT_T_LEN + 1];
+    u_char                     size[NGX_INT_T_LEN + 1];
+    u_char                     time[NGX_HTTP_PUSH_STREAM_TIME_FMT_LEN + 1];
+    size_t                     id_len, tag_len, time_len, size_len;
+
+    ngx_str_t *channel_id = (channel != NULL) ? &channel->id : &NGX_HTTP_PUSH_STREAM_EMPTY;
+    ngx_str_t *event_id = (message->event_id != NULL) ? message->event_id : &NGX_HTTP_PUSH_STREAM_EMPTY;
+    ngx_str_t *event_type = (message->event_type != NULL) ? message->event_type : &NGX_HTTP_PUSH_STREAM_EMPTY;
+
+    ngx_sprintf(id, "%d%Z", message->id);
+    id_len = ngx_strlen(id);
+
+    last = ngx_http_time(time, message->time);
+    time_len = last - time;
+
+    ngx_sprintf(tag, "%d%Z", message->tag);
+    tag_len = ngx_strlen(tag);
+
+    ngx_sprintf(size, "%d%Z", text->len);
+    size_len = ngx_strlen(size);
+
+    len += template->qtd_channel * channel_id->len;
+    len += template->qtd_event_id * event_id->len;
+    len += template->qtd_event_type * event_type->len;
+    len += template->qtd_message_id * id_len;
+    len += template->qtd_time * time_len;
+    len += template->qtd_tag * tag_len;
+    len += template->qtd_text * text->len;
+    len += template->qtd_size * size_len;
+    len += template->literal_len;
+
+    txt = ngx_http_push_stream_create_str(temp_pool, len);
+    if (txt == NULL) {
+        ngx_log_error(NGX_LOG_ERR, temp_pool->log, 0, "push stream module: unable to allocate memory to format message");
+        return NULL;
+    }
+
+    last = txt->data;
+    for (q = ngx_queue_head(&template->parts); q != ngx_queue_sentinel(&template->parts); q = ngx_queue_next(q)) {
+        ngx_http_push_stream_template_parts_t *cur = ngx_queue_data(q, ngx_http_push_stream_template_parts_t, queue);
+        switch (cur->kind) {
+            case PUSH_STREAM_TEMPLATE_PART_TYPE_CHANNEL:
+                last = ngx_cpymem(last, channel_id->data, channel_id->len);
+                break;
+            case PUSH_STREAM_TEMPLATE_PART_TYPE_EVENT_ID:
+                last = ngx_cpymem(last, event_id->data, event_id->len);
+                break;
+            case PUSH_STREAM_TEMPLATE_PART_TYPE_EVENT_TYPE:
+                last = ngx_cpymem(last, event_type->data, event_type->len);
+                break;
+            case PUSH_STREAM_TEMPLATE_PART_TYPE_ID:
+                last = ngx_cpymem(last, id, id_len);
+                break;
+            case PUSH_STREAM_TEMPLATE_PART_TYPE_LITERAL:
+                last = ngx_cpymem(last, cur->text.data, cur->text.len);
+                break;
+            case PUSH_STREAM_TEMPLATE_PART_TYPE_TAG:
+                last = ngx_cpymem(last, tag, tag_len);
+                break;
+            case PUSH_STREAM_TEMPLATE_PART_TYPE_TEXT:
+                last = ngx_cpymem(last, text->data, text->len);
+                break;
+            case PUSH_STREAM_TEMPLATE_PART_TYPE_SIZE:
+                last = ngx_cpymem(last, size, size_len);
+                break;
+            case PUSH_STREAM_TEMPLATE_PART_TYPE_TIME:
+                last = ngx_cpymem(last, time, time_len);
+                break;
+            default:
+                break;
+        }
+    }
+
+    return txt;
+}
+
+
+static ngx_http_push_stream_module_ctx_t *
+ngx_http_push_stream_add_request_context(ngx_http_request_t *r)
+{
+    ngx_pool_cleanup_t                      *cln;
+    ngx_http_push_stream_module_ctx_t       *ctx = ngx_http_get_module_ctx(r, ngx_http_push_stream_module);
+
+    if (ctx != NULL) {
+        return ctx;
+    }
+
+    if ((ctx = ngx_pcalloc(r->pool, sizeof(ngx_http_push_stream_module_ctx_t))) == NULL) {
+        return NULL;
+    }
+
+    if ((cln = ngx_pool_cleanup_add(r->pool, 0)) == NULL) {
+        ngx_log_error(NGX_LOG_ERR, r->connection->log, 0, "push stream module: unable to allocate memory for cleanup");
+        return NULL;
+    }
+
+    if ((ctx->temp_pool = ngx_create_pool(4096, r->connection->log)) == NULL) {
+        return NULL;
+    }
+
+    ctx->busy = NULL;
+    ctx->free = NULL;
+    ctx->disconnect_timer = NULL;
+    ctx->ping_timer = NULL;
+    ctx->subscriber = NULL;
+    ctx->longpolling = 0;
+    ctx->message_sent = 0;
+    ctx->padding = NULL;
+    ctx->callback = NULL;
+    ctx->requested_channels = NULL;
+
+    // set a cleaner to request
+    cln->handler = (ngx_pool_cleanup_pt) ngx_http_push_stream_cleanup_request_context;
+    cln->data = r;
+
+    ngx_http_set_ctx(r, ctx, ngx_http_push_stream_module);
+
+    return ctx;
+}
+
+
+static void
+ngx_http_push_stream_cleanup_request_context(ngx_http_request_t *r)
+{
+    ngx_http_push_stream_module_ctx_t       *ctx = ngx_http_get_module_ctx(r, ngx_http_push_stream_module);
+
+    r->read_event_handler = ngx_http_request_empty_handler;
+
+    if (ctx != NULL) {
+        if ((ctx->disconnect_timer != NULL) && ctx->disconnect_timer->timer_set) {
+            ngx_del_timer(ctx->disconnect_timer);
+        }
+
+        if ((ctx->ping_timer != NULL) && ctx->ping_timer->timer_set) {
+            ngx_del_timer(ctx->ping_timer);
+        }
+
+        if (ctx->subscriber != NULL) {
+            ngx_http_push_stream_worker_subscriber_cleanup(ctx->subscriber);
+        }
+
+        if (ctx->temp_pool != NULL) {
+            ngx_destroy_pool(ctx->temp_pool);
+        }
+
+        ctx->temp_pool = NULL;
+        ctx->disconnect_timer = NULL;
+        ctx->ping_timer = NULL;
+        ctx->subscriber = NULL;
+    }
+}
+
+
+static void
+ngx_http_push_stream_worker_subscriber_cleanup(ngx_http_push_stream_subscriber_t *worker_subscriber)
+{
+    ngx_http_push_stream_main_conf_t        *mcf = ngx_http_get_module_main_conf(worker_subscriber->request, ngx_http_push_stream_module);
+    ngx_http_push_stream_shm_data_t         *data = mcf->shm_data;
+    ngx_slab_pool_t                         *shpool = mcf->shpool;
+    ngx_queue_t                             *cur;
+
+    while (!ngx_queue_empty(&worker_subscriber->subscriptions)) {
+        cur = ngx_queue_head(&worker_subscriber->subscriptions);
+        ngx_http_push_stream_subscription_t *subscription = ngx_queue_data(cur, ngx_http_push_stream_subscription_t, queue);
+        ngx_shmtx_lock(subscription->channel->mutex);
+        NGX_HTTP_PUSH_STREAM_DECREMENT_COUNTER(subscription->channel->subscribers);
+        NGX_HTTP_PUSH_STREAM_DECREMENT_COUNTER(subscription->channel_worker_sentinel->subscribers);
+        ngx_queue_remove(&subscription->channel_worker_queue);
+        ngx_queue_remove(&subscription->queue);
+        ngx_shmtx_unlock(subscription->channel->mutex);
+
+        ngx_http_push_stream_send_event(mcf, ngx_cycle->log, subscription->channel, &NGX_HTTP_PUSH_STREAM_EVENT_TYPE_CLIENT_UNSUBSCRIBED, worker_subscriber->request->pool);
+    }
+
+    ngx_shmtx_lock(&shpool->mutex);
+    ngx_queue_remove(&worker_subscriber->worker_queue);
+    NGX_HTTP_PUSH_STREAM_DECREMENT_COUNTER(data->subscribers);
+    NGX_HTTP_PUSH_STREAM_DECREMENT_COUNTER(data->ipc[ngx_process_slot].subscribers);
+    ngx_shmtx_unlock(&shpool->mutex);
+}
+
+
+static ngx_http_push_stream_content_subtype_t *
+ngx_http_push_stream_match_channel_info_format_and_content_type(ngx_http_request_t *r, ngx_uint_t default_subtype)
+{
+    ngx_uint_t      i;
+    ngx_http_push_stream_content_subtype_t *subtype = &subtypes[default_subtype];
+
+    if (r->headers_in.accept) {
+        u_char     *cur = r->headers_in.accept->value.data;
+        size_t      rem = 0;
+
+        while ((cur != NULL) && (cur = ngx_strnstr(cur, "/", r->headers_in.accept->value.len)) != NULL) {
+            cur = cur + 1;
+            rem = r->headers_in.accept->value.len - (r->headers_in.accept->value.data - cur);
+
+            for(i=0; i<(sizeof(subtypes) / sizeof(ngx_http_push_stream_content_subtype_t)); i++) {
+                if (ngx_strncmp(cur, subtypes[i].subtype, rem < subtypes[i].len ? rem : subtypes[i].len) == 0) {
+                    subtype = &subtypes[i];
+                    // force break while
+                    cur = NULL;
+                    break;
+                }
+            }
+        }
+    }
+
+    return subtype;
+}
+
+static ngx_str_t *
+ngx_http_push_stream_get_formatted_current_time(ngx_pool_t *pool)
+{
+    ngx_tm_t                            tm;
+    ngx_str_t                          *currenttime;
+
+    currenttime = ngx_http_push_stream_create_str(pool, 19); //ISO 8601 pattern
+    if (currenttime != NULL) {
+        ngx_gmtime(ngx_time(), &tm);
+        ngx_sprintf(currenttime->data, (char *) NGX_HTTP_PUSH_STREAM_DATE_FORMAT_ISO_8601.data, tm.ngx_tm_year, tm.ngx_tm_mon, tm.ngx_tm_mday, tm.ngx_tm_hour, tm.ngx_tm_min, tm.ngx_tm_sec);
+    } else {
+        currenttime = &NGX_HTTP_PUSH_STREAM_EMPTY;
+    }
+
+    return currenttime;
+}
+
+static ngx_str_t *
+ngx_http_push_stream_get_formatted_hostname(ngx_pool_t *pool)
+{
+    ngx_str_t                          *hostname;
+
+    hostname = ngx_http_push_stream_create_str(pool, sizeof(ngx_str_t) + ngx_cycle->hostname.len);
+    if (hostname != NULL) {
+        ngx_memcpy(hostname->data, ngx_cycle->hostname.data, ngx_cycle->hostname.len);
+    } else {
+        hostname = &NGX_HTTP_PUSH_STREAM_EMPTY;
+    }
+
+    return hostname;
+}
+
+
+uint64_t
+ngx_http_push_stream_htonll(uint64_t value) {
+    int num = 42;
+    if (*(char *)&num == 42) {
+        uint32_t high_part = htonl((uint32_t)(value >> 32));
+        uint32_t low_part = htonl((uint32_t)(value & 0xFFFFFFFFLL));
+        return (((uint64_t)low_part) << 32) | high_part;
+    } else {
+        return value;
+    }
+}
+
+
+uint64_t
+ngx_http_push_stream_ntohll(uint64_t value) {
+    int num = 42;
+    if (*(char *)&num == 42) {
+        uint32_t high_part = ntohl((uint32_t)(value >> 32));
+        uint32_t low_part = ntohl((uint32_t)(value & 0xFFFFFFFFLL));
+        return (((uint64_t)low_part) << 32) | high_part;
+    } else {
+        return value;
+    }
+}
+
+
+static ngx_str_t *
+ngx_http_push_stream_get_formatted_websocket_frame(const u_char *opcode, off_t opcode_len, const u_char *text, off_t len, ngx_pool_t *temp_pool)
+{
+    ngx_str_t            *frame;
+    u_char               *last;
+
+    frame = ngx_http_push_stream_create_str(temp_pool, NGX_HTTP_PUSH_STREAM_WEBSOCKET_FRAME_HEADER_MAX_LENGTH + len);
+    if (frame != NULL) {
+        last = ngx_copy(frame->data, opcode, opcode_len);
+
+        if (len <= 125) {
+            last = ngx_copy(last, &len, 1);
+        } else if (len < (1 << 16)) {
+            last = ngx_copy(last, &NGX_HTTP_PUSH_STREAM_WEBSOCKET_PAYLOAD_LEN_16_BYTE, sizeof(NGX_HTTP_PUSH_STREAM_WEBSOCKET_PAYLOAD_LEN_16_BYTE));
+            uint16_t len_net = htons(len);
+            last = ngx_copy(last, &len_net, 2);
+        } else {
+            last = ngx_copy(last, &NGX_HTTP_PUSH_STREAM_WEBSOCKET_PAYLOAD_LEN_64_BYTE, sizeof(NGX_HTTP_PUSH_STREAM_WEBSOCKET_PAYLOAD_LEN_64_BYTE));
+            uint64_t len_net = ngx_http_push_stream_htonll(len);
+            last = ngx_copy(last, &len_net, 8);
+        }
+        last = ngx_copy(last, text, len);
+        frame->len = last - frame->data;
+    }
+    return frame;
+}
+
+
+static ngx_str_t *
+ngx_http_push_stream_create_str(ngx_pool_t *pool, uint len)
+{
+    ngx_str_t *aux = (ngx_str_t *) ngx_pcalloc(pool, sizeof(ngx_str_t) + len + 1);
+    if (aux != NULL) {
+        aux->data = (u_char *) (aux + 1);
+        aux->len = len;
+        ngx_memset(aux->data, '\0', len + 1);
+    }
+    return aux;
+}
+
+
+static ngx_http_push_stream_line_t *
+ngx_http_push_stream_add_line_to_queue(ngx_queue_t *lines, u_char *text, u_int len, ngx_pool_t *temp_pool)
+{
+    ngx_http_push_stream_line_t        *cur = NULL;
+    ngx_str_t                          *line;
+    if (len > 0) {
+        cur = ngx_pcalloc(temp_pool, sizeof(ngx_http_push_stream_line_t));
+        line = ngx_http_push_stream_create_str(temp_pool, len);
+        if ((cur == NULL) || (line == NULL)) {
+            return NULL;
+        }
+        cur->line = line;
+        ngx_memcpy(cur->line->data, text, len);
+        ngx_queue_insert_tail(lines, &cur->queue);
+    }
+    return cur;
+}
+
+static ngx_queue_t *
+ngx_http_push_stream_split_by_crlf(ngx_str_t *msg, ngx_pool_t *temp_pool)
+{
+    ngx_queue_t                        *lines = NULL;
+    u_char                             *pos = NULL, *start = NULL, *crlf_pos, *cr_pos, *lf_pos;
+    u_int                               step = 0, len = 0;
+
+    if ((lines = ngx_pcalloc(temp_pool, sizeof(ngx_queue_t))) == NULL) {
+        return NULL;
+    }
+
+    ngx_queue_init(lines);
+
+    start = msg->data;
+    do {
+        crlf_pos = (u_char *) ngx_strstr(start, CRLF);
+        cr_pos = (u_char *) ngx_strstr(start, "\r");
+        lf_pos = (u_char *) ngx_strstr(start, "\n");
+
+        pos = crlf_pos;
+        step = 2;
+        if ((pos == NULL) || (cr_pos < pos)) {
+            pos = cr_pos;
+            step = 1;
+        }
+
+        if ((pos == NULL) || (lf_pos < pos)) {
+            pos = lf_pos;
+            step = 1;
+        }
+
+        if (pos != NULL) {
+            len = pos - start;
+            if ((len > 0) && (ngx_http_push_stream_add_line_to_queue(lines, start, len, temp_pool) == NULL)) {
+                return NULL;
+            }
+            start = pos + step;
+        }
+
+    } while (pos != NULL);
+
+    len = (msg->data + msg->len) - start;
+    if ((len > 0) && (ngx_http_push_stream_add_line_to_queue(lines, start, len, temp_pool) == NULL)) {
+        return NULL;
+    }
+
+    return lines;
+}
+
+
+static ngx_str_t *
+ngx_http_push_stream_join_with_crlf(ngx_queue_t *lines, ngx_pool_t *temp_pool)
+{
+    ngx_http_push_stream_line_t     *cur;
+    ngx_str_t                       *result = NULL, *tmp = &NGX_HTTP_PUSH_STREAM_EMPTY;
+    ngx_queue_t                     *q;
+
+    if (ngx_queue_empty(lines)) {
+        return &NGX_HTTP_PUSH_STREAM_EMPTY;
+    }
+
+    for (q = ngx_queue_head(lines); q != ngx_queue_sentinel(lines); q = ngx_queue_next(q)) {
+        cur = ngx_queue_data(q, ngx_http_push_stream_line_t, queue);
+
+        if ((cur->line == NULL) || (result = ngx_http_push_stream_create_str(temp_pool, tmp->len + cur->line->len)) == NULL) {
+            return NULL;
+        }
+
+        ngx_memcpy(result->data, tmp->data, tmp->len);
+        ngx_memcpy((result->data + tmp->len), cur->line->data, cur->line->len);
+
+        tmp = result;
+    }
+
+    return result;
+}
+
+
+static ngx_str_t *
+ngx_http_push_stream_apply_template_to_each_line(ngx_str_t *text, const ngx_str_t *message_template, ngx_pool_t *temp_pool)
+{
+    ngx_http_push_stream_line_t     *cur;
+    ngx_str_t                       *result = NULL;
+    ngx_queue_t                     *lines, *q;
+
+    lines = ngx_http_push_stream_split_by_crlf(text, temp_pool);
+    if (lines != NULL) {
+        for (q = ngx_queue_head(lines); q != ngx_queue_sentinel(lines); q = ngx_queue_next(q)) {
+            cur = ngx_queue_data(q, ngx_http_push_stream_line_t, queue);
+            cur->line = ngx_http_push_stream_str_replace(message_template, &NGX_HTTP_PUSH_STREAM_TOKEN_MESSAGE_TEXT, cur->line, 0, temp_pool);
+            if (cur->line == NULL) {
+                return NULL;
+            }
+        }
+        result = ngx_http_push_stream_join_with_crlf(lines, temp_pool);
+    }
+
+    return result;
+}
+
+static void
+ngx_http_push_stream_add_polling_headers(ngx_http_request_t *r, time_t last_modified_time, ngx_int_t tag, ngx_pool_t *temp_pool)
+{
+    ngx_http_push_stream_module_ctx_t          *ctx = ngx_http_get_module_ctx(r, ngx_http_push_stream_module);
+
+    if (ctx->callback != NULL) {
+        r->headers_out.content_type_len = NGX_HTTP_PUSH_STREAM_CALLBACK_CONTENT_TYPE.len;
+        r->headers_out.content_type = NGX_HTTP_PUSH_STREAM_CALLBACK_CONTENT_TYPE;
+    } else {
+        ngx_http_set_content_type(r);
+    }
+
+    if (last_modified_time > 0) {
+        r->headers_out.last_modified_time = last_modified_time;
+    }
+
+    if (tag >= 0) {
+        ngx_str_t *etag = ngx_http_push_stream_create_str(temp_pool, NGX_INT_T_LEN + 3);
+        if (etag != NULL) {
+            ngx_sprintf(etag->data, "W/%ui%Z", tag);
+            etag->len = ngx_strlen(etag->data);
+            r->headers_out.etag = ngx_http_push_stream_add_response_header(r, &NGX_HTTP_PUSH_STREAM_HEADER_ETAG, etag);
+        }
+    }
+}
+
+
+static void
+ngx_http_push_stream_get_last_received_message_values(ngx_http_request_t *r, time_t *if_modified_since, ngx_int_t *tag, ngx_str_t **last_event_id)
+{
+    ngx_http_push_stream_module_ctx_t              *ctx = ngx_http_get_module_ctx(r, ngx_http_push_stream_module);
+    ngx_http_push_stream_loc_conf_t                *cf = ngx_http_get_module_loc_conf(r, ngx_http_push_stream_module);
+    ngx_str_t                                      *etag = NULL, vv_etag = ngx_null_string;
+    ngx_str_t                                       vv_event_id = ngx_null_string, vv_time = ngx_null_string;
+
+    if (cf->last_received_message_time != NULL) {
+        ngx_http_push_stream_complex_value(r, cf->last_received_message_time, &vv_time);
+    } else if (r->headers_in.if_modified_since != NULL) {
+        vv_time = r->headers_in.if_modified_since->value;
+    }
+
+    if (cf->last_received_message_tag != NULL) {
+        ngx_http_push_stream_complex_value(r, cf->last_received_message_tag, &vv_etag);
+        etag = vv_etag.len ? &vv_etag : NULL;
+    } else {
+        etag = ngx_http_push_stream_get_header(r, &NGX_HTTP_PUSH_STREAM_HEADER_IF_NONE_MATCH);
+    }
+
+    if ((etag != NULL) && (etag->len > 2) && (etag->data[0] == 'W') && (etag->data[1] == '/')) {
+        etag->len -= 2;
+        etag->data = etag->data + 2;
+    }
+
+    if (cf->last_event_id != NULL) {
+        ngx_http_push_stream_complex_value(r, cf->last_event_id, &vv_event_id);
+        if (vv_event_id.len) {
+            *last_event_id = ngx_http_push_stream_create_str(ctx->temp_pool, vv_event_id.len);
+            ngx_memcpy(((ngx_str_t *)*last_event_id)->data, vv_event_id.data, vv_event_id.len);
+        }
+    } else {
+        *last_event_id = ngx_http_push_stream_get_header(r, &NGX_HTTP_PUSH_STREAM_HEADER_LAST_EVENT_ID);
+    }
+
+    *if_modified_since = vv_time.len ? ngx_http_parse_time(vv_time.data, vv_time.len) : -1;
+    *tag = ((etag != NULL) && ((*tag = ngx_atoi(etag->data, etag->len)) != NGX_ERROR)) ? ngx_abs(*tag) : -1;
+}
+
+
+/**
+ * Copied from nginx code to only send headers added on this module code
+ * */
+static ngx_int_t
+ngx_http_push_stream_send_only_added_headers(ngx_http_request_t *r)
+{
+    size_t                     len;
+    ngx_str_t                 *status_line = NULL;
+    ngx_buf_t                 *b;
+    ngx_uint_t                 i;
+    ngx_chain_t                out;
+    ngx_list_part_t           *part;
+    ngx_table_elt_t           *header;
+
+    if (r->header_sent) {
+        return NGX_OK;
+    }
+
+    r->header_sent = 1;
+
+    if (r != r->main) {
+        return NGX_OK;
+    }
+
+    if (r->http_version < NGX_HTTP_VERSION_10) {
+        return NGX_OK;
+    }
+
+    if (r->method == NGX_HTTP_HEAD) {
+        r->header_only = 1;
+    }
+
+    if (r->headers_out.last_modified_time != -1) {
+        if (r->headers_out.status != NGX_HTTP_OK
+            && r->headers_out.status != NGX_HTTP_PARTIAL_CONTENT
+            && r->headers_out.status != NGX_HTTP_NOT_MODIFIED)
+        {
+            r->headers_out.last_modified_time = -1;
+            r->headers_out.last_modified = NULL;
+        }
+    }
+
+    len = sizeof("HTTP/1.x ") - 1 + sizeof(CRLF) - 1
+          /* the end of the header */
+          + sizeof(CRLF) - 1;
+
+    /* status line */
+
+    if (r->headers_out.status_line.len) {
+        len += r->headers_out.status_line.len;
+        status_line = &r->headers_out.status_line;
+    }
+
+    part = &r->headers_out.headers.part;
+    header = part->elts;
+
+    for (i = 0; /* void */; i++) {
+
+        if (i >= part->nelts) {
+            if (part->next == NULL) {
+                break;
+            }
+
+            part = part->next;
+            header = part->elts;
+            i = 0;
+        }
+
+        if (header[i].hash == 0) {
+            continue;
+        }
+
+        len += header[i].key.len + sizeof(": ") - 1 + header[i].value.len + sizeof(CRLF) - 1;
+    }
+
+    b = ngx_create_temp_buf(r->pool, len);
+    if (b == NULL) {
+        return NGX_ERROR;
+    }
+
+    /* "HTTP/1.x " */
+    b->last = ngx_cpymem(b->last, "HTTP/1.1 ", sizeof("HTTP/1.x ") - 1);
+
+    /* status line */
+    if (status_line) {
+        b->last = ngx_copy(b->last, status_line->data, status_line->len);
+    }
+    *b->last++ = CR; *b->last++ = LF;
+
+    part = &r->headers_out.headers.part;
+    header = part->elts;
+
+    for (i = 0; /* void */; i++) {
+
+        if (i >= part->nelts) {
+            if (part->next == NULL) {
+                break;
+            }
+
+            part = part->next;
+            header = part->elts;
+            i = 0;
+        }
+
+        if (header[i].hash == 0) {
+            continue;
+        }
+
+        b->last = ngx_copy(b->last, header[i].key.data, header[i].key.len);
+        *b->last++ = ':'; *b->last++ = ' ';
+
+        b->last = ngx_copy(b->last, header[i].value.data, header[i].value.len);
+        *b->last++ = CR; *b->last++ = LF;
+    }
+
+    /* the end of HTTP header */
+    *b->last++ = CR; *b->last++ = LF;
+
+    r->header_size = b->last - b->pos;
+
+    if (r->header_only) {
+        b->last_buf = 1;
+    }
+
+    out.buf = b;
+    out.next = NULL;
+    b->flush = 1;
+    b->memory = 1;
+    b->temporary = 0;
+
+    return ngx_http_write_filter(r, &out);
+}
+
+
+static ngx_queue_t *
+ngx_http_push_stream_parse_paddings(ngx_conf_t *cf,  ngx_str_t *paddings_by_user_agent)
+{
+    ngx_int_t                           rc;
+    u_char                              errstr[NGX_MAX_CONF_ERRSTR];
+    ngx_regex_compile_t                 padding_rc, *agent_rc;
+    int                                 captures[12];
+    ngx_queue_t                        *paddings;
+    ngx_http_push_stream_padding_t     *padding;
+    ngx_str_t                           aux, *agent;
+
+
+    if ((paddings = ngx_pcalloc(cf->pool, sizeof(ngx_queue_t))) == NULL) {
+        ngx_conf_log_error(NGX_LOG_ERR, cf, 0, "push stream module: unable to allocate memory to save padding info");
+        return NULL;
+    }
+    ngx_queue_init(paddings);
+
+    ngx_memzero(&padding_rc, sizeof(ngx_regex_compile_t));
+
+    padding_rc.pattern = NGX_HTTP_PUSH_STREAM_PADDING_BY_USER_AGENT_PATTERN;
+    padding_rc.pool = cf->pool;
+    padding_rc.err.len = NGX_MAX_CONF_ERRSTR;
+    padding_rc.err.data = errstr;
+
+    if (ngx_regex_compile(&padding_rc) != NGX_OK) {
+        ngx_conf_log_error(NGX_LOG_ERR, cf, 0, "push stream module: unable to compile padding pattern %V", &NGX_HTTP_PUSH_STREAM_PADDING_BY_USER_AGENT_PATTERN);
+        return NULL;
+    }
+
+    aux.data = paddings_by_user_agent->data;
+    aux.len = paddings_by_user_agent->len;
+
+    do {
+        rc = ngx_regex_exec(padding_rc.regex, &aux, captures, 12);
+        if (rc == NGX_REGEX_NO_MATCHED) {
+            ngx_conf_log_error(NGX_LOG_ERR, cf, 0, "push stream module: padding pattern not match the value %V", &aux);
+            return NULL;
+        }
+
+        if (rc < 0) {
+            ngx_conf_log_error(NGX_LOG_ERR, cf, 0, "push stream module: error applying padding pattern to %V", &aux);
+            return NULL;
+        }
+
+        if (captures[0] != 0) {
+            ngx_conf_log_error(NGX_LOG_ERR, cf, 0, "push stream module: error applying padding pattern to %V", &aux);
+            return NULL;
+        }
+
+        if ((agent = ngx_http_push_stream_create_str(cf->pool, captures[3] - captures[2])) == NULL) {
+            ngx_conf_log_error(NGX_LOG_ERR, cf, 0, "video security module: unable to allocate memory to copy agent pattern");
+            return NGX_CONF_ERROR;
+        }
+        ngx_memcpy(agent->data, aux.data + captures[2], agent->len);
+
+        if ((agent_rc = ngx_pcalloc(cf->pool, sizeof(ngx_regex_compile_t))) == NULL) {
+            ngx_conf_log_error(NGX_LOG_ERR, cf, 0, "video security module: unable to allocate memory to compile agent patterns");
+            return NGX_CONF_ERROR;
+        }
+
+        agent_rc->pattern = *agent;
+        agent_rc->pool = cf->pool;
+        agent_rc->err.len = NGX_MAX_CONF_ERRSTR;
+        agent_rc->err.data = errstr;
+
+        if (ngx_regex_compile(agent_rc) != NGX_OK) {
+            ngx_conf_log_error(NGX_LOG_ERR, cf, 0, "push stream module: unable to compile agent pattern %V", &agent);
+            return NULL;
+        }
+
+        if ((padding = ngx_pcalloc(cf->pool, sizeof(ngx_http_push_stream_padding_t))) == NULL) {
+            ngx_conf_log_error(NGX_LOG_ERR, cf, 0, "push stream module: unable to allocate memory to save padding info");
+            return NULL;
+        }
+
+        padding->agent = agent_rc->regex;
+        padding->header_min_len = ngx_atoi(aux.data + captures[4], captures[5] - captures[4]);
+        padding->message_min_len = ngx_atoi(aux.data + captures[6], captures[7] - captures[6]);
+
+        ngx_queue_insert_tail(paddings, &padding->queue);
+
+        ngx_conf_log_error(NGX_LOG_INFO, cf, 0, "push stream module: padding detected %V, header_min_len %d, message_min_len %d", &agent_rc->pattern, padding->header_min_len, padding->message_min_len);
+
+        aux.data = aux.data + (captures[1] - captures[0] + 1);
+        aux.len  = aux.len - (captures[1] - captures[0] + 1);
+
+    } while (aux.data < (paddings_by_user_agent->data + paddings_by_user_agent->len));
+
+    return paddings;
+}
+
+
+static void
+ngx_http_push_stream_complex_value(ngx_http_request_t *r, ngx_http_complex_value_t *val, ngx_str_t *value)
+{
+    ngx_http_complex_value(r, val, value);
+    ngx_http_push_stream_unescape_uri(value);
+}
+
+
+static void
+ngx_http_push_stream_unescape_uri(ngx_str_t *value)
+{
+    u_char                                         *dst, *src;
+
+    if (value->len) {
+        dst = value->data;
+        src = value->data;
+        ngx_unescape_uri(&dst, &src, value->len, NGX_UNESCAPE_URI);
+        if (dst < src) {
+            *dst = '\0';
+            value->len = dst - value->data;
+        }
+    }
+}
+
+
+/**
+ * borrowed from Nginx core files
+ */
+static ngx_int_t
+ngx_http_push_stream_set_expires(ngx_http_request_t *r, ngx_http_push_stream_expires_t expires, time_t expires_time)
+{
+    size_t            len;
+    time_t            now, expires_header_time, max_age;
+    ngx_uint_t        i;
+    ngx_table_elt_t  *expires_header, *cc, **ccp;
+
+    expires_header = r->headers_out.expires;
+
+    if (expires_header == NULL) {
+
+        expires_header = ngx_list_push(&r->headers_out.headers);
+        if (expires_header == NULL) {
+            return NGX_ERROR;
+        }
+
+        r->headers_out.expires = expires_header;
+
+        expires_header->hash = 1;
+        ngx_str_set(&expires_header->key, "Expires");
+    }
+
+    len = sizeof("Mon, 28 Sep 1970 06:00:00 GMT");
+    expires_header->value.len = len - 1;
+
+    ccp = r->headers_out.cache_control.elts;
+
+    if (ccp == NULL) {
+
+        if (ngx_array_init(&r->headers_out.cache_control, r->pool, 1, sizeof(ngx_table_elt_t *)) != NGX_OK) {
+            return NGX_ERROR;
+        }
+
+        ccp = ngx_array_push(&r->headers_out.cache_control);
+        if (ccp == NULL) {
+            return NGX_ERROR;
+        }
+
+        cc = ngx_list_push(&r->headers_out.headers);
+        if (cc == NULL) {
+            return NGX_ERROR;
+        }
+
+        cc->hash = 1;
+        ngx_str_set(&cc->key, "Cache-Control");
+        *ccp = cc;
+
+    } else {
+        for (i = 1; i < r->headers_out.cache_control.nelts; i++) {
+            ccp[i]->hash = 0;
+        }
+
+        cc = ccp[0];
+    }
+
+    if (expires == NGX_HTTP_PUSH_STREAM_EXPIRES_EPOCH) {
+        expires_header->value.data = (u_char *) "Thu, 01 Jan 1970 00:00:01 GMT";
+        ngx_str_set(&cc->value, "no-cache, no-store, must-revalidate");
+        return NGX_OK;
+    }
+
+    if (expires == NGX_HTTP_PUSH_STREAM_EXPIRES_MAX) {
+        expires_header->value.data = (u_char *) "Thu, 31 Dec 2037 23:55:55 GMT";
+        /* 10 years */
+        ngx_str_set(&cc->value, "max-age=315360000");
+        return NGX_OK;
+    }
+
+    expires_header->value.data = ngx_pnalloc(r->pool, len);
+    if (expires_header->value.data == NULL) {
+        return NGX_ERROR;
+    }
+
+    if (expires_time == 0 && expires != NGX_HTTP_PUSH_STREAM_EXPIRES_DAILY) {
+        ngx_memcpy(expires_header->value.data, ngx_cached_http_time.data, ngx_cached_http_time.len + 1);
+        ngx_str_set(&cc->value, "max-age=0");
+        return NGX_OK;
+    }
+
+    now = ngx_time();
+
+    if (expires == NGX_HTTP_PUSH_STREAM_EXPIRES_DAILY) {
+        expires_header_time = ngx_next_time(expires_time);
+        max_age = expires_header_time - now;
+
+    } else if (expires == NGX_HTTP_PUSH_STREAM_EXPIRES_ACCESS || r->headers_out.last_modified_time == -1) {
+        expires_header_time = now + expires_time;
+        max_age = expires_time;
+
+    } else {
+        expires_header_time = r->headers_out.last_modified_time + expires_time;
+        max_age = expires_header_time - now;
+    }
+
+    ngx_http_time(expires_header->value.data, expires_header_time);
+
+    if (expires_time < 0 || max_age < 0) {
+        ngx_str_set(&cc->value, "no-cache, no-store, must-revalidate");
+        return NGX_OK;
+    }
+
+    cc->value.data = ngx_pnalloc(r->pool, sizeof("max-age=") + NGX_TIME_T_LEN + 1);
+    if (cc->value.data == NULL) {
+        return NGX_ERROR;
+    }
+
+    cc->value.len = ngx_sprintf(cc->value.data, "max-age=%T", max_age) - cc->value.data;
+
+    return NGX_OK;
+}
+
+
+ngx_http_push_stream_requested_channel_t *
+ngx_http_push_stream_parse_channels_ids_from_path(ngx_http_request_t *r, ngx_pool_t *pool) {
+    ngx_http_push_stream_main_conf_t               *mcf = ngx_http_get_module_main_conf(r, ngx_http_push_stream_module);
+    ngx_http_push_stream_loc_conf_t                *cf = ngx_http_get_module_loc_conf(r, ngx_http_push_stream_module);
+    ngx_str_t                                       vv_channels_path = ngx_null_string;
+    ngx_http_push_stream_requested_channel_t       *requested_channels, *requested_channel;
+    ngx_str_t                                       aux;
+    int                                             captures[15];
+    ngx_int_t                                       n;
+
+    ngx_http_push_stream_complex_value(r, cf->channels_path, &vv_channels_path);
+    if (vv_channels_path.len == 0) {
+        return NULL;
+    }
+
+    if ((requested_channels = ngx_pcalloc(pool, sizeof(ngx_http_push_stream_requested_channel_t))) == NULL) {
+        ngx_log_error(NGX_LOG_ERR, r->connection->log, 0, "push stream module: unable to allocate memory for requested_channels queue");
+        return NULL;
+    }
+
+    ngx_queue_init(&requested_channels->queue);
+
+    // doing the parser of given channel path
+    aux.data = vv_channels_path.data;
+    do {
+        aux.len = vv_channels_path.len - (aux.data - vv_channels_path.data);
+        if ((n = ngx_regex_exec(mcf->backtrack_parser_regex, &aux, captures, 15)) >= 0) {
+            if ((requested_channel = ngx_pcalloc(pool, sizeof(ngx_http_push_stream_requested_channel_t))) == NULL) {
+                ngx_log_error(NGX_LOG_ERR, r->connection->log, 0, "push stream module: unable to allocate memory for channel_id item");
+                return NULL;
+            }
+
+            if ((requested_channel->id = ngx_http_push_stream_create_str(pool, captures[0])) == NULL) {
+                ngx_log_error(NGX_LOG_ERR, r->connection->log, 0, "push stream module: unable to allocate memory for channel_id string");
+                return NULL;
+            }
+            ngx_memcpy(requested_channel->id->data, aux.data, captures[0]);
+            requested_channel->backtrack_messages = 0;
+            if (captures[7] > captures[6]) {
+                requested_channel->backtrack_messages = ngx_atoi(aux.data + captures[6], captures[7] - captures[6]);
+            }
+
+            ngx_queue_insert_tail(&requested_channels->queue, &requested_channel->queue);
+
+            aux.data = aux.data + captures[1];
+        }
+    } while ((n != NGX_REGEX_NO_MATCHED) && (aux.data < (vv_channels_path.data + vv_channels_path.len)));
+
+    return requested_channels;
+}
+
+
+ngx_int_t
+ngx_http_push_stream_create_shmtx(ngx_shmtx_t *mtx, ngx_shmtx_sh_t *addr, u_char *name)
+{
+    u_char           *file;
+
+#if (NGX_HAVE_ATOMIC_OPS)
+
+    file = NULL;
+
+#else
+
+    ngx_str_t        logs_dir = ngx_string("logs/");
+
+    if (ngx_conf_full_name((ngx_cycle_t  *) ngx_cycle, &logs_dir, 0) != NGX_OK) {
+        return NGX_ERROR;
+    }
+
+    file = ngx_pnalloc(ngx_cycle->pool, logs_dir.len + ngx_strlen(name));
+    if (file == NULL) {
+        return NGX_ERROR;
+    }
+
+    (void) ngx_sprintf(file, "%V%s%Z", &logs_dir, name);
+
+#endif
+
+    if (ngx_shmtx_create(mtx, addr, file) != NGX_OK) {
+        return NGX_ERROR;
+    }
+
+    return NGX_OK;
+}
+
+
+ngx_flag_t
+ngx_http_push_stream_is_utf8(u_char *p, size_t n)
+{
+    u_char  c, *last;
+    size_t  len;
+
+    last = p + n;
+
+    for (len = 0; p < last; len++) {
+
+        c = *p;
+
+        if (c < 0x80) {
+            p++;
+            continue;
+        }
+
+        if (ngx_utf8_decode(&p, n) > 0x10ffff) {
+            /* invalid UTF-8 */
+            return 0;
+        }
+    }
+
+    return 1;
+}
diff -Naur nginx-1.11.3/nginx-push-stream-module/src/ngx_http_push_stream_module_websocket.c nginx-1.11.3-push/nginx-push-stream-module/src/ngx_http_push_stream_module_websocket.c
--- nginx-1.11.3/nginx-push-stream-module/src/ngx_http_push_stream_module_websocket.c	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/src/ngx_http_push_stream_module_websocket.c	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,479 @@
+/*
+ * Copyright (C) 2010-2015 Wandenberg Peixoto <wandenberg@gmail.com>, Rog√©rio Carvalho Schneider <stockrt@gmail.com>
+ *
+ * This file is part of Nginx Push Stream Module.
+ *
+ * Nginx Push Stream Module is free software: you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License as published by
+ * the Free Software Foundation, either version 3 of the License, or
+ * (at your option) any later version.
+ *
+ * Nginx Push Stream Module is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with Nginx Push Stream Module.  If not, see <http://www.gnu.org/licenses/>.
+ *
+ *
+ * ngx_http_push_stream_module_websocket.c
+ *
+ * Created: Oct 20, 2011
+ * Authors: Wandenberg Peixoto <wandenberg@gmail.com>, Rog√©rio Carvalho Schneider <stockrt@gmail.com>
+ */
+
+#include <ngx_http_push_stream_module_websocket.h>
+
+ngx_str_t *ngx_http_push_stream_generate_websocket_accept_value(ngx_http_request_t *r, ngx_str_t *sec_key, ngx_pool_t *temp_pool);
+ngx_int_t  ngx_http_push_stream_recv(ngx_connection_t *c, ngx_event_t *rev, ngx_buf_t *buf, ssize_t len);
+void       ngx_http_push_stream_set_buffer(ngx_buf_t *buf, u_char *start, u_char *last, ssize_t len);
+
+static ngx_int_t
+ngx_http_push_stream_websocket_handler(ngx_http_request_t *r)
+{
+#if !(NGX_HAVE_SHA1)
+    ngx_log_error(NGX_LOG_ERR, r->connection->log, 0, "push stream module: sha1 support is needed to use WebSocket");
+    return NGX_OK;
+#endif
+    ngx_http_push_stream_main_conf_t               *mcf = ngx_http_get_module_main_conf(r, ngx_http_push_stream_module);
+    ngx_http_push_stream_loc_conf_t                *cf = ngx_http_get_module_loc_conf(r, ngx_http_push_stream_module);
+    ngx_http_push_stream_subscriber_t              *worker_subscriber;
+    ngx_http_push_stream_requested_channel_t       *requested_channels, *requested_channel;
+    ngx_queue_t                                    *q;
+    ngx_http_push_stream_module_ctx_t              *ctx;
+    ngx_int_t                                       tag;
+    time_t                                          if_modified_since;
+    ngx_str_t                                      *last_event_id = NULL;
+    ngx_int_t                                       status_code;
+    ngx_str_t                                      *explain_error_message;
+    ngx_str_t                                      *upgrade_header, *connection_header, *sec_key_header, *sec_version_header, *sec_accept_header;
+    ngx_int_t                                       version;
+
+    // WebSocket connections must not use keepalive
+    r->keepalive = 0;
+
+    // only accept GET method
+    if (!(r->method & NGX_HTTP_GET)) {
+        ngx_http_push_stream_add_response_header(r, &NGX_HTTP_PUSH_STREAM_HEADER_ALLOW, &NGX_HTTP_PUSH_STREAM_ALLOW_GET);
+        return ngx_http_push_stream_send_only_header_response(r, NGX_HTTP_NOT_ALLOWED, NULL);
+    }
+
+    ngx_http_push_stream_set_expires(r, NGX_HTTP_PUSH_STREAM_EXPIRES_EPOCH, 0);
+
+    upgrade_header = ngx_http_push_stream_get_header(r, &NGX_HTTP_PUSH_STREAM_HEADER_UPGRADE);
+    connection_header = ngx_http_push_stream_get_header(r, &NGX_HTTP_PUSH_STREAM_HEADER_CONNECTION);
+    sec_key_header = ngx_http_push_stream_get_header(r, &NGX_HTTP_PUSH_STREAM_HEADER_SEC_WEBSOCKET_KEY);
+    sec_version_header = ngx_http_push_stream_get_header(r, &NGX_HTTP_PUSH_STREAM_HEADER_SEC_WEBSOCKET_VERSION);
+
+    if ((upgrade_header == NULL) || (connection_header == NULL) || (sec_key_header == NULL) || (sec_version_header == NULL)) {
+        ngx_log_error(NGX_LOG_ERR, r->connection->log, 0, "push stream module: %V", &NGX_HTTP_PUSH_STREAM_NO_MANDATORY_HEADERS_MESSAGE);
+        return ngx_http_push_stream_send_only_header_response(r, NGX_HTTP_BAD_REQUEST, &NGX_HTTP_PUSH_STREAM_NO_MANDATORY_HEADERS_MESSAGE);
+    }
+
+    version = ngx_atoi(sec_version_header->data, sec_version_header->len);
+    if ((version != NGX_HTTP_PUSH_STREAM_WEBSOCKET_VERSION_8) && (version != NGX_HTTP_PUSH_STREAM_WEBSOCKET_VERSION_13)) {
+        ngx_log_error(NGX_LOG_ERR, r->connection->log, 0, "push stream module: version: %d %V", version, &NGX_HTTP_PUSH_STREAM_WRONG_WEBSOCKET_VERSION_MESSAGE);
+        ngx_http_push_stream_add_response_header(r, &NGX_HTTP_PUSH_STREAM_HEADER_SEC_WEBSOCKET_VERSION, &NGX_HTTP_PUSH_STREAM_WEBSOCKET_SUPPORTED_VERSIONS);
+        return ngx_http_push_stream_send_only_header_response(r, NGX_HTTP_BAD_REQUEST, &NGX_HTTP_PUSH_STREAM_WRONG_WEBSOCKET_VERSION_MESSAGE);
+    }
+
+    if ((ctx = ngx_http_push_stream_add_request_context(r)) == NULL) {
+        ngx_log_error(NGX_LOG_ERR, r->connection->log, 0, "push stream module: unable to create request context");
+        return NGX_HTTP_INTERNAL_SERVER_ERROR;
+    }
+
+    if ((ctx->frame = ngx_pcalloc(r->pool, sizeof(ngx_http_push_stream_frame_t))) == NULL) {
+        ngx_log_error(NGX_LOG_ERR, r->connection->log, 0, "push stream module: unable to create frame structure");
+        return NGX_HTTP_INTERNAL_SERVER_ERROR;
+    }
+    ctx->frame->step = NGX_HTTP_PUSH_STREAM_WEBSOCKET_READ_START_STEP;
+    ctx->frame->payload = NULL;
+    ctx->frame->last_fragment = 0;
+    ctx->frame->fragmented = 0;
+    ngx_str_set(&ctx->frame->consolidated, "");
+    ngx_http_push_stream_set_buffer(&ctx->frame->buf, ctx->frame->header, NULL, 8);
+
+    if ((sec_accept_header = ngx_http_push_stream_generate_websocket_accept_value(r, sec_key_header, ctx->temp_pool)) == NULL) {
+        ngx_log_error(NGX_LOG_WARN, r->connection->log, 0, "push stream module: could not generate security accept header value");
+        return NGX_HTTP_INTERNAL_SERVER_ERROR;
+    }
+
+    ngx_http_push_stream_add_response_header(r, &NGX_HTTP_PUSH_STREAM_HEADER_UPGRADE, &NGX_HTTP_PUSH_STREAM_WEBSOCKET_UPGRADE);
+    ngx_http_push_stream_add_response_header(r, &NGX_HTTP_PUSH_STREAM_HEADER_CONNECTION, &NGX_HTTP_PUSH_STREAM_WEBSOCKET_CONNECTION);
+    ngx_http_push_stream_add_response_header(r, &NGX_HTTP_PUSH_STREAM_HEADER_SEC_WEBSOCKET_ACCEPT, sec_accept_header);
+    r->headers_out.status_line = NGX_HTTP_PUSH_STREAM_101_STATUS_LINE;
+
+    ngx_http_push_stream_send_only_added_headers(r);
+
+    //get channels ids and backtracks from path
+    requested_channels = ngx_http_push_stream_parse_channels_ids_from_path(r, ctx->temp_pool);
+    if ((requested_channels == NULL) || ngx_queue_empty(&requested_channels->queue)) {
+        ngx_log_error(NGX_LOG_WARN, r->connection->log, 0, "push stream module: the push_stream_channels_path is required but is not set");
+        return ngx_http_push_stream_send_only_header_response(r, NGX_HTTP_BAD_REQUEST, &NGX_HTTP_PUSH_STREAM_NO_CHANNEL_ID_MESSAGE);
+    }
+
+    //validate channels: name, length and quantity. check if channel exists when authorized_channels_only is on. check if channel is full of subscribers
+    if (ngx_http_push_stream_validate_channels(r, requested_channels, &status_code, &explain_error_message) == NGX_ERROR) {
+        return ngx_http_push_stream_send_websocket_close_frame(r, status_code, explain_error_message);
+    }
+
+    // get control values
+    ngx_http_push_stream_get_last_received_message_values(r, &if_modified_since, &tag, &last_event_id);
+
+    // stream access
+    if ((worker_subscriber = ngx_http_push_stream_subscriber_prepare_request_to_keep_connected(r)) == NULL) {
+        return ngx_http_push_stream_send_websocket_close_frame(r, NGX_HTTP_INTERNAL_SERVER_ERROR, &NGX_HTTP_PUSH_STREAM_EMPTY);
+    }
+
+    // sending response content header
+    if (ngx_http_push_stream_send_response_content_header(r, cf) == NGX_ERROR) {
+        ngx_log_error(NGX_LOG_ERR, r->connection->log, 0, "push stream module: could not send content header to subscriber");
+        return ngx_http_push_stream_send_websocket_close_frame(r, NGX_HTTP_INTERNAL_SERVER_ERROR, &NGX_HTTP_PUSH_STREAM_EMPTY);
+    }
+
+    if (ngx_http_push_stream_registry_subscriber(r, worker_subscriber) == NGX_ERROR) {
+        return ngx_http_push_stream_send_websocket_close_frame(r, NGX_HTTP_INTERNAL_SERVER_ERROR, &NGX_HTTP_PUSH_STREAM_EMPTY);
+    }
+
+    // adding subscriber to channel(s) and send backtrack messages
+    for (q = ngx_queue_head(&requested_channels->queue); q != ngx_queue_sentinel(&requested_channels->queue); q = ngx_queue_next(q)) {
+        requested_channel = ngx_queue_data(q, ngx_http_push_stream_requested_channel_t, queue);
+        if (ngx_http_push_stream_subscriber_assign_channel(mcf, cf, r, requested_channel, if_modified_since, tag, last_event_id, worker_subscriber, ctx->temp_pool) != NGX_OK) {
+            return ngx_http_push_stream_send_websocket_close_frame(r, NGX_HTTP_INTERNAL_SERVER_ERROR, &NGX_HTTP_PUSH_STREAM_EMPTY);
+        }
+    }
+
+    if (ctx->temp_pool != NULL) {
+        ngx_destroy_pool(ctx->temp_pool);
+        ctx->temp_pool = NULL;
+    }
+    return NGX_DONE;
+}
+
+
+ngx_str_t *
+ngx_http_push_stream_generate_websocket_accept_value(ngx_http_request_t *r, ngx_str_t *sec_key, ngx_pool_t *temp_pool)
+{
+#if (NGX_HAVE_SHA1)
+    ngx_str_t    *sha1_signed, *accept_value;
+    ngx_sha1_t   sha1;
+
+    sha1_signed = ngx_http_push_stream_create_str(temp_pool, NGX_HTTP_PUSH_STREAM_WEBSOCKET_SHA1_SIGNED_HASH_LENGTH);
+    accept_value = ngx_http_push_stream_create_str(r->pool, ngx_base64_encoded_length(NGX_HTTP_PUSH_STREAM_WEBSOCKET_SHA1_SIGNED_HASH_LENGTH));
+
+    if ((sha1_signed == NULL) || (accept_value == NULL)) {
+        return NULL;
+    }
+
+    ngx_sha1_init(&sha1);
+    ngx_sha1_update(&sha1, sec_key->data, sec_key->len);
+    ngx_sha1_update(&sha1, NGX_HTTP_PUSH_STREAM_WEBSOCKET_SIGN_KEY.data, NGX_HTTP_PUSH_STREAM_WEBSOCKET_SIGN_KEY.len);
+    ngx_sha1_final(sha1_signed->data, &sha1);
+
+    ngx_encode_base64(accept_value, sha1_signed);
+
+    return accept_value;
+#else
+    return NULL;
+#endif
+}
+
+
+void
+ngx_http_push_stream_websocket_reading(ngx_http_request_t *r)
+{
+    ngx_http_push_stream_main_conf_t  *mcf = ngx_http_get_module_main_conf(r, ngx_http_push_stream_module);
+    ngx_http_push_stream_loc_conf_t   *cf = ngx_http_get_module_loc_conf(r, ngx_http_push_stream_module);
+    ngx_http_push_stream_module_ctx_t *ctx = ngx_http_get_module_ctx(r, ngx_http_push_stream_module);
+    ngx_int_t                          rc = NGX_OK;
+    ngx_event_t                       *rev;
+    ngx_connection_t                  *c;
+    uint64_t                           i;
+    ngx_queue_t                       *q;
+    u_char                            *aux, *last;
+    unsigned char                      opcode;
+
+    ngx_http_push_stream_set_buffer(&ctx->frame->buf, ctx->frame->buf.start, ctx->frame->buf.last, 0);
+
+    c = r->connection;
+    rev = c->read;
+
+    for (;;) {
+        if (c->error || c->timedout || c->close || c->destroyed || rev->closed || rev->eof) {
+            goto finalize;
+        }
+
+        switch (ctx->frame->step) {
+            case NGX_HTTP_PUSH_STREAM_WEBSOCKET_READ_START_STEP:
+                //reading frame header
+                if ((rc = ngx_http_push_stream_recv(c, rev, &ctx->frame->buf, 2)) != NGX_OK) {
+                    goto exit;
+                }
+
+                ctx->frame->fin  = (ctx->frame->header[0] >> 7) & 1;
+                ctx->frame->rsv1 = (ctx->frame->header[0] >> 6) & 1;
+                ctx->frame->rsv2 = (ctx->frame->header[0] >> 5) & 1;
+                ctx->frame->rsv3 = (ctx->frame->header[0] >> 4) & 1;
+                opcode           = ctx->frame->header[0] & 0xf;
+
+                ctx->frame->mask = (ctx->frame->header[1] >> 7) & 1;
+                ctx->frame->payload_len = ctx->frame->header[1] & 0x7f;
+
+                if (ctx->frame->fin == 0) {
+                    if (opcode == 0) {
+                        if (!ctx->frame->fragmented) {
+                            ngx_log_error(NGX_LOG_ERR, r->connection->log, 0, "push stream module: wrong websocket frames sequence");
+                            goto close;
+                        }
+                    } else {
+                        if (!ctx->frame->fragmented) {
+                            ctx->frame->fragmented = 1;
+                            ctx->frame->opcode = opcode;
+                        }
+                    }
+                } else {
+                    if (opcode == 0) {
+                        if (ctx->frame->fragmented) {
+                            ctx->frame->last_fragment = 1;
+                        } else {
+                            ngx_log_error(NGX_LOG_ERR, r->connection->log, 0, "push stream module: wrong websocket frames sequence");
+                            goto close;
+                        }
+                    } else {
+                        if (ctx->frame->fragmented) {
+                            ngx_log_error(NGX_LOG_ERR, r->connection->log, 0, "push stream module: wrong websocket frames sequence");
+                            goto close;
+                        } else {
+                            ctx->frame->last_fragment = 1;
+                            ctx->frame->opcode = opcode;
+                        }
+                    }
+                }
+
+                if ((ctx->frame->payload_len == 126) || (ctx->frame->payload_len == 127)) {
+                    ctx->frame->step = NGX_HTTP_PUSH_STREAM_WEBSOCKET_READ_GET_REAL_SIZE_STEP;
+                    ngx_http_push_stream_set_buffer(&ctx->frame->buf, ctx->frame->header, NULL, 8);
+                } else if (ctx->frame->mask) {
+                    ctx->frame->step = NGX_HTTP_PUSH_STREAM_WEBSOCKET_READ_GET_MASK_KEY_STEP;
+                    ngx_http_push_stream_set_buffer(&ctx->frame->buf, ctx->frame->mask_key, NULL, 4);
+                } else {
+                    ctx->frame->step = NGX_HTTP_PUSH_STREAM_WEBSOCKET_READ_GET_PAYLOAD_STEP;
+                }
+
+                break;
+
+            case NGX_HTTP_PUSH_STREAM_WEBSOCKET_READ_GET_REAL_SIZE_STEP:
+
+                if (ctx->frame->payload_len == 126) {
+                    if ((rc = ngx_http_push_stream_recv(c, rev, &ctx->frame->buf, 2)) != NGX_OK) {
+                        goto exit;
+                    }
+                    uint16_t len;
+                    ngx_memcpy(&len, ctx->frame->header, 2);
+                    ctx->frame->payload_len = ntohs(len);
+                } else if (ctx->frame->payload_len == 127) {
+                    if ((rc = ngx_http_push_stream_recv(c, rev, &ctx->frame->buf, 8)) != NGX_OK) {
+                        goto exit;
+                    }
+                    uint64_t len;
+                    ngx_memcpy(&len, ctx->frame->header, 8);
+                    ctx->frame->payload_len = ngx_http_push_stream_ntohll(len);
+                }
+
+                if (ctx->frame->mask) {
+                    ctx->frame->step = NGX_HTTP_PUSH_STREAM_WEBSOCKET_READ_GET_MASK_KEY_STEP;
+                    ngx_http_push_stream_set_buffer(&ctx->frame->buf, ctx->frame->mask_key, NULL, 4);
+                } else {
+                    ctx->frame->step = NGX_HTTP_PUSH_STREAM_WEBSOCKET_READ_GET_PAYLOAD_STEP;
+                }
+
+                break;
+
+            case NGX_HTTP_PUSH_STREAM_WEBSOCKET_READ_GET_MASK_KEY_STEP:
+
+                if ((rc = ngx_http_push_stream_recv(c, rev, &ctx->frame->buf, 4)) != NGX_OK) {
+                    goto exit;
+                }
+
+                ctx->frame->step = NGX_HTTP_PUSH_STREAM_WEBSOCKET_READ_GET_PAYLOAD_STEP;
+
+                break;
+
+            case NGX_HTTP_PUSH_STREAM_WEBSOCKET_READ_GET_PAYLOAD_STEP:
+                if (
+                    (ctx->frame->opcode != NGX_HTTP_PUSH_STREAM_WEBSOCKET_TEXT_OPCODE) &&
+                    (ctx->frame->opcode != NGX_HTTP_PUSH_STREAM_WEBSOCKET_CLOSE_OPCODE) &&
+                    (ctx->frame->opcode != NGX_HTTP_PUSH_STREAM_WEBSOCKET_PING_OPCODE) &&
+                    (ctx->frame->opcode != NGX_HTTP_PUSH_STREAM_WEBSOCKET_PONG_OPCODE)
+                   ) {
+                    goto close;
+                }
+
+                if (ctx->frame->payload_len > 0) {
+                    //create a temporary pool to allocate temporary elements
+                    if (ctx->temp_pool == NULL) {
+                        if ((ctx->temp_pool = ngx_create_pool(4096, r->connection->log)) == NULL) {
+                            ngx_log_error(NGX_LOG_ERR, r->connection->log, 0, "push stream module: unable to allocate memory for temporary pool");
+                            goto finalize;
+                        }
+
+                    }
+
+                    if (ctx->frame->payload == NULL) {
+                        if ((ctx->frame->payload = ngx_pcalloc(ctx->temp_pool, ctx->frame->payload_len)) == NULL) {
+                            ngx_log_error(NGX_LOG_ERR, r->connection->log, 0, "push stream module: unable to allocate memory for payload");
+                            goto finalize;
+                        }
+
+                        ngx_http_push_stream_set_buffer(&ctx->frame->buf, ctx->frame->payload, NULL, ctx->frame->payload_len);
+                    }
+
+                    if ((rc = ngx_http_push_stream_recv(c, rev, &ctx->frame->buf, ctx->frame->payload_len)) != NGX_OK) {
+                        goto exit;
+                    }
+
+                    if (ctx->frame->mask) {
+                        for (i = 0; i < ctx->frame->payload_len; i++) {
+                            ctx->frame->payload[i] = ctx->frame->payload[i] ^ ctx->frame->mask_key[i % 4];
+                        }
+                    }
+
+                    if (!ngx_http_push_stream_is_utf8(ctx->frame->payload, ctx->frame->payload_len)) {
+                        goto finalize;
+                    }
+
+                    if (ctx->frame->fragmented) {
+                        if (ctx->frame->consolidated.len == 0) {
+                            ctx->frame->consolidated.data = ctx->frame->payload;
+                            ctx->frame->consolidated.len = ctx->frame->payload_len;
+                        } else {
+                            if ((aux = ngx_pcalloc(ctx->temp_pool, ctx->frame->payload_len + ctx->frame->consolidated.len)) == NULL) {
+                                ngx_log_error(NGX_LOG_ERR, r->connection->log, 0, "push stream module: unable to allocate memory for consolidated payload for %ui bytes", ctx->frame->payload_len + ctx->frame->consolidated.len);
+                                goto finalize;
+                            }
+                            last = ngx_cpymem(aux, ctx->frame->consolidated.data, ctx->frame->consolidated.len);
+                            ngx_memcpy(last, ctx->frame->payload, ctx->frame->payload_len);
+                            ctx->frame->consolidated.data = aux;
+                            ctx->frame->consolidated.len = ctx->frame->payload_len + ctx->frame->consolidated.len;
+                        }
+
+                        if (ctx->frame->last_fragment) {
+                            ctx->frame->payload = ctx->frame->consolidated.data;
+                            ctx->frame->payload_len = ctx->frame->consolidated.len;
+                        }
+                    }
+
+                    if (cf->websocket_allow_publish && ctx->frame->last_fragment && (ctx->frame->opcode == NGX_HTTP_PUSH_STREAM_WEBSOCKET_TEXT_OPCODE)) {
+                        for (q = ngx_queue_head(&ctx->subscriber->subscriptions); q != ngx_queue_sentinel(&ctx->subscriber->subscriptions); q = ngx_queue_next(q)) {
+                            ngx_http_push_stream_subscription_t *subscription = ngx_queue_data(q, ngx_http_push_stream_subscription_t, queue);
+                            if (subscription->channel->for_events) {
+                                // skip events channel on publish by websocket connections
+                                continue;
+                            }
+
+                            if (ngx_http_push_stream_add_msg_to_channel(mcf, r->connection->log, subscription->channel, ctx->frame->payload, ctx->frame->payload_len, NULL, NULL, cf->store_messages, ctx->temp_pool) != NGX_OK) {
+                                goto finalize;
+                            }
+                        }
+                    }
+                }
+
+                if (ctx->frame->last_fragment) {
+                    ctx->frame->last_fragment = 0;
+                    ctx->frame->fragmented = 0;
+                    ngx_str_set(&ctx->frame->consolidated, "");
+
+                    if (ctx->temp_pool != NULL) {
+                        ngx_destroy_pool(ctx->temp_pool);
+                        ctx->temp_pool = NULL;
+                    }
+                }
+                ctx->frame->step = NGX_HTTP_PUSH_STREAM_WEBSOCKET_READ_START_STEP;
+                ctx->frame->payload = NULL;
+                ngx_http_push_stream_set_buffer(&ctx->frame->buf, ctx->frame->header, NULL, 8);
+
+                if (ctx->frame->opcode == NGX_HTTP_PUSH_STREAM_WEBSOCKET_PING_OPCODE) {
+                    ngx_http_push_stream_send_response_text(r, NGX_HTTP_PUSH_STREAM_WEBSOCKET_PONG_LAST_FRAME_BYTE, sizeof(NGX_HTTP_PUSH_STREAM_WEBSOCKET_PONG_LAST_FRAME_BYTE), 1);
+                }
+
+                if (ctx->frame->opcode == NGX_HTTP_PUSH_STREAM_WEBSOCKET_CLOSE_OPCODE) {
+                    goto close;
+                }
+                return;
+
+                break;
+
+            default:
+                ngx_log_debug(NGX_LOG_DEBUG, c->log, 0, "push stream module: unknown websocket step (%d)", ctx->frame->step);
+                goto finalize;
+                break;
+        }
+    }
+
+exit:
+    if (rc == NGX_AGAIN) {
+        if (!c->read->ready) {
+            if (ngx_handle_read_event(c->read, 0) != NGX_OK) {
+                ngx_log_error(NGX_LOG_INFO, c->log, ngx_socket_errno, "push stream module: failed to restore read events");
+                goto finalize;
+            }
+        }
+    }
+
+    if (rc == NGX_ERROR) {
+        rev->eof = 1;
+        c->error = 1;
+        ngx_log_error(NGX_LOG_INFO, c->log, ngx_socket_errno, "push stream module: client closed prematurely connection");
+        goto finalize;
+    }
+
+    return;
+
+close:
+    ngx_http_push_stream_send_response_text(r, NGX_HTTP_PUSH_STREAM_WEBSOCKET_CLOSE_LAST_FRAME_BYTE, sizeof(NGX_HTTP_PUSH_STREAM_WEBSOCKET_CLOSE_LAST_FRAME_BYTE), 1);
+
+finalize:
+    ngx_http_push_stream_run_cleanup_pool_handler(r->pool, (ngx_pool_cleanup_pt) ngx_http_push_stream_cleanup_request_context);
+    ngx_http_finalize_request(r, c->error ? NGX_HTTP_CLIENT_CLOSED_REQUEST : NGX_OK);
+}
+
+
+ngx_int_t
+ngx_http_push_stream_recv(ngx_connection_t *c, ngx_event_t *rev, ngx_buf_t *buf, ssize_t len)
+{
+    ssize_t size = len - (buf->last - buf->start);
+    if (size == 0) {
+        return NGX_OK;
+    }
+
+    ssize_t n = c->recv(c, buf->last, size);
+
+    if (n == NGX_AGAIN) {
+        return NGX_AGAIN;
+    }
+
+    if ((n == NGX_ERROR) || (n == 0)) {
+        return NGX_ERROR;
+    }
+
+    buf->last += n;
+
+    if ((buf->last - buf->start) < len) {
+        return NGX_AGAIN;
+    }
+
+    return NGX_OK;
+}
+
+
+void
+ngx_http_push_stream_set_buffer(ngx_buf_t *buf, u_char *start, u_char *last, ssize_t len)
+{
+    buf->start = start;
+    buf->pos = buf->start;
+    buf->last = (last != NULL) ? last : start;
+    buf->end = len ? buf->start + len : buf->end;
+    buf->temporary = 0;
+    buf->memory = 1;
+}
diff -Naur nginx-1.11.3/nginx-push-stream-module/src/ngx_http_push_stream_rbtree_util.c nginx-1.11.3-push/nginx-push-stream-module/src/ngx_http_push_stream_rbtree_util.c
--- nginx-1.11.3/nginx-push-stream-module/src/ngx_http_push_stream_rbtree_util.c	1970-01-01 01:00:00.000000000 +0100
+++ nginx-1.11.3-push/nginx-push-stream-module/src/ngx_http_push_stream_rbtree_util.c	2016-09-06 20:27:15.000000000 +0200
@@ -0,0 +1,217 @@
+/*
+ * This file is distributed under the MIT License.
+ *
+ * Copyright (c) 2009 Leo Ponomarev
+ *
+ * Permission is hereby granted, free of charge, to any person
+ * obtaining a copy of this software and associated documentation
+ * files (the "Software"), to deal in the Software without
+ * restriction, including without limitation the rights to use,
+ * copy, modify, merge, publish, distribute, sublicense, and/or sell
+ * copies of the Software, and to permit persons to whom the
+ * Software is furnished to do so, subject to the following
+ * conditions:
+ *
+ * The above copyright notice and this permission notice shall be
+ * included in all copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
+ * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES
+ * OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
+ * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT
+ * HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,
+ * WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
+ * FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
+ * OTHER DEALINGS IN THE SOFTWARE.
+ *
+ *
+ * ngx_http_push_stream_rbtree_util.c
+ *
+ * Modified: Oct 26, 2010
+ * Modifications by: Wandenberg Peixoto <wandenberg@gmail.com>, Rog√©rio Carvalho Schneider <stockrt@gmail.com>
+ */
+
+#include <ngx_http_push_stream_rbtree_util.h>
+
+static ngx_http_push_stream_channel_t *
+ngx_http_push_stream_find_channel_on_tree(ngx_str_t *id, ngx_log_t *log, ngx_rbtree_t *tree)
+{
+    uint32_t                            hash;
+    ngx_rbtree_node_t                  *node, *sentinel;
+    ngx_int_t                           rc;
+    ngx_http_push_stream_channel_t     *channel = NULL;
+
+    hash = ngx_crc32_short(id->data, id->len);
+
+    node = tree->root;
+    sentinel = tree->sentinel;
+
+    while ((node != NULL) && (node != sentinel)) {
+        if (hash < node->key) {
+            node = node->left;
+            continue;
+        }
+
+        if (hash > node->key) {
+            node = node->right;
+            continue;
+        }
+
+        /* hash == node->key */
+
+        channel = (ngx_http_push_stream_channel_t *) node;
+
+        rc = ngx_memn2cmp(id->data, channel->id.data, id->len, channel->id.len);
+        if (rc == 0) {
+            return channel;
+        }
+
+        node = (rc < 0) ? node->left : node->right;
+    }
+
+    return NULL;
+}
+
+
+static ngx_http_push_stream_channel_t *
+ngx_http_push_stream_find_channel(ngx_str_t *id, ngx_log_t *log, ngx_http_push_stream_main_conf_t *mcf)
+{
+    ngx_http_push_stream_shm_data_t    *data = mcf->shm_data;
+    ngx_http_push_stream_channel_t     *channel = NULL;
+
+    if (id == NULL) {
+        ngx_log_error(NGX_LOG_ERR, log, 0, "push stream module: tried to find a channel with a null id");
+        return NULL;
+    }
+
+    ngx_shmtx_lock(&data->channels_queue_mutex);
+    channel = ngx_http_push_stream_find_channel_on_tree(id, log, &data->tree);
+    ngx_shmtx_unlock(&data->channels_queue_mutex);
+
+    return channel;
+}
+
+
+// find a channel by id. if channel not found, make one, insert it, and return that.
+static ngx_http_push_stream_channel_t *
+ngx_http_push_stream_get_channel(ngx_str_t *id, ngx_log_t *log, ngx_http_push_stream_main_conf_t *mcf)
+{
+    ngx_http_push_stream_shm_data_t       *data = mcf->shm_data;
+    ngx_http_push_stream_channel_t        *channel;
+    ngx_slab_pool_t                       *shpool = mcf->shpool;
+    ngx_flag_t                             is_wildcard_channel = 0;
+
+    if (id == NULL) {
+        ngx_log_error(NGX_LOG_ERR, log, 0, "push stream module: tried to create a channel with a null id");
+        return NULL;
+    }
+
+    ngx_shmtx_lock(&data->channels_queue_mutex);
+
+    // check again to see if any other worker didn't create the channel
+    channel = ngx_http_push_stream_find_channel_on_tree(id, log, &data->tree);
+    if (channel != NULL) { // we found our channel
+        ngx_shmtx_unlock(&data->channels_queue_mutex);
+        return channel;
+    }
+
+    if ((mcf->wildcard_channel_prefix.len > 0) && (ngx_strncmp(id->data, mcf->wildcard_channel_prefix.data, mcf->wildcard_channel_prefix.len) == 0)) {
+        is_wildcard_channel = 1;
+    }
+
+    if (((!is_wildcard_channel) && (mcf->max_number_of_channels != NGX_CONF_UNSET_UINT) && (mcf->max_number_of_channels == data->channels)) ||
+        ((is_wildcard_channel) && (mcf->max_number_of_wildcard_channels != NGX_CONF_UNSET_UINT) && (mcf->max_number_of_wildcard_channels == data->wildcard_channels))) {
+        ngx_shmtx_unlock(&data->channels_queue_mutex);
+        ngx_log_error(NGX_LOG_ERR, log, 0, "push stream module: number of channels were exceeded");
+        return NGX_HTTP_PUSH_STREAM_NUMBER_OF_CHANNELS_EXCEEDED;
+    }
+
+    if ((channel = ngx_slab_alloc(shpool, sizeof(ngx_http_push_stream_channel_t))) == NULL) {
+        ngx_shmtx_unlock(&data->channels_queue_mutex);
+        ngx_log_error(NGX_LOG_ERR, log, 0, "push stream module: unable to allocate memory for new channel");
+        return NULL;
+    }
+
+    if ((channel->id.data = ngx_slab_alloc(shpool, id->len + 1)) == NULL) {
+        ngx_slab_free(shpool, channel);
+        ngx_shmtx_unlock(&data->channels_queue_mutex);
+        ngx_log_error(NGX_LOG_ERR, log, 0, "push stream module: unable to allocate memory for new channel id");
+        return NULL;
+    }
+
+    channel->id.len = id->len;
+    ngx_memcpy(channel->id.data, id->data, channel->id.len);
+    channel->id.data[channel->id.len] = '\0';
+
+    channel->wildcard = is_wildcard_channel;
+    channel->channel_deleted_message = NULL;
+    channel->last_message_id = 0;
+    channel->last_message_time = 0;
+    channel->last_message_tag = 0;
+    channel->stored_messages = 0;
+    channel->subscribers = 0;
+    channel->deleted = 0;
+    channel->for_events = ((mcf->events_channel_id.len > 0) && (channel->id.len == mcf->events_channel_id.len) && (ngx_strncmp(channel->id.data, mcf->events_channel_id.data, mcf->events_channel_id.len) == 0));
+    channel->expires = ngx_time() + mcf->channel_inactivity_time;
+
+    ngx_queue_init(&channel->message_queue);
+    ngx_queue_init(&channel->workers_with_subscribers);
+
+    channel->node.key = ngx_crc32_short(channel->id.data, channel->id.len);
+    ngx_rbtree_insert(&data->tree, &channel->node);
+    ngx_queue_insert_tail(&data->channels_queue, &channel->queue);
+    (channel->wildcard) ? data->wildcard_channels++ : data->channels++;
+
+    channel->mutex = &data->channels_mutex[data->mutex_round_robin++ % 9];
+
+    ngx_shmtx_unlock(&data->channels_queue_mutex);
+
+    ngx_http_push_stream_send_event(mcf, log, channel, &NGX_HTTP_PUSH_STREAM_EVENT_TYPE_CHANNEL_CREATED, NULL);
+
+    return channel;
+}
+
+
+static void
+ngx_rbtree_generic_insert(ngx_rbtree_node_t *temp, ngx_rbtree_node_t *node, ngx_rbtree_node_t *sentinel, int (*compare) (const ngx_rbtree_node_t *left, const ngx_rbtree_node_t *right))
+{
+    ngx_rbtree_node_t       **p;
+
+    for (;;) {
+        if (node->key < temp->key) {
+            p = &temp->left;
+        } else if (node->key > temp->key) {
+            p = &temp->right;
+        } else { /* node->key == temp->key */
+            p = (compare(node, temp) < 0) ? &temp->left : &temp->right;
+        }
+
+        if (*p == sentinel) {
+            break;
+        }
+
+        temp = *p;
+    }
+
+    *p = node;
+    node->parent = temp;
+    node->left = sentinel;
+    node->right = sentinel;
+    ngx_rbt_red(node);
+}
+
+
+static void
+ngx_http_push_stream_rbtree_insert(ngx_rbtree_node_t *temp, ngx_rbtree_node_t *node, ngx_rbtree_node_t *sentinel)
+{
+    ngx_rbtree_generic_insert(temp, node, sentinel, ngx_http_push_stream_compare_rbtree_node);
+}
+
+
+static int
+ngx_http_push_stream_compare_rbtree_node(const ngx_rbtree_node_t *v_left, const ngx_rbtree_node_t *v_right)
+{
+    ngx_http_push_stream_channel_t *left = (ngx_http_push_stream_channel_t *) v_left, *right = (ngx_http_push_stream_channel_t *) v_right;
+
+    return ngx_memn2cmp(left->id.data, right->id.data, left->id.len, right->id.len);
+}
